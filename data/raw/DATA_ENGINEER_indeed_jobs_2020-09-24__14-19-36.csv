job_title,company,company_rating,location,job_text,date
Data Engineer,Vacasa,2.8 out of 5,Oregon,"['100% coverage option', '401K retirement savings plan with up to a 6% company match', 'Vacation time', 'Paid sick leave and holidays', 'Career advancement opportunities', 'Employee discounts', ""Design, implement, and manage Vacasa's BI and analytics platform"", 'Develop data warehousing standards, transformations, and ingress patterns for production data', 'Collaborate with engineering and product teams to ensure BI and reporting goals are met', 'Mentor and train engineering and analytics staff', 'Troubleshoot Redshift performance problems or bottlenecks', '2+ years experience in a data-related field, including data engineering, data warehousing, business intelligence, data visualization, and/or data science', '1-2 years experience using AWS', 'Professional experience using Python to build data pipelines', 'Hands on experience with Airflow or similar data pipeline tools', 'Knowledge of relational database management systems', 'Ability to identify, repair, and troubleshoot data quality issues', 'Ability to write and understand SQL', 'An understanding of Redshift query execution plans, table distribution, and workload management', 'A desire to learn and experiment with new and emerging technologies', 'Health/dental/vision insurance—100% coverage option', '401K retirement savings plan with up to a 6% company match', 'Vacation time', 'Paid sick leave and holidays', 'Career advancement opportunities', 'Employee discounts', ""All the equipment you'll need to be successful"", 'Great colleagues and culture']",2020-09-24 13:25:32
Cloud Data Engineer (Azure),Navy Federal Credit Union,4 out of 5,"Vienna, VA 22180","['Job', 'Company', '$120,000 - $215,000', 'Best-in-Class Benefits!', '7% 401k match / Pension plan / Tuition reimbursement / Great insurance options)', 'FORTUNE 100 Best Companies to Work For®', 'Computerworld® Best Places to Work in IT', 'FORTUNE® Best Workplaces for Millennials', 'Forbes® America’s Best Employers', 'Provide Business Intelligence (BI) and Data Warehousing (DW) solutions and support by leveraging project standards and leading analytics platforms', 'Evaluate and define functional requirements for BI and DW solutions', 'Define and build data integration processes to be used across the organization', 'Build conceptual and logical data models for stakeholders and management', 'Analyze and validate data accuracy of report results', 'Work directly with management understand requirement; and propose and develop best business solution that enables effective decision-making, and drive business objectives', 'Prepares realistic project implementation plans which highlight major milestones and deliverables leveraging standard methods and work planning tools', 'Recognizes potential issues and risks during the analytics project implementation and can suggest realistic mitigation strategies', 'Coaches and mentors project team members in carrying out analytics project implementation activities', 'Leads the preparation of high quality project deliverables that are valued by the business and presents them in such a manner that they are easily understood by project stakeholders', 'Interpreting data presented in models, charts, and tables and transforming it into a format that is useful to the business and aids effective decision making', 'Use of statistical practices to analyze current and historical data to make predictions, identify risks, and opportunities enabling better decisions on planned/future events', 'The ability to understand the business problem and determine what aspects of it require optimization; articulate those aspects in a clear and concise manner', 'The ability to define and analyze models that predict the probability of an outcome', 'Offers improvements to the way in which analytics service the entire function', 'Communicating and owning the process in manipulating and merging large datasets', 'Ability to view and understand other project or functional areas in order to consolidate analytical needs and processes', 'Being a key point of contact between the data analyst/data scientist and the project/functional analytics leads', 'Perform other duties as assigned', ""Bachelor's degree in Information Systems, Computer Science, Engineering, or related field, or the equivalent combination of education, training and experience"", '5 years’ experience working in a cloud computing with Azure experience required', 'Experience with data migration to cloud based environment', 'Extensive 5 years of experience in providing data architecture solutions for Cloud applications', 'Knowledge of and the ability to perform basic statistical analysis such as measures of central tendency, normal distribution, variance, standard deviation, basic tests, correlation, and regression techniques', 'Experienced in the use of standard ETL tools and techniques', 'Experienced in sourcing, maintaining, and updating data', 'Understanding of data warehousing, data cleaning, data pipelines and other analytical techniques required for data usage', 'Demonstrates functional knowledge of data visualization tools such as Microsoft Power BI, Tableau', 'Has working knowledge of various data structures and the ability to manipulate data within visualization tools', 'Ability to manipulate raw data into effective visualization dashboards', 'Ability to communicate end to end data outcomes visually', 'Demonstrates a deep understanding of multiple database concepts', 'Has a working knowledge of various data structures and the ability to extract data from various data sources (such as Cognos, Informatica)', 'Understands the concepts and application of data mapping and building requirements', 'Optimal understanding of SQL', 'Graduate education in Information Systems, Computer Science, Engineering, or related field', 'Knowledge of Navy Federal Credit Union instructions, standards, and procedures']",2020-09-24 13:25:32
Data Engineer - Junior Level,USAA,3.9 out of 5,"Plano, TX 75024","['Identifies and manages existing and emerging risks that stem from business activities and the job role.', 'Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled.', 'Follows written risk and compliance policies and procedures for business activities.', 'Collaborate with senior engineers and assist in the implementation of technical solutions.', 'Design, write, test and deploy data pipeline code.', 'Participate in design and code review sessions.', ""Bachelor's degree in related field of study, OR Certification from an approved technical field of study, OR 4 additional years of related experience beyond the minimum required"", '0 to 2 years of data management experience implementing data solutions or coursework in applicable discipline', '1+ years of data warehouse experience', 'Experience with ETL DataStage', 'Experience with Unix/Linux and shell scripting', 'Database experience (Hadoop, SQL, Oracle, DB2)', 'Knowledge of data visualization (Tableau)', 'Knowledge of data modeling concepts', 'Experience with job scheduling tools such as Control-M', 'Knowledge of working in cloud engineering', 'Curious and excited by new ideas', 'Energized by a fast-paced environment', 'Able to understand and translate business needs into leading-edge technology', 'Comfortable working as part of a connected team, but self-motivated', 'Community-focused, dependable and committee', 'Exceptionally detail-oriented']",2020-09-24 13:25:32
Graduate - Data Engineer,Rio Tinto,3.9 out of 5,"Boron, CA 93596","['A competitive salary package with annual cash incentive awards (STIP) for eligible employees', 'Career development & education assistance to further your ambitions', 'Access to top tier family-friendly health and medical programs', 'Excellent retirement plan including 6% defined company contribution', 'Generous 401k matching program', 'A comprehensive leave policy that covers all moments that matter in life (vacation/annual, paid parental leave, short term sick leave, paid holidays)', 'Ongoing individual wellbeing support for you and your family for personal and professional matter', 'Join one of the largest mining and metal companies in the world, focused on safety and inclusion', 'Work with the newest technology and innovation, in an environment where we challenge you to drive positive change', 'Start your career and be part of our prestigious Graduate Development Program', 'Discovery of new data sources and conducting exploratory analysis based on prioritized business objectives', 'MS SQL DDL, ETL Development, and Data Warehousing', 'Report and dashboard development using Power BI and other applicable platforms', 'Support and development of existing operational data systems, relevant documentation management, and data stewardship', 'Recommending methods and performing various analyses of data, such as descriptive, predictive, or machine learning as appropriate for specific projects', 'Manual file data collection and workflow automation for users', 'End-user training, engagement, and culture transformation support', 'Participation in Rio Tinto Borates big data and digital transformation initiatives, and joining special projects teams', 'A pioneering spirit and alignment to our values of Safety, Teamwork, Respect, Integrity and Excellence', 'Curious mind, a willingness to learn, and make an impact, and challenge the status quo', 'Bachelor or master’s degree in Data Science, Data Analytics, Business Intelligence, Computer Science, Software Engineering or any related field', 'A safety-focused and inclusive working environment', 'A competitive salary package with annual cash incentive awards (STIP) for eligible employees', 'Career development & education assistance to further your ambitions', 'Access to top tier family-friendly health and medical programs', 'Excellent retirement plan including 6% defined company contribution', 'Generous 401k matching program', 'A comprehensive leave policy that covers all moments that matter in life (vacation/annual, paid parental leave, short term sick leave, paid holidays)', 'Ongoing individual wellbeing support for you and your family for personal and professional matter', 'Generous Rio Tinto employee share program', 'Rio Tinto reserves the right to remove job postings prior to the stated closing date, therefore, if you are interested in applying for this vacancy please submit your application as soon as possible']",2020-09-24 13:25:32
Database Engineer (Data Warehouse),American Advisors Group,3.6 out of 5,"Irvine, CA 92612","['Consolidate and optimize available data warehouse infrastructure utilizing SSIS/SSAS/Snowflake', 'Create stored procedures, SSIS packages, and using other methods to import/translate/manipulate data', 'Analyze potential data quality issues to determine the root cause, and creating effective solutions', 'Conceive analytics and business intelligence platform architecture for clients, including internal and third-party clients', 'Design and implement, monitoring, and tuning ETL Processes', 'Collaborate with business and technology stakeholders in ensuring data warehouse architecture development and utilization', 'Perform the design and extension of data marts, meta data, and data models', 'Ensure all data warehouse architecture codes are maintained in a version control system.', 'Design and implement ETL procedures for intake of data from both internal and outside sources; as well as ensure data is verified and quality is checked', 'Perform the design and extension of data marts, meta data, and data models', 'Develop, monitor and maintain data marts across the enterprise, while ensuring high levels of data availability.', 'Develops, maintains and optimizes all efforts related to Data Warehouse (SSIS, Stored Procedures, Views etc.)', 'Identifies and implements optimizations to both performance and accuracy of databases, as required and appropriate.', 'Develops and adheres to standards, processes and procedures to create, deploy and maintain databases.', 'Design, implement, and maintain new and existing database objects including tables, indexes, constraints, stored procedures, and user-defined functions in support of data conversion projects.', 'Data Warehousing and related tools: SSAS, SSIS, Snowflake, SQL Server and Informatica Cloud Integration Services', 'Azure and Cloud Certification is a plus', 'Database Modeling, Tuning, Security, Administration and Management', 'Structured thinker and effective communicator, comfortable interacting with constituents', 'EDUCATION / WORK EXPERIENCE', 'Possess Bachelor’s degree in information technology, Computer science, and engineering discipline', '10+ years or more experience performing data warehouse architecture development and management', 'Remarkable experience with technologies such as SQL Server, Snowflake as well as SSIS and stored procedures', 'Strong Experience with Informatica', 'Exceptional experience developing codes, testing for quality assurance, administering RDBMS, and monitoring of database', 'Strong working knowledge of application and T-SQL code and ability to demonstrate the ability to write functional requirements.', 'High proficiency in dimensional modeling techniques and their applications', 'Extensive hands on experience in data warehousing design, tuning and ETL/ELT process development Solid communication skills – both written and verbal', 'Ability to meet deadlines', 'Excellent communication skills (written and verbal)', 'Client-facing presence and excellent business acumen.', 'Attention to detail and solid organization skills']",2020-09-24 13:25:32
Data Engineer,Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['Job', 'Company', 'Experience with scripting languages like Python.', 'Ability to manage competing priorities simultaneously and drive projects to completion.', ""Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering)."", 'Understanding of Big data technologies and frameworks. Hive, Spark, Hadoop, SQL on Big Data, Redshift', 'Understanding of near real time analytics', 'Understanding of ETL, Data Modeling, and large-scale data processing concepts.', 'Extremely proficient in writing performant SQL working with large data volumes', 'Ability to communicate complex ideas simply, coherently and fluently both in writing and verbally.', 'Ability to manage a large and varied operational workload and stakeholder expectations', 'Experience with large scale data processing, data structure optimization and scalability of algorithms is a plus', 'Real time ingestion pipeline technologies SNS, SQS, Kinesis, etc.']",2020-09-24 13:25:32
Data Engineer,Altimetrik Corp,4 out of 5,United States,"['6+ Years of Industry Work Experience', 'Experience extracting data from a variety of sources, and a desire to expand those skills (working knowledge in SQL and Hive is mandatory)', 'Need to have a good understanding of TeraData and Hadoop SQL with focus on migration from TeraData to Hadoop, hands on experience in Google Cloud Platform', 'Excellent Data Analysis skills. Must be comfortable with querying and analyzing large amount of data on Hadoop HDFS using Hive and Spark.', 'Experience handling Unix systems, for optimal usage to host enterprise web applications.', 'Excellent Communication Skills to Understand and Pass on Requirements.', 'Ability to work on standalone tasks without much guidance']",2020-09-24 13:25:32
Data Engineer - Basepaws (Genetics & Personalized Medicine),Basepaws,N/A,"Los Angeles, CA","['Medical, Vision, and Dental Plan available Salary based on experience and stock options Local, OC or LA-based applicants only', 'From $80,000.00 per year', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Vision insurance', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Vision insurance', 'Monday to Friday', 'Los Angeles, CA (Required)', 'Fully Remote', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'www.basepaws.com', 'https://www.facebook.com/basepaws']",2020-09-24 13:25:32
Data Engineer,Nota Bene Global Services Inc,N/A,"Denver, CO","['Monday to Friday', 'Total IT Industry: 7 years (Preferred)', 'GCP: 1 year (Required)', 'Data Engineer: 5 years (Required)', 'Temporarily due to COVID-19']",2020-09-24 13:25:32
Data Engineer,"Excygent, LLC",N/A,"Reston, VA 20190","['Up to $200,000.00 per year', 'Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'Develop data pipelines for ingesting structured and unstructured data into a centralized data repository for storage and analysis.', 'Design entity relationship diagrams for different types of data.', 'Contribute to the on-going design and development of the data repository architecture as new datasets are incorporated.', '2+ years of relevant experience', 'Strong programming skills in one or more programming languages (e.g. Python, Golang).', 'Strong scripting skills (e.g. Bash).', 'Experience developing data pipelines.', 'Experience designing Entity Relationship (ER) diagrams.', 'Experience working with a variety of databases (e.g. SQL, Elasticsearch, Neo4j).', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', ""Bachelor's (Preferred)"", 'United States (Required)', 'Multiple locations', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.excygent.com', 'Only full-time employees eligible', 'No']",2020-09-24 13:25:32
Associate Curriculum Engineer for Data Science & Analytics,HackerU,4.8 out of 5,Florida,"['Will write and create the Data Analytics curriculum used to teach in the program', 'Will utilize known Data Analytics skills and methods to promote best practices and develop concise lesson plans', 'Will work within our team as a subject matter expert to develop technical and non-technical content', 'Will have to stay up to date and knowledgeable of emerging technologies and required educational methodsOpportunity to work as a teachers assistant at one of our partnered universities', 'Must have 3 years of hands-on Data Analytics experience', 'Must have 1 year of experience in education', 'Must have excellent writing capabilities to clearly and concisely communicate engaging instructions', 'Bachelor degree in Information Systems Computer Science engineering or other technical areas which provide analysis and programming or equivalent experience', 'Experience developing exercises or lessons']",2020-09-24 13:25:32
Data Engineer,Airvet,N/A,"Los Angeles, CA","['$80,000.00 - $110,000.00 per year', 'Benefits:', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', '3+ years experience with Python', 'Must be very proficient with SQL', 'Must have experience with Airflow', 'Must have experience with Looker / LookML', 'AWS knowledge of EC2 & Redshift', 'Stripe experience', 'Salesforce experience', 'Quickbooks experience', 'Amplitude analytics experience or similar', 'Design, build, and maintain ETL pipelines', 'Work with stakeholders to define end-to-end analytics', 'You have an insatiable need to learn & use new languages and tools.', ""It's not your first rodeo. You thrive in a fast-paced environment with changing priorities."", ""You understand the customer and the business. You know who you are building for, and the benefits you're providing the end user."", 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'Fully Remote', 'No: Not providing sponsorship for this job', 'https://airvet.com', 'Only full-time employees eligible']",2020-09-24 13:25:32
Remote - Data Engineer - BI ETL Azure Data Factory PySpark,"Malani Consulting and Omni Sourcing, Inc.",N/A,"Long Island, NY","['Pay:', '$68.00 - $85.00 per hour', 'At least an undergrad in Computer Science or related field', '4+ years of experience focused in business analytics', 'Experience in Azure Cloud technologies e.g. Azure Cortana, Azure Data Factory, Azure Function, Azure SQL DW, Spark, Scala, Databricks, Azure Analysis Service (AAS)', 'Must have experience in PySpark', 'Experience designing, developing, and implementing data platforms using Azure Cloud architecture with structured data sources', 'Monday to Friday', 'Possible', 'Fully Remote', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'www.malani.co']",2020-09-24 13:25:32
Data Engineer I,xentity corporation,4.2 out of 5,"Denver, CO","['Job', 'Company', 'Competitive Salary.', 'Multiple Recognition and Rewards Bonus Programs (Performance plan reviewed twice annually - total ranging from 2-5% of salary and Business Development Bonus Plan, Employee Referral Bonus Plan, and Company Profit Sharing Plan).', 'Paid Time off - (10) Paid Holidays, (10) Personal Time Off, and (5) Sick Leave', 'Medical Insurance - Coverage for Major Medical and Surgical, Medical Health Care, Dependents’ Health Care.', 'Options to enroll in Dental Insurance, Vision Discount Program, Prescription Discount Program, Group Term Life Insurance, Accidental Death & Dismemberment Insurance, and Professional insurance advisors to guide employees through these benefits as needed.', 'Solid, managed retirement savings plan including - Multiple 401(k) funds with traditional and Roth options, Company paid fees, Company Match, Third-party Trust Management with personalized retirement portfolio web analysis tools.', 'Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Python for data management, Pandas, Requests, Data Cleaning, Understanding of Metadata and ETL/Data Pipelines', 'Advanced experience using Excel and Google sheets to store, analyze, and visualize data', 'We prefer more data processing experience in data feeds and data scripts over management of information systems.', 'Demonstration of handling, manipulating data, records, feeds', 'General knowledge familiarity of use patterns in services, analytics, applications, dashboards and other use by data scientists', 'Data : Open and Public Data Experience, REST APIs for Data Services, data dashboards and visualizations, NLP', 'Programming Languages: Python, NodeJS', 'Database Technology: PostgreSQL, MS SSQL Server', 'Cloud Experience: AWS ECS, EC2, S3 hands-on experience, Kubernetes, Docker', 'Tools and Software: Power BI, Tableau, similar, GIT, JIRA, Trello, Excel, Google Sheets', 'Plus to Have: GIS -Foundation in GIS Principles and experience working with and manipulating GIS data', 'Bachelor’s Degree min. Education and 1 years min. experience', 'Must be able to pass basic NACI, background, drug and reference checks', 'Must be local to Denver, CO area.:  No Relocation Assistance.', 'Ability to thrive in an energetic, fast-paced environment - learn and become productive quickly and meet team goals, can-do attitude, able to do what it takes to deliver.', 'Ability to work multiple, time-sensitive tasks - Able to rapidly context switch across subject matter, communication and architecture products, and stakeholder audiences.', 'Ability to work independently as well as as part of an integrated team.', 'Excellent oral and written communication skills.', 'Demonstrate strong analytical and critical thinking skills.', 'Maintain a Public Data Catalog. Manage an ETL environment to maintain over 300 active dataset updates to a centralized portal, setup new ETL scripts for incoming datasets ~35/year, and manage associated documentation spreadsheets.', 'Assist State Agencies in Making Their Data Public. Work with a wide variety of State Agencies to provide them with the technical support required to keep datasets current on the centralized portal. Publish new datasets (as derived from any given tech stack) to a centralized portal and make them discoverable', 'Cultivate Dataset Back Stories. Curate metadata that conveys context to End Users of Public Data.', 'Data Storytelling, Dashboards, Data Visualizations. Create Public Data stories and demonstrations that show the value of Public Data. Generate content for users to better understand and utilize Public Data.', 'Public and Open Data Evangelism. Explore ways to build content on the benefits of Public Data to communities, and specifically the impact and status of the current state of Public Data in Colorado.', 'Technical Writing. Make updates to process documentation as new technologies are utilized and workflows are improved.', 'Data and Metadata QA/QC Analysis. Ensure that internally managed datasets are of high quality and have associated high quality metadata.', 'GIS Analysis and Tech. Geospatial knowledge required for some data transform work.', 'We emphasize a balance of work and life and target 40-50 hour weeks with ample time to refresh with great paid-time off.', 'Salary & Bonus Programs : - Competitive Salary. Multiple Recognition and Rewards Bonus Programs (Performance Bonus:  plan reviewed twice annually - total ranging from 2-5% of salary and Business Development Bonus Plan, Employee Referral Bonus Plan, and Company Profit Sharing Plan).', 'Paid Time off - (10) Paid Holidays, (10) Personal Time Off, and (5) Sick Leave', 'Medical Insurance - Coverage for Major Medical and Surgical, Medical Health Care, Dependents’ Health Care. Options to enroll in Dental Insurance, Vision Discount Program, Prescription Discount Program, Group Term Life Insurance, Accidental Death & Dismemberment Insurance, and Professional insurance advisors to guide employees through these benefits as needed.', '-Solid, managed retirement savings plan including - Multiple 401(k) funds with traditional and Roth options, Company paid fees, Company Match, Third-party Trust Management with personalized retirement portfolio web analysis tools.', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'Denver, CO (Required)', 'One location', 'xentity.com', 'Temporarily due to COVID-19']",2020-09-24 13:25:32
Data Engineer,Vertava Health,N/A,"Nashville, TN 37203","['401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Vision insurance', 'Collaborating directly with business and technology departments to define future-state business capabilities & requirements, and translating those into transitional and target state data architectures', 'Analyzing the current technology environment to detect critical deficiencies, and recommend solutions for improvement', 'Designing, implementing, and maintaining data warehouses and near real-time data pipelines via the practical application of existing and new data engineering techniques', 'Developing continuous integration and continuous deployment pipelines for data solutions that include automated unit & integration testing', 'Mentoring, motivating, and supporting the team to achieve organizational objectives and goals', 'Advocating for agile practices to increase delivery throughput', 'Ensuring consistency with published development, coding and testing standards', 'Bachelor degree in Computer Science, Mathematics, or related fields', '4+ years of data engineering, schema design, dimensional data modeling, and / or data management experience', 'MDM (Master Data Management) Experience a plus, such as Master Data Services or equivalent technology', 'Proficient with data management tools and languages[3] , such as Python, SQL, Java, and use of Git', 'Demonstrated experience with extracting, cleaning, managing, optimizing, and exploiting large and very complex data sets', 'Experience with best practices for compute, storage, and transfer optimization in processing large volumes of data', 'Can perform data discovery', 'Experience with salesforce.com reporting and integration projects', 'Experience building in Microsoft BI Toolsets (SSRS/SSAS/SSIS/Power BI[4] )', 'Experience on data warehouse / data lake projects', 'Experience with Azure preferred (Azure Data Factory, Azure Analysis Services)', 'Ability to sit, use hands and fingers, talk and hear continually. Ability to stand, walk and reach continually. Ability to climb or balance, stoop, kneel, or crouch frequently.', 'Ability to frequently lift and carry up to 20 lbs.', 'Close vision required to see computer monitor, read documents, and operate copy and fax machine.', 'Work environment is indoors and climate controlled. Occasionally exposed to outdoor weather conditions.', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Vision insurance']",2020-09-24 13:25:32
Big Data Engineer,Coalition Inc.,N/A,"San Francisco, CA","['Health, dental, and vision benefits for you and your family', 'Life insurance and disability benefits', 'Paid Parental Leave', '401(k) plan', 'Wellness and commuter benefits', '$116,673.00 - $147,000.00 per year', 'Benefits:', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Implement risk models for various insurance products', 'Evaluate, recommend, and implement data pipelines for a variety of data sources used at Coalition', 'Deliver production-quality software implementations for ETL and streaming pipelines', 'Explore new data sources and develop insights into existing data sources that improve business efficiency', '3+ years working with large disparate data sets', 'Deep understanding of ETL pipelines, statistical modeling, data analytics, and large scale data streaming', 'Expert-level knowledge of SQL, Python, R, or similar language used for data engineering', 'A proven track record of successfully automating business value from data insights', 'Experience with at least one big data search tool, such as Elastic', 'Excellent oral and written communications skills at all levels', 'Bachelor’s degree in Computer Science or a related field preferred', 'Prior experience with insurance or network security technologies', 'In-depth knowledge of AWS or other cloud-hosted platforms relevant to data engineering', 'Experience with data visualization technologies', 'Enjoy a highly fulfilling, mission-driven culture', 'Health, dental, and vision benefits for you and your family', 'Life insurance and disability benefits', 'Paid Parental Leave', '401(k) plan', 'Wellness and commuter benefits', 'Flexible working hours', 'Open vacation days', 'We embrace distributed work; some benefits will vary by location', 'You are an owner! We offer stock options to each of our employees', 'More details at https://www.coalitioninc.com/careers', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Monday to Friday', 'www.coalition.com', 'Only full-time employees eligible']",2020-09-24 13:26:14
Azure Data Engineer,7Kingscode,N/A,"Miami, FL","['Pay:', '$38.00 - $55.00 per hour', 'Work as part of a team to develop Azure Cloud Applications, work with Big Data Cloud Data and Analytics solutions', 'Participate in development of cloud SQL data warehouses, data as a service, business intelligence solutions', 'Complex Py-spark Coding', 'Creation of Pipelines', 'Transforming data to a more gradual level', 'Data wrangling of heterogeneous data', 'Ability to provide solutions that are forward-thinking in data and analytics', 'Work Eastern Standard Time Hours', 'Delivery a quality product', 'Monday to Friday', 'Likely', 'Fully Remote']",2020-09-24 13:26:14
Staff—Data Privacy and Security Engineer,Delphix,3.2 out of 5,United States,"['Architect, design and implement large components of the product', 'Lead a team of engineers to deliver complex projects by defining structure in areas of uncertainty, identifying and expressing discrete deliverables, and managing interactions between different teams', 'Find opportunities to integrate data security and data delivery that unlock unique value for our platform', 'Think broadly about the Delphix product by working with engineering teams, product management, sales, and customers to understand requirements and develop solutions', 'Aid the development of teammates and enable others through mentorship and guidance', '5-10 years of experience building and architecting enterprise applications deployed on-prem and/or in the cloud', 'Excellent analytical and problem-solving skills', 'Ability and desire to work in a fast-paced, test-driven, agile, collaborative, and iterative programming environment', 'Ability to think clearly and articulate your vision with the appropriate technical depth', 'A desire to build great products, learn new technical areas, and dive in wherever there is a need', 'Experience architecting and implementing enterprise Java applications', 'Experience designing and implementing software for Data Security, Cryptography, Data Loss Prevention (DLP), or other security tools', 'Experience designing, developing, testing, and maintaining ETL processes, Informatica, DataStage, Ab Initio, or custom ETL implementations', 'Experience with large/complex relational databases, data warehouses (Oracle, SQL Server, DB2, Azure, Amazon RDS, Teradata, etc.) and other business data formats (XML, ASC X12, etc.)', 'Open to remote applicants from the Americas. The team is mostly located around Boston, Massachusetts, with some team members in separate remote locations.']",2020-09-24 13:26:14
Data Engineer,Infolob Solutions Inc,3.5 out of 5,"Tarentum, PA 15084","['Pay:', '$34.00 - $42.00 per hour', '8 hour shift', 'Temporarily due to COVID-19']",2020-09-24 13:26:14
Data Analytics Engineer,Quadrant Resource LLC,N/A,"Redmond, WA 98052","['Pay:', '$65.00 - $70.00 per hour', 'Monday to Friday', 'DAX: 1 year (Preferred)', 'SSAS: 1 year (Preferred)', 'Tabular Model: 1 year (Preferred)', 'More than 1 year']",2020-09-24 13:26:14
Sr. Data Engineer,Iconic Technology Group,N/A,"San Francisco, CA","['Extensive experience with Cloud, Dataware ETL, Data Visualization and reporting', 'Hands-on batch and bean airflow, spark and high', 'Experience in Google Cloud data products, IOT Architecture, and Realtime data-streaming', 'Must know Python, Scala, SQL DB', 'Capacity Planning and customer-facing in some cases', 'Also, must have experience in Machine Learning', 'Google Platform Certification or any google certification']",2020-09-24 13:26:14
DATA ENGINEER APPRENTICE,Digital Creative Institute,5 out of 5,"Job, WV","['Associate degree or equivalent', 'Adventurers needed. You’ll have the opportunity to be placed in one of our partner company’s offices in Dallas, Charlotte, Seattle, Atlanta, or Chicago.', 'Strong computer skills, including experience with programming languages (Python, Java, SQL, R, etc.)', 'Experience with Microsoft Office tools, especially creating/ maintaining Excel spreadsheets', 'High level of attention to detail and problem-solving ability', 'Ability to accurately sort and analyze data', 'Ability to communicate ideas both verbally and in writing', 'Must be willing to learn additional data engineering and analytics toolsets', 'Architect, design and detail processes', 'Troubleshoot issues, document process, review checklists, and develop a reference implementation', 'Develop and implement databases, data collection systems, data analytics and other strategies that optimize efficiency and quality', 'Acquire data from primary or secondary data sources and maintain databases/data systems', 'Support technical team deployment with activities to ensure a smooth go-live of new processes, products, or systems', 'Understand the existing system and processes to document', 'Reverse knowledge transfer to document the process of support and maintenance']",2020-09-24 13:26:14
Data Engineer,"Meridian Technologies, Inc.",3 out of 5,"Peoria, IL","['Pay:', '$65.00 - $70.00 per hour', 'Benefits:', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Monday to Friday', 'Data Governance: 6 years (Preferred)', '1 year', 'No: Not providing sponsorship for this job']",2020-09-24 13:26:14
Data Scientist/Data Engineer,SEKAI,N/A,Remote,"['Competitive salary.', '20 days vacation.', 'Work on web based data driven tools.', 'Help scale a fast-growing and unique system.', 'Prototype new features and algorithms,', 'Monitor and improve data processing for SEKAI and our customers.', 'Refactor a algorithms in Python or Scala.', 'Working with GIS data and map based visualizations,', 'Developing applications based on GraphQL API.', 'Plan and build product features - directly impact how our customers can be more productive.', 'Improve our developer platform - directly impact the way developers integrate SEKAI into their IT environments.', 'Experiment: this is a startup so engineering innovations can change.', 'Competitive salary.', '20 days vacation.', 'Work with a loving team that treats everyone as family.']",2020-09-24 13:26:14
Azure Data Engineer,Riya Software Consulting,N/A,"Alpharetta, GA 30009","['Pay:', '$31.00 - $60.00 per hour', 'Experience of building data ETL pipelines, using Azure Datafactory, Azure Analytics', 'Experience of BI reporting, such as building power BI report, building OLAP solution etc', 'Very good in SQL, SQL DW', 'Experience in Azure Data Factory and ADLS', 'Strong ability to troubleshoot and resolve data issues.', 'Experience in Azure Databricks', 'Excellent Communication', 'Monday to Friday', 'Azure: 5 years (Preferred)', 'Temporarily due to COVID-19']",2020-09-24 13:26:14
Data Engineer Intern,Equifax,3.6 out of 5,"St. Louis, MO 63146","['Understand how to make data visually appealing and simple to both navigate and comprehend for end-users', 'Aggregate data from various sources to construct streamlined data pipelines and integrate data from multiple Equifax Inc systems', 'Identify key metrics and build exec-facing dashboards to track progress of the business and its highest priority initiatives', 'Identify key business levers, establish cause & effect, perform analyses, and communicate key findings to various stakeholders', 'Work closely across the matrix with teams like Finance, Marketing, Product, Engineering and technology leaders', 'Lead and participate in special projects/initiatives: innovate and implement large-scale quality improvements to processes and/or systems by conducting data analysis and making recommendations, troubleshooting technical issues, and refining processes around customer support', 'Must be earning a Bachelor’s or Master’s degree in Computer Science, Math, Statistics or related field', 'Experience with one or multiple of the following will be highly desirable; Python, Java, Tableau, Jupyter Notebooks, BigQuery, Hadoop/Hive, Oracle, JavaScript, SQL, Airflow, Linux, Perl, PHP', 'Experience with applying statistics and data science to real-world problems', 'Excellent understanding of computer science fundamentals, data structures, and algorithms', 'Demonstrated experience, familiarity and ease with handling large data sets and crunching numbers', 'Information Retrieval (search/recommendation/classification) experience or Human Judgment/User Interface experience', 'Strong written and verbal communication skills with the ability to translate complex problems into simpler terms, and effectively influence both peers and senior leadership']",2020-09-24 13:26:14
Data Engineer,Applied Information Sciences,4.2 out of 5,"Chevy Chase, MD","['Work in a team using cutting edge technologies to solve challenging business problems and build solutions', 'Interact directly with our client(s) to understand their needs and meet, or exceed their expectations by meeting delivery deadlines', 'Work in an agile environment with participation in daily stand-ups/scrum', 'Design, write, test, troubleshoot, and document data transformations', 'Learn new technologies and be aware of industry standards, best practices, and trends.', '3+ years of experience working with Scala', 'Hands on Programming experience in Scala with Spark for ETL', 'Advanced SQL skills', 'Possess Hive skills with HiveQL.', 'Experience in designing efficient and robust ETL/ELT workflows, schedulers using Oozie, and event-based triggers', 'Big Data Experience - Experience with Ab Initio, MDM, Microstrategy, Cassandra, Hadoop, Spring Cloud', 'Data Operations and Security - experience with tools like Collibra, able to establish data standards and policies', 'Proven ability to work with clients to understand requirements and envision data ingestion solutions', 'Experience with the Azure storage technologies (Azure Data Lake, Azure SQL Data Warehouse, Azure SQL Database)', 'Knowledge of Azure data movement and transformation capabilities (Azure Data Factory, Data Lake Analytics, Data Bricks, Stream Analytics)', 'Knowledge of Talend ETL', 'Microsoft related certifications such as the MCSD/MCSE', 'Smart people with a passion for technology', 'Strong technical capabilities with a consultancy mindset', 'Close involvement with local technical communities', 'A willingness to think outside of the box to provide innovative solutions to clients', 'Ability to solve challenging technical business problems', 'Self-directed professionals', 'Client Success', 'Continued Learning and Technical Excellence', 'Strong Client Relationships', 'Citizenship and Community']",2020-09-24 13:26:14
DCYF PDG Data Engineer - Olympia,"State of Washington Dept of Children, Youth, and Families",3.4 out of 5,"Olympia, WA","['Securely source data from numerous internal and external sources.', 'Design effective data models for optimal storage and retrieval.', 'Implement data collection, processing, and storage processes using SQL and other programming languages.', 'Deploy data quality checks throughout the data lifecycle.', 'Maintain a data dictionary/documentation to enable others to use the data effectively.', 'Provide continuous optimization of data pipeline processing stages as the usage of the platform evolves.', 'Monitor health of the data platform to proactively identify issues/failures.', 'Develop automated deployment processes to release updates and fixes.', 'Ensure changes to external interfaces and data sources do not disrupt the availability of data and reliability of the platform.', 'Develop the core platform to support the ability to pull and extract data in an ad-hoc manner.', 'Work with requestors or other subject matter experts to clarify and refine requests.', 'Evaluate requests and identify relevant source of data and systems.', 'Translate the internal data model into a format and model that is appropriate for requests.', 'Acquire information regarding the data source systems and integrated data platform from a business and technical perspective.', 'Serve as the primary resources for OIAA staff to develop products using this data.', 'A Bachelor’s degree in computer science, management, information systems, or a related field.', 'Five years of information technology or software engineering experience analyzing, designing, programming, or maintaining computer systems, applications, or databases.', 'Three years of experience with information systems, data modeling, relational database design, and knowledge of how to access information for analytical purposes.', 'Three years of experience with Python, Java, Scala, or similar high-level programming language.', 'Knowledge of data structures and software architecture.', 'Experience with non-relational databases and big data engineering tools and architectures.', 'Experience with cloud computing, specifically Microsoft Azure PaaS and SaaS services for data engineering and analysis.', 'Skills in verbal and written communication, and the ability to communicate from a technical and business perspective.', 'Ability to work in a team environment.', 'Experience with Washington State early learning programs and data systems.', 'Letter of interest describing how you meet the specific qualifications for this position', 'Current resume detailing experience and education', 'Read the job posting very carefully. Find out as much as you can about the position.', 'Make sure you are very diligent in following all the application instructions. Include all requested documentation.', 'Make sure your application and supplemental question responses address how you meet each of the required and desired qualifications.', ""Carefully read each of the supplemental questions and respond completely to each one. Pay careful attention to each component of the question, providing examples, and thoroughly describing when and where you achieved the proficiency level, and detail the types of work you performed, the work products, etc., to demonstrate 'how'."", 'Specifically include all of your work experiences doing the same or similar work, especially if you reference work in these jobs in describing when/where you gained proficiency level skills.', 'Make sure your application reflects your best writing.']",2020-09-24 13:26:14
"BI Developer, Data Engineer",Microsoft,4.2 out of 5,"Redmond, WA","['Creating reports and dashboards that make complex data readily consumable', 'Creating data pipelines that automate the flow and transformation of data between key systems', 'Debugging and optimizing performance of queries, reports, dashboards, and data pipelines', 'Designing, building, running, and analyzing A/B tests, customer segments, and personalized experiences', 'Analyzing web traffic and usage data to identify trends and hypothesis for experimentationand personalization projects', 'Using real-time web analytics for monitoring results and optimizing testing outcomes', 'Advising and educating internal customers on experimentationand personalization best practices', 'Managing expectations appropriately and keep projects on schedule and within scope', '3+ years of experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets', '3+ years of experience in SQL', '3+ years of experience with web optimization & analytics solutions includingPower BI, Excel, Adobe Analytics, Adobe Audience Manager, Adobe Target, Tableau, Google Analytics, etc.', 'Solid understanding of online controlled experiments, A/B/n tests, multivariate tests, randomization, sample size, confidence levels, p-value, statistical significance, etc.', 'Experience using Azure Data Explorer and the Kusto Query Language', 'Experience working with web analytics data from a variety of analytics services', 'Experience using Git/GitHub and working with an agile methodology', 'Strong problem-solving and analytical skills', 'Excellent English written and verbal communication/presentation skills through all levels of the organization, technical and non-technical', 'Accountable for and capable of working on multiple concurrent projects and meeting deadlines']",2020-09-24 13:26:14
Data Engineer / Spark Scala,Brevco Services,N/A,"Atlanta, GA","['Monday to Friday', 'Spark Scala: 5 years (Required)', 'More than 1 year', 'Temporarily due to COVID-19']",2020-09-24 13:26:14
DCYF PDG Data Engineer - Olympia,"State of Washington Dept of Children, Youth, and Families",3.4 out of 5,"Olympia, WA","['Securely source data from numerous internal and external sources.', 'Design effective data models for optimal storage and retrieval.', 'Implement data collection, processing, and storage processes using SQL and other programming languages.', 'Deploy data quality checks throughout the data lifecycle.', 'Maintain a data dictionary/documentation to enable others to use the data effectively.', 'Provide continuous optimization of data pipeline processing stages as the usage of the platform evolves.', 'Monitor health of the data platform to proactively identify issues/failures.', 'Develop automated deployment processes to release updates and fixes.', 'Ensure changes to external interfaces and data sources do not disrupt the availability of data and reliability of the platform.', 'Develop the core platform to support the ability to pull and extract data in an ad-hoc manner.', 'Work with requestors or other subject matter experts to clarify and refine requests.', 'Evaluate requests and identify relevant source of data and systems.', 'Translate the internal data model into a format and model that is appropriate for requests.', 'Acquire information regarding the data source systems and integrated data platform from a business and technical perspective.', 'Serve as the primary resources for OIAA staff to develop products using this data.', 'A Bachelor’s degree in computer science, management, information systems, or a related field.', 'Five years of information technology or software engineering experience analyzing, designing, programming, or maintaining computer systems, applications, or databases.', 'Three years of experience with information systems, data modeling, relational database design, and knowledge of how to access information for analytical purposes.', 'Three years of experience with Python, Java, Scala, or similar high-level programming language.', 'Knowledge of data structures and software architecture.', 'Experience with non-relational databases and big data engineering tools and architectures.', 'Experience with cloud computing, specifically Microsoft Azure PaaS and SaaS services for data engineering and analysis.', 'Skills in verbal and written communication, and the ability to communicate from a technical and business perspective.', 'Ability to work in a team environment.', 'Experience with Washington State early learning programs and data systems.', 'Letter of interest describing how you meet the specific qualifications for this position', 'Current resume detailing experience and education', 'Read the job posting very carefully. Find out as much as you can about the position.', 'Make sure you are very diligent in following all the application instructions. Include all requested documentation.', 'Make sure your application and supplemental question responses address how you meet each of the required and desired qualifications.', ""Carefully read each of the supplemental questions and respond completely to each one. Pay careful attention to each component of the question, providing examples, and thoroughly describing when and where you achieved the proficiency level, and detail the types of work you performed, the work products, etc., to demonstrate 'how'."", 'Specifically include all of your work experiences doing the same or similar work, especially if you reference work in these jobs in describing when/where you gained proficiency level skills.', 'Make sure your application reflects your best writing.']",2020-09-24 13:26:53
Jr. Mechanical Engineer-Data Administrator,Acuren Inspection Inc,3.4 out of 5,"Leander, TX","['Data entry and administrative tasks as needed', 'Accurate data entry of inspection field reports', 'Recognize, identify and investigate data issues', 'Adheres to quality standards and ensures accuracy of work', 'Participates in Team Meetings and keeps connected to organization’s annual goals and objectives', 'Works within time budget allocations for projects', 'Ensures completion dates are met in conjunction with other team members with customer satisfaction in mind', 'Accountable for project deliverables on time where it applies to data processing and data management', 'Participate in planning and scheduling meetings with Inspection team', 'Develop and maintain relationships with internal and external clients', 'Communicate to all in a professional, effective and courteous manner', 'Various administrative support tasks as needed', '4-year, 2-year or Technical Degree in Mechanical Engineering Required', '1+ years of data entry experience in an office setting', 'Knowledge of MS Office computer programs (Word, Excel, Outlook)', 'Excellent communication skills (written / verbal) and command of the English language (oral, written and comprehension)', 'High level of accuracy and attention to detail', 'Strong administrative, organizational and planning skills', 'Ability to perform repetitive tasks', 'Ability to work with limited supervision and have an appreciation of deadlines', 'Strong written and oral communication skills', 'Must work effectively as a team player', 'Excellent listening skills and ability to ask questions and make decisions', 'Demonstrates the ability to recognize, investigate and identify issues', 'Works cooperatively with others to achieve work goals', 'Respects and values diversity in the workplace', 'Desire to learn and acquire additional skills through internal and external courses.']",2020-09-24 13:26:53
"BI Developer, Data Engineer",Microsoft,4.2 out of 5,"Redmond, WA","['Creating reports and dashboards that make complex data readily consumable', 'Creating data pipelines that automate the flow and transformation of data between key systems', 'Debugging and optimizing performance of queries, reports, dashboards, and data pipelines', 'Designing, building, running, and analyzing A/B tests, customer segments, and personalized experiences', 'Analyzing web traffic and usage data to identify trends and hypothesis for experimentationand personalization projects', 'Using real-time web analytics for monitoring results and optimizing testing outcomes', 'Advising and educating internal customers on experimentationand personalization best practices', 'Managing expectations appropriately and keep projects on schedule and within scope', '3+ years of experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets', '3+ years of experience in SQL', '3+ years of experience with web optimization & analytics solutions includingPower BI, Excel, Adobe Analytics, Adobe Audience Manager, Adobe Target, Tableau, Google Analytics, etc.', 'Solid understanding of online controlled experiments, A/B/n tests, multivariate tests, randomization, sample size, confidence levels, p-value, statistical significance, etc.', 'Experience using Azure Data Explorer and the Kusto Query Language', 'Experience working with web analytics data from a variety of analytics services', 'Experience using Git/GitHub and working with an agile methodology', 'Strong problem-solving and analytical skills', 'Excellent English written and verbal communication/presentation skills through all levels of the organization, technical and non-technical', 'Accountable for and capable of working on multiple concurrent projects and meeting deadlines']",2020-09-24 13:26:53
Data Engineer / Spark Scala,Brevco Services,N/A,"Atlanta, GA","['Monday to Friday', 'Spark Scala: 5 years (Required)', 'More than 1 year', 'Temporarily due to COVID-19']",2020-09-24 13:26:53
ETL Data Engineer (100% Remote Contract to Perm job - No C2C Inquiry Plz),"Samay Consulting, Inc",N/A,"Portland, OR",['Yes'],2020-09-24 13:26:53
Data Pipeline Engineer,TMP Worldwide,3.6 out of 5,United States,"['TMP Programmatic works on data services across the programmatic platform within TMP, and supports building customer facing data visualization products', 'The team has extensive experience in ETL development and works with large scale data in real time']",2020-09-24 13:26:53
Senior Data Engineer - 12 months – SFO,DataSys America,N/A,"San Francisco, CA","['Pay:', '$117,420.00 - $133,000.00 per year', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'Stable -- traditional, stable, strong processes', 'Waiting period may apply', 'Temporarily due to COVID-19']",2020-09-24 13:26:53
"$60/hr-Data Engineer (SSIS, SSAS, AZURE SQL, Some Power BI ), Seattle, WA",BLOCKnit Technologies Ltd,N/A,"Seattle, WA","['Pay:', '$101,445.00 - $178,828.00 per year', 'Strong working experience in SQL Server, Azure SQL,SSIS & SSAS.', 'Strong working experience in Microsoft Tabular & multi-dimensional.', 'Very strong in DW', 'Experience in one of ADF/ADL/ ADW is must with good knowledge of other Azure BI technologies', 'Strong analytical thinking and problem solving skills, Team Player', 'Power BI: Moderate knowledge', '8 Hour Shift', '1 year', 'More than 1 year']",2020-09-24 13:26:53
Data Engineer,Digital Dhara,N/A,Remote,"['big data: 10 years (Required)', 'medical claims data : 5 years (Required)', 'ETL: 10 years (Required)', 'Redshift, Snowflake, Spark, Python, R, Databricks: 5 years (Preferred)']",2020-09-24 13:26:53
Data Migration Engineer,IRESS Limited,N/A,"Warwick, RI","['Global opportunities', 'Health Benefits including Private Medical Insurance', 'Iress Community', '3 days’ leave per year for charity initiatives', '25 days holiday plus Bank Holidays', 'Owning the end to end process of a migration, including the migration setup, execution and post migration analysis', 'Developing, testing and maintaining migration tools for single use or re-use', 'Running migrations for a variety of 3rd party systems as per the agreed specifications of the clients request', 'Executing Data Repair and deletion requests for existing clients', 'Operating within server environments to execute migrations and ensure the required infrastructure is in place to implement migrations successfully', 'Proactively identifying and addressing issues that have the potential to impact a migration, as well as identifying reasons for migration failures and following correct procedures to resume/rerun migrations or raise development items', 'Working with a variety of teams across Iress in particular Data Analysts, Project Managers and product teams to make sure Data Migration deliveries are in line with the overall project plan', 'Competitive remuneration', 'Global opportunities', 'Casual dress, flexible work policy', 'Access to learning and development programs', 'Health Benefits including Private Medical Insurance', 'Iress Community', '3 days’ leave per year for charity initiatives', 'Global 36-hour hackathon', 'Cycle to Work scheme', '25 days holiday plus Bank Holidays', 'Profit Share Plan', 'Up to 26 weeks’ paid parental leave for primary carers (up to 4 weeks for secondary carers), and the ability to work part-time when returning to work']",2020-09-24 13:26:53
"Engineer, Data & Analytics",Comcast,3.7 out of 5,"Philadelphia, PA 19103","['Utilizes resources, SQL optimization skills, quality assurance, and troubleshooting skills to find and solve moderate to major development problems in SQL Server, OBIEE, and Tableau. Able to troubleshoot, perform root cause analysis, and determine/recommend short and long term solutions to management.', 'Supports the established deployment process, including completing code reviews in GitHub.', 'Perform engineering tasks such as database design, data manipulation, ETL, implementation, information storage and retrieval, data flow and analysis.', 'Preemptively recognize and resolve technical issues utilizing knowledge of policies and processes.', 'Identifies and reacts to system notification and log to ensure quality standards for databases and applications. Solve abstract problems beyond single development language or situation by reusing data file and flags already set.', 'Solves critical issues and shares knowledge such as trends, aggregate, quantity volume regarding specific data sources.', 'Participate in the implementation of solutions via data architecture, data engineering, or data manipulation within big data systems like Hadoop and SQL.', 'Acts as a liaison between business owners and technical associates to ensure the data collected and processed is both actionable and relevant to the end goals.', 'Determines appropriateness of data for storage and optimum storage organization. Determines how tables relate to each other and how fields interact within the tables to develop relational models.', 'Collaborates with technology and platform management partners to optimize data sourcing and processing rules to ensure appropriate data quality.', 'Consistent exercise of independent judgment and discretion in matters of significance.', 'Regular, consistent and punctual attendance. Must be able to work nights and weekends, variable schedule(s) as necessary.', 'Other duties and responsibilities as assigned.', 'Bachelor’s Degree', 'Computer Science or related field', 'Generally requires 2-5 years related experience with SQL Server, SSIS, stored procedures, ETL optimization, GitHub, and OBI/Tableau.']",2020-09-24 13:26:53
Data/Analytics Engineer,"Netpace, Inc.",N/A,"Pleasanton, CA","['Strong Data Analytics as core background', 'Strong in Python and SQL and working in Spark /Databricks actively .', 'hands-on experience with big data migration and processing, using Spark Python, SparkSQL, Hive', 'hands-on experience with SQL & NoSql database, such as Mongo / Cassandra', 'hands-on experience with Kafka topic, such as consuming message from Kafka by Spark.', 'Proficient in Java core and Spark/SparkSQL technical question.']",2020-09-24 13:26:53
Senior Hadoop Data Engineer,Talent Hire Consulting,N/A,"Hartford, CT 06112","['Pay:', 'Up to $71.00 per hour', 'Develops large scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs.', 'Collaborates with other data teams to transform data and integrate algorithms and models into automated processes.', 'Uses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelines.', 'Builds data marts and data models to support Data Science and other internal customers.', 'Analyzes current information technology environments to identify and assess critical capabilities and recommend solutions.', 'Experiments with available tools and advises on new tools in order to determine optimal solution given the requirements dictated by the model/use cases', '3 or more years of progressively complex related experience.', 'Has strong knowledge of large scale search applications and building high volume data pipelines.', 'Experience building data transformation and processing solutions.', 'Knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment.', 'Ability to understand complex systems and solve challenging analytical problems.', 'Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources.', 'Strong collaboration and communication skills within and across teams.', 'Strong problem solving skills and critical thinking ability.', 'Hive', 'Shell Script', 'Unix', 'Hadoop Concepts (Sqoop, YARN, MapReduce ,etc.)', 'Python', 'Monday to Friday', 'Unix: 1 year (Preferred)', 'Hive: 1 year (Preferred)', 'Hadoop: 2 years (Required)', 'Shell Script: 1 year (Preferred)', 'Python: 1 year (Required)', 'Yes', 'No: Not providing sponsorship for this job', 'talenthireconsulting.com', 'Temporarily due to COVID-19']",2020-09-24 13:26:53
Data Engineer,VoxTech,N/A,"Frisco, TX 75034",[],2020-09-24 13:26:53
Data Engineer,Lenora Systems Inc,N/A,"Austin, TX","['Pay:', 'Up to $55.00 per hour', 'Automate end-to-end ETL/ML pipelines with a structural understanding of data products.', 'Work with team members to assist with data-related technical issues and support their data product needs.', 'A background in computer science, engineering, mathematics, or similar quantitative field with a minimum of 5+ years’ professional experience', 'Experience in implementing data pipelines using python', 'Experience with workflow scheduling/orchestration, such as Kubernetes, Airflow, or Oozie.', 'Extract Transform Load (ETL) experience using Spark, Kafka, Hadoop, and similar technologies.', 'Experience with REST APIs and query APIs using JSON, Protocol Buffers, or XML.', 'Experience with Unix-based command-line interface and Bash scripts.', 'Experience with Pandas a plus.', 'Database development experience with Relational or MPP/distributed systems such as Oracle/Teradata/Vertica/Hive a plus', 'Data visualization or web development skills a plus', 'Bachelors in computer science or engineering; Masters preferred.']",2020-09-24 13:26:53
Data Engineer (Migration),Lenora Systems Inc,N/A,"Baton Rouge, LA","['Data engineering (especially data QA and data pipeline automation and maintenance)', 'Need to support data pipelines in production, and build as needed', 'Proficient in Python and SQL (knowing SAS is a plus)', 'General experience with data exploration, operation, cleaning, and transformation tasks', 'Experienced with Git and Github', 'Familiarity with Salesforce platform is a bonus', 'Temporarily due to COVID-19']",2020-09-24 13:27:38
Senior Data Engineer,GitLab,3.6 out of 5,United States,"['Base salary', 'Unlimited time off']",2020-09-24 13:27:38
Data Engineer - Basepaws (Genetics & Personalized Medicine),Basepaws,N/A,"Los Angeles, CA","['Medical, Vision, and Dental Plan available Salary based on experience and stock options Local, OC or LA-based applicants only', 'From $80,000.00 per year', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Vision insurance', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Vision insurance', 'Monday to Friday', 'Los Angeles, CA (Required)', 'Fully Remote', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'www.basepaws.com', 'https://www.facebook.com/basepaws']",2020-09-24 13:27:38
Sr. Big Data Engineer,Perito Systems Inc,N/A,"Denver, CO","['Pay:', '$55.00 - $65.00 per hour', 'Monday to Friday', 'BIGDATA: 9 years (Preferred)', 'Health Care: 3 years (Preferred)', 'HL7: 5 years (Preferred)', 'Databricks or Mulesoft: 4 years (Preferred)', '1 year', 'Yes']",2020-09-24 13:27:38
Data Engineer (Remote),Icon Fitness,3.8 out of 5,"Logan, UT","['Excellent health, vision, dental insurance', '401k match', 'Excellent PTO', 'MacBook Pro and external monitor', 'A cell phone of your choice + monthly phone plan', 'Free piece of fitness equipment of your choice', 'Continuing education opportunities', 'Highly competitive salary and compensation package', 'Use an analytical, data-driven approach to drive a deep understanding of our business.', 'Build data pipelines and data models that will empower engineers and analysts to make data-driven decisions', 'Build data models to deliver insightful analytics', 'Deliver the highest standard in data integrity', 'Strong analytical skills with ability to analyze and project sales, subscriber, and engagement data. Performs competitive analysis, reviews industry information for current trends and opportunities. Works closely with analytics teams to develop comprehensive analytical reports to enable data-driven decisions to increase engagement and conversions of target customer segments.', 'Experience in business intelligence, analytics, or an equivalent analyst position with experience in SQL and an additional object-oriented programming language (e.g., Python, Java).', 'High level of expertise in data modeling.', 'Effective problem solving and analytical skills. Ability to manage multiple projects and report simultaneously across different stakeholders.', 'Structured thinking with ability to easily break down ambiguous problems and propose impactful data modeling designs.', 'Attention to detail and effective verbal/written communication skills.', 'Bachelor’s degree in Engineering, Computer Science, Statistics, Economics, Mathematics, Finance, a related quantitative field, or equivalent practical experience.', '2-6 years of experience in consulting, business intelligence, analytics, or an equivalent analyst position with experience in SQL and Python.', 'Ability to effectively and accurately present information to customers, coworkers, and managers.', 'Ability to define problems, collect data, establish facts, and draw valid conclusions.', 'The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. While performing the duties, the employee is regularly required to sit and talk or hear. The employee is frequently required to stand and walk. The employee must occasionally lift and/or move up to 25 pounds. Specific vision abilities required by this job include vision, and color vision.', 'The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. The noise level in the work environment is usually moderate. Typical office environment.', 'Excellent health, vision, dental insurance', '401k match', 'Excellent PTO', 'MacBook Pro and external monitor', 'A cell phone of your choice + monthly phone plan', 'Free piece of fitness equipment of your choice', 'Semi-annual team meet-ups', 'Continuing education opportunities', 'Highly competitive salary and compensation package', 'Yearly performance/pay evaluation', 'List of states we are able to hire in: AR, AK, AZ, CA CO, CT, FL, GA, ID, IL, IN, KS, MI, MD, MN, MO, NC, NH, NJ, OH, OR, PA, SC, TX, UT, VA, WA, WI.']",2020-09-24 13:27:38
Data & Reporting Engineer,Converse,4.2 out of 5,"Boston, MA 02115","['Interact with many types of data in both SQL and non-SQL based environments.', 'Parse data in common formats such as JSON, Parquet, excel/csv so that it can be usable for insights and analysis.', 'Partner with the Converse Analytics Technology team to define data requirements and source data, either in terms of raw data or modeled data and logic to support insights, dashboard and report requirements.', 'Strong SQL ability; able to write complex SQL queries against data warehouse/databases for the purposes of extracting required data and building data models for automated reporting and insights use case.', 'Able to parse different types of data (JSON, parquet, excel/csv) for analysis using tools like R or Python.', 'Able to quickly visualize and profile data in tools like Tableau, PowerPivot, etc.', 'Partner with stakeholders in Global Finance to identify key reports, business questions, hypotheses, and areas of exploration that will have a material impact on business decision-making, and translate these areas into requirements for insights, reports and data visualizations.', 'Review, assess and automate the existing set of reports that are being run across Global Finance; Reports are run across a variety of tools, such as Business Objects, Excel and Tableau.', 'Provide front-line support for data visualizations, dashboards and reports, answering user questions and resolving issues. Work with the Analytics Technology team to address back-end data or platform issues affecting reports.', 'Strong business analysis capabilities; Ability to ask go beyond reporting and ask “why”; Strong drive to drill into data and uncover root causes.', 'Strong ability to “tell stories” with data to business stakeholders, particularly stakeholders within our Finance and Controlling organizations.', 'Work as part of an agile team, delivering reports and insights in an iterative manner with a “progress over perfection” mindset.', ""Bachelor's degree in Information Systems, Information Technology or Computer Science or equivalent professional experience; MBA or other graduate specialization in Finance and/or Accounting preferred"", 'Solid SQL skills; ability to query data in a data warehouse and prepare data for reporting and insights automation needs. Experience with using Python/Pandas for data preparation/cleansing and analysis ideal but not required.', 'Experience with a variety of reporting and data visualization tools; Tableau, Business Objects, and PowerPivot preferred. Proven track record building and automating reports, data visualizations and dashboards in a business context for a variety of stakeholders, from leadership oriented summary dashboards to more granular and detailed analyses.', 'Strong communication skills; Ability to engage with stakeholders on key business questions and hypotheses and tell compelling stories with data through visualization and reporting tools.', 'Automation mindset; Identify opportunities to automate insights generation work and ability to partner with Technology teams to implement solutions where possible.', 'Experience working in an agile setting, working with developers to release in an iterative fashion.', 'Experience working in a business setting; Experience working in a Corporate Finance and/or Controlling context and familiarity with key Finance terms, KPIs and typical reports strongly preferred.']",2020-09-24 13:27:38
Asset Data Analytics Manager (Non-Engineer),State of Utah,3.7 out of 5,Utah,"['Supervise Highway Data Group.', 'Ensure skid data is processed and analyzed.', 'Publish the skid data and wet pavement crashes to UPLAN.', 'Process and analyze collected IRI, rutting, faulting, and percent cracking data on fed-aid sample sections.', 'Coordinate with HPMS, LRS, and other end users for updates to systems and maps, etc.', 'Maintain historical record of all changes to functional classification system for the state.', 'Maintain updated online UPLAN map of Highway functional classification and adjusted urban boundaries.', 'Coordinate with local governments, MPOs, regions, region planners, and FHWA for changes/balancing.', 'Participate in asset sub-committees.', 'Update and maintain asset resources.', 'Develop asset tools and maps necessary to convey information to users.', 'Maintain asset resister of quantities and values of the Department’s tiered assets.', 'Provide oversight to Mandli collection efforts.', 'A Bachelor’s degree, or higher, in a related field (or equivalent experience)', 'At least six years of transportation asset management, transportation planning, or other related experience', 'This position will require travel across the state, especially during the Major Census Updates.', 'Working Conditions: Risks found in the typical office setting, which is adequately lighted, heated and ventilated, e.g., safe use of office equipment, avoiding trips and falls, observing fire regulations, etc.', 'Physical Requirements: Typically, the employee may sit comfortably to perform the work; however, there may be some walking; standing; bending; carrying light items; driving an automobile, etc. Special physical demands are not required to perform the work.', 'Employee may be reassigned to a different location as deemed necessary by the Region Director/Group Leader.']",2020-09-24 13:27:38
Data Integration Engineer,Arkansas Heart Hospital,4 out of 5,"Little Rock, AR 72211","['Develop interfaces and ETL solutions to meet the needs of the health system Work with users, Team Leader, vendors, and other members of the group.', 'Mange and work on Interface design and architecture', 'Responsible for ETL solutions that allow for movement and transformation of data between systems.', 'Responsible for integration development, analysis, coding design, development, configuration, implementation, testing, documentation, application programming and solution analysis', 'Support, maintenance and troubleshooting existing Interfaces for Data Transfers.', 'Identify potential areas of improvement for existing interfaces and propose/implement changes to improve those processes.', 'Maintain knowledge of current and future ETL & API technologies for data transfer']",2020-09-24 13:27:38
Data Engineer,Elkay Manufacturing,3.3 out of 5,"Downers Grove, IL 60515","['I’m proud to work for Elkay.', 'The company invests in my success.', 'I do work that makes a difference.', 'I love my co-workers.', 'I feel like part of a family.', 'Design, develop and maintain data models, database architectures, and associated database objects in Snowflake, Oracle, and other database solutions such as Azure.', 'Design, develop, and maintain data integrations using Informatica Power Center, Informatica Integrated Cloud Services, and data prep tools.', 'Participate in or drive project activities such as requirements gathering, design, develop, test, and deploy.', 'Assist in the set-up of, and administer, on premise and cloud tools used in the Elkay analytics infrastructure.', 'Create and maintain necessary technical documentation, including requirements, design, and test documents.', 'Identify emerging trends, processes, and techniques impacting Elkay’s analytics infrastructure and make suggestions for incorporation of these into the analytics infrastructure.', 'A Master’s or Bachelor’s degree in Computer Science, MIS, engineering, or a related technical discipline is required.', '5+ years of experience in data engineering, data warehousing, business intelligence, ETL on databases such as Oracle or SQL Server, and/or big data is required.', '3+ years of experience in ETL/ data integration is required with 2+ years of experience in Informatica PowerCenter, job scheduling tools is required.', 'Working experience in Python/R/Scala, Snowflake is required.', 'Hands on experience in writing and understanding complex SQL (e.g. CTE’s others).', 'Thorough understanding of relational database design and best practices, including dimensional (star, snowflake) models is required.', 'A collaborative working style and ability to work well within the team and with business consumers is required.', 'Ability to clearly communicate to technical and non-technical audience by written and verbal is required.', 'Independent analytical, critical thinking, and problem-solving ability in complex technical environments is required.', 'Production experience in OBIEE, Oracle Analytics Cloud (OAC) and Tableau is nice to have.', 'Familiarity with big data technologies such as Microsoft Azure Data or AWS is nice to have.']",2020-09-24 13:27:38
Data Engineer,Confluent,3.6 out of 5,"Mountain View, CA","['Design, build and launch extremely efficient and reliable data pipelines to move data across a number of platforms including Data Warehouse and real-time systems', 'Developing strong subject matter expertise and manage the SLAs for those data pipelines; improve existing or develop new tools to detect data anomalies real time and through offline metrics', 'Data Modeling - Partner with analytic consumers to improve existing datasets and build new ones', 'Set up and improve BI tooling and platforms to help the team create dynamic tools and reporting', 'Partnering with Data Scientists and business partners to develop internal data products to improve operational efficiencies organizationally', '3+ years of experience in a Data Engineering role, with a focus on data warehouse technologies, data pipelines and BI tooling', 'Bachelor or advanced degree in Computer Science, Mathematics, Statistics, Engineering, or related technical discipline', 'Expert knowledge of SQL and of relational database systems and concepts', 'Strong knowledge of data architectures and data modeling and data infrastructure ecosystem', 'Experience with enterprise business systems such as Salesforce, Marketo, Zendesk, etc.', 'Experience with ETL pipeline tools like Airflow, and with code version control systems like Git', 'The ability to communicate cross-functionally, derive requirements and architect shared datasets; ability to synthesize, simplify and explain complex problems to different types of audiences, including executives', 'The ability to thrive in a dynamic environment. That means being flexible and willing to jump in and do whatever it takes to be successful.', 'Experience with Apache Kafka', 'Knowledge of batch and streaming data architectures', 'Product mindset to understand business needs, and come up with scalable engineering solutions']",2020-09-24 13:27:38
Asset Data Analytics Manager (Engineer),State of Utah,3.7 out of 5,Utah,"['Supervise Highway Data Group.', 'Ensure skid data is processed and analyzed.', 'Publish the skid data and wet pavement crashes to UPLAN.', 'Process and analyze collected IRI, rutting, faulting, and percent cracking data on fed-aid sample sections.', 'Coordinate with HPMS, LRS, and other end users for updates to systems and maps, etc.', 'Maintain historical record of all changes to functional classification system for the state.', 'Maintain updated online UPLAN map of Highway functional classification and adjusted urban boundaries.', 'Coordinate with local governments, MPOs, regions, region planners, and FHWA for changes/balancing.', 'Participate in asset sub-committees.', 'Update and maintain asset resources.', 'Develop asset tools and maps necessary to convey information to users.', 'Maintain asset resister of quantities and values of the Department’s tiered assets.', 'Provide oversight to Mandli collection efforts.', 'Be registered as a professional engineer in Utah', 'At least two years of engineering experience following licensure as a PE', 'This position will require travel across the state, especially during the Major Census Updates.', 'Working Conditions: Risks found in the typical office setting, which is adequately lighted, heated and ventilated, e.g., safe use of office equipment, avoiding trips and falls, observing fire regulations, etc.', 'Physical Requirements: Typically, the employee may sit comfortably to perform the work; however, there may be some walking; standing; bending; carrying light items; driving an automobile, etc. Special physical demands are not required to perform the work.', 'Employee may be reassigned to a different location as deemed necessary by the Region Director/Group Leader.']",2020-09-24 13:27:38
Data Engineer,Pyramid,3.9 out of 5,"Portland, OR","['Pay:', '$50.00 - $55.00 per hour', 'Data Engineer with hands on experience on ETL process.Experienced in working with Python.', 'Experienced in developing Web Services with Python programming language.', 'Integrate up-and-coming data management and software engineering technologies into existing data structures.', 'Develop set processes for data mining, data modeling, and data production.', 'Create custom software components and analytics applications.']",2020-09-24 13:27:38
Data Engineer,Gooten,N/A,"Washington, DC","['Interface with business stakeholders to understand data needs and help build data products that scale across the company', 'Drive the design, building, and launching of new data models and data pipelines in production', 'Build data expertise and own data quality for allocated areas of ownership', 'Develop solutions that utilize the highest standards of analytical rigor and data integrity', '3-5 years of experience in designing, developing, and managing a highly optimized, flexible, and scalable data platform for business analytics.', '3-5 years of experience building a connected low latency data platform (highly distributed, scalable with high availability), and stitching together various large and disparate data sources for data analysis.', 'Structured thinking with ability to easily break down ambiguous problems and propose impactful data modeling designs.', 'Experience managing data engineering efforts through all phases, including requirements, ETL, data quality assessments, and data exploration', 'Attention to detail and effective verbal/written communication skills.', 'Experience with Snowflake, DBT, and GitHub', 'Exceptional troubleshooting and problem-solving abilities', 'Experience with Cloud Technologies (S3, Redshift, lambda, AWS, etc.)', 'Experience with Reporting/Analytics tools']",2020-09-24 13:27:38
Senior Data Engineer - Remote,StrongMind,3.3 out of 5,United States,"['We offer great benefits including a competitive salary, health and dental, 401K, an onsite gym, generous PTO, and holidays', '$87,642.00 - $150,000.00 per year', 'Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee discount', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'You will be our go-to person when it comes to Data, whether it’s data manipulation, data warehousing, or engineering', 'Ability to pitch the right solution when it comes to Data be it a relational databases or non-relational databases', 'Build magical product experiences. Make the technical & complex, simple and effortless.', ""Be empowered to contribute to growing StrongMind's technical excellence, culture, and customer delight."", 'Participate in all aspects of the software life-cycle, including ideation, development, and production support.', 'Mentor and be mentored, educate and learn, lead, and be led by other engineers in problem solving and solutioning.', 'Drive improvements to enable your team to deliver quality outcomes that lead to customer success.', 'Collaborate deeply with a diverse, cross functional team of Engineers, UX, Product, and Operations.', 'Leverage engineering best practices such as CI/CD, Pairing, and Test-Driven Development to deliver early and often.', 'Actively engage with the education community to understand product needs.', 'Apply Lean Startup/Agile approaches to software development', 'Work in an open space environment (no cube walls)', 'BS in a related field, bootcamp, self-taught or equivalent experience', 'Experience working with both SQL and NoSQL databases, knowing which paradigm works best for different use cases', 'Demonstrated experience working with various components of Big Data ecosystem: Hadoop, Spark/Spark Streaming, Hive, Kafka', 'Ability to use industry standard dimensional modeling techniques to organize data from disparate systems into Data Marts and Warehouses', 'Experience with both OLTP and OLAP environments', 'Familiarity with ETL and ELT data transformation best practices', 'Mastery of Business Intelligence is a must', 'Experience to a variety of data technologies (Relational, Non-Relational, NoSQL, Data Warehouses, Big Data)', 'Ability to deliver iterative vertical slices of business value consisting of data visualization, transformation, and persistence.', 'Data security, e.g., HIPPA or FERPA compliance, experience helpful, but not required', 'Experience developing in AWS, Azure, or other cloud services', 'Preference for working within an Agile methodology (i.e. Scrum, Kanban, XP)', 'Prior knowledge of Snowflake is a bonus', 'Familiarity with software engineering best practices', 'Passion for self-driven, continuous learning, both in and out of the office', 'Leadership qualities and capabilities', 'Opinionated on technology, in theory, but flexible in practice', 'Passion for Education is a must; experience in Ed-Tech helpful, but not required', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee discount', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'United States (Required)', 'Fully Remote']",2020-09-24 13:27:38
Data Engineer,iknowvate technologies,N/A,"Basking Ridge, NJ",[],2020-09-24 13:27:38
Data Engineer,iknowvate technologies,N/A,"Basking Ridge, NJ",[],2020-09-24 13:28:18
Data Engineer,Mercato,N/A,"San Diego, CA","['Collaborate with Product Management and Engineering to understand data needs, solve problems, and identify trends and opportunities.', 'Design, build and launch new data extraction, transformation, and loading processes in production.', 'Manage data warehouse plans for a group of products.', 'Work with data infrastructure to triage infrastructure issues and drive to resolution.', 'Build data expertise and own data quality for allocated areas of ownership.', 'Support existing processes running in production.', 'Experience with custom ETL design, implementation and maintenance, including schema design and dimensional data modeling.', 'Significant experience with workflow management engines (i.e. Airflow, AWS Step Functions, etc).', 'Expert proficiency in any scripting language (Python, Node.js, R, etc.) and SQL.', 'Experience working with cloud or on-prem Big Data/MPP analytics platform (i.e., AWS Redshift or similar).', 'Ability to analyze data to identify deliverables, gaps, and inconsistencies.', 'Communication skills. A strong ability to identify and communicate data-driven insights.', 'Managing and communicating data warehouse plans to internal clients.', '4+ years experience working with either a Map Reduce or an MPP system.', 'Ability to thrive in an unstructured environment, working autonomously to find opportunities to deliver business impact.', 'Must be able to convey information in a clear, focused, and concise manner.', 'Experience in planning, coordinating, and executing multiple projects simultaneously.', 'Ability to think creatively and work in a team environment.', 'Must work well in a dynamic environment and be able to recommend and implement process improvements, work independently, and handle multiple tasks simultaneously.', 'Passion for helping others.', 'Competitive salary', 'Stock options', 'Medical, dental, and vision insurance', 'Generous PTO Policy, paid holidays', 'Get in on the ground floor and shape the strategic direction of the company', 'Ongoing training and growth opportunities', 'Consistent & fair leadership: we are transparent and set clear goals', 'Upbeat work environment at a company with a huge vision']",2020-09-24 13:28:18
Graduate - Data Engineer,Rio Tinto,3.9 out of 5,"Boron, CA 93596","['Join one of the largest mining and metal companies in the world, focused on safety and inclusion', 'Work with the newest technology and innovation, in an environment where we challenge you to drive positive change', 'Start your career and be part of our prestigious Graduate Development Program', 'Discovery of new data sources and conducting exploratory analysis based on prioritized business objectives', 'MS SQL DDL, ETL Development, and Data Warehousing', 'Report and dashboard development using Power BI and other applicable platforms', 'Support and development of existing operational data systems, relevant documentation management, and data stewardship', 'Recommending methods and performing various analyses of data, such as descriptive, predictive, or machine learning as appropriate for specific projects', 'Manual file data collection and workflow automation for users', 'End-user training, engagement, and culture transformation support', 'Participation in Rio Tinto Borates big data and digital transformation initiatives, and joining special projects teams', 'A pioneering spirit and alignment to our values of Safety, Teamwork, Respect, Integrity and Excellence', 'Curious mind, a willingness to learn, and make an impact, and challenge the status quo', 'Bachelor or master’s degree in Data Science, Data Analytics, Business Intelligence, Computer Science, Software Engineering or any related field', 'A safety-focused and inclusive working environment', 'A competitive salary package with annual cash incentive awards (STIP) for eligible employees', 'Career development & education assistance to further your ambitions', 'Access to top tier family-friendly health and medical programs', 'Excellent retirement plan including 6% defined company contribution', 'Generous 401k matching program', 'A comprehensive leave policy that covers all moments that matter in life (vacation/annual, paid parental leave, short term sick leave, paid holidays)', 'Ongoing individual wellbeing support for you and your family for personal and professional matter', 'Generous Rio Tinto employee share program', 'Rio Tinto reserves the right to remove job postings prior to the stated closing date, therefore, if you are interested in applying for this vacancy please submit your application as soon as possible']",2020-09-24 13:28:18
SQL Data Engineer,"Infinity Consulting Solutions, Inc.",N/A,"Chicago, IL 60608",[],2020-09-24 13:28:18
Data Engineer SQL,Tesla,3.5 out of 5,"Fremont, CA","['Work in a time constrained environment to analyze, design, develop and deliver Enterprise Data Warehouse solutions for Tesla’s Finance and Accounting teams', 'Work on ETL tools like SSIS and Informatica, Business Intelligence & Reporting tools like SSRS, SSAS and Tableau', 'Work with systems that handle sensitive data with strict SOX controls and change management processes', 'Develop collaborative relationships with key business sponsors and IT resources for the efficient resolution of work requests.', 'Provide timely and accurate estimates for newly proposed functionality enhancements', 'critical situation', 'Communicate technical and business topics, as appropriate, in a 360 degree fashion, when required; communicate using written, verbal and/or presentation materials as necessary.', 'Develop, enforce, and recommend enhancements to Applications in the area of standards, methodologies, compliance, and quality assurance practices; participate in design and code walkthroughs.', 'Utilize technical and domain knowledge to develop and implement effective solutions; provide hands on mentoring to team members through all phases of the Systems Development Life Cycle (SDLC) using Agile practices.', 'As a full time Tesla employee you will receive full benefits from day 1 for you and your dependents.', 'Kaiser and UnitedHealthcare PPO and HSA plans (including infertility coverage)', '3 medical plan choices with $0 paycheck contribution', 'Vision & dental plans (including orthodontic coverage)', 'Company paid Life, AD&D, short-term and long-term disability', '401(k), Employee Stock Purchase Plans, and other financial benefits', 'Employee Assistance Program, Paid Time Off, and Paid Holidays', 'Back-up childcare and employee discounts']",2020-09-24 13:28:18
Data Engineer,Vizio Inc.,N/A,"Denver, CO 80014","['You are an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.', 'You are comfortable supporting the data needs of multiple teams, systems and products.', 'You are excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.', 'You have 4+ years of experience in a Data Engineer role, and you have earned a B.S in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.', 'You have demonstrated experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'You possess strong analytic skills related to working with unstructured datasets.', 'You have Eexperience supporting and working with cross-functional teams in a dynamic environment.', 'You have demonstrated experience building processes supporting data transformation, data structures, metadata, dependency and workload management.', 'You have a successful history of manipulating, processing and extracting value from large disconnected datasets.', 'Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.', 'Experience with AWS cloud services: EC2, EMR, RDS, Redshift', 'Experience with stream-processing systems: Storm, Spark-Streaming, etc.', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Experience with data pipeline and workflow management tools: AWS Data Pipeline, Apache Airflow, etc.', 'Experience with big data tools: Hadoop, Spark, Kafka, etc', 'Create and maintain optimal data pipeline architecture,', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.', 'Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.']",2020-09-24 13:28:18
Big Data Engineer,Noha,N/A,"Herndon, VA","['4-6 years of related experience; Experienced with Agile practices/ methodologies (e.g. Scrum, TDD, BDD, etc)', '2+ years with Big Data Hadoop cluster (HDFS, Yarn, Hive, MapReduce frameworks), Spark', '2+ years of recent experience with building and deploying applications in AWS (S3, Hive, Glue, EMR, AWS Batch, Dynamo DB, Redshift, Cloudwatch, RDS, Lambda, SNS, SQS etc.)', '4+ years of Java/Python, SQL, SparkSQL, PySpark', 'Excellent problem-solving skills, strong verbal & written communication skills', 'Ability to work independently as well as part of a team', 'Knowledge of Spark streaming technologies, Graph Database will be a nice to have', 'Familiar with Hadoop information architecture, data modeling, machine learning, Talend', 'Knowledge of Financial Products, Risk Management, Portfolio Management is preferred but not mandatory. Training will be provided to help you gain ground', '8 hour shift']",2020-09-24 13:28:18
Data Engineer,Yochana IT inc,N/A,"Dearborn, MI",[],2020-09-24 13:28:18
Data Engineer,Centric Consulting,4.1 out of 5,"Indianapolis, IN","['Develop information processes for data acquisition, data transformation, data migration, data verification, data modeling, and data mining', 'Work closely with various teams including architecture, security, infrastructure, and application to design and implement the automation of data, data platforms, and tools', 'Lead data architecture design and ensures that data architecture standards are adhered', '5+ years of experience as a data engineer or related specialty (Software Engineer/Developer, BI Engineer/Developer, DBA)', 'Should have 5 years+ of experience with data platforms and in data transformation and extraction: some combination of ETL/ELT, table and database design, query design, performance analysis and optimization', 'Hands on experience with handling of large amount of data using SQL, Azure Data Factory, Snowflake, Python, Spark, Azure Cloud architecture', 'Deep understanding of data modeling techniques for analytical data (i.e. facts, dimensions, measures)', 'Experience developing and managing reporting solutions, dashboards, etc. Design and architecture experience in data transformation.', 'Knowledge of cloud architecture and data solutions', 'Proficiency in Python, R or Scala.', 'Excellent written and verbal communication skills', 'Special Culture – Our people make us different. We have highly talented, intelligent individuals across a broad variety of disciplines – who are eager to learn from you and share their own expertise. We embrace fresh perspectives and each other. Don’t take our word for it – check us out on Glassdoor, Facebook, Twitter or Instagram to get a glimpse inside what makes us different.', ""Growth opportunities – As a mid-size firm, there is more flexibility when it comes to career paths. Figure out what you want to do and we'll help you figure out how to get there."", 'Impact – We think of ourselves as a big company with a small company feel – a local player with global reach that combines business, technology and industry expertise.', 'Unmatched Experiences – We are allowed to be ourselves here. We are encouraged to be human. It’s at the root of who we are as a firm and why we’re here.', 'Innovation – We value passion, determination, perseverance, and innovation. We are inspired because we believe in what we are doing and where we are going.', 'Passion for the greater good – We are steadfast in our devotion to the communities we serve and in actively promoting employee involvement in community improvement projects.']",2020-09-24 13:28:18
Data Migration Engineer,IRESS Limited,N/A,"Warwick, RI","['Owning the end to end process of a migration, including the migration setup, execution and post migration analysis', 'Developing, testing and maintaining migration tools for single use or re-use', 'Running migrations for a variety of 3rd party systems as per the agreed specifications of the clients request', 'Executing Data Repair and deletion requests for existing clients', 'Operating within server environments to execute migrations and ensure the required infrastructure is in place to implement migrations successfully', 'Proactively identifying and addressing issues that have the potential to impact a migration, as well as identifying reasons for migration failures and following correct procedures to resume/rerun migrations or raise development items', 'Working with a variety of teams across Iress in particular Data Analysts, Project Managers and product teams to make sure Data Migration deliveries are in line with the overall project plan', 'Competitive remuneration', 'Global opportunities', 'Casual dress, flexible work policy', 'Access to learning and development programs', 'Health Benefits including Private Medical Insurance', 'Iress Community', '3 days’ leave per year for charity initiatives', 'Global 36-hour hackathon', 'Cycle to Work scheme', '25 days holiday plus Bank Holidays', 'Profit Share Plan', 'Up to 26 weeks’ paid parental leave for primary carers (up to 4 weeks for secondary carers), and the ability to work part-time when returning to work']",2020-09-24 13:28:18
Data Engineer,Yapstone,3.5 out of 5,"Walnut Creek, CA","['Design, build and launch extremely efficient & reliable data pipelines to move data to our Data Warehouse/Data Mart.', 'Own end-to-end data quality for the data pipelines you build', 'Develop ETL routines to populate databases from multiple disparate data sources and create aggregates', 'Create and run data migrations across different servers and different databases including Enterprise CRM and ERP applications.', 'Perform complex data transformations, create/update stored procedures/functions, and optimize existing stored procedures/functions using indexing, temp tables, views, logic changes, etc.', 'Design/develop new systems and tools to enable stakeholders to consume and understand data faster', 'Data cleansing and manipulation using your expert SQL & programming skills', 'Troubleshoot data issues and present solutions to the issues', 'Prepare activity and progress reports regarding database & data health and status', 'Design and improve agile development processes as it applies to data and data structure design', 'Design, code and automate data quality checks, metrics, standards and guidelines', 'Work across multiple teams in high visibility roles and own the solution end-to-end', 'BS or MS in Computer Science, Information Management, or related field', '5+ years of experience as a Data Engineer.', 'Candidate must have a deep understanding of logical and physical data modeling for OLTP and OLAP systems.', 'Ability to translate a logical data model into a relational or non-relational solution as appropriate', 'Familiar with multiple relational platforms, recent MSSQL Server experience is required.', 'Hands-on expertise in database development using views, T-SQL, MSSQL and/or SQL scripts and SSIS packages and transformations. Experience building and troubleshooting SSAS cubes.', 'Fluent in using tools like SQL Server Management Studio or similar.', 'Recent experience in SQL tuning, indexing, partitioning, data access patterns and scaling strategies', 'Programming/Scripting experience in Windows (C#, PowerShell) as well as Unix/Linux environments (Python, Bash)', 'Experience in NoSQL/Big Data technologies (Couchbase or MongoDB)', 'Excellent analytical problem solving and decision-making skills', 'Experience working with large complex sets of data in a high-availability environment', 'Experience with agile methodology process and development practices', 'Payment or e-commerce industry experience', 'Experience working with Informatica Intelligent Cloud Services (IICS)', 'Experience in Business Intelligence tools and technologies', 'Experience with Snowflake – Snowpipe, SnowSQL, Snowflake Procedures', 'Experience in building out BI solutions in Looker']",2020-09-24 13:28:18
Staff Data Engineer,Figure,N/A,California,"['Leverage Spark, Airflow, Google Kubernetes Engine, BigQuery and other tools to build robust and efficient data pipelines.', 'Expand and optimize our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams.', 'Collaborate with project leads and other software engineers across multiple teams', 'Work on data software solutions that will transform the consumer lending and blockchain space', 'Be a leader, use your voice, apply your tech skills to solve real world problems', 'BS degree in Computer Science or related technical field, or equivalent practical experience.', '6+ years of proven working experience as a data engineer', ""3+ years' experience with Spark, either in Python or in Scala. Bonus points for Spark on EMR, Dataproc, or Kubernetes."", 'Working knowledge of Google Cloud tools (compute, cloud storage, GKE, GCR, AutoML, etc.)', 'Expertise building and optimizing data pipelines using Kafka (preferred), Kinesis, or other event bus.', 'Deep experience with data frameworks and tools like Spark, SparkML, Spark Streaming, Apache Beam, and Airflow.', 'Comfort with and experience working within CI/CD processes and tools and software development practices.', 'Experience with production machine learning workflows and processes.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of SQL and NoSQL databases, including BigQuery (preferable), MySQL/MariaDB, Postgres or Cassandra.', 'Expertise in data modeling for data science, reporting, and analytics, including dimensional and transactional models.', 'Nice to have: experience building real-time transformations and learning models on streams.', 'Ability to thrive in a fast-paced growing company.', 'Competitive salary', 'Firm-wide performance based bonus', 'Competitive stock options package', 'A flexible paid time off and vacation policy', 'Comprehensive health, vision, dental insurance', 'Company FSA, 401k, commuter benefits', 'And much more to come!']",2020-09-24 13:28:18
Data Engineer,LOCKHEED MARTIN CORPORATION,4 out of 5,"Herndon, VA 20171","['Test-driven development in using the appropriate data storage and access solutions, using the most efficient languages for the task, e.g. Java, Python and/or SQL', 'Implementing multi-processing algorithms to parallelize ingest operations.', 'Execute operating system level scripts for production data load routines.', 'Analyze new large volume data collections looking for opportunities to optimize the data ingest processes.', 'Develop software tools that efficiently preprocess, modify, aggregate, load, index, and archive large data collections.', 'Generate metrics that track data ingest statistics to ensure data integrity and pedigrees are maintained.', 'Proficiency with languages/tools such as SQL, Python, R, and Git.', 'Experience with cleaning, management, optimizing performance and processing large volumes of data.', 'Familiarity with industry best-practices for software-hardware optimization when processing large sets of data.', 'Experience with storage/computing processes such as Hadoop, Spark', 'Experience with machine learning, with statistical modeling and time-series forecasting', 'Thorough/Working knowledge of research designs.', 'Thorough/Working knowledge of collection methods, capabilities and tasking process.', 'Familiarity with project management concepts and principles.', 'Intellectual curiosity; creativity and innovation to go beyond current tools to deliver the best solution to complex problems.', 'Strong analytical and critical thinking skills.']",2020-09-24 13:28:18
Data Engineer,Amplify Consulting Partners,N/A,"Bellevue, WA 98007","['Help lead the business, design, test, and development teams', 'Shape how we capture data to improve our test-driven methodologies and build a culture around data driven development', '3+ years’ experience with SQL Server. Expert level TSQL knowledge required', '3+ years’ experience designing and implementing scalable ETL processes including data movement (SSIS, replication, etc.) and quality tools', '2+ years’ experience building cloud hosted data systems. Azure preferred', '2+ years’ experience with SQL Server Analysis Services (SSAS)', '2+ years’ experience with SQL Server Integration Services (SSIS)', '2+ years’ experience with OOP language (C#, Python)', 'Strong communication and collaboration skills will possess superior testing skills, experience with data quality systems and techniques, as well as a strong attention to detail', 'Fully paid medical/dental/vision benefits for you', '3 weeks of PTO, plus 10 paid holidays', '401(k) program', 'Company and team building events', 'Parental Leave program', 'Amplify You benefit program']",2020-09-24 13:28:18
Senior Data Engineer,IT America,N/A,Remote,"['Understanding of Meta Data & Master Data Management concepts & practices', 'Experience working with enterprise data stores, data lakes, external data sources and APIs', 'Experience working with remote teams spread across the globe', 'Experience with broad set of analytics use cases; one or more of supply-chain, transportation, sales and operations', 'AWS: 1 year (Preferred)', 'Data Engineer: 5 years (Preferred)', 'Python: 1 year (Preferred)', 'ETL: 1 year (Preferred)', 'Yes']",2020-09-24 13:28:18
Data Engineer,LOCKHEED MARTIN CORPORATION,4 out of 5,"Herndon, VA 20171","['Test-driven development in using the appropriate data storage and access solutions, using the most efficient languages for the task, e.g. Java, Python and/or SQL', 'Implementing multi-processing algorithms to parallelize ingest operations.', 'Execute operating system level scripts for production data load routines.', 'Analyze new large volume data collections looking for opportunities to optimize the data ingest processes.', 'Develop software tools that efficiently preprocess, modify, aggregate, load, index, and archive large data collections.', 'Generate metrics that track data ingest statistics to ensure data integrity and pedigrees are maintained.', 'Proficiency with languages/tools such as SQL, Python, R, and Git.', 'Experience with cleaning, management, optimizing performance and processing large volumes of data.', 'Familiarity with industry best-practices for software-hardware optimization when processing large sets of data.', 'Experience with storage/computing processes such as Hadoop, Spark', 'Experience with machine learning, with statistical modeling and time-series forecasting', 'Thorough/Working knowledge of research designs.', 'Thorough/Working knowledge of collection methods, capabilities and tasking process.', 'Familiarity with project management concepts and principles.', 'Intellectual curiosity; creativity and innovation to go beyond current tools to deliver the best solution to complex problems.', 'Strong analytical and critical thinking skills.']",2020-09-24 13:28:59
Data Engineer,Amplify Consulting Partners,N/A,"Bellevue, WA 98007","['Help lead the business, design, test, and development teams', 'Shape how we capture data to improve our test-driven methodologies and build a culture around data driven development', '3+ years’ experience with SQL Server. Expert level TSQL knowledge required', '3+ years’ experience designing and implementing scalable ETL processes including data movement (SSIS, replication, etc.) and quality tools', '2+ years’ experience building cloud hosted data systems. Azure preferred', '2+ years’ experience with SQL Server Analysis Services (SSAS)', '2+ years’ experience with SQL Server Integration Services (SSIS)', '2+ years’ experience with OOP language (C#, Python)', 'Strong communication and collaboration skills will possess superior testing skills, experience with data quality systems and techniques, as well as a strong attention to detail', 'Fully paid medical/dental/vision benefits for you', '3 weeks of PTO, plus 10 paid holidays', '401(k) program', 'Company and team building events', 'Parental Leave program', 'Amplify You benefit program']",2020-09-24 13:28:59
Senior Data Engineer,IT America,N/A,Remote,"['Experience:AWS, 1 year (Preferred)Data Engineer, 5 years (Preferred)Python, 1 year (Preferred)ETL, 1 year (Preferred)', 'Understanding of Meta Data & Master Data Management concepts & practices', 'Experience working with enterprise data stores, data lakes, external data sources and APIs', 'Experience working with remote teams spread across the globe', 'Experience with broad set of analytics use cases; one or more of supply-chain, transportation, sales and operations', 'AWS: 1 year (Preferred)', 'Data Engineer: 5 years (Preferred)', 'Python: 1 year (Preferred)', 'ETL: 1 year (Preferred)', 'Yes']",2020-09-24 13:28:59
Data Engineer (Data Concepts & Data Modelling ),Youth Power Technosoft LLC,N/A,"Upper Providence, PA",[],2020-09-24 13:28:59
Data Engineer (USA),ITTStar Consulting LLC,N/A,United States,"['United States America', 'full time', '$ 50/ Hourly/ W-2', '40h / week', '3 years experience', 'Master or Bachelor', 'Skills RequiredPrimary Skills :- AWS, EC2, EMR, Glue, Lambda, Python, Redshift, S3, SparkSecondary Skills :- Hadoop, HBase, Hive', 'M.E/M.Tech/B.E/B.Tech/MCA/MSc or similar 4 or 4+ years degree in relevant field.', 'At least 3+ years of hands on experience onAWS [S3, EC2, ECS, EMR, GLUE, Redshift, Lambda, Dynamo DB , Kinesis, RDS, Data Pipeline etc]', 'At least 3+ years of hands on experience with Big Data stack includingSparkHadoopHiveKafkaHBase or other NoSQL solutions', 'Strong knowledge and handson experience in writing highly optimized and if required complex queries. [Oracle/Postgres /MySQL/ SQLServer etc]', 'Strong Python Programming knowledge from Data Engineering perspective. Good knowledge on libs likePandasNumpyMatlabplotSeabornScikitLearn etc', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with unstructured datasets', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets', 'Strong project management and organizational skills.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Good Communication Skills.']",2020-09-24 13:28:59
Data Engineer,Techno Tasks Inc,N/A,"St. Louis, MO","['Experience:EMR, 2 years (Preferred)Apache Spark, 3 years (Preferred)Scala, 2 years (Preferred)Data Engineer, 5 years (Preferred)Python, 2 years (Preferred)', 'This project is all about Data Pipelining for marketing work for Card LOB.', 'Need to have strong exp on Data Engineering and AWS.', 'They need to have solid understanding of Big Data Concepts and how to do manipulation of data.', 'Must Have – AWS (EMR clusters), Scala(development) & Python(Scripting is good but Development is preferred).', 'Entire code is written in Scala.', '2+ yrs of Scala development and Overall 5+yrs of experience as Software Engineer.', 'Candidate needs do some Production Support and Enhancement of Data jobs.', 'Spark', 'Building pipelines and marketing metrics', 'EMR: 2 years (Preferred)', 'Apache Spark: 3 years (Preferred)', 'Scala: 2 years (Preferred)', 'Data Engineer: 5 years (Preferred)', 'Python: 2 years (Preferred)', 'Temporarily due to COVID-19']",2020-09-24 13:28:59
Cyber Associate Data Engineer,New York City DEPT OF INFO TECH & TELECOMM,3.8 out of 5,"Manhattan, NY 10005","['Developing and maintaining our data pipeline using Apache Beam, Java, Python and other data processing technologies;', 'Identifying and implementing performance improvements across all pipelines;', 'Engaging with data consumers and producers in order to design appropriate models to suit all needs;', 'Maintaining information exchanges through publish, subscribe, and alert functions that enable users to send and receive critical information as required;', 'Supporting incident management, service-level management, change management, release management, continuity management, and availability management for databases and data management systems;', 'Administering databases and/or data management systems that allow for the secure storage, query, protection, and utilization of data.', 'A bachelor’s degree in computer science or information systems with a specialization in mathematics, number; theory, applied cryptography, or statistics or relevant experience;', 'Experience with the Agile Development Methodology;', 'Expert knowledge in both Java and Python;', 'Familiarity with Unix scripting, Web development, and automated testing;', 'Familiarity with machine learning techniques and machine learning toolkits such as R, scikit-learn, etc;', 'Experience working with Terraform;', 'Familiarity with the CI/CD process,', 'At least one year professional, academic, or personal experience with software development or data engineering experience (includes internship experience);', 'At least 1 year professional, academic, or personal experience with object-oriented/object function scripting languages; preferably java or python;', 'Familiarity with or exposure to cloud application development;', 'Familiarity with distributed data processing frameworks.', 'Interested applicants with other civil service titles who meet the preferred requirements should also submit a resume for consideration']",2020-09-24 13:28:59
Big Data Engineer,"Turnberry Solutions, Inc",N/A,"Los Angeles, CA",[],2020-09-24 13:28:59
Data Engineer,Campus Crusade for Christ,4.4 out of 5,"Orlando, FL 32832","['Supporting data analysts, data scientists, and other data consumers to provide them with large, complex, decision-making datasets', 'Creating, scheduling, maintaining, and debugging ETL and ELT processes', 'Data cleansing and data wrangling to prepare structured and unstructured data for various modes of consumption including AI, ML, statistical models, analysis, dashboards, etc.', 'Gathering specific requirements and suggesting solutions', 'Providing mentoring to less senior engineers in coding best practices and problem solving', 'Troubleshooting and debugging', 'Optimizing performance', 'Staying up-to-date with new technology trends', 'Getting Hands on Training from Senior Team Members', 'Getting Training through Conferences', 'Drinking & Making Coffee', 'Going to Company Parties', 'Proven experience as a Data Engineer', 'Extensive experience working with Enterprise databases and ETL tools', 'Strong technical expertise with complex ETL/ELT flows and data pipelines', 'In-depth knowledge of modern programming languages and platforms like Python, Oracle, Google Cloud Platform, R, SQL, Scala', 'Comprehensive knowledge of Modern Data Warehouse design principles and architecture', 'Proficiency in Data Modeling principles', 'Ability to perform in a team environment and yet work independently', 'Strong project management skills, including the ability to work independently and coordinate and prioritize multiple tasks', 'Excellent oral and written communication', 'Must have a high level of interpersonal skills to handle sensitive/confidential situations and information', 'Apache Airflow or GCP Composer', 'Geospatial queries', 'Snowplow', 'Deep love for Jesus Christ', 'Deep desire to share the Gospel with the world', 'Willingness to receive and respond to feedback (it’s not personal)', 'Living in or willing to relocate to Orlando, Florida', 'BS degree in Computer Science or relevant field', 'High School Diploma']",2020-09-24 13:28:59
Streaming Data Engineer,Cisco Systems,4.1 out of 5,"San Jose, CA",[],2020-09-24 13:28:59
Entry Level Data Engineer Position,Jerneltechcorp,N/A,"New York, NY","[""Education:Bachelor's (Required)"", 'We are looking for a passionate Data Engineer to turn data into information, information into insight and insight into business decisions.', 'You will conduct full life cycle activities to include requirements analysis and design, develop analysis and reporting capabilities, and continuously monitor performance and quality control plans to identify improvements.', 'We are seeking an entry level Data Engineer . In this exciting role, you will be responsible for the following:', 'Expert level proficiency with data analysis tools like SQL, MSBI, POWER BI ,concept and knowledge of Excel, concept and knowledge of NumPy, Map, Filters, Pandas, Seaborn, Functions.', 'Technical background and solid programming experience.', 'Fluency in data analysis and communication around data with advanced data visualization abilities using Power BI and Python Data Structure along with Cleaning Data, Conditional Statements & Loops.', 'Proven track record of using data to generate insight and drive business results.', 'Statistics knowledge and hypothesis testing experience.', 'Basic understanding of probability and statistical models (generative and descriptive models).', 'Ability to run experiments scientifically and analyze results.', 'Strong written and verbal communication skills', 'Ability to collaborate effectively across multiple teams and stakeholders, including analytics teams, development teams, product management and operations.', 'Hands-on experience in using data to generate insight and drive business results.', 'Expert knowledge in SQL, MSBI and Power BI.', 'Statistics knowledge and hypothesis testing experience.', 'Experience with Performance Engineering including testing, tuning and monitoring tools', 'Bachelors’ or above in quantitative discipline: Statistics, Applied Mathematics, Economics, Computer Science, Engineering, or related field; Master’s degree Preferred.', 'Uses several techniques to solve complex problems where analysis of situations or data requires a review and analysis of several factors.', 'May lead the implementation of tactical plans in support of strategic initiatives.', 'Receives objectives and determines approach to achieving objectives.', 'Accountable for the achievement of operational goals in at least one department or work area.', 'Integrates customer/client needs and concerns with business issues.', 'Serves as an advocate for client.', 'Serves as a liaison on specific projects with other work areas.', 'Influences, inspires or persuades others in order to accomplish work objectives.', ""Bachelor's degree or equivalent education and relevant experience."", 'Possesses detailed knowledge of one technology or professional discipline, or basic knowledge of several areas.', 'Experience working with data (customer data or databases).', 'Employee assistance program', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Parental leave', 'Professional development assistance', 'Relocation assistance', 'Monday to Friday', ""Bachelor's (Required)""]",2020-09-24 13:28:59
Entry Level Associate Data Engineer - CIC Baton Rouge,IBM,3.9 out of 5,"Baton Rouge, LA 70802","['Implement and validate predictive models as well as create and maintain statistical models with a focus on big data.', 'You’ll incorporate a variety of statistical and machine learning techniques', 'Communicate with internal and external clients to understand and define business needs, providing analytical solutions.', 'Use leading edge tools such as Linux, SQL, Python, Spark, Hadoop, Java, and Cloud Vendors such as AWS, Azure, etc.', 'Work in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.', 'Build teams or writing programs to cleanse and integrate data in an efficient and reusable manner, developing predictive or prescriptive models, and evaluating modeling results', 'Ask business and industry questions to identify appropriate modeling techniques', 'Communicate results to technical and non-technical audiences', 'The IBM Client Innovation Center is an in-bound delivery model where we support our clients from our Baton Rouge center (aka: we work in a traditional IBM Agile office setting).', 'Travel is expected and all candidates must be willing and able to travel to meet our client needs across the US. Travel is typically related to knowledge transfer and training at the client site (Monday thru Friday). You are expected to travel approximately 50% of the time.', 'You must live in, or be willing to relocate to, LOUISIANA. The work location is 100 North St, Baton Rouge, LA 70802. This is not a work from home position.', 'Our Motto: Right Time, Right Place, Change the World.', 'Check us out on Youtube: http://ibm.biz/BatonRougeCIC', 'Skill development: helping our employees grow their foundational skills', 'Finding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations', 'Diversity of people: Diversity of thought driving collective innovation', 'http://www.ibm.com/ibm/responsibility/initiatives.html', 'http://www.ibm.com/ibm/responsibility/corporateservicecorps', 'You’re great at solving problems by looking at thing differently, debugging, troubleshooting, and designing & implementing solutions to complex technical issues.', 'You thrive on teamwork and have excellent verbal and written communication skills.', 'Strong fundamentals in Mathematics and Computer Science (algorithms)', 'You have strong technical and analytical abilities, a knack for driving impact and growth, and some experience with programming/scripting in a language such as Java or Python.', ""You're proficient at least one of the statistical programming language such as R, Python, or Scala"", 'You have an interest in, understanding of, or experience with Design Thinking and Agile Development Methodologies', 'You have a basic understanding of Cloud (AWS,Azure, etc)', ""Bachelor's in Computer Science, Data Science, Math, Statistics or related areas preferred"", 'Tableau knowledge preferred', 'PowerBI experience preferred', 'Data warehousing and ETL experience a plus!', 'Hadoop (Hbase, Hive, Mapreduce) preferred', 'Knowledge of SQL preferred', 'Cloud platform exposure (especially AWS) preferred']",2020-09-24 13:28:59
Data Engineer,HASH,2.5 out of 5,Remote,[],2020-09-24 13:28:59
Data Engineer,"Attain, LLC",3.6 out of 5,"McLean, VA 22102","['Passion Seekers. You genuinely care about the work that you do and its impact on society.', 'Self-Starters. You’re a go-getter who isn’t afraid to step up and disrupt the status quo.', 'Entrepreneurs. You bring fresh ideas to the table, work hard, develop business and consistently seek new challenges.', 'Collaborators. You’re a great contributor to a high performing team that accomplishes great feats for our clients.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Establish performance monitoring of databases and create data pipeline architecture', 'Manage data life cycle from transactions to reporting to archival of data', ""Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies"", 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', '5 years of proven expertise in relational and dimensional data modelling', '5 years in modern data development, upgrading, support and design.', 'Proven experience in leading data teams on data migration and transformation', 'Experience in establishing performance and statistical monitoring of enterprise databases to include, but not limited to; wellness checks, data integrity, privacy and security scans.', 'Experience in supporting cloud database environments, specifically AWS (i.e., EC2, S3, Neptune or Redshift) to include backup and archiving of data.', 'Good to have experience with data lakes implementations', 'Should be able to work early morning hours i.e. 6 am to 2 pm (US Eastern Time) for atleast 2-3 days a week', 'Experience with Apache NiFi is desired', 'Experience with OpenText Captiva is desired.']",2020-09-24 13:28:59
Research Data Engineer,Galaxy Tek Hires,N/A,"Chicago, IL","['Design, develop, test, and deploy elegant software solutions across the firm to support critical investment decisions', 'Partner with business leaders, quantitative researchers and technologists to define priorities and deliver custom solutions', 'A deep passion for working with data and developing software to address data processing challenges', 'Minimum of a bachelor’s degree in Computer Science or equivalent experience with good software design and engineering skills', 'Proficiency within one or more programming languages including Python, C, C++, R and/or JavaScript is a plus', 'Proficiency with multiple data platforms including RDBMS, NoSQL, MongoDB, Spark, Hadoop', 'Experience with some of the following areas: Distributed Computing, Natural Language Processing, Machine Learning, Cloud Platform Development, Networking, and/or REST Service Development', 'Good analytical and quantitative abilities', 'Demonstrated ability to quickly learn new technologies and skills', 'Ability to manage multiple tasks and thrive in a fast-paced team environment']",2020-09-24 13:28:59
Entry Level Associate Data Engineer - CIC Baton Rouge,IBM,3.9 out of 5,"Baton Rouge, LA 70802","['Health Insurance.', 'Paid time off.', 'Implement and validate predictive models as well as create and maintain statistical models with a focus on big data.', 'You’ll incorporate a variety of statistical and machine learning techniques', 'Communicate with internal and external clients to understand and define business needs, providing analytical solutions.', 'Use leading edge tools such as Linux, SQL, Python, Spark, Hadoop, Java, and Cloud Vendors such as AWS, Azure, etc.', 'Work in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.', 'Build teams or writing programs to cleanse and integrate data in an efficient and reusable manner, developing predictive or prescriptive models, and evaluating modeling results', 'Ask business and industry questions to identify appropriate modeling techniques', 'Communicate results to technical and non-technical audiences', 'The IBM Client Innovation Center is an in-bound delivery model where we support our clients from our Baton Rouge center (aka: we work in a traditional IBM Agile office setting).', 'Travel is expected and all candidates must be willing and able to travel to meet our client needs across the US. Travel is typically related to knowledge transfer and training at the client site (Monday thru Friday). You are expected to travel approximately 50% of the time.', 'You must live in, or be willing to relocate to, LOUISIANA. The work location is 100 North St, Baton Rouge, LA 70802. This is not a work from home position.', 'Our Motto: Right Time, Right Place, Change the World.', 'Check us out on Youtube: http://ibm.biz/BatonRougeCIC', 'Skill development: helping our employees grow their foundational skills', 'Finding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations', 'Diversity of people: Diversity of thought driving collective innovation', 'http://www.ibm.com/ibm/responsibility/initiatives.html', 'http://www.ibm.com/ibm/responsibility/corporateservicecorps', 'You’re great at solving problems by looking at thing differently, debugging, troubleshooting, and designing & implementing solutions to complex technical issues.', 'You thrive on teamwork and have excellent verbal and written communication skills.', 'Strong fundamentals in Mathematics and Computer Science (algorithms)', 'You have strong technical and analytical abilities, a knack for driving impact and growth, and some experience with programming/scripting in a language such as Java or Python.', ""You're proficient at least one of the statistical programming language such as R, Python, or Scala"", 'You have an interest in, understanding of, or experience with Design Thinking and Agile Development Methodologies', 'You have a basic understanding of Cloud (AWS,Azure, etc)', ""Bachelor's in Computer Science, Data Science, Math, Statistics or related areas preferred"", 'Tableau knowledge preferred', 'PowerBI experience preferred', 'Data warehousing and ETL experience a plus!', 'Hadoop (Hbase, Hive, Mapreduce) preferred', 'Knowledge of SQL preferred', 'Cloud platform exposure (especially AWS) preferred']",2020-09-24 13:29:41
Data Engineer,HASH,2.5 out of 5,Remote,"['Competitive salary and equity: commensurate with experience and incentive-aligned ✅', '28 days annual holiday including company holidays', 'A range of location-specific benefits, including access to a 401(k) and fully comprehensive health insurance and a fully funded Health Savings Account (HSA) for US-based employees, as well as free annual NYC MetroCards and (truly) infinite caffeine for those working from our Manhattan office.']",2020-09-24 13:29:41
Data Engineer,"Attain, LLC",3.6 out of 5,"McLean, VA 22102","['Passion Seekers. You genuinely care about the work that you do and its impact on society.', 'Self-Starters. You’re a go-getter who isn’t afraid to step up and disrupt the status quo.', 'Entrepreneurs. You bring fresh ideas to the table, work hard, develop business and consistently seek new challenges.', 'Collaborators. You’re a great contributor to a high performing team that accomplishes great feats for our clients.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Establish performance monitoring of databases and create data pipeline architecture', 'Manage data life cycle from transactions to reporting to archival of data', ""Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies"", 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', '5 years of proven expertise in relational and dimensional data modelling', '5 years in modern data development, upgrading, support and design.', 'Proven experience in leading data teams on data migration and transformation', 'Experience in establishing performance and statistical monitoring of enterprise databases to include, but not limited to; wellness checks, data integrity, privacy and security scans.', 'Experience in supporting cloud database environments, specifically AWS (i.e., EC2, S3, Neptune or Redshift) to include backup and archiving of data.', 'Good to have experience with data lakes implementations', 'Should be able to work early morning hours i.e. 6 am to 2 pm (US Eastern Time) for atleast 2-3 days a week', 'Experience with Apache NiFi is desired', 'Experience with OpenText Captiva is desired.']",2020-09-24 13:29:41
Research Data Engineer,Galaxy Tek Hires,N/A,"Chicago, IL","['Design, develop, test, and deploy elegant software solutions across the firm to support critical investment decisions', 'Partner with business leaders, quantitative researchers and technologists to define priorities and deliver custom solutions', 'A deep passion for working with data and developing software to address data processing challenges', 'Minimum of a bachelor’s degree in Computer Science or equivalent experience with good software design and engineering skills', 'Proficiency within one or more programming languages including Python, C, C++, R and/or JavaScript is a plus', 'Proficiency with multiple data platforms including RDBMS, NoSQL, MongoDB, Spark, Hadoop', 'Experience with some of the following areas: Distributed Computing, Natural Language Processing, Machine Learning, Cloud Platform Development, Networking, and/or REST Service Development', 'Good analytical and quantitative abilities', 'Demonstrated ability to quickly learn new technologies and skills', 'Ability to manage multiple tasks and thrive in a fast-paced team environment']",2020-09-24 13:29:41
Data Warehouse Engineer,"Groupon, Inc.",3.6 out of 5,"Chicago, IL 60654","['Perfect best practices for data visualization design, workflow optimization, and analyst’s tools', 'Enabling analysts through education of technical and soft skills', 'Growing a community spirit within analytics throughout Groupon', 'Identifying, collaborating and developing dashboards in internal consulting efforts', 'Collaborating and developing / maintaining data tools', 'Mentoring analysts', 'Drive the discussion and decisions of topics related to data visualization, analyst’s tools, data, and optimizing the processes of analysts at Groupon', 'Creative problem solving with analysts', 'Working knowledge of SQL and using databases for data retrieval such as Snowflake, Dremio, Teradata, Hive, Tableau, ETL tools', 'Working knowledge of Tableau or an equivalent data visualization tool where you can bring across the concepts', 'Excellent knowledge of data visualization design', 'SQL skills', 'Good communication and collaboration skills', 'Customer-focused: We believe that doing what’s right for the customer is ultimately what will drive our business forward.', 'Obsessed with quality: Your production code just works & scales linearly', 'Team players. You believe that more can be achieved together. You listen to feedback and also provide supportive feedback to help others grow/improve.', 'Fast learners: We are willing to disrupt our existing business to trial new products and solutions. You love learning how to use new technologies and then rapidly apply them to new problems.', 'Pragmatic: We do things quickly to learn what our customers desire. You know when it’s appropriate to take shortcuts that don’t sacrifice quality or maintainability.', 'Owners: Engineers at Groupon know how to positively impact the business.']",2020-09-24 13:29:41
Machine Learning Engineer,Octi,N/A,"Los Angeles, CA","['$100,000.00 - $139,999.00 per year', 'Benefits:', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Professional development assistance', 'Work with other Machine Learning Engineers to build and improve networks for on device use', 'Develop algorithms to supplement and improve the networks on device', 'Collect and evaluate training data', 'Improve the on device performance of networks', 'Up to date with current Machine Learning developments', 'Strong communication and time management skills', 'Ability to work in a fast moving focused team', 'Bachelor’s Degree in computer science or similar', 'Experience building Machine Learning networks for object detection, segmentation, classification, tracking and recognition.', 'Experience with deep learning frameworks such as Keras, Tensorflow, CoreML PyTorch or similar.', 'Strong coding and algorithms skills in Python and C++', 'Strong background of applied Mathematics', ""Master's or PhD in Machine Learning or similar"", 'Experience developing real time networks for mobile devices', 'Experience collecting and building datasets for commercial use', 'Experience in 3D Computer Vision', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Professional development assistance', '8 hour shift', 'Monday to Friday', 'Machine Learning: 1 year (Preferred)', 'Fully Remote']",2020-09-24 13:29:41
Clinical Solutions Engineer (Fully Remote Position),"Curebase, Inc.",N/A,"San Francisco, CA","['$45,000.00 - $60,000.00 per year', 'Benefits:', '401(k)', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Bridge the needs of our customers with our technology team', 'Attend customer meetings and explain technical product aspects', 'Create technical requirements for each of our clinical trials and look for technology gaps', 'Work directly with both our client-facing project managers and our engineers', 'Configure the Curebase software platform for each clinical trial protocol we run', 'Devise custom technology solutions and collaborate with our software engineering team to ship them', 'Drive and develop the integrations of data from technology partners into our system', 'Act as the official Data Manager on specific clinical trials', 'Passionate about clinical and medical research', 'Some background in the clinical research world', 'Have technology skills including SQL and Javascript', 'Have amazing communication skills and be able to speak with both customers and engineers', '401(k)', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Monday to Friday', 'Fully Remote', 'curebase.com', 'Yes']",2020-09-24 13:29:41
Data Engineer (SQL),data.world,N/A,"Austin, TX 78731","['Collaborate with business groups at data.world to ask thoughtful questions and gather requirements around key insights and reporting needs.', 'Engineer lasting solutions that turn application data and streaming events into self-service reports and insights.', 'Develop and maintain a suite of production SQL data models using DBT to transform our streaming and transactional data into a form suitable and efficient for analytics and data science work.', 'Administer and optimize our Snowflake data warehouse and BI infrastructure.', 'Evolve our star schema and data flows to ensure utility and performance. Diagram and document as needed to support understanding and troubleshooting.', 'Write and maintain SQL jobs in support of ETL/ELT and BI analysis, reporting, and visualization, as well as ability to troubleshoot SQL jobs as required.', 'Build and maintain internal data catalog including data dictionaries, glossary, and curated datasets in support of easy self-service by the rest of the company.', 'Develop BI data reports, visualizations, and queries to support measuring our KPIs and supporting the success of our SaaS business.', 'Implement new productized data and analytics capabilities in support of customers understanding their usage and improving data governance.', 'Conduct evidence-based investigations and draw actionable conclusions in support of company and team goals and overall product success.', 'Be a steward and evangelist for data driven culture and data best practices within the company.', 'Be customer zero, leveraging our product and providing feedback as one of the key target users that data.world is actually intended for.', '5+ years of SQL experience with ability to write and tune SQL jobs for a variety of usage patterns', '5+ years of experience working with BI or data warehouse technologies in support of insights and reporting', 'Strong data modeling experience, for example ETL, ELT, star schema, and other data model and data warehouse concepts, techniques, and best practices', 'Strong interpersonal skills and experience interfacing with others internally and externally from the company', 'Good data visualization skills and ability to choose the best way to present information', 'Good communication and presentation skills with the ability to explain concepts and conclusions around data and insights in a clear, concise, and compelling way', 'Experience working with and administering Snowflake or another similar cloud SQL data warehouse technology', 'Experience working with Tableau, Looker, or other modern data visualization tools', 'Computer Science degree or equivalent software engineering experience', 'Experience with DBT and/or Python', 'Experience working in for SaaS or enterprise software companies in the data or analytics space']",2020-09-24 13:29:41
Pricing Data Engineer,Lenovo,3.9 out of 5,"Morrisville, NC",[],2020-09-24 13:29:41
Data Center Hardware Engineer I,General Dynamics Information Technology,3.8 out of 5,"Manassas, VA 20109",[],2020-09-24 13:29:41
"Engineer, Data (Bank Charter)",SoFi,3.2 out of 5,"Seattle, WA","['Competitive salary packages and bonuses', 'Comprehensive medical, dental, vision and life insurance benefits', 'Generous vacation and holidays', 'Paid parental leave for eligible employees', '401(k) and education on retirement planning', 'Tuition reimbursement on approved programs', 'Monthly contribution up to $200 to help you pay off your student loans', 'Great health & well-being benefits including: telehealth parental support, subsidized gym program', 'Employer paid lunch program (except for remote employees)', 'Fully stocked kitchen (snacks and drinks)', 'Build and modify data pipelines via Extract, Transform, Load (ETL) processes', 'Provision, optimize and maintain data feeds to external systems', 'Write SQL queries to validate quality and clean existing data', 'Build out automated checks and work within the team for data quality', 'Help analytics team and business users in querying and understanding the Data Warehouse', ""Bachelor's degree"", '2+ years industry experience', 'Experience writing SQL against different database platforms and advising best practices along the way', 'Demonstrated skills and experience in finding, investigating, and resolving data quality issues', 'Demonstrated skills and experience in building data feeds and business reports', 'Self-motivated', 'Ability to bring new ideas and promote process improvement', 'Experience with reporting systems such as Tableau', 'An interest to learn Python', 'First-rate attention to detail', 'Ability to thrive in a fast-paced growing company', 'Ability to drive a project from inception to completion', 'Enthusiasm for solving challenging problems', 'Team attitude: a willingness to roll up your sleeves, work with others and get stuff done', 'Ability to work quickly and accurately under pressure', 'Competitive salary packages and bonuses', 'Comprehensive medical, dental, vision and life insurance benefits', 'Generous vacation and holidays', 'Paid parental leave for eligible employees', '401(k) and education on retirement planning', 'Tuition reimbursement on approved programs', 'Monthly contribution up to $200 to help you pay off your student loans', 'Great health & well-being benefits including: telehealth parental support, subsidized gym program', 'Employer paid lunch program (except for remote employees)', 'Fully stocked kitchen (snacks and drinks)']",2020-09-24 13:29:41
Python Data Engineer,Accenture,4 out of 5,"New York, NY 10011","['We are seeking a Python Data Engineer our client in New York City, NY', 'This is a contract opportunity that does not offer sponsorship nor in the future', 'Must be willing to work on W2', 'Full stack development including triage, design, coding and implementation', 'Plan and implement procedures that will maximize operating efficiency for application integration technologies, this includes managing the evolution and maturity in agile delivery, automating and improving development operational processes and engineering (Dev Ops)', 'Perform code reviews with scrum teams to approve for Production deployment', 'Conduct research to identify new solutions and methods to fulfill diverse and evolving business needs', 'Establish/Improve/Maintain Proactive monitoring and management of supported assets assuring performance, availability, security, and capacity', 'Identify and drive process improvement opportunities', 'Maintains a strong and collaborative relationship with delivery partners and business stakeholders', 'Minimum 3+ Years of Python Development experience', 'AWS Development', 'Kubernetes/OpenShift Development', 'SQL', 'Python Data Engineer']",2020-09-24 13:29:41
Junior Full Stack Growth Engineer,Betterment LLC,N/A,United States,"['Collaborate, with purpose. You’ll work in small groups with other talented thinkers and figure out how to make Betterment’s revolutionary software even better for prospective customers.', 'Work with people who care. Almost half of our team is made up of engineers, but we believe everyone at Betterment is an engineer with their own tools. We’re a group of talented professionals who pride ourselves on what we do. We’re smart, innovative, energetic, and lots of fun.', 'Empower our brand and advice teams to engage prospective users and provide informative content in a self service manner.', 'Invest in tools that allow our CRM team to talk to our customers in the best possible way.', 'Work with marketing and analytics to decide how to best reach potential customers with the most impact.', 'Create experiences on our brochure site that explain how Betterment works in accessible and interactive fashion.', 'Build features that allow new customers to set their accounts up efficiently and learn strong investing behaviors without any guesswork.', 'Interest in learning marketing and growth technology; understanding of our existing platform landscape and how to optimize it.', 'Experience in at least one server-side language - Ruby, Java, C#, C++, Python. We build our apps in Ruby on Rails and PHP', 'Interest in building interactive web applications using modern Javascript frameworks. We use Stimulus and React to create delightful experiences', 'Experience implementing third-party tools and integrating them in first-party applications.', 'A desire to be a good internet citizen. Prioritization of accessibility and performance when building web experiences.', 'Ability to make the tradeoffs required to ship without compromising quality', 'Ability to thrive in a startup environment', 'You’ll join a Community:', 'You’ll stay Happy and Healthy:', 'You’ll Learn & Grow:']",2020-09-24 13:29:41
Data Engineer-Master Data Management,IBM,3.9 out of 5,California,[],2020-09-24 13:29:41
Data Engineer (Contract),Unite Us,5 out of 5,New York State,"['Execute a data architecture and infrastructure to meet business objectives', 'Work closely with Solutions Architects and Product Managers to make sure that the technical infrastructure can support client requirements', 'Develop ETL and data pipeline solutions to load data warehouse', 'Test internal data pipelines for reliability and performance', 'Experience as a Data Engineer in which you set up data pipelines', 'Experience using and building solutions to support various reporting and data user tools (Chartio, Tableau, Looker, etc)', 'Experience with Spark using Scala and Python.', 'Experience working with data warehouses, data lakes and ETL pipelines (Snowflake, Infomatica, Redshift, Postgres, SQL, etc)', 'Experience setting up an maintaining databases within AWS', 'Experience working on applications serving large enterprise clients', 'Experience working on healthcare and/or social determinants of health data products', 'A focus on building performant systems', 'Ability to think forward and build a scalable solution that satisfies various needs of enterprise clients with dedicated data teams', 'This position is remote']",2020-09-24 13:29:41
Senior Data Engineer,IT America,N/A,Remote,"['Pay:', '$87,946.00 - $194,120.00 per year', 'Understanding of Meta Data & Master Data Management concepts & practices', 'Experience working with enterprise data stores, data lakes, external data sources and APIs', 'Experience working with remote teams spread across the globe', 'Experience with broad set of analytics use cases; one or more of supply-chain, transportation, sales and operations', 'AWS: 1 year (Preferred)', 'Data Engineer: 5 years (Preferred)', 'Python: 1 year (Preferred)', 'ETL: 1 year (Preferred)', 'Yes']",2020-09-24 13:30:22
Data Engineer (Data Concepts & Data Modelling ),Youth Power Technosoft LLC,N/A,"Upper Providence, PA","['Pay:', '$55.00 - $60.00 per hour']",2020-09-24 13:30:22
Data Engineer (USA),ITTStar Consulting LLC,N/A,United States,"['$ 50/ Hourly/ W-2', '40h / week', 'United States America', 'full time', '$ 50/ Hourly/ W-2', '40h / week', '3 years experience', 'Master or Bachelor', 'Skills RequiredPrimary Skills :- AWS, EC2, EMR, Glue, Lambda, Python, Redshift, S3, SparkSecondary Skills :- Hadoop, HBase, Hive', 'M.E/M.Tech/B.E/B.Tech/MCA/MSc or similar 4 or 4+ years degree in relevant field.', 'At least 3+ years of hands on experience onAWS [S3, EC2, ECS, EMR, GLUE, Redshift, Lambda, Dynamo DB , Kinesis, RDS, Data Pipeline etc]', 'At least 3+ years of hands on experience with Big Data stack includingSparkHadoopHiveKafkaHBase or other NoSQL solutions', 'Strong knowledge and handson experience in writing highly optimized and if required complex queries. [Oracle/Postgres /MySQL/ SQLServer etc]', 'Strong Python Programming knowledge from Data Engineering perspective. Good knowledge on libs likePandasNumpyMatlabplotSeabornScikitLearn etc', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with unstructured datasets', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets', 'Strong project management and organizational skills.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Good Communication Skills.']",2020-09-24 13:30:22
Data Engineer,Techno Tasks Inc,N/A,"St. Louis, MO","['Pay:', '$50.00 per hour', 'This project is all about Data Pipelining for marketing work for Card LOB.', 'Need to have strong exp on Data Engineering and AWS.', 'They need to have solid understanding of Big Data Concepts and how to do manipulation of data.', 'Must Have – AWS (EMR clusters), Scala(development) & Python(Scripting is good but Development is preferred).', 'Entire code is written in Scala.', '2+ yrs of Scala development and Overall 5+yrs of experience as Software Engineer.', 'Candidate needs do some Production Support and Enhancement of Data jobs.', 'Spark', 'Building pipelines and marketing metrics', 'EMR: 2 years (Preferred)', 'Apache Spark: 3 years (Preferred)', 'Scala: 2 years (Preferred)', 'Data Engineer: 5 years (Preferred)', 'Python: 2 years (Preferred)', 'Temporarily due to COVID-19']",2020-09-24 13:30:22
Cyber Associate Data Engineer,New York City DEPT OF INFO TECH & TELECOMM,3.8 out of 5,"Manhattan, NY 10005","['Developing and maintaining our data pipeline using Apache Beam, Java, Python and other data processing technologies;', 'Identifying and implementing performance improvements across all pipelines;', 'Engaging with data consumers and producers in order to design appropriate models to suit all needs;', 'Maintaining information exchanges through publish, subscribe, and alert functions that enable users to send and receive critical information as required;', 'Supporting incident management, service-level management, change management, release management, continuity management, and availability management for databases and data management systems;', 'Administering databases and/or data management systems that allow for the secure storage, query, protection, and utilization of data.', 'A bachelor’s degree in computer science or information systems with a specialization in mathematics, number; theory, applied cryptography, or statistics or relevant experience;', 'Experience with the Agile Development Methodology;', 'Expert knowledge in both Java and Python;', 'Familiarity with Unix scripting, Web development, and automated testing;', 'Familiarity with machine learning techniques and machine learning toolkits such as R, scikit-learn, etc;', 'Experience working with Terraform;', 'Familiarity with the CI/CD process,', 'At least one year professional, academic, or personal experience with software development or data engineering experience (includes internship experience);', 'At least 1 year professional, academic, or personal experience with object-oriented/object function scripting languages; preferably java or python;', 'Familiarity with or exposure to cloud application development;', 'Familiarity with distributed data processing frameworks.', 'Interested applicants with other civil service titles who meet the preferred requirements should also submit a resume for consideration']",2020-09-24 13:30:22
Big Data Engineer,"Turnberry Solutions, Inc",N/A,"Los Angeles, CA",[],2020-09-24 13:30:22
Data Engineer,Campus Crusade for Christ,4.4 out of 5,"Orlando, FL 32832","['Supporting data analysts, data scientists, and other data consumers to provide them with large, complex, decision-making datasets', 'Creating, scheduling, maintaining, and debugging ETL and ELT processes', 'Data cleansing and data wrangling to prepare structured and unstructured data for various modes of consumption including AI, ML, statistical models, analysis, dashboards, etc.', 'Gathering specific requirements and suggesting solutions', 'Providing mentoring to less senior engineers in coding best practices and problem solving', 'Troubleshooting and debugging', 'Optimizing performance', 'Staying up-to-date with new technology trends', 'Getting Hands on Training from Senior Team Members', 'Getting Training through Conferences', 'Drinking & Making Coffee', 'Going to Company Parties', 'Proven experience as a Data Engineer', 'Extensive experience working with Enterprise databases and ETL tools', 'Strong technical expertise with complex ETL/ELT flows and data pipelines', 'In-depth knowledge of modern programming languages and platforms like Python, Oracle, Google Cloud Platform, R, SQL, Scala', 'Comprehensive knowledge of Modern Data Warehouse design principles and architecture', 'Proficiency in Data Modeling principles', 'Ability to perform in a team environment and yet work independently', 'Strong project management skills, including the ability to work independently and coordinate and prioritize multiple tasks', 'Excellent oral and written communication', 'Must have a high level of interpersonal skills to handle sensitive/confidential situations and information', 'Apache Airflow or GCP Composer', 'Geospatial queries', 'Snowplow', 'Deep love for Jesus Christ', 'Deep desire to share the Gospel with the world', 'Willingness to receive and respond to feedback (it’s not personal)', 'Living in or willing to relocate to Orlando, Florida', 'BS degree in Computer Science or relevant field', 'High School Diploma']",2020-09-24 13:30:22
Streaming Data Engineer,Cisco Systems,4.1 out of 5,"San Jose, CA",[],2020-09-24 13:30:22
Entry Level Data Engineer Position,Jerneltechcorp,N/A,"New York, NY","['Pay:', '$55,000.00 - $65,000.00 per year', 'Employee assistance program', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Parental leave', 'Professional development assistance', 'We are looking for a passionate Data Engineer to turn data into information, information into insight and insight into business decisions.', 'You will conduct full life cycle activities to include requirements analysis and design, develop analysis and reporting capabilities, and continuously monitor performance and quality control plans to identify improvements.', 'We are seeking an entry level Data Engineer . In this exciting role, you will be responsible for the following:', 'Expert level proficiency with data analysis tools like SQL, MSBI, POWER BI ,concept and knowledge of Excel, concept and knowledge of NumPy, Map, Filters, Pandas, Seaborn, Functions.', 'Technical background and solid programming experience.', 'Fluency in data analysis and communication around data with advanced data visualization abilities using Power BI and Python Data Structure along with Cleaning Data, Conditional Statements & Loops.', 'Proven track record of using data to generate insight and drive business results.', 'Statistics knowledge and hypothesis testing experience.', 'Basic understanding of probability and statistical models (generative and descriptive models).', 'Ability to run experiments scientifically and analyze results.', 'Strong written and verbal communication skills', 'Ability to collaborate effectively across multiple teams and stakeholders, including analytics teams, development teams, product management and operations.', 'Hands-on experience in using data to generate insight and drive business results.', 'Expert knowledge in SQL, MSBI and Power BI.', 'Statistics knowledge and hypothesis testing experience.', 'Experience with Performance Engineering including testing, tuning and monitoring tools', 'Bachelors’ or above in quantitative discipline: Statistics, Applied Mathematics, Economics, Computer Science, Engineering, or related field; Master’s degree Preferred.', 'Uses several techniques to solve complex problems where analysis of situations or data requires a review and analysis of several factors.', 'May lead the implementation of tactical plans in support of strategic initiatives.', 'Receives objectives and determines approach to achieving objectives.', 'Accountable for the achievement of operational goals in at least one department or work area.', 'Integrates customer/client needs and concerns with business issues.', 'Serves as an advocate for client.', 'Serves as a liaison on specific projects with other work areas.', 'Influences, inspires or persuades others in order to accomplish work objectives.', ""Bachelor's degree or equivalent education and relevant experience."", 'Possesses detailed knowledge of one technology or professional discipline, or basic knowledge of several areas.', 'Experience working with data (customer data or databases).', 'Employee assistance program', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Parental leave', 'Professional development assistance', 'Relocation assistance', 'Monday to Friday', ""Bachelor's (Required)""]",2020-09-24 13:30:22
Entry Level Associate Data Engineer - CIC Baton Rouge,IBM,3.9 out of 5,"Baton Rouge, LA 70802","['Health Insurance.', 'Paid time off.', 'Implement and validate predictive models as well as create and maintain statistical models with a focus on big data.', 'You’ll incorporate a variety of statistical and machine learning techniques', 'Communicate with internal and external clients to understand and define business needs, providing analytical solutions.', 'Use leading edge tools such as Linux, SQL, Python, Spark, Hadoop, Java, and Cloud Vendors such as AWS, Azure, etc.', 'Work in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.', 'Build teams or writing programs to cleanse and integrate data in an efficient and reusable manner, developing predictive or prescriptive models, and evaluating modeling results', 'Ask business and industry questions to identify appropriate modeling techniques', 'Communicate results to technical and non-technical audiences', 'The IBM Client Innovation Center is an in-bound delivery model where we support our clients from our Baton Rouge center (aka: we work in a traditional IBM Agile office setting).', 'Travel is expected and all candidates must be willing and able to travel to meet our client needs across the US. Travel is typically related to knowledge transfer and training at the client site (Monday thru Friday). You are expected to travel approximately 50% of the time.', 'You must live in, or be willing to relocate to, LOUISIANA. The work location is 100 North St, Baton Rouge, LA 70802. This is not a work from home position.', 'Our Motto: Right Time, Right Place, Change the World.', 'Check us out on Youtube: http://ibm.biz/BatonRougeCIC', 'Skill development: helping our employees grow their foundational skills', 'Finding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee’s strengths and career aspirations', 'Diversity of people: Diversity of thought driving collective innovation', 'http://www.ibm.com/ibm/responsibility/initiatives.html', 'http://www.ibm.com/ibm/responsibility/corporateservicecorps', 'You’re great at solving problems by looking at thing differently, debugging, troubleshooting, and designing & implementing solutions to complex technical issues.', 'You thrive on teamwork and have excellent verbal and written communication skills.', 'Strong fundamentals in Mathematics and Computer Science (algorithms)', 'You have strong technical and analytical abilities, a knack for driving impact and growth, and some experience with programming/scripting in a language such as Java or Python.', ""You're proficient at least one of the statistical programming language such as R, Python, or Scala"", 'You have an interest in, understanding of, or experience with Design Thinking and Agile Development Methodologies', 'You have a basic understanding of Cloud (AWS,Azure, etc)', ""Bachelor's in Computer Science, Data Science, Math, Statistics or related areas preferred"", 'Tableau knowledge preferred', 'PowerBI experience preferred', 'Data warehousing and ETL experience a plus!', 'Hadoop (Hbase, Hive, Mapreduce) preferred', 'Knowledge of SQL preferred', 'Cloud platform exposure (especially AWS) preferred']",2020-09-24 13:30:22
Design Engineer,JBT Corporation,3.2 out of 5,"Columbus, OH 43232","['Maintain engineering data for assigned projectsIncludes drawings and 3D data for Production and Manuals', 'Design and detail parts and assemblies', 'Gather and report test data', 'Create and maintain BOM(s) in PDM and NAV', 'Review and act upon engineering change requests', 'Communicate with field—service, sales, customers', 'New MachinesSupport R&D to determine scope and parametersTravel to test/demo site, gather data, consult with customerDevelop training documentsExisting Machines - Implement design changes and improvements', 'Develop Engineering Approval documents and Checkoff Sheets for Order Processing and Quality Control', 'Maintain communication with operations, production and assembly during the manufacturing process', 'Check parts for quality during manufacturing process', 'Maintain vendor contacts', 'Understand manufacturing capabilities of PRIME and local vendors', 'Provide technical assistance to Service when required', 'Assist in development of Technical Service Bulletins (TSBs) as required', 'Follow PRIME Engineering Design Standards', 'Document project related hours', 'Lead design reviews for equipment prior to releasing for production', 'Assess designs for compliance to safety standards and sanitary design', 'Bachelor’s Degree in Mechanical Engineering or equivalent experience', '5 Years’ experience designing SS Food Processing Equipment']",2020-09-24 13:30:22
Data Engineer,Vertava Health,N/A,"Nashville, TN 37203","['401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Vision insurance', 'Collaborating directly with business and technology departments to define future-state business capabilities & requirements, and translating those into transitional and target state data architectures', 'Analyzing the current technology environment to detect critical deficiencies, and recommend solutions for improvement', 'Designing, implementing, and maintaining data warehouses and near real-time data pipelines via the practical application of existing and new data engineering techniques', 'Developing continuous integration and continuous deployment pipelines for data solutions that include automated unit & integration testing', 'Mentoring, motivating, and supporting the team to achieve organizational objectives and goals', 'Advocating for agile practices to increase delivery throughput', 'Ensuring consistency with published development, coding and testing standards', 'Bachelor degree in Computer Science, Mathematics, or related fields', '4+ years of data engineering, schema design, dimensional data modeling, and / or data management experience', 'MDM (Master Data Management) Experience a plus, such as Master Data Services or equivalent technology', 'Proficient with data management tools and languages[3] , such as Python, SQL, Java, and use of Git', 'Demonstrated experience with extracting, cleaning, managing, optimizing, and exploiting large and very complex data sets', 'Experience with best practices for compute, storage, and transfer optimization in processing large volumes of data', 'Can perform data discovery', 'Experience with salesforce.com reporting and integration projects', 'Experience building in Microsoft BI Toolsets (SSRS/SSAS/SSIS/Power BI[4] )', 'Experience on data warehouse / data lake projects', 'Experience with Azure preferred (Azure Data Factory, Azure Analysis Services)', 'Ability to sit, use hands and fingers, talk and hear continually. Ability to stand, walk and reach continually. Ability to climb or balance, stoop, kneel, or crouch frequently.', 'Ability to frequently lift and carry up to 20 lbs.', 'Close vision required to see computer monitor, read documents, and operate copy and fax machine.', 'Work environment is indoors and climate controlled. Occasionally exposed to outdoor weather conditions.', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Vision insurance']",2020-09-24 13:30:22
Diagnostic Engineer/Writer,GGS Information Services,4 out of 5,"Moline, IL","['GGS offers a competitive salary and benefits package, including medical, dental and vision benefits, as well as a 401(k) plan with company match and tuition reimbursement.', 'M/W/D/V).', 'Pay:', '$20.00 - $24.00 per hour', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Professional development assistance', 'Tuition reimbursement', 'Authorstechnical documentation and diagnostic service procedures from source material gathered from engineeringresources and/or develops automotive/heavy equipment troubleshooting, operatorand maintenance manuals.', 'Musthave a technical understanding of machine operating principles for electricaland/or hydraulic systems.', 'Accuratelydevelops system specific diagnostics and electrical service procedures usingclient supplied information.', 'Interfaceswith engineers, technical writers, product specialists and technicians.', 'Abilityto interpret blueprints and detailed engineering specifications is required.', 'Mustbe proficient with a personal computer and various software including desktoppublishing, spreadsheet, word processing, illustration, and database programs.', 'Strict adherence to using QualityAssurance Plans and Standard Operating Procedures.', 'RequiresAssociates degree (minimum), in addition to vocational, career, or relatedtechnical studies in technical writing, automotive repair or other engineeringdiscipline, preferably with hands-on automotive/agriculture repair experience.', 'Experienced in developing diagnostic information for automotive service industry or industry equivalent.', 'Familiaritywith heavy truck engine, agriculture and vehicle product lines is desirable.', 'Experiencein developing diagnostic information for heavy equipment/agriculture serviceindustry is desirable.', 'Experience in desktop publishingsoftware including Arbortext, FrameMaker and/or InDesign is desirable.', 'Extremely well organized and must beextremely detailed oriented.', '""High visibility""position--must have expert communication and computer skills and the ability toeffectively work with internal and external customers.', 'Can multi-task and be flexible to workwhen “peak” volume periods are encountered.', 'Must be able to work to establishedprogram schedules, provide reports, and coordinate with global suppliers on an as-neededbasis.', 'Must be willing to travel occasionally.', 'Excel: 1 year (Preferred)', 'Word: 1 year (Preferred)', 'Associate (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Flexible schedule', 'Parental leave', 'Professional development assistance', 'Tuition reimbursement', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Autonomous/Independent -- enjoys working with little direction', 'Monday to Friday']",2020-09-24 13:30:22
Lead Manufacturing Engineer,"Vickers Engineering, Inc.",N/A,"New Troy, MI 49119","['$70,000.00 - $80,000.00 per year', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'CNC Setup: 3 years (Preferred)', 'United States (Required)', 'One location', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Flexible schedule', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'Team-oriented -- cooperative and collaborative', 'Monday to Friday', 'Day shift']",2020-09-24 13:30:22
Graduate - Data Engineer,Rio Tinto,3.9 out of 5,"Boron, CA 93596","['A competitive salary package with annual cash incentive awards (STIP) for eligible employees', 'Career development & education assistance to further your ambitions', 'Access to top tier family-friendly health and medical programs', 'Excellent retirement plan including 6% defined company contribution', 'Generous 401k matching program', 'A comprehensive leave policy that covers all moments that matter in life (vacation/annual, paid parental leave, short term sick leave, paid holidays)', 'Ongoing individual wellbeing support for you and your family for personal and professional matter', 'Join one of the largest mining and metal companies in the world, focused on safety and inclusion', 'Work with the newest technology and innovation, in an environment where we challenge you to drive positive change', 'Start your career and be part of our prestigious Graduate Development Program', 'Discovery of new data sources and conducting exploratory analysis based on prioritized business objectives', 'MS SQL DDL, ETL Development, and Data Warehousing', 'Report and dashboard development using Power BI and other applicable platforms', 'Support and development of existing operational data systems, relevant documentation management, and data stewardship', 'Recommending methods and performing various analyses of data, such as descriptive, predictive, or machine learning as appropriate for specific projects', 'Manual file data collection and workflow automation for users', 'End-user training, engagement, and culture transformation support', 'Participation in Rio Tinto Borates big data and digital transformation initiatives, and joining special projects teams', 'A pioneering spirit and alignment to our values of Safety, Teamwork, Respect, Integrity and Excellence', 'Curious mind, a willingness to learn, and make an impact, and challenge the status quo', 'Bachelor or master’s degree in Data Science, Data Analytics, Business Intelligence, Computer Science, Software Engineering or any related field', 'A safety-focused and inclusive working environment', 'A competitive salary package with annual cash incentive awards (STIP) for eligible employees', 'Career development & education assistance to further your ambitions', 'Access to top tier family-friendly health and medical programs', 'Excellent retirement plan including 6% defined company contribution', 'Generous 401k matching program', 'A comprehensive leave policy that covers all moments that matter in life (vacation/annual, paid parental leave, short term sick leave, paid holidays)', 'Ongoing individual wellbeing support for you and your family for personal and professional matter', 'Generous Rio Tinto employee share program', 'Rio Tinto reserves the right to remove job postings prior to the stated closing date, therefore, if you are interested in applying for this vacancy please submit your application as soon as possible']",2020-09-24 13:30:22
Technician - Materials and Concrete,JENSEN HUGHES,3.7 out of 5,"Chicago, IL 60661","['Completes lab and field technician work', 'Performs routine and specialized tests in laboratory and field with minimal supervision', 'Maintains laboratory and field-testing equipment', 'Plays a lead role in the quality assurance program', 'Works as part of a collaborative team of technicians, scientists, and engineers to achieve project goals', 'Ability to attend meetings at various office, field and construction sites', 'Ability to perform inspections of buildings and other structures, both visually and with instruments', 'Ability to lift and carry materials and equipment up to 50 lbs.', 'Ability to perform work in the temperature extremes presented by work in the outdoors', 'Ability to read construction drawings, diagrams, printed materials and computer screens', 'Ability to record data clearly', 'Ability to travel', 'Ability to safely work at heights and/or constrained spaces', 'Ability to safely use and/or operate ladders, scaffolds, lifts and other access equipment', 'Ability to understand and appreciate safety training specific to numerous workplace and construction hazards', 'Ability to safely work in a variety of occupationally hazardous locations', 'Medically fit to utilize respiratory protection devices and other forms of Personal Protective Equipment', 'Ability to drive and safely operate a motor vehicle', 'High school diploma', '5-7 years of relevant work experience', 'Hands-on capabilities with experience in testing', 'Developed understanding with ability to follow instructions of routine tests', 'Ability to perform routine tasks with little or no direction', 'Ability to work independently and to perform tasks after verbal and written instruction', 'Appropriate certifications and training for primary practice areas (may include AutoCAD, ACI field training and lab certifications, instrumentation installation and problem solving, and strain gauge understanding)', 'Willingness to travel to job sites for up to two weeks at a time', 'Detail-oriented with effective written and oral communication skills', 'Knowledge of MS Office computer programs', 'Valid driver’s license and access to a vehicle']",2020-09-24 13:30:22
Technician - Materials and Concrete,JENSEN HUGHES,N/A,"Chicago, IL 60661","['Interviews on the spot', 'Tuesday, September 29, 20202:00 PM - 6:00 PM US/Central', ""Interviewing via webYou'll receive an email on how to connect."", '146 slots left', '', 'Data EngineerFull-timeThe Data Engineer will generate representative data sets for demonstrations, technology evaluation, and systems development.QUALIFICATIONSActive SECRET security clearance is required.Senior skill levelBachelor’s degree in Computer Science, Data Science, or related discipline; 4 additional years of experience can be substituted for a Bachelor’s degree, or 2 years of additional experience with an Associates4+ years of data engineering, schema design, dimensional data modeling, and / or data management experienceProficient with data management tools, such as Python, SQL, Java, and use of GitDemonstrated experience with extracting, cleaning, managing, optimizing, and exploiting large and very complex data setsExperience with best practices for compute, storage, and transfer optimization in processing large volumes of dataPreferred:Experience with graph databases and event sourcing modelsFamiliarity with machine learning, artificial intelligence, and / or geospatial data analysisStrong interpersonal skills combined with ability to multi-task and maintain flexibility and creativity in a variety of situations', 'Active SECRET security clearance is required.', 'Senior skill level', 'Bachelor’s degree in Computer Science, Data Science, or related discipline; 4 additional years of experience can be substituted for a Bachelor’s degree, or 2 years of additional experience with an Associates', '4+ years of data engineering, schema design, dimensional data modeling, and / or data management experience', 'Proficient with data management tools, such as Python, SQL, Java, and use of Git', 'Demonstrated experience with extracting, cleaning, managing, optimizing, and exploiting large and very complex data sets', 'Experience with best practices for compute, storage, and transfer optimization in processing large volumes of data', 'Experience with graph databases and event sourcing models', 'Familiarity with machine learning, artificial intelligence, and / or geospatial data analysis', 'Strong interpersonal skills combined with ability to multi-task and maintain flexibility and creativity in a variety of situations', 'Software DeveloperFull-timeQUALIFICATIONSActive Secret Security Clearance requiredBachelor’s degree in Computer Science or related discipline; 4 additional years of experience can be substituted for a Bachelor’s degree, or 2 years of additional experience with an AssociatesExperience with building, implementing and maintaining CI/CD pipelines3+ years programming experience with JavaExperience with API design and development using Java (specifically with REST)2+ years of experience using Jenkins to support multiple build pipelines for a variety of languages (emphasis on java)Familiarity with microservices design and development patternsExperience with one or more Configuration Management Tools, such as AnsibleFamiliarity with container-based applications (Docker, OpenShift) and Kubernetes managementExperience developing data solutions with RDBMS and / or NoSQL databaseFamiliar with Test Driven DevelopmentExperience supporting code reviewsEffective communicator with peers, leads, and managementPreferred:Experience with UI developmentExperience with C#Experience with Swagger Components, and Swagger CodeGenExperience with Cloud Providers (AWS, GCP)', 'Active Secret Security Clearance required', 'Bachelor’s degree in Computer Science or related discipline; 4 additional years of experience can be substituted for a Bachelor’s degree, or 2 years of additional experience with an Associates', 'Experience with building, implementing and maintaining CI/CD pipelines', '3+ years programming experience with Java', 'Experience with API design and development using Java (specifically with REST)', '2+ years of experience using Jenkins to support multiple build pipelines for a variety of languages (emphasis on java)', 'Familiarity with microservices design and development patterns', 'Experience with one or more Configuration Management Tools, such as Ansible', 'Familiarity with container-based applications (Docker, OpenShift) and Kubernetes management', 'Experience developing data solutions with RDBMS and / or NoSQL database', 'Familiar with Test Driven Development', 'Experience supporting code reviews', 'Effective communicator with peers, leads, and management', 'Experience with UI development', 'Experience with C#', 'Experience with Swagger Components, and Swagger CodeGen', 'Experience with Cloud Providers (AWS, GCP)', 'Database EngineerFull-timeThe Database Engineer designs and maintains one or more databases that meet the information requirements of the systems and users. The Database Engineer is in charge of executing designs and keeping the resulting database solutions available, secure, and stable. They work with Data Engineers to test data for corruption and other potential issues. Responsible for integrating new products and software packages into the system(s).Bachelor’s degree in Computer Science, Data Science, or related discipline; 4 additional years of experience can be substituted for a Bachelor’s degree, or 2 years of additional experience with an Associates4 years of database design, execution, operations, and managementRelational, graph, and other NoSQL experience preferredKnowledge of various database management, testing, and data tools requiredAbility to work within a broader, matrixed team within agile practicesSECRET clearance', 'Bachelor’s degree in Computer Science, Data Science, or related discipline; 4 additional years of experience can be substituted for a Bachelor’s degree, or 2 years of additional experience with an Associates', '4 years of database design, execution, operations, and management', 'Relational, graph, and other NoSQL experience preferred', 'Knowledge of various database management, testing, and data tools required', 'Ability to work within a broader, matrixed team within agile practices', 'SECRET clearance', 'Security EngineerFull-timeThe Security Engineer leverages broad experience in cyber and continuity of operations to inform the design, maintenance, and resiliency of robust systems. Security Engineers develop and execute plans for systems hardening, AAA protections, high availability requirements, and recovery modes. They are well-versed in threat assessment / mitigations, developing and executing cyber defense tests and exercises, and monitoring systems and networks for potential events.Bachelor’s degree in Computer Science, Cyber Security, or related discipline; 4 additional years of experience can be substituted for a Bachelor’s degree, or 2 years of additional experience with an Associates6 years’ of cyber security and continuity of operations experienceProficient at identifying, assessing, and mitigating potential threat vectorsStrong understanding of associated physical security requirementsBroad knowledge of various security monitoring, testing, and response tools, methods and techniquesExcellent communications abilities, to develop security plans, brief stakeholders, and inform broader development / maintenance teamsSECRET clearance', 'Bachelor’s degree in Computer Science, Cyber Security, or related discipline; 4 additional years of experience can be substituted for a Bachelor’s degree, or 2 years of additional experience with an Associates', '6 years’ of cyber security and continuity of operations experience', 'Proficient at identifying, assessing, and mitigating potential threat vectors', 'Strong understanding of associated physical security requirements', 'Broad knowledge of various security monitoring, testing, and response tools, methods and techniques', 'Excellent communications abilities, to develop security plans, brief stakeholders, and inform broader development / maintenance teams', 'SECRET clearance', ""NT Concepts' Customer Site, 1 Lockheed Blvd, Fort Worth, TX 76108 US"", 'Interviews on the spot', 'Tuesday, September 29, 20202:00 PM - 6:00 PM US/Central', ""Interviewing via webYou'll receive an email on how to connect."", '146 slots left', 'United States+1', 'United Kingdom+44', '', 'Afghanistan (\u202bافغانستان\u202c\u200e)+93', 'Albania (Shqipëri)+355', 'Algeria (\u202bالجزائر\u202c\u200e)+213', 'American Samoa+1684', 'Andorra+376', 'Angola+244', 'Anguilla+1264', 'Antigua and Barbuda+1268', 'Argentina+54', 'Armenia (Հայաստան)+374', 'Aruba+297', 'Australia+61', 'Austria (Österreich)+43', 'Azerbaijan (Azərbaycan)+994', 'Bahamas+1242', 'Bahrain (\u202bالبحرين\u202c\u200e)+973', 'Bangladesh (বাংলাদেশ)+880', 'Barbados+1246', 'Belarus (Беларусь)+375', 'Belgium (België)+32', 'Belize+501', 'Benin (Bénin)+229', 'Bermuda+1441', 'Bhutan (འབྲུག)+975', 'Bolivia+591', 'Bosnia and Herzegovina (Босна и Херцеговина)+387', 'Botswana+267', 'Brazil (Brasil)+55', 'British Indian Ocean Territory+246', 'British Virgin Islands+1284', 'Brunei+673', 'Bulgaria (България)+359', 'Burkina Faso+226', 'Burundi (Uburundi)+257', 'Cambodia (កម្ពុជា)+855', 'Cameroon (Cameroun)+237', 'Canada+1', 'Cape Verde (Kabu Verdi)+238', 'Caribbean Netherlands+599', 'Cayman Islands+1345', 'Central African Republic (République centrafricaine)+236', 'Chad (Tchad)+235', 'Chile+56', 'China (中国)+86', 'Christmas Island+61', 'Cocos (Keeling) Islands+61', 'Colombia+57', 'Comoros (\u202bجزر القمر\u202c\u200e)+269', 'Congo (DRC) (Jamhuri ya Kidemokrasia ya Kongo)+243', 'Congo (Republic) (Congo-Brazzaville)+242', 'Cook Islands+682', 'Costa Rica+506', 'Côte d’Ivoire+225', 'Croatia (Hrvatska)+385', 'Cuba+53', 'Curaçao+599', 'Cyprus (Κύπρος)+357', 'Czech Republic (Česká republika)+420', 'Denmark (Danmark)+45', 'Djibouti+253', 'Dominica+1767', 'Dominican Republic (República Dominicana)+1', 'Ecuador+593', 'Egypt (\u202bمصر\u202c\u200e)+20', 'El Salvador+503', 'Equatorial Guinea (Guinea Ecuatorial)+240', 'Eritrea+291', 'Estonia (Eesti)+372', 'Ethiopia+251', 'Falkland Islands (Islas Malvinas)+500', 'Faroe Islands (Føroyar)+298', 'Fiji+679', 'Finland (Suomi)+358', 'France+33', 'French Guiana (Guyane française)+594', 'French Polynesia (Polynésie française)+689', 'Gabon+241', 'Gambia+220', 'Georgia (საქართველო)+995', 'Germany (Deutschland)+49', 'Ghana (Gaana)+233', 'Gibraltar+350', 'Greece (Ελλάδα)+30', 'Greenland (Kalaallit Nunaat)+299', 'Grenada+1473', 'Guadeloupe+590', 'Guam+1671', 'Guatemala+502', 'Guernsey+44', 'Guinea (Guinée)+224', 'Guinea-Bissau (Guiné Bissau)+245', 'Guyana+592', 'Haiti+509', 'Honduras+504', 'Hong Kong (香港)+852', 'Hungary (Magyarország)+36', 'Iceland (Ísland)+354', 'India (भारत)+91', 'Indonesia+62', 'Iran (\u202bایران\u202c\u200e)+98', 'Iraq (\u202bالعراق\u202c\u200e)+964', 'Ireland+353', 'Isle of Man+44', 'Israel (\u202bישראל\u202c\u200e)+972', 'Italy (Italia)+39', 'Jamaica+1', 'Japan (日本)+81', 'Jersey+44', 'Jordan (\u202bالأردن\u202c\u200e)+962', 'Kazakhstan (Казахстан)+7', 'Kenya+254', 'Kiribati+686', 'Kosovo+383', 'Kuwait (\u202bالكويت\u202c\u200e)+965', 'Kyrgyzstan (Кыргызстан)+996', 'Laos (ລາວ)+856', 'Latvia (Latvija)+371', 'Lebanon (\u202bلبنان\u202c\u200e)+961', 'Lesotho+266', 'Liberia+231', 'Libya (\u202bليبيا\u202c\u200e)+218', 'Liechtenstein+423', 'Lithuania (Lietuva)+370', 'Luxembourg+352', 'Macau (澳門)+853', 'Macedonia (FYROM) (Македонија)+389', 'Madagascar (Madagasikara)+261', 'Malawi+265', 'Malaysia+60', 'Maldives+960', 'Mali+223', 'Malta+356', 'Marshall Islands+692', 'Martinique+596', 'Mauritania (\u202bموريتانيا\u202c\u200e)+222', 'Mauritius (Moris)+230', 'Mayotte+262', 'Mexico (México)+52', 'Micronesia+691', 'Moldova (Republica Moldova)+373', 'Monaco+377', 'Mongolia (Монгол)+976', 'Montenegro (Crna Gora)+382', 'Montserrat+1664', 'Morocco (\u202bالمغرب\u202c\u200e)+212', 'Mozambique (Moçambique)+258', 'Myanmar (Burma) (မြန်မာ)+95', 'Namibia (Namibië)+264', 'Nauru+674', 'Nepal (नेपाल)+977', 'Netherlands (Nederland)+31', 'New Caledonia (Nouvelle-Calédonie)+687', 'New Zealand+64', 'Nicaragua+505', 'Niger (Nijar)+227', 'Nigeria+234', 'Niue+683', 'Norfolk Island+672', 'North Korea (조선 민주주의 인민 공화국)+850', 'Northern Mariana Islands+1670', 'Norway (Norge)+47', 'Oman (\u202bعُمان\u202c\u200e)+968', 'Pakistan (\u202bپاکستان\u202c\u200e)+92', 'Palau+680', 'Palestine (\u202bفلسطين\u202c\u200e)+970', 'Panama (Panamá)+507', 'Papua New Guinea+675', 'Paraguay+595', 'Peru (Perú)+51', 'Philippines+63', 'Poland (Polska)+48', 'Portugal+351', 'Puerto Rico+1', 'Qatar (\u202bقطر\u202c\u200e)+974', 'Réunion (La Réunion)+262', 'Romania (România)+40', 'Russia (Россия)+7', 'Rwanda+250', 'Saint Barthélemy+590', 'Saint Helena+290', 'Saint Kitts and Nevis+1869', 'Saint Lucia+1758', 'Saint Martin (Saint-Martin (partie française))+590', 'Saint Pierre and Miquelon (Saint-Pierre-et-Miquelon)+508', 'Saint Vincent and the Grenadines+1784', 'Samoa+685', 'San Marino+378', 'São Tomé and Príncipe (São Tomé e Príncipe)+239', 'Saudi Arabia (\u202bالمملكة العربية السعودية\u202c\u200e)+966', 'Senegal (Sénégal)+221', 'Serbia (Србија)+381', 'Seychelles+248', 'Sierra Leone+232', 'Singapore+65', 'Sint Maarten+1721', 'Slovakia (Slovensko)+421', 'Slovenia (Slovenija)+386', 'Solomon Islands+677', 'Somalia (Soomaaliya)+252', 'South Africa+27', 'South Korea (대한민국)+82', 'South Sudan (\u202bجنوب السودان\u202c\u200e)+211', 'Spain (España)+34', 'Sri Lanka (ශ්\u200dරී ලංකාව)+94', 'Sudan (\u202bالسودان\u202c\u200e)+249', 'Suriname+597', 'Svalbard and Jan Mayen+47', 'Swaziland+268', 'Sweden (Sverige)+46', 'Switzerland (Schweiz)+41', 'Syria (\u202bسوريا\u202c\u200e)+963', 'Taiwan (台灣)+886', 'Tajikistan+992', 'Tanzania+255', 'Thailand (ไทย)+66', 'Timor-Leste+670', 'Togo+228', 'Tokelau+690', 'Tonga+676', 'Trinidad and Tobago+1868', 'Tunisia (\u202bتونس\u202c\u200e)+216', 'Turkey (Türkiye)+90', 'Turkmenistan+993', 'Turks and Caicos Islands+1649', 'Tuvalu+688', 'U.S. Virgin Islands+1340', 'Uganda+256', 'Ukraine (Україна)+380', 'United Arab Emirates (\u202bالإمارات العربية المتحدة\u202c\u200e)+971', 'United Kingdom+44', 'United States+1', 'Uruguay+598', 'Uzbekistan (Oʻzbekiston)+998', 'Vanuatu+678', 'Vatican City (Città del Vaticano)+39', 'Venezuela+58', 'Vietnam (Việt Nam)+84', 'Wallis and Futuna (Wallis-et-Futuna)+681', 'Western Sahara (\u202bالصحراء الغربية\u202c\u200e)+212', 'Yemen (\u202bاليمن\u202c\u200e)+967', 'Zambia+260', 'Zimbabwe+263', 'Åland Islands+358']",2020-09-24 13:30:22
Database Engineer (Data Warehouse),American Advisors Group,3.6 out of 5,"Irvine, CA 92612","['Consolidate and optimize available data warehouse infrastructure utilizing SSIS/SSAS/Snowflake', 'Create stored procedures, SSIS packages, and using other methods to import/translate/manipulate data', 'Analyze potential data quality issues to determine the root cause, and creating effective solutions', 'Conceive analytics and business intelligence platform architecture for clients, including internal and third-party clients', 'Design and implement, monitoring, and tuning ETL Processes', 'Collaborate with business and technology stakeholders in ensuring data warehouse architecture development and utilization', 'Perform the design and extension of data marts, meta data, and data models', 'Ensure all data warehouse architecture codes are maintained in a version control system.', 'Design and implement ETL procedures for intake of data from both internal and outside sources; as well as ensure data is verified and quality is checked', 'Perform the design and extension of data marts, meta data, and data models', 'Develop, monitor and maintain data marts across the enterprise, while ensuring high levels of data availability.', 'Develops, maintains and optimizes all efforts related to Data Warehouse (SSIS, Stored Procedures, Views etc.)', 'Identifies and implements optimizations to both performance and accuracy of databases, as required and appropriate.', 'Develops and adheres to standards, processes and procedures to create, deploy and maintain databases.', 'Design, implement, and maintain new and existing database objects including tables, indexes, constraints, stored procedures, and user-defined functions in support of data conversion projects.', 'Data Warehousing and related tools: SSAS, SSIS, Snowflake, SQL Server and Informatica Cloud Integration Services', 'Azure and Cloud Certification is a plus', 'Database Modeling, Tuning, Security, Administration and Management', 'Structured thinker and effective communicator, comfortable interacting with constituents', 'EDUCATION / WORK EXPERIENCE', 'Possess Bachelor’s degree in information technology, Computer science, and engineering discipline', '10+ years or more experience performing data warehouse architecture development and management', 'Remarkable experience with technologies such as SQL Server, Snowflake as well as SSIS and stored procedures', 'Strong Experience with Informatica', 'Exceptional experience developing codes, testing for quality assurance, administering RDBMS, and monitoring of database', 'Strong working knowledge of application and T-SQL code and ability to demonstrate the ability to write functional requirements.', 'High proficiency in dimensional modeling techniques and their applications', 'Extensive hands on experience in data warehousing design, tuning and ETL/ELT process development Solid communication skills – both written and verbal', 'Ability to meet deadlines', 'Excellent communication skills (written and verbal)', 'Client-facing presence and excellent business acumen.', 'Attention to detail and solid organization skills']",2020-09-24 13:30:22
Data Engineer - Junior Level,USAA,3.9 out of 5,"Euless, TX 76039",[],2020-09-24 13:30:22
Data Engineer - Junior Level,USAA,N/A,"Euless, TX 76039","['Interviews on the spot', 'Thursday, October 1, 20201:00 PM - 4:00 PM US/Eastern', ""Interviewing via webYou'll receive an email on how to connect."", '72 slots left', '', ""Internship Program$15.00 - $16.50 / hour, Full-time, Part-timePharmaCord is seeking interns who will assist in our reenrollment season!\xa0A day in the life of an intern can include the following:Benefit VerificationPatient Assistance\xa0Answer and assist inbound callersFile paperworkAssist in mail roomEducation and Experience:High School diploma or equivalent is requiredStrongly prefer those in school working towards a Bachelors Degree or recent college graduatePhysical Demands:While performing the duties of this job, the employee is regularly required to talk or hear. The employee is frequently required to sit, use hands to type, handle or feel; and reach with hands and arms. Must be able to type 35 WPM with 97% accuracy.Work Schedule & Environment:\xa0This is an internship opportunity and hours will be based on candidate's availability and business needThis role routinely uses standard office equipment such as computers, phones, photocopiers, etc.Position could extend through early 2021 and potentially end in a full-time offer if there is a business need\xa0Any offer of employment is contingent on completion of a background check and drug screen to company standard.\xa0PharmaCord is proud to be an equal opportunity employer."", 'Benefit Verification', 'Patient Assistance', 'Answer and assist inbound callers', 'File paperwork', 'Assist in mail room', 'High School diploma or equivalent is required', 'Strongly prefer those in school working towards a Bachelors Degree or recent college graduate', 'While performing the duties of this job, the employee is regularly required to talk or hear. The employee is frequently required to sit, use hands to type, handle or feel; and reach with hands and arms. Must be able to type 35 WPM with 97% accuracy.', ""This is an internship opportunity and hours will be based on candidate's availability and business need"", 'This role routinely uses standard office equipment such as computers, phones, photocopiers, etc.', 'Position could extend through early 2021 and potentially end in a full-time offer if there is a business need', 'PharmaCord, 11001 Bluegrass Parkway, Louisville, KY 40299 US', 'Interviews on the spot', 'Thursday, October 1, 20201:00 PM - 4:00 PM US/Eastern', ""Interviewing via webYou'll receive an email on how to connect."", '72 slots left', 'United States+1', 'United Kingdom+44', '', 'Afghanistan (\u202bافغانستان\u202c\u200e)+93', 'Albania (Shqipëri)+355', 'Algeria (\u202bالجزائر\u202c\u200e)+213', 'American Samoa+1684', 'Andorra+376', 'Angola+244', 'Anguilla+1264', 'Antigua and Barbuda+1268', 'Argentina+54', 'Armenia (Հայաստան)+374', 'Aruba+297', 'Australia+61', 'Austria (Österreich)+43', 'Azerbaijan (Azərbaycan)+994', 'Bahamas+1242', 'Bahrain (\u202bالبحرين\u202c\u200e)+973', 'Bangladesh (বাংলাদেশ)+880', 'Barbados+1246', 'Belarus (Беларусь)+375', 'Belgium (België)+32', 'Belize+501', 'Benin (Bénin)+229', 'Bermuda+1441', 'Bhutan (འབྲུག)+975', 'Bolivia+591', 'Bosnia and Herzegovina (Босна и Херцеговина)+387', 'Botswana+267', 'Brazil (Brasil)+55', 'British Indian Ocean Territory+246', 'British Virgin Islands+1284', 'Brunei+673', 'Bulgaria (България)+359', 'Burkina Faso+226', 'Burundi (Uburundi)+257', 'Cambodia (កម្ពុជា)+855', 'Cameroon (Cameroun)+237', 'Canada+1', 'Cape Verde (Kabu Verdi)+238', 'Caribbean Netherlands+599', 'Cayman Islands+1345', 'Central African Republic (République centrafricaine)+236', 'Chad (Tchad)+235', 'Chile+56', 'China (中国)+86', 'Christmas Island+61', 'Cocos (Keeling) Islands+61', 'Colombia+57', 'Comoros (\u202bجزر القمر\u202c\u200e)+269', 'Congo (DRC) (Jamhuri ya Kidemokrasia ya Kongo)+243', 'Congo (Republic) (Congo-Brazzaville)+242', 'Cook Islands+682', 'Costa Rica+506', 'Côte d’Ivoire+225', 'Croatia (Hrvatska)+385', 'Cuba+53', 'Curaçao+599', 'Cyprus (Κύπρος)+357', 'Czech Republic (Česká republika)+420', 'Denmark (Danmark)+45', 'Djibouti+253', 'Dominica+1767', 'Dominican Republic (República Dominicana)+1', 'Ecuador+593', 'Egypt (\u202bمصر\u202c\u200e)+20', 'El Salvador+503', 'Equatorial Guinea (Guinea Ecuatorial)+240', 'Eritrea+291', 'Estonia (Eesti)+372', 'Ethiopia+251', 'Falkland Islands (Islas Malvinas)+500', 'Faroe Islands (Føroyar)+298', 'Fiji+679', 'Finland (Suomi)+358', 'France+33', 'French Guiana (Guyane française)+594', 'French Polynesia (Polynésie française)+689', 'Gabon+241', 'Gambia+220', 'Georgia (საქართველო)+995', 'Germany (Deutschland)+49', 'Ghana (Gaana)+233', 'Gibraltar+350', 'Greece (Ελλάδα)+30', 'Greenland (Kalaallit Nunaat)+299', 'Grenada+1473', 'Guadeloupe+590', 'Guam+1671', 'Guatemala+502', 'Guernsey+44', 'Guinea (Guinée)+224', 'Guinea-Bissau (Guiné Bissau)+245', 'Guyana+592', 'Haiti+509', 'Honduras+504', 'Hong Kong (香港)+852', 'Hungary (Magyarország)+36', 'Iceland (Ísland)+354', 'India (भारत)+91', 'Indonesia+62', 'Iran (\u202bایران\u202c\u200e)+98', 'Iraq (\u202bالعراق\u202c\u200e)+964', 'Ireland+353', 'Isle of Man+44', 'Israel (\u202bישראל\u202c\u200e)+972', 'Italy (Italia)+39', 'Jamaica+1', 'Japan (日本)+81', 'Jersey+44', 'Jordan (\u202bالأردن\u202c\u200e)+962', 'Kazakhstan (Казахстан)+7', 'Kenya+254', 'Kiribati+686', 'Kosovo+383', 'Kuwait (\u202bالكويت\u202c\u200e)+965', 'Kyrgyzstan (Кыргызстан)+996', 'Laos (ລາວ)+856', 'Latvia (Latvija)+371', 'Lebanon (\u202bلبنان\u202c\u200e)+961', 'Lesotho+266', 'Liberia+231', 'Libya (\u202bليبيا\u202c\u200e)+218', 'Liechtenstein+423', 'Lithuania (Lietuva)+370', 'Luxembourg+352', 'Macau (澳門)+853', 'Macedonia (FYROM) (Македонија)+389', 'Madagascar (Madagasikara)+261', 'Malawi+265', 'Malaysia+60', 'Maldives+960', 'Mali+223', 'Malta+356', 'Marshall Islands+692', 'Martinique+596', 'Mauritania (\u202bموريتانيا\u202c\u200e)+222', 'Mauritius (Moris)+230', 'Mayotte+262', 'Mexico (México)+52', 'Micronesia+691', 'Moldova (Republica Moldova)+373', 'Monaco+377', 'Mongolia (Монгол)+976', 'Montenegro (Crna Gora)+382', 'Montserrat+1664', 'Morocco (\u202bالمغرب\u202c\u200e)+212', 'Mozambique (Moçambique)+258', 'Myanmar (Burma) (မြန်မာ)+95', 'Namibia (Namibië)+264', 'Nauru+674', 'Nepal (नेपाल)+977', 'Netherlands (Nederland)+31', 'New Caledonia (Nouvelle-Calédonie)+687', 'New Zealand+64', 'Nicaragua+505', 'Niger (Nijar)+227', 'Nigeria+234', 'Niue+683', 'Norfolk Island+672', 'North Korea (조선 민주주의 인민 공화국)+850', 'Northern Mariana Islands+1670', 'Norway (Norge)+47', 'Oman (\u202bعُمان\u202c\u200e)+968', 'Pakistan (\u202bپاکستان\u202c\u200e)+92', 'Palau+680', 'Palestine (\u202bفلسطين\u202c\u200e)+970', 'Panama (Panamá)+507', 'Papua New Guinea+675', 'Paraguay+595', 'Peru (Perú)+51', 'Philippines+63', 'Poland (Polska)+48', 'Portugal+351', 'Puerto Rico+1', 'Qatar (\u202bقطر\u202c\u200e)+974', 'Réunion (La Réunion)+262', 'Romania (România)+40', 'Russia (Россия)+7', 'Rwanda+250', 'Saint Barthélemy+590', 'Saint Helena+290', 'Saint Kitts and Nevis+1869', 'Saint Lucia+1758', 'Saint Martin (Saint-Martin (partie française))+590', 'Saint Pierre and Miquelon (Saint-Pierre-et-Miquelon)+508', 'Saint Vincent and the Grenadines+1784', 'Samoa+685', 'San Marino+378', 'São Tomé and Príncipe (São Tomé e Príncipe)+239', 'Saudi Arabia (\u202bالمملكة العربية السعودية\u202c\u200e)+966', 'Senegal (Sénégal)+221', 'Serbia (Србија)+381', 'Seychelles+248', 'Sierra Leone+232', 'Singapore+65', 'Sint Maarten+1721', 'Slovakia (Slovensko)+421', 'Slovenia (Slovenija)+386', 'Solomon Islands+677', 'Somalia (Soomaaliya)+252', 'South Africa+27', 'South Korea (대한민국)+82', 'South Sudan (\u202bجنوب السودان\u202c\u200e)+211', 'Spain (España)+34', 'Sri Lanka (ශ්\u200dරී ලංකාව)+94', 'Sudan (\u202bالسودان\u202c\u200e)+249', 'Suriname+597', 'Svalbard and Jan Mayen+47', 'Swaziland+268', 'Sweden (Sverige)+46', 'Switzerland (Schweiz)+41', 'Syria (\u202bسوريا\u202c\u200e)+963', 'Taiwan (台灣)+886', 'Tajikistan+992', 'Tanzania+255', 'Thailand (ไทย)+66', 'Timor-Leste+670', 'Togo+228', 'Tokelau+690', 'Tonga+676', 'Trinidad and Tobago+1868', 'Tunisia (\u202bتونس\u202c\u200e)+216', 'Turkey (Türkiye)+90', 'Turkmenistan+993', 'Turks and Caicos Islands+1649', 'Tuvalu+688', 'U.S. Virgin Islands+1340', 'Uganda+256', 'Ukraine (Україна)+380', 'United Arab Emirates (\u202bالإمارات العربية المتحدة\u202c\u200e)+971', 'United Kingdom+44', 'United States+1', 'Uruguay+598', 'Uzbekistan (Oʻzbekiston)+998', 'Vanuatu+678', 'Vatican City (Città del Vaticano)+39', 'Venezuela+58', 'Vietnam (Việt Nam)+84', 'Wallis and Futuna (Wallis-et-Futuna)+681', 'Western Sahara (\u202bالصحراء الغربية\u202c\u200e)+212', 'Yemen (\u202bاليمن\u202c\u200e)+967', 'Zambia+260', 'Zimbabwe+263', 'Åland Islands+358']",2020-09-24 13:31:16
Data Engineer,HASH,2.5 out of 5,Remote,"['Competitive salary and equity: commensurate with experience and incentive-aligned ✅', '28 days annual holiday including company holidays', 'A range of location-specific benefits, including access to a 401(k) and fully comprehensive health insurance and a fully funded Health Savings Account (HSA) for US-based employees, as well as free annual NYC MetroCards and (truly) infinite caffeine for those working from our Manhattan office.']",2020-09-24 13:31:16
Data Engineer,"Attain, LLC",3.6 out of 5,"McLean, VA 22102","['Passion Seekers. You genuinely care about the work that you do and its impact on society.', 'Self-Starters. You’re a go-getter who isn’t afraid to step up and disrupt the status quo.', 'Entrepreneurs. You bring fresh ideas to the table, work hard, develop business and consistently seek new challenges.', 'Collaborators. You’re a great contributor to a high performing team that accomplishes great feats for our clients.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Establish performance monitoring of databases and create data pipeline architecture', 'Manage data life cycle from transactions to reporting to archival of data', ""Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies"", 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', '5 years of proven expertise in relational and dimensional data modelling', '5 years in modern data development, upgrading, support and design.', 'Proven experience in leading data teams on data migration and transformation', 'Experience in establishing performance and statistical monitoring of enterprise databases to include, but not limited to; wellness checks, data integrity, privacy and security scans.', 'Experience in supporting cloud database environments, specifically AWS (i.e., EC2, S3, Neptune or Redshift) to include backup and archiving of data.', 'Good to have experience with data lakes implementations', 'Should be able to work early morning hours i.e. 6 am to 2 pm (US Eastern Time) for atleast 2-3 days a week', 'Experience with Apache NiFi is desired', 'Experience with OpenText Captiva is desired.']",2020-09-24 13:31:16
Research Data Engineer,Galaxy Tek Hires,N/A,"Chicago, IL","['Design, develop, test, and deploy elegant software solutions across the firm to support critical investment decisions', 'Partner with business leaders, quantitative researchers and technologists to define priorities and deliver custom solutions', 'A deep passion for working with data and developing software to address data processing challenges', 'Minimum of a bachelor’s degree in Computer Science or equivalent experience with good software design and engineering skills', 'Proficiency within one or more programming languages including Python, C, C++, R and/or JavaScript is a plus', 'Proficiency with multiple data platforms including RDBMS, NoSQL, MongoDB, Spark, Hadoop', 'Experience with some of the following areas: Distributed Computing, Natural Language Processing, Machine Learning, Cloud Platform Development, Networking, and/or REST Service Development', 'Good analytical and quantitative abilities', 'Demonstrated ability to quickly learn new technologies and skills', 'Ability to manage multiple tasks and thrive in a fast-paced team environment']",2020-09-24 13:31:16
Data Warehouse Engineer,"Groupon, Inc.",3.6 out of 5,"Chicago, IL 60654","['Perfect best practices for data visualization design, workflow optimization, and analyst’s tools', 'Enabling analysts through education of technical and soft skills', 'Growing a community spirit within analytics throughout Groupon', 'Identifying, collaborating and developing dashboards in internal consulting efforts', 'Collaborating and developing / maintaining data tools', 'Mentoring analysts', 'Drive the discussion and decisions of topics related to data visualization, analyst’s tools, data, and optimizing the processes of analysts at Groupon', 'Creative problem solving with analysts', 'Working knowledge of SQL and using databases for data retrieval such as Snowflake, Dremio, Teradata, Hive, Tableau, ETL tools', 'Working knowledge of Tableau or an equivalent data visualization tool where you can bring across the concepts', 'Excellent knowledge of data visualization design', 'SQL skills', 'Good communication and collaboration skills', 'Customer-focused: We believe that doing what’s right for the customer is ultimately what will drive our business forward.', 'Obsessed with quality: Your production code just works & scales linearly', 'Team players. You believe that more can be achieved together. You listen to feedback and also provide supportive feedback to help others grow/improve.', 'Fast learners: We are willing to disrupt our existing business to trial new products and solutions. You love learning how to use new technologies and then rapidly apply them to new problems.', 'Pragmatic: We do things quickly to learn what our customers desire. You know when it’s appropriate to take shortcuts that don’t sacrifice quality or maintainability.', 'Owners: Engineers at Groupon know how to positively impact the business.']",2020-09-24 13:31:16
Machine Learning Engineer,Octi,N/A,"Los Angeles, CA","['$100,000.00 - $139,999.00 per year', 'Benefits:', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Professional development assistance', 'Work with other Machine Learning Engineers to build and improve networks for on device use', 'Develop algorithms to supplement and improve the networks on device', 'Collect and evaluate training data', 'Improve the on device performance of networks', 'Up to date with current Machine Learning developments', 'Strong communication and time management skills', 'Ability to work in a fast moving focused team', 'Bachelor’s Degree in computer science or similar', 'Experience building Machine Learning networks for object detection, segmentation, classification, tracking and recognition.', 'Experience with deep learning frameworks such as Keras, Tensorflow, CoreML PyTorch or similar.', 'Strong coding and algorithms skills in Python and C++', 'Strong background of applied Mathematics', ""Master's or PhD in Machine Learning or similar"", 'Experience developing real time networks for mobile devices', 'Experience collecting and building datasets for commercial use', 'Experience in 3D Computer Vision', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Professional development assistance', '8 hour shift', 'Monday to Friday', 'Machine Learning: 1 year (Preferred)', 'Fully Remote']",2020-09-24 13:31:16
Clinical Solutions Engineer (Fully Remote Position),"Curebase, Inc.",N/A,"San Francisco, CA","['$45,000.00 - $60,000.00 per year', 'Benefits:', '401(k)', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Bridge the needs of our customers with our technology team', 'Attend customer meetings and explain technical product aspects', 'Create technical requirements for each of our clinical trials and look for technology gaps', 'Work directly with both our client-facing project managers and our engineers', 'Configure the Curebase software platform for each clinical trial protocol we run', 'Devise custom technology solutions and collaborate with our software engineering team to ship them', 'Drive and develop the integrations of data from technology partners into our system', 'Act as the official Data Manager on specific clinical trials', 'Passionate about clinical and medical research', 'Some background in the clinical research world', 'Have technology skills including SQL and Javascript', 'Have amazing communication skills and be able to speak with both customers and engineers', '401(k)', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Monday to Friday', 'Fully Remote', 'curebase.com', 'Yes']",2020-09-24 13:31:16
Data Engineer (SQL),data.world,N/A,"Austin, TX 78731","['Collaborate with business groups at data.world to ask thoughtful questions and gather requirements around key insights and reporting needs.', 'Engineer lasting solutions that turn application data and streaming events into self-service reports and insights.', 'Develop and maintain a suite of production SQL data models using DBT to transform our streaming and transactional data into a form suitable and efficient for analytics and data science work.', 'Administer and optimize our Snowflake data warehouse and BI infrastructure.', 'Evolve our star schema and data flows to ensure utility and performance. Diagram and document as needed to support understanding and troubleshooting.', 'Write and maintain SQL jobs in support of ETL/ELT and BI analysis, reporting, and visualization, as well as ability to troubleshoot SQL jobs as required.', 'Build and maintain internal data catalog including data dictionaries, glossary, and curated datasets in support of easy self-service by the rest of the company.', 'Develop BI data reports, visualizations, and queries to support measuring our KPIs and supporting the success of our SaaS business.', 'Implement new productized data and analytics capabilities in support of customers understanding their usage and improving data governance.', 'Conduct evidence-based investigations and draw actionable conclusions in support of company and team goals and overall product success.', 'Be a steward and evangelist for data driven culture and data best practices within the company.', 'Be customer zero, leveraging our product and providing feedback as one of the key target users that data.world is actually intended for.', '5+ years of SQL experience with ability to write and tune SQL jobs for a variety of usage patterns', '5+ years of experience working with BI or data warehouse technologies in support of insights and reporting', 'Strong data modeling experience, for example ETL, ELT, star schema, and other data model and data warehouse concepts, techniques, and best practices', 'Strong interpersonal skills and experience interfacing with others internally and externally from the company', 'Good data visualization skills and ability to choose the best way to present information', 'Good communication and presentation skills with the ability to explain concepts and conclusions around data and insights in a clear, concise, and compelling way', 'Experience working with and administering Snowflake or another similar cloud SQL data warehouse technology', 'Experience working with Tableau, Looker, or other modern data visualization tools', 'Computer Science degree or equivalent software engineering experience', 'Experience with DBT and/or Python', 'Experience working in for SaaS or enterprise software companies in the data or analytics space']",2020-09-24 13:31:16
Pricing Data Engineer,Lenovo,3.9 out of 5,"Morrisville, NC",[],2020-09-24 13:31:16
Data Center Hardware Engineer I,General Dynamics Information Technology,3.8 out of 5,"Manassas, VA 20109",[],2020-09-24 13:31:16
"Engineer, Data (Bank Charter)",SoFi,3.2 out of 5,"Seattle, WA","['Competitive salary packages and bonuses', 'Comprehensive medical, dental, vision and life insurance benefits', 'Generous vacation and holidays', 'Paid parental leave for eligible employees', '401(k) and education on retirement planning', 'Tuition reimbursement on approved programs', 'Monthly contribution up to $200 to help you pay off your student loans', 'Great health & well-being benefits including: telehealth parental support, subsidized gym program', 'Employer paid lunch program (except for remote employees)', 'Fully stocked kitchen (snacks and drinks)', 'Build and modify data pipelines via Extract, Transform, Load (ETL) processes', 'Provision, optimize and maintain data feeds to external systems', 'Write SQL queries to validate quality and clean existing data', 'Build out automated checks and work within the team for data quality', 'Help analytics team and business users in querying and understanding the Data Warehouse', ""Bachelor's degree"", '2+ years industry experience', 'Experience writing SQL against different database platforms and advising best practices along the way', 'Demonstrated skills and experience in finding, investigating, and resolving data quality issues', 'Demonstrated skills and experience in building data feeds and business reports', 'Self-motivated', 'Ability to bring new ideas and promote process improvement', 'Experience with reporting systems such as Tableau', 'An interest to learn Python', 'First-rate attention to detail', 'Ability to thrive in a fast-paced growing company', 'Ability to drive a project from inception to completion', 'Enthusiasm for solving challenging problems', 'Team attitude: a willingness to roll up your sleeves, work with others and get stuff done', 'Ability to work quickly and accurately under pressure', 'Competitive salary packages and bonuses', 'Comprehensive medical, dental, vision and life insurance benefits', 'Generous vacation and holidays', 'Paid parental leave for eligible employees', '401(k) and education on retirement planning', 'Tuition reimbursement on approved programs', 'Monthly contribution up to $200 to help you pay off your student loans', 'Great health & well-being benefits including: telehealth parental support, subsidized gym program', 'Employer paid lunch program (except for remote employees)', 'Fully stocked kitchen (snacks and drinks)']",2020-09-24 13:31:16
Senior Software Engineer,"Tyler Technologies, Inc.",3.6 out of 5,"Yarmouth, ME 04096","['Research, develop, and test new software design concepts.', 'Identify areas to improve system performance, reusability, and quality.', 'Resolve complex technical design issues.', 'Design and integrate third party software suites.', 'Analyze user requirements and convert requirements to design documents.', 'Work with experienced team members to conduct root cause analysis of issues.', 'Develop process testing as needed.', 'Develop technical specifications.', 'Collaborate on technical decisions that provide solutions to business challenges.', 'Communicate with management, technical teams and stakeholders.', 'Provide comprehensive support to internal and external customers', 'Position assumes a bachelor’s degree in computer science or engineering or comparable work experience.', 'Strong development fundamentals, from analysis through testing and documentation.', 'Moderate to expert level development experience in C#, HTML, TypeScript, Angular and SQL.', 'Experience with cloud (AWS preferred) and/or microservice architecture.', 'Moderate to expert level experience with REST/SOAP API development and integration.', 'Experience with relational database development and administration.', 'Ability to work independently as well as provide mentorship.', 'Demonstrated problem-solving skills, curiosity, industriousness, and perseverance.', 'Excellent written and verbal communication.']",2020-09-24 13:31:16
Big Data Engineer,"CaptiveAire, Inc.",3.3 out of 5,"Raleigh, NC 27616","['Job', 'Company', 'Medical, dental and vision insurance', 'Disability & life insurance based upon election of medical insurance', 'Paid holidays, vacation, and sick days based upon tenure', '401k with employer match', 'Flexible spending account (FSA)', 'Salary:', 'This position requires the ability to work well in a team as well as independently.', 'This position is heavy in coding.', 'As part of this position you will be supporting and enhancing the existing CASLink Analytics Platform.', 'You will have the opportunity to contribute to architectural discussions and POC’s for improving the CASLink Analytics Platform.', '.Net', 'Microsoft Azure', 'Blob Storage', 'HDInsight', 'Apache Spark', 'Scala', 'Power BI', 'Machine Learning (ML.Net, Python)', 'SQL Server', 'Rabbit MQ', 'Medical, dental and vision insurance', 'Disability & life insurance based upon election of medical insurance', 'Paid holidays, vacation, and sick days based upon tenure', '401k with employer match', 'Flexible spending account (FSA)', 'Apache Spark: 5 years (Required)', 'Azure: 5 years (Required)', '.Net: 5 years (Required)', 'One location', 'No: Not providing sponsorship for this job', 'www.captiveaire.com', 'No']",2020-09-24 13:31:16
Graduate - Data Engineer,Rio Tinto,3.9 out of 5,"Boron, CA 93596","['A competitive salary package with annual cash incentive awards (STIP) for eligible employees', 'Career development & education assistance to further your ambitions', 'Access to top tier family-friendly health and medical programs', 'Excellent retirement plan including 6% defined company contribution', 'Generous 401k matching program', 'A comprehensive leave policy that covers all moments that matter in life (vacation/annual, paid parental leave, short term sick leave, paid holidays)', 'Ongoing individual wellbeing support for you and your family for personal and professional matter', 'Join one of the largest mining and metal companies in the world, focused on safety and inclusion', 'Work with the newest technology and innovation, in an environment where we challenge you to drive positive change', 'Start your career and be part of our prestigious Graduate Development Program', 'Discovery of new data sources and conducting exploratory analysis based on prioritized business objectives', 'MS SQL DDL, ETL Development, and Data Warehousing', 'Report and dashboard development using Power BI and other applicable platforms', 'Support and development of existing operational data systems, relevant documentation management, and data stewardship', 'Recommending methods and performing various analyses of data, such as descriptive, predictive, or machine learning as appropriate for specific projects', 'Manual file data collection and workflow automation for users', 'End-user training, engagement, and culture transformation support', 'Participation in Rio Tinto Borates big data and digital transformation initiatives, and joining special projects teams', 'A pioneering spirit and alignment to our values of Safety, Teamwork, Respect, Integrity and Excellence', 'Curious mind, a willingness to learn, and make an impact, and challenge the status quo', 'Bachelor or master’s degree in Data Science, Data Analytics, Business Intelligence, Computer Science, Software Engineering or any related field', 'A safety-focused and inclusive working environment', 'A competitive salary package with annual cash incentive awards (STIP) for eligible employees', 'Career development & education assistance to further your ambitions', 'Access to top tier family-friendly health and medical programs', 'Excellent retirement plan including 6% defined company contribution', 'Generous 401k matching program', 'A comprehensive leave policy that covers all moments that matter in life (vacation/annual, paid parental leave, short term sick leave, paid holidays)', 'Ongoing individual wellbeing support for you and your family for personal and professional matter', 'Generous Rio Tinto employee share program', 'Rio Tinto reserves the right to remove job postings prior to the stated closing date, therefore, if you are interested in applying for this vacancy please submit your application as soon as possible']",2020-09-24 13:31:16
Systems Engineer,TYCHON,N/A,"Sierra Vista, AZ","['$100,000.00 - $115,000.00 per year', 'Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', '3 to 5+ years’ experience as a systems engineer or technical account manager supporting enterprise accounts.', 'Possess a technology background', 'Experience deploying enterprise software', 'Excellent problem solving and communication skills', 'Ability to build strong, long-lasting relationships with management and subordinates', 'Positions located in Sierra Vista Arizona', 'Be eligible to work shifts in 7x24x365 OPS Center', 'Maintaining TYCHON Appliance Services and Operating Systems', 'Troubleshooting Kibana and ElasticSearch services and performance', 'Working with customers and developers to create new TYCHON Micro-Service based use cases for the enterprise', 'Creating content for big data feeds, dashboards/visuals and Machine Learning (ML) jobs', 'Developing orchestration workflows and automation tasks', 'Integrating TYCHON into new and existing technologies', 'Performing testing tasks for the TYCHON core application', 'Submitting and monitoring tickets for troubleshooting, bugs and feature enhancements.', 'Windows Desktop Management (Server, Workstation)', 'Linux Management and Troubleshooting (CentOS, Red Hat)', 'OSX Desktop Management', 'Experience with OS Shell Scripting (Windows PowerShell, Linux Bash, OSX Bash)', 'Skilled at stand-alone Troubleshooting and Problem Solving', 'Good verbal and digital communication skills (Report Writing + Briefings)', 'Understanding of NoSQL Databases (ElasticSearch)', 'Understanding of Messaging Fabrics (Kafka, Mosquito)', 'Understanding of Web Services (Apache, Tomcat, IIS)', 'Understanding of Cyber Security Services (Anti-Virus, Firewall, STIGs, Patches)', 'Understanding of High-Level Programming (JavaScript + Python)', 'TS and SCI Eligible', 'Ability to become DoD 8570 IAT Level II Qualified within 90 days.', 'Work shifts as part of a 24/7/365 Security Operations Center', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', '10 hour shift', 'Day shift', 'Holidays', 'Monday to Friday', 'Night shift', 'Weekends', 'One location', 'tychon.io', 'No']",2020-09-24 13:31:16
Validation Engineer,Midwest Sterilization Corporation,2.8 out of 5,"Jackson, MO 63755","['Health insurance', 'Dental insurance', 'Vision insurance', 'Paid time off', 'Works with validations team to ensure timely completions of customer protocols', 'Reviews and approves customer or consultant supplied validation protocols for applicability at Midwest Sterilization and ensuring the protocols conform with Midwest Sterilization’s operating procedures and all current regulatory standards', 'Execution of customer protocols and other customer requests', 'Scheduling customer validation cycles, lab requests, and sample shipping requirements', 'Programming MSC equipment with customer cycle specifications', 'Preparing customer reports and process records', 'Collecting and shipping microbiological samples', 'Collecting and analyzing statistical data', 'Assuring proper storage, handling, and shipping of bioburden, biological indicators , or residual samples to the appropriate laboratory', 'Assist Engineering team with equipment IQ/OQ/PQ', 'Provides on-going reports to the validation manager and other managers as necessary', 'Maintains the quality and integrity of information required for validation records', 'Works with customers to answer inquires and communicate protocol status', 'Performs other responsibilities as assigned', ""Associate's degree in science, engineering, physics, mathematics or a similar field/experience"", 'Associate (Required)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Paid time off', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Monday to Friday']",2020-09-24 13:31:16
Senior Fiber Optics Engineer,Bolt Medical,N/A,"Carlsbad, CA 92008","['From $100,000.00 per year', '401(k)', 'Dental insurance', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Vision insurance', 'Design, assemble, align, test, and troubleshoot fiber optic, laser delivery and single-use devices.', 'Work with manufacturers to define requirements for components and subsystems and realize prototypes.', 'Fabricate laser probes using cleaving, polishing, fusing, end-capping and related processes.', 'Develop processes for prototype level fabrication and translate these to production.', 'Derive product design requirements based on top-level requirements and user needs input.', 'Medical device development activities such as prototyping and testing, pilot builds, V&V, risk assessment, and validation of ramp-up to production.', 'Contribute to patent portfolio and strategy development.', 'Identify technical, project schedule, and commercial viability risks.', 'Five or more years of industry experience working with fiber optic device to interface with high-energy, Q-switched, diode-driven fiber optic or other solid state lasers.', 'Area expertise in Fiber Optics, Photonics and Optomechanics.', 'Development of fiber optic energy delivery devices, fiber optic probes and laser systems.', 'Termination of fiber optics, connectors and ferrules for single and multi-optic assemblies.', 'Proficiency with industry standard tools and methods for optical, photonic, and electro-optical systems engineering.', 'Broad knowledge of process development methodologies and ability to translate to manufacturing readiness.', 'Vendor and supplier management for optical components, complex sub-systems, or OEM.', 'Hands-on experience in laboratory technical work, preferably in lasers, photonics and optics.', 'Experience in documenting technical work and results, writing lab reports, analysis and presentation of data.', 'Biomedical product or medical device development experience.', 'Experience with Class 3B & Class 4 lasers and optics for energy delivery and related single-use devices.', 'Solid understanding of Design Controls according to 21 CFR 820 or ISO 13485.', 'Proficient in Risk Management according to ISO 14971.', '401(k)', 'Dental insurance', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'No']",2020-09-24 13:31:16
Data Engineer,RTS Labs,N/A,"Glen Allen, VA 23060","['Have strong SQL skills and knowledge of BI concept', 'Solve challenges with out-of-the-box thinking', 'Love to learn and to share your insights', 'Know what it means to be a team player', 'Build relationships with clients based on trust', 'Reliably manage yourself', 'a high standard, ensuring that you work with smart people', 'a technically proficient, learning-oriented culture', 'a hard-working, but casual workplace, few meetings, and a get-it-done philosophy', 'MS SQL (T-SQL, Stored Procedures, Functions), SSRS, SSIS, SSAS, Microsoft Power View, Tableau, Jaspersoft']",2020-09-24 13:32:03
Remote NPL (Natural Language Processing) Engineer,Samiti Technology,N/A,"San Antonio, TX","['Monday to Friday', 'numPy: 1 year (Preferred)', 'Machine Learning Engineer: 3 years (Preferred)', 'Domino: 1 year (Preferred)', 'Kafka: 1 year (Preferred)', 'Jupyter Notebooks: 1 year (Preferred)', 'data movement: 1 year (Preferred)', 'git: 1 year (Preferred)', 'Java: 1 year (Preferred)', 'sci-kit learn: 1 year (Preferred)', 'SPSS: 1 year (Preferred)', 'pandas: 1 year (Preferred)', 'Python: 3 years (Preferred)', 'machine learning development platforms: 1 year (Preferred)', 'CI/CS: 1 year (Preferred)', 'RStudio: 1 year (Preferred)', 'Airflow: 1 year (Preferred)', 'API: 1 year (Preferred)', 'industry stand machine learning libraries: 1 year (Preferred)', 'Can you work on W2 or Corp to Corp?']",2020-09-24 13:32:03
Sr. Data Platform Engineer,Iconic Technology Group,N/A,"Houston, TX","['Kubernetes – 5 years', 'Python', 'Hadoop / big data', 'Over all 8 – 10 years', 'IT – Data – Big Data']",2020-09-24 13:32:03
Data Engineer,Bitfocus,N/A,Nevada,"['Build and refine our analytics platform.', 'Develop automated unit-testing processes.', 'Build automated data cleansing tools.', 'Assist in helping individuals and communities transform their data into actionable insights.', 'Contribute to the implementation of HUD policies and procedures as they pertain to data structure and implement best practices in regard to HMIS data analysis.', 'Design and build actionable dashboards for all aspects of homeless services.', 'Act as a subject matter expert and liaison with other areas within Clarity Human Services on data integration topics.', 'Complete ad-hoc projects as assigned.', 'You want to make an impact. You thrive on helping others and want your work to make a difference.', 'You love data and use it to make decisions.', 'You want to be part of a world class, dedicated, supportive team.', ""5 years' experience in a data modeling or business intelligence environment."", 'Strong SQL skills, including the ability to write queries and stored procedures.', 'Experience with data analytics tools such as Looker, Tableau, or Qlik.', 'Experience with scripting languages such as Python or R.', 'Solid understanding of data systems, including data relationships and data modeling with the ability to learn and understand various data environments.', 'Sound planning and organizational skills with strong attention to detail.', 'Demonstrated ability to handle multiple concurrent projects and priorities in a fast-paced, evolving environment.', 'Work independently and with others; self-directed and results-oriented.', 'Excellent interpersonal skills.', 'Willingness to learn new technologies to best solve data-related issues.', 'Effective written and oral communication skills in English.', 'Experience working in a completely remote company.', 'A college degree (a major in information systems, computer science, mathematics, finance, accounting, statistics or related field is preferred).', 'MariaDB/ MySQL experience preferred.', 'Data Analytics tools such as Looker or Tableau preferred', 'Strong preference for experience in social services and/or HMIS experience.', 'Work in a fully remote/virtual environment', 'A unique, friendly and caring culture! Hear more from our employees on Glassdoor (https://www.glassdoor.com/Reviews/Bitfocus-Reviews-E2388426.htm).', 'Medical, dental, vision insurance', '401K Retirement Plan', 'Paid parental leave', 'Paid time off', 'Paid volunteer time off', 'Bitfocus primarily uses Apple computers; all new employees receive either an iMac or MacBook Pro to use in their role at Bitfocus', 'Opportunities for professional growth and development']",2020-09-24 13:32:03
Data Engineer,Vertava Health,N/A,"Nashville, TN 37203","['Collaborating directly with business and technology departments to define future-state business capabilities & requirements, and translating those into transitional and target state data architectures', 'Analyzing the current technology environment to detect critical deficiencies, and recommend solutions for improvement', 'Designing, implementing, and maintaining data warehouses and near real-time data pipelines via the practical application of existing and new data engineering techniques', 'Developing continuous integration and continuous deployment pipelines for data solutions that include automated unit & integration testing', 'Mentoring, motivating, and supporting the team to achieve organizational objectives and goals', 'Advocating for agile practices to increase delivery throughput', 'Ensuring consistency with published development, coding and testing standards', 'Bachelor degree in Computer Science, Mathematics, or related fields', '4+ years of data engineering, schema design, dimensional data modeling, and / or data management experience', 'MDM (Master Data Management) Experience a plus, such as Master Data Services or equivalent technology', 'Proficient with data management tools and languages[3] , such as Python, SQL, Java, and use of Git', 'Demonstrated experience with extracting, cleaning, managing, optimizing, and exploiting large and very complex data sets', 'Experience with best practices for compute, storage, and transfer optimization in processing large volumes of data', 'Can perform data discovery', 'Experience with salesforce.com reporting and integration projects', 'Experience building in Microsoft BI Toolsets (SSRS/SSAS/SSIS/Power BI[4] )', 'Experience on data warehouse / data lake projects', 'Experience with Azure preferred (Azure Data Factory, Azure Analysis Services)', 'Ability to sit, use hands and fingers, talk and hear continually. Ability to stand, walk and reach continually. Ability to climb or balance, stoop, kneel, or crouch frequently.', 'Ability to frequently lift and carry up to 20 lbs.', 'Close vision required to see computer monitor, read documents, and operate copy and fax machine.', 'Work environment is indoors and climate controlled. Occasionally exposed to outdoor weather conditions.', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Vision insurance']",2020-09-24 13:32:03
Data Analyst CCB Wholesale Intelligence,U.S. Bank,3.6 out of 5,United States,"['Wholesale App Core Data reporting and transparency including the delivery of reporting via modern BI tools that: Provide insight into clients activities within US Bank and across lines of business; External activities, prioritizes potential new leads to improve prospecting, data for deepening engagement within our existing client set, reducing the risk of attrition, and providing insight into industry activities.', 'Enable a data foundation that includes descriptive and diagnostic reporting for the Wholesale bank that allows our key find, track and discover opportunities.', 'Exploring statistical analysis that could be applied to the data; Performing descriptive statistics including mean, variance, median, correlation', 'Documenting calculations, code, and adhering to data management principles', 'Validating and testing data assets of others in the form of peer review', 'Participate in the buildout of the reporting and technology infrastructure required to support the delivery of models, insights and reporting.', 'Researches data assets from multiple disparate sources, applies various technologies find and move data assets for analysis, development of metrics, reports, and statistics.', 'Play an active role with TOS engineers to ensure critical data is available, with quality in the proper platforms with clear SLAs.', ""Bachelor's degree in a quantitative field such as econometrics, computer science, engineering or applied mathematics, or equivalent work experience"", 'Four to five years of statistical experience', 'BA/BS in Math, Statistics, Economics, Finance, Computer Science or equivalent work experience', 'Experience with programming languages such as SQL, R, Python', '3 plus years relevant experience in analysis, reporting and data visualization', 'Experience with at least 1 modern visualization tool (ex. PowerBI, Tableau, Microstratetgy 10, Domo); experience with Power BI preferred including DAX.', 'Experience leveraging tools for basic last mile ETL and data wrangling', 'Basic knowledge of data quality', 'Extensive experience with standard relational databases (Teradata, DB2, Postgres)', 'Working knowledge of Hadoop (HDFS) with ability to query Hive; exposure to Druid a plus.', 'Experience with GitHub a plus.', 'Strong communication skills to support business consulting and collaboration with business partners', 'Strong problem solving and analytical skills', 'Experience working in an agile environment preferred.']",2020-09-24 13:32:03
Software Engineer Data Platforms,Wish,3.8 out of 5,"San Francisco, CA","['Design and Develop data collection and processing systems to handle large data sets. You’ll have the opportunity to design innovative solutions and solve challenging problems.', 'Build and integrate scalable backend systems, services, and tools.', 'Design, Develop and Support highly-parallel, and fault-tolerant applications.', 'Minimum 2 years of experience as a Software Engineer using Java, Scala or any other programming language.', 'Experience with development, integration and tuning using Presto, Spark, Hive or other Query processing framework.', 'Bachelor or Master degree in Computer Science or related field.', '4 years of work experience in Software Development or Software Engineering.', 'Experience working on Amazon Web Services, or other cloud computing platforms.', 'Experience in building a framework to automate and scale workflows.', 'Experience with Kakfa or other messaging systems.', 'Experience with Flink, Spark or other stream processing frameworks.', 'Experience with Kubernetes, Yarn or other job schedulers.']",2020-09-24 13:32:03
PYTHON DATA ENGINEER,InspiHER Tech,N/A,"Chicago, IL","['Working with Python-driven data management and data pipeline development', 'Driving decisions on processing and storage formats', 'Measure and monitor on prem and cloud processes for fault tolerance and optimization opportunities', 'Understand, update and automate research pipelines', 'Work effectively both independently and with small teams', '2+ years’ experience using Python in a data driven environment', 'Strong background in Python, building applications and automation tools', 'Hands-on experience with Docker, Kubernetes, Dask, Spark, Hadoop and other data processing technologies', 'Experience and understanding of data caching strategies for data management', 'Proficiency in a Linux environment is required', 'Excellent written and verbal communication skills is needed']",2020-09-24 13:32:03
Data Engineer,Brinks Home Security,3.4 out of 5,"Farmers Branch, TX 75234","['Integrity in Action: Be True, Be Responsive, Be Accountable', 'Sense of Urgency: Every Moment Matters', 'Relentless Discipline: Rigor, Precision and Excellence in Every Single Action', 'Results Matter: Account to Customers, Employees & Stakeholders', 'Live and lead by Brinks Home Security values and behaviors.', 'Create and maintain optimal data pipeline architecture.', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Azure ‘big data’ technologies.', 'Contribute towards the development and application of the Enterprise Data Hubs Governance Standards, Data Modelling and associated processes.', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs.', 'Keep our data separated and secure across regional boundaries through multiple data centers.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', '2+ years of experience in a Data Engineer role', 'Bachelors or higher degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.', 'Experience using the following software/tools:', 'Big data tools: Hadoop, Spark, Kafka, etc.', 'Relational SQL and NoSQL databases.', 'Data pipeline and workflow management tools.', 'Azure cloud services. AWS knowledge is a bonus.', 'Stream-processing systems.', 'Object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with unstructured datasets.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.', 'Strong project management and organizational skills.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Excellent interpersonal, written/verbal communication of complex findings in a plain language (as well as technical when necessary), and leadership skills with the ability to quickly build credibility, influence and make recommendations to all levels.', 'Organizational skills - ability to manage multiple projects and tasks simultaneously, prioritize, and execute on assigned deliverables.', 'Strong cross-functional team player.', 'Strong business acumen and solid understanding of the business problems the company is trying to solve.', 'Enjoys higher learning and maintains an intellectual curiosity that fosters a current knowledge base of latest technology trends regarding advancements in Data Engineering / Science.', 'Ability to change direction quickly based on analytic needs.', 'Ability to travel on occasion as well as work remotely as the needs arise.', '401(k)', '401(k) matching', 'Dental insurance', 'Employee assistance program', 'Employee discount', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Referral program', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Aggressive -- competitive and growth-oriented', 'Outcome-oriented -- results-focused with strong performance culture', 'www.brinkshome.com', 'Waiting period may apply', 'Temporarily due to COVID-19']",2020-09-24 13:32:03
Senior Data Engineer,Wish,3.8 out of 5,"San Francisco, CA","['Design and Develop data collecting and processing systems to handle large data sets. You’ll have the opportunity to design innovative data solutions and solve challenging problems.', 'Design, Develop and Support highly-parallel, and fault-tolerant applications.', 'Build and integrate scalable backend systems, services, platforms, and tools', 'Contribute to the design and code of complex data pipelines operating on production data', 'Optimize current approaches to efficiently handle ever-increasing volumes of data', 'Build proof of concept using modern technologies and convert them into production-grade implementation.', 'Create best-practice reports and dashboards based on data mining, analysis, and visualization', '5 + years of experience as a Software Engineer or Data Engineer using Python, java or any other programming language', 'Expertise with SQL and data storage systems', 'Experience and knowledge of modern data warehouse, pipeline and reporting/analytic techniques and tools such as Airflow, Presto/Hive, Spark, or any other scheduling frameworks, Tableau or other reporting tools', 'Experience working on Amazon Web Services or other cloud computing platforms', ""Bachelor's degree in Computer Science or related field."", 'Experience in data visualization a plus.']",2020-09-24 13:32:03
Data Engineer,Airtable,N/A,"San Francisco, CA 94103","['Work between our engineering organization and stakeholders from our data science, growth, sales, marketing, and product teams, to understand the data needs of the business and produce pipelines, data marts and other data solutions that enable better product and growth decision-making.', 'Design and update our foundational business tables in order to simplify analysis across the entire company.', 'Continue to improve the performance and reliability of our data-warehouse.', 'Build and enforce a pattern language across our data stack, ensuring that our event taxonomy and tables are consistent, accurate, and well-understood.', ""You're passionate and thoughtful about building systems that enhance human understanding."", 'You have professional experience designing, creating and maintaining scalable data pipelines.', ""You've wrangled enough data to understand how often the complex systems that produce data can go wrong."", 'You can write clear, correct code in at least one programming language, and are willing to become effective in others as needed to get your job done.', 'You are highly effective with SQL and understand how to write and tune complex queries.', 'You communicate with clarity and precision in written form; experience communicating with graphs and plots, or at least understanding how to enable other people to do this, is a big bonus.', ""Health care: we have you 100% covered (and your dependents 50% covered) with competitive medical, dental, and vision insurance. You'll also be eligible for a complimentary membership to One Medical Group"", 'Learning & Development: we offer a $2,000 per year stipend for your personal career development', ""Gym Membership: we're proud to provide employees in our San Francisco and New York offices with complimentary gym memberships to Equinox, or up to $100/month reimbursement towards any other gym"", ""Catered lunches: we have high-quality catered lunches every day and well-stocked kitchens. We'll also reimburse you for any reasonable food expenses incurred while working"", 'Generous PTO, sick leave, and parental leave']",2020-09-24 13:32:03
Senior Data Engineer,Kamis,N/A,"McLean, VA","['Minimum of 5+ years experience with SQL development demonstrating a mastery of use.', '5-8 years experience working with data in a variety of capacities – analyst, developer, report development', 'Hands-on experience with at least one of the following Databases (SqlServer, Oracle, Snowflake)', 'Ability to create reports using PowerBi or other industry leading Business Intelligence Software', 'Experience with ETL/ELT tools such as SSIS, Azure Data Factory, Pentaho, Talend, etc', 'Dev-ops experience using GIT, developing, deploying code to production', 'Proficient in working in Unix/Linux as well as Windows server environment', 'Proficient in using Azure Cloud Services such as Azure Data Factory, key vaults, service bus, logic apps, power automate, etc', 'Proficient in programming in Python/shell or other scripting languages for the purpose of data movement', 'Make major contributions in setting the foundation for ETL/ELT framework for Data Analytics Team', 'Design and develop pipelines to bring data into and send data from our Data warehouse to other analytical solutions', 'Support existing pipelines and troubleshoot issues as they arise.', 'Create and maintain PowerBI apps, reports, dashboards that assist various departments and communities to use analytics to increase organizational efficiencies and help improve senior care.', 'Improve governance of our data assets including our PowerBi Datasets, Dataflows.', 'Taking a lead role in selection/creation of data catalog for all data assets.', 'Is an active and influential technical leader and a recognized data expert within the department.', 'Partners closely with department peers to ensure holistic data solutions for our data science community and analytic users.', 'Identifies new areas of data, research and data technology that can solve business problems', 'Utilize effective project planning techniques to break down complex projects into tasks, manage the scope of projects, and ensure deadlines are kept', 'Leverages, contributes and uses data best practices / lessons learned to develop technical solutions used for descriptive analytics, ETL, predictive modeling, and prescriptive “real time decisions” analytics', 'Develops technical solutions using data techniques in data & analytics processes.', 'Develops and builds frameworks/prototypes that integrate data and advanced analytics to make business decisions.', 'Implements new areas of data technologies, (ingestion, processing, distribution) and research delivery methods that can solve business problems.', 'Understands the data related problems and requirements to identify the optimal technical approach.', 'Works with peers to ensure efforts within owned tracks of work will meet their needs.', 'Identifies and develops data sources & techniques to solve business problems.', 'Co-mingles data sources to lead work on data and problems across departments to drive improved business & technical results through designing.', 'Bachelor’s degree in Computer Science or Information Technology or equivalent experience']",2020-09-24 13:32:03
Data Scientist I,"Amazon Web Services, Inc.",3.6 out of 5,"Seattle, WA","['Bachelor’s degree or foreign equivalent in Statistics, Computer Science, Applied Math, Information Systems, Operations Research, Economics, Engineering or a related quantitative field', '2+ years of relevant work experience in data science or related field', 'Must have two years of experience in the following skills: building statistical models and machine learning models using large datasets from multiple resources', 'Experience using database technologies including Redshift, SQL, or SPSS', 'Expertise applying specialized modelling (e.g. SAS, R, Matlab, or Stata)', 'Design and scripting experience in one or more scripting languages (Python, Java, Shell)', 'Ability to display complex quantitative data in a simple, intuitive format and to present findings in a clear and concise manner, using visualization (e.g. creating dashboards) and narrative formats', 'Organize and structure large data sets', 'Work closely with the teams to define the performance indicators', 'Determine how the key metrics and performance indicators will be calculated, owned, and managed.', 'Collaborate with colleagues across AWS Sales, Data Scientists, Economists, and the Worldwide Revenue Operations team to build and manage data infrastructure and models in support of predictive research and other scientific experiments', 'Dive deep to understand data sets and ensure statistical accuracy to support conclusions', 'Analyze data and present information to support decision making', 'Ability to display complex quantitative data in a simple, intuitive format and to present findings in a clear and concise manner, using visualization (e.g. creating dashboards) and narrative formats', 'Demonstrated ability to thrive in ambiguous environments and drive results', 'Experience in working and delivering projects independently', 'Solid communication skills and team player', 'Excellent organizational and multitasking skills with ability to balance competing priorities', 'Experience with time-series modelling', 'Experience with multiple database platforms is a plus', 'Experience with Amazon and other AWS technologies', 'Demonstrated ability to coordinate projects across functional and partners']",2020-09-24 13:32:03
Data Engineer,illumis,N/A,Remote,"['Write, maintain, and improve Python code for collecting and processing data from thousands of different third-party sources', 'Analyze new data sources to understand how to best acquire and model/catalogue the data', 'Develop a strong understanding of the ways our users use our products to help inform how we can best present records and data to meet their needs', 'Work with many different kinds of data, both public and proprietary, in many different structured and unstructured formats, ingested from sources such as APIs, databases, websites, files, cloud storage, etc.', 'Curate and monitor existing source integrations to ensure data in our platform is accurate, consistent, available', 'Analyze our data to deliver insights that improve our platform and power new features and products', 'You LOVE (or are at least intensely interested by) data and the idea of collecting, organizing, and making it more accessible and usable', 'You have worked programmatically with data in a role such as a software engineer, data analyst, digital archivist, scientist, researcher, or data programmer', 'You can quickly profile and understand a data set and implement an appropriate process in code for working with it', 'You’re experienced and proficient with Python, and have a strong working knowledge of web technologies such as HTTP, HTML, and JSON', 'You have experience ingesting data from varied and complex real-world sources including websites, files in multiple formats, databases, and APIs', 'You have a strong understanding of data types, schemas, and normalization and how to work with “dirty” data', 'You are a fast, motivated learner and are willing to pick up new tools and technologies on the fly to solve a problem', 'You’re excited by open-ended problems and are comfortable owning and delivering a solution from start-to-finish', 'You have a VERY strong attention to detail and documentation', 'You enjoy working collaboratively and really care about the work you do, the people you do it with, and the customers who ultimately use the product', 'Python, ElasticSearch, Postgres, Redis, Linux, Celery, Docker, GCP']",2020-09-24 13:32:03
Big Data Engineer,Lenora Systems Inc,N/A,"Mooresville, NC",['Temporarily due to COVID-19'],2020-09-24 13:32:03
Senior Data Engineer,Arvest,3.8 out of 5,"Bentonville, AR 72712","['Works closely with Architects, IT and Data Scientists to design, build, test, deliver, maintain and optimize sustainable and highly scalable data structures in support of strategic data science initiatives.', 'Participates in the prioritization of the data science backlog, weighing-in on viability and feasibility.', 'Proactively collaborates and aligns with key partners including data stewards, data owners, and IT to ensure the availability of subject matter experts for design, data modeling and definitions.', 'Researches data acquisition and evaluates suitability; identifies and understands anomalies; and works, as needed, with data stewards and the data governance committee to address systemic data quality and integrity issues.', 'Utilizes advanced technical expertise to design, develop and execute queries to extract both internal and external data from various sources that will be required for a robust and reliable data infrastructure.', 'Develops and manages data processes to ensure that data is available and usable.', 'Creates and automates data pipelines and platforms', 'Manages and monitors data quality and data loads using automated testing frameworks and methodologies such as Data-Driven Testing (DDT).', 'Leads or assists efforts of bringing data science models into production to drive strategic business outcomes.', 'Serves as a technical resource and widely promotes the re-use of data across the Company.', 'Provides guidance, direction, oversight and assistance to IT, contractors, and third-party partners in the build-out and support of data environments, for advanced analytics (Data Vault and Sandbox, for example).', 'Mentors and develops technical staff and analysts on the use and support of the data vault.', ""Understands and complies with bank policy, laws, regulations, and the bank's BSA/AML Program, as applicable to one’s job duties. This includes but is not limited to the following: completes compliance training and adheres to internal procedures and controls; reports any known violations of compliance policy, laws, or regulations and reports any suspicious customer and/or account activity."", 'Support and uphold the Arvest Mission Statement.', 'Uphold the Arvest Code of Ethics and ensure that confidential information is safeguarded.', 'Maintain a high level of cooperation and rapport with all associates in order to ensure accurate and efficient operations and service.', 'Formulate and communicate new ideas and suggestions that will improve profitability and efficiency for the company’s overall operation.', 'Promote professionalism at all times.', 'Bachelor’s Degree in Information Systems, Computer Science, Business Intelligence, or related field, or equivalent related work experience, is required.', '6 years of experience in designing, developing data queries for extracting, and transforming and merging large data sets for analysis, is required.', '2 years of experience in designing, building, managing and optimizing data environments for advanced analytics and data science.', 'Advanced SQL experience is required.', 'Advanced experience with IBM Infosphere DataStage integration tool or similar ETL tool, is required.', 'Experience with the extraction, transfer and loading of both structured and unstructured data sources, is required.', 'Experience with Data Vault architecture, advanced data structures that support the performance of various algorithms, and change data/historization methods, is preferred.', 'Experience with programming languages including Python, Java (Hadoop) and Scala (Kafka, Cassandra), is preferred.', 'Hands-on experience with data visualization tools (Tableau or similar) is preferred.', 'Prior experience in banking or financial services is preferred.', 'Demonstrable experience in influencing, communicating and collaborating with management and in working across all level of the organization', 'Technically savvy, entrepreneurial spirit who thrives in environments that reward self-initiative and resourcefulness', 'Strong Organization, follow-up, and follow through skills', 'Great communication skills (clear, concise, informative and engaging)', 'Must be able to conclusions from raw data and summarize results quickly and efficiently', 'Must be able to arrive at work on time, work on site and have regular work attendance', 'Must be able to work cooperatively and cordially with other customers and co-workers regardless of personality, presence or communication style', 'Must be able to perform several tasks at once', 'Must be able to work in a stressful atmosphere', 'Must be able to rotate job tasks', 'Must be able to coordinate multiple and changing priorities', 'Must be able to occasionally work outside of normal business hours.', 'Must be able to move from department, division, or bank to department, division, or bank to attend meetings', 'Must be able to create reports, schedules and other appropriate documentation']",2020-09-24 13:32:44
Petroleum Engineer / Production Engineer,Countrymark Refining and Logistics,N/A,"Evansville, IN 47715","['Identify, generate and implement production enhancement opportunities, both completion and drilling, as part of a multi-discipline area team.', 'Monitor performance of existing production and provide recommendations for improvement and best optimization methods.', 'Identify, plan, and implement expense and capital production enhancement projects (workovers, stimulations, waterfloods, new drills, etc.).', 'Develop workover and waterflood drilling projects and Authorization for Expenditure (AFE).', 'Perform artificial lift optimization and selection of artificial lift type.', 'Design and/or size facilities and equipment.', 'Work with integrative team members to prepare risked reserve estimates and economics for drilling prospects, workovers, well service jobs and new facility or expansion projects.', 'Foster operation reviews involving production, completion and expense optimization of individual well or field performance.', 'Utilize ARIES program to provide economic evaluations for projects and acquisitions including calculation of estimated reserves, costs and cash flow.', 'Forecast production data for yearly budget process, Long Range Plan, and other presentations/forecasts, including end of month reports and Balance Score Card.', 'Run project economics.', 'Analyze potential acquisition opportunities and prepare presentations.', 'Solve technical problems for the field operations.', 'Put together data for and manage the process to have annual reserve report prepared.', 'Provide technical and operational support for company-operated completions and remedial workovers in oil and gas wells', 'Participate in multi-discipline well planning team', 'Interface with Operations & Technical Team Leaders (Engineers, Geologists, Techs, etc.) to execute projects effectively.', 'Perform field studies and build economic models to determine value for acquisitions or divestitures.', ""Carry out budget preparation and monitoring; prepare cost analysis, estimates, and AFE's for routine workovers and completion/recompletion of wells."", 'Liaise with production managers to champion capital project activities and regular well reviews.', 'As needed, supervise field activities such as drilling, frac jobs, acid jobs, and other work that may arise.', 'Develop goals and performance metrics. Track and measure metrics, implementing improvements as necessary.', 'Identify and incorporate best practices from past operations to ensure continuous improvement.', 'Proficiency in ARIES or other economic-related analysis programs.', 'Knowledge of well design and completion operations, with capability to ensure safe, consistent and high performance operations.', 'Strong analytical and problem solving skills.', 'Knowledge of government regulations and permitting requirements.', 'Strong communication skills, teamwork behaviors, ability to work in cross-functional teams and influence partners.', 'Ability to communicate throughout the organization including making presentations and communicating with executive management.', 'Work effectively, relate well with others, and exhibit a professional manner in dealing with others, working to maintain constructive working relationships.', 'Demonstrate the ability to organize and manage multiple priorities.', 'Knowledge of operations; production, injection, gathering systems and surface facilities equipment.', 'Capable of measuring performance to company goals and standards.', 'Serve as a resource (experience, knowledge, process) to team and teammates.', 'Able to function well on high performance teams and be a strong team player.', 'Proficient in Microsoft Office Suite.', 'Experience with Avocet and Oil Field Manager (OFM) preferred.', 'Advocate for the use of industry standard production equipment and practices.', 'Strong decision-making skills.', 'Adapts to change and ambiguity.', 'Perform in field and on-site observations.', 'Demonstrates CountryMark’s core values of Excellence, Improvement, Innovation, Integrity, and Reliability.', 'Must be able to accommodate travel (5%) and extended hours as needed.']",2020-09-24 13:32:44
Scientific Data Engineer I - Image Processing - Cell Science,Allen Institute,3.3 out of 5,"Seattle, WA 98109","['Assist in developing and implementing robust image processing pipelines, algorithms, feature extraction, and analyses of image-based assays of cell organization, dynamics, states, activities, and functions', 'Collaborate with other teams in the institute to scale-up data analysis and image processing protocols into a high throughput microscopy and analysis pipeline', 'Maintain rigorous quality control standards', 'Maintain meticulous records and work closely with other scientists to coordinate complex activities', 'Follow the Allen Institute for Cell Science’s software management and deployment standards including source code management, issue tracking, staging and deployment standards, and documentation', 'Coordinate with other programs in the Institute to ensure seamless integration and sharing of resources and data', 'BA/BS in any science, computation, or engineering field or related degree', 'Experience in image processing, data analysis, and machine learning', 'Basic hands-on experience in Python', 'M.S. in any science, computation, engineering field or related degree', 'Hands-on experience either from internship or undergraduate research in one or more of the following areas:Classic approaches to image processingDeep learning approaches to image processingBiological or biomedical image processingMicroscopy image processing3D image processingLow signal to noise image processing (including e.g. in astronomy or other non-biological researchStatistical analyses', 'Careful attention to detail', 'Basic knowledge of version control using github', 'Experience working in a multi-disciplinary environment in academic or industrial settings', 'Ability to work both independently and in a collaborative, multi-disciplinary environment', 'Open office seating, Cubicle layout', 'May enter laboratory environment, including potential exposure to lasers, biohazards', 'Occasional lifting to 30 pounds', 'Fine motor movements in fingers/hands to operate computers and other office equipment; lab equipment', 'This is an onsite, M-F, regular business hours position', 'Occasional travel to partner sites for compliance oversight required', 'Attendance and participation in national and international conferences may be required', '**Please note, this opportunity offers relocation assistance**', '**Please note, this opportunity offers work visa sponsorship**']",2020-09-24 13:32:44
Senior Data Engineer,TRILLIUM HEALTH RESOURCES,3.2 out of 5,"Wilmington, NC 28403","['Developing and modifying existing databases, warehouses and database management systems', 'Testing programs or databases, correcting errors and making necessary modifications', 'Planning, coordinating and implementing security measures (including regular audits) to safeguard information in databases and computer files against accidental or unauthorized damage, modification or disclosure', 'Assisting with creating reports, data mining and data management', 'Developing reference and workflow documents for documentation purposes', 'Flexible Work Schedules', 'Health Insurance - no premium for employee coverage', 'Flexible Spending Accounts', 'Paid vacation and sick leave, plus 10 paid holidays', 'NC Local Government retirement pension, plus 401k with 4% employer match', 'Public Service Loan Forgiveness Qualifying Employer', 'Employer NameDates of serviceAverage number of hours worked per weekEssential duties of the job as related to the position you’re applying for', 'EducationDegree typeDate degree was awardedInstitution', 'Licensure/certification, if applicable']",2020-09-24 13:32:44
Senior Data Engineer,Valukoda,N/A,"Plano, TX 75024","['Responsibility of contributing to the continual improvement of the business’ data platforms through observations and well-researched knowledge', 'Proficient with programming in at least one programming language (Python, Bash scripting, etc.)', 'Proficient with horizontally distributed database technologies', 'Strong ETL proficiency using GUI-based tools or code-based patterns', 'Proficient with data-modeling principles', 'Keeps track of industry best practices and trends and through his acquired knowledge, takes advantage of process and system improvement opportunities', 'Experience building and managing data warehouses to fulfill reporting requirements', 'Excellent verbal and written communication', 'Result-driven individual and strategic thinker', 'Be proactive requiring minimal supervision, be highly organized', 'Have an ability to handle multiple tasks and meet tight deadlines', 'Can communicate effectively and simplify complexity', 'Work comfortably work in a collaborative setting, work comfortably with senior departmental leadership', 'Ability to combine experience, knowledge, perspective, and awareness to make sound business decisions', 'Strong problem-solving skills', 'Adaptability and flexibility in changing situations', 'Passion for delivering compelling solutions that exceed client expectations', 'Understanding of data storage strategies and optimizing read/write tradeoffs', 'Familiarity with “Lambda Architecture” and streaming / batch data', 'Understands data design implications and communicates risks/tradeoffs', 'Understands algorithmic complexity and “Big O” notation', 'Understands data partitioning strategies', 'Understands clustering and parallelism strategies', 'Understands MapReduce and the popular technologies build around it', 'Understands DAGs and their use in ETL', 'Amazon Redshift, RDS (Postgres), S3, Kinesis, DynamoDB and related AWS data products', ""Bachelor's degree in Computer Science, Mathematics, Statistics or a related field"", '5+ years of related experience', 'Dental insurance', 'Health insurance', 'Monday to Friday', 'data engineering: 5 years (Required)', 'Plano, TX 75024 (Preferred)', 'United States (Required)', 'Will you now or in the future require sponsorship for employment visa status (e.g., H-1B visa status)?', 'Temporarily due to COVID-19']",2020-09-24 13:32:44
Data Entry Operator II (Temporary),Sciolex Corporation,4.4 out of 5,"Saint Albans, VT 05478","['401(k)', 'Employee discount', 'Retirement plan', '8 hour shift', 'Monday to Friday', 'data entry: 1 year (Preferred)', 'High school or equivalent (Preferred)', 'No']",2020-09-24 13:32:44
CVML Data Engineer- VCV Synthetic Data Group,Apple,4.2 out of 5,"Santa Clara Valley, CA 95014","['5+ years of experience with Python / Matlab / C++ for data analysis, algorithm development, and visualization', 'Breadth knowledge in computer vision, with understanding of traditional and deep learning solutions to various perception problems (with experience developing and testing Convolutional Neural Network)', 'Work with world-class computer vision engineers to understand the algorithms they develop, propose adequate synthetic datasets requirements and drive the implementation of the synthetic dataset platform', 'Build systems to gather analytics and report metrics to quantify synthetic data and algorithm performance, streamline development operations, and relate them to user experiences', 'Experience using Synthetic Data for training computer vision models', 'Experience using Deep Learning packages such as Tensorflow/Keras & PyTorch', 'Familiarity with assembling test plans, designing test cases, and developing test applications and/or tools to quickly track and debug failures in a large scale systems']",2020-09-24 13:32:44
Data Scientist,"TraceLink, Inc.",N/A,Remote,"['Collaboratively identify data science opportunities that support business and product goals', 'Propose, develop, evaluate, and perfect specific data science solutions', 'Modify solutions to address application constraints', 'Integrate modified solutions into cloud-based product offerings', 'Communicate results and ideas to business leaders', ""Master's Degree in Applied Mathematics, Data Science, or related field"", 'Analytical, data-driven, inquisitive mindset with a bias toward precision', 'Superb written and oral technical communication skills', 'Learn quickly especially within computer technologies and mathematical concepts', 'Proficiency in mathematics, statistical analysis, and software development', 'Proficiency in data science environments, tools, and technologies', 'Broad knowledge of data science techniques', 'Develop, evaluate, perfect, and implement data science solutions', 'Implement analytical models into production by collaborating with software developers and machine learning engineers.', 'PhD in Applied Mathematics or similar field', 'Formal training in data science or related disciplines such as mathematics, engineering, or computer science', 'Experience with big data cloud technologies especially Amazon offerings', 'Experience with software engineering tools and processes (agile software development)', 'Proficiency with MSOffice and Google G Suite tools', 'Experience with Java, Scala, javascript, SQL, Python, R, XML, yaml, JSON, shell scripting', 'Proficiency with applied mathematics such as probability and statistics, stochastic systems, queueing theory, optimization, control theory, and adaptive systems.']",2020-09-24 13:32:44
SQL Query Engineer (3123-SH),"Stout Systems Development, Inc.",N/A,"Ann Arbor, MI 48108","['Advanced knowledge of and experience with SQL and relational databases, including indices, joins and aggregation.', 'Familiarity with Microsoft Excel', 'Clear communication skills in person, by email, and by phone', 'A strong customer service orientation', 'Excellent attention to detail and ability to follow processes', 'Experience with MySQL', 'Programming experience in PHP, Python, or Java', 'Familiarity with Linux', 'Experience with a data visualization tool', 'There is tremendous opportunity to grow in this company.', 'One possible growth path is in the direction of business intelligence and data visualization.', 'Another possible growth path is in the direction of programming.']",2020-09-24 13:32:44
Spring 2021 CBS Sports Data Engineering Intern,CBS,3.9 out of 5,United States,"['Performing exploratory and data gap analysis on core sports data', 'Building out real-time predictive data pipelines', 'Building out visualization dashboards', 'Building out new data features for sports gambling insights.', ""This is a paid internship and can also be for university credit if it meets your university's guidelines"", 'A sports fanatic - you are really sad when your favorite team(s) loses, you can break down matchups across different leagues, you have a strong opinion about which activities should be deemed a sport.', 'Good understanding of data structures, algorithms, object oriented design and patterns.', 'Intern must be a student currently enrolled in an accredited college, university or bootcamp', 'Must be at least 18 years old', 'Experience with sport data research', 'Experience building web applications for data visualization', 'Technology experiences with: AWS, SageMaker, Python, NodeJS, Lambda, API Gateway, DynamoDB & RDS']",2020-09-24 13:32:44
"Data Engineer, Cell Qualification",Tesla,3.5 out of 5,"Palo Alto, CA","['Design data pipelines and infrastructure for a multitude of cell characterization techniques.', 'Apply the same software framework to new test methods as they come online', 'Implement near real time monitoring and visualization of the data systems and their associated data', 'Improve the robustness of our experimental pipeline from the time we receive cells, to test, to results', 'Help construct machine learning infrastructure to help increase our learnings and experimental throughput', 'Build tables with the optimum indices for fast querying. These tables will also be constrained to reduce the chance of bad data leaking into our system', 'BS/MS in Computer Science or or a similar background with strong software engineering experience', 'Experience building data scalable data pipelines complete with monitoring', 'Experience with Python and relational databases', 'Experience with a production task scheduler like celery or airflow', 'Experience with front end technology like React is a plus']",2020-09-24 13:32:44
Data Engineer - AWS Security,"Amazon Dev Center U.S., Inc.",3.6 out of 5,United States,"['Bachelors degree in Computer Science, related field, or equivalent work experience', '3+ years of relevant experience including Data Engineering, Database Engineering, Business Intelligence', 'Proficient in one of Programming languages (e.g., Python, Java, Ruby, Scala)', 'Proven experience in data modeling, ETL development, and data warehousing, or similar skills.', 'Demonstrable skills and experience using SQL with large data sets', 'Experience with agile development or similar methodologies for continuous development of product and technology', 'Work with managers, software engineers, and scientists to design and develop data infrastructure.', 'Enable effective decision making by retrieving and aggregating data from multiple sources and compiling it into digestible and actionable forms.', 'Perform deep-dives to find root causes of variances of key forecasting parameters over a given time period.', 'Develop intelligent, insightful self-reporting tools.', 'Optimizing the performance of business-critical queries and dealing with ETL job related issues', 'Masters degree or PhD in Computer Science, Engineering, or related field', 'Experience with AWS technologies stack including Redshift, RDS, S3, EMR or similar solutions build around Hive/Spark etc', 'Proven track record of successful communication of data infrastructure, data models, and data engineering solutions through written communication, including an ability to effectively communicate with both business and technical teams', 'Experience in communicating with users, other technical teams, and senior management to collect requirements, describe software product features, technical designs, and product strategy', 'Proficient in shell scripting', 'Strong organizational and multitasking skills with ability to balance competing priorities.', 'An ability to work in a fast-paced environment where continuous innovation is desired and ambiguity is the norm.', 'Experience designing and operating very large Data Warehouses.', 'Knowledge about statistical models and data mining algorithms', 'Solid communication skills and team player.', 'Track record for quickly learning new technologies', 'Experience with distributed systems', 'Experience influencing technical best practices within your team', 'Meets/exceeds Amazon’s leadership principles requirements for this role', 'Meets/exceeds Amazon’s functional/technical depth and complexity for this role']",2020-09-24 13:32:44
Database Engineer (Data Warehouse),American Advisors Group,3.6 out of 5,"Irvine, CA 92612","['Consolidate and optimize available data warehouse infrastructure utilizing SSIS/SSAS/Snowflake', 'Create stored procedures, SSIS packages, and using other methods to import/translate/manipulate data', 'Analyze potential data quality issues to determine the root cause, and creating effective solutions', 'Conceive analytics and business intelligence platform architecture for clients, including internal and third-party clients', 'Design and implement, monitoring, and tuning ETL Processes', 'Collaborate with business and technology stakeholders in ensuring data warehouse architecture development and utilization', 'Perform the design and extension of data marts, meta data, and data models', 'Ensure all data warehouse architecture codes are maintained in a version control system.', 'Design and implement ETL procedures for intake of data from both internal and outside sources; as well as ensure data is verified and quality is checked', 'Perform the design and extension of data marts, meta data, and data models', 'Develop, monitor and maintain data marts across the enterprise, while ensuring high levels of data availability.', 'Develops, maintains and optimizes all efforts related to Data Warehouse (SSIS, Stored Procedures, Views etc.)', 'Identifies and implements optimizations to both performance and accuracy of databases, as required and appropriate.', 'Develops and adheres to standards, processes and procedures to create, deploy and maintain databases.', 'Design, implement, and maintain new and existing database objects including tables, indexes, constraints, stored procedures, and user-defined functions in support of data conversion projects.', 'Data Warehousing and related tools: SSAS, SSIS, Snowflake, SQL Server and Informatica Cloud Integration Services', 'Azure and Cloud Certification is a plus', 'Database Modeling, Tuning, Security, Administration and Management', 'Structured thinker and effective communicator, comfortable interacting with constituents', 'EDUCATION / WORK EXPERIENCE', 'Possess Bachelor’s degree in information technology, Computer science, and engineering discipline', '10+ years or more experience performing data warehouse architecture development and management', 'Remarkable experience with technologies such as SQL Server, Snowflake as well as SSIS and stored procedures', 'Strong Experience with Informatica', 'Exceptional experience developing codes, testing for quality assurance, administering RDBMS, and monitoring of database', 'Strong working knowledge of application and T-SQL code and ability to demonstrate the ability to write functional requirements.', 'High proficiency in dimensional modeling techniques and their applications', 'Extensive hands on experience in data warehousing design, tuning and ETL/ELT process development Solid communication skills – both written and verbal', 'Ability to meet deadlines', 'Excellent communication skills (written and verbal)', 'Client-facing presence and excellent business acumen.', 'Attention to detail and solid organization skills']",2020-09-24 13:32:44
Data Analyst,Big Health,3.5 out of 5,United States,"['Provide accurate reporting on user engagement and behavior to internal consumers company-wide.', 'Consolidate frequent requests into dashboards and other on-demand resources.', 'Help the Customer Success and Sales teams make their cases with compelling quantitative claims and sound supporting evidence.', 'Identify trends in client, end user, and marketing data that make the Customer Success team more effective at driving adoption of our products. Write scripts that automate regular reporting to clients and partners.', 'Develop engaging ways to depict and present multifaceted outcomes data to clients.', 'Manage financial datasets and the processes for keeping them up-to-date and accurate.', 'You should be able to write complicated SQL queries, be a power user of R or Python for data analysis and manipulation, have some experience with scripting, and have strong skills in Excel/ Google sheets.', 'Comprehensive data manipulation abilities that allow you to confidently transform data while maintaining its integrity using all the tools listed above.', 'Exceptional attention to detail - the numbers you share will have a big impact, so you will need to be sure that they reflect what you intend.', 'Strong communication and presentation skills. Analyzing and compiling data is only the first step - you also need to be able to effectively communicate your findings to the rest of the team (including people who aren’t familiar with data analysis).', 'Experience with stakeholder management. You will need to juggle diverse requests from across the company, so the ability to set expectations and hit the hard deadlines you agree to is essential.', 'Be part of a team that includes clinical psychologists, software engineers, business leaders and even a former professional magician [shh… it’s a secret].', 'Surround yourself with the smartest, most enthusiastic and dedicated people you’ll ever meet, but who listen well, learn from their mistakes and when things go wrong, generously pull together to help each other out', 'Check out our values - they’re a living, breathing part of our culture', 'Enjoy benefits including a generous vacation policy, professional development fund, flexible working locations and more.', 'Competitive salary packages including stock options.']",2020-09-24 13:32:44
Data Analysis / Engineer,AC HOME,N/A,"Houston, TX 77036","['Provide services to end-users in planning, developing and deploying real estate data online', 'Develop custom data repositories, content indexing and workflow', 'Configure and administer services, User Profile Services, site metadata, and Excel services', 'Provide system administration including, but not limited to, analysis, capacity planning, integration and quality assurance', 'Promote online solutions and facilitate those solutions; identify practices and processes that can be improved', 'Create reports for use internally as well as for clients with internal and external data', ""Bachelor's degree or at least 4 years of equivalent work experience"", '3 years of experience', 'Solid technical aptitude and leadership', 'Strong analytical skills', 'Strong verbal and written communication skills', 'Experience in the real estate industry a plus']",2020-09-24 13:32:44
Data Analysis / Engineer,AC HOME,N/A,"Houston, TX 77036","['Provide services to end-users in planning, developing and deploying real estate data online', 'Develop custom data repositories, content indexing and workflow', 'Configure and administer services, User Profile Services, site metadata, and Excel services', 'Provide system administration including, but not limited to, analysis, capacity planning, integration and quality assurance', 'Promote online solutions and facilitate those solutions; identify practices and processes that can be improved', 'Create reports for use internally as well as for clients with internal and external data', ""Bachelor's degree or at least 4 years of equivalent work experience"", '3 years of experience', 'Solid technical aptitude and leadership', 'Strong analytical skills', 'Strong verbal and written communication skills', 'Experience in the real estate industry a plus']",2020-09-24 13:33:26
Data Engineer,"Ames IT and Numeric Solutions, LLC",N/A,"El Monte, CA 91731","['Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.', 'Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.', 'Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.', 'Writes unit/integration tests, contributes to engineering wiki, and documents work.', 'Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.', 'Works closely with a team of frontend and backend engineers, product managers, and analysts.', 'Defines company data assets (data models), spark, sparkSQL, and hiveSQL jobs to populate data models.', 'Designs data integrations and data quality framework.', 'Designs and evaluates open source and vendor tools for data lineage.', 'Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.', 'Knowledge of best practices and IT operations in an always-up, always-available service', 'Experience with or knowledge of Agile Software Development methodologies', 'Excellent problem solving and troubleshooting skills', 'Process oriented with great documentation skills', 'Excellent oral and written communication skills with a keen sense of customer service', 'BS or MS degree in Computer Science or a related technical field', '3+ years of Python or Java development experience', '3+ years of SQL experience (No-SQL experience is a plus)', '3+ years of experience with schema design and dimensional data modeling', 'Ability in managing and communicating data warehouse plans to internal clients', 'Experience designing, building, and maintaining data processing systems', 'Experience working with either a Map Reduce or an MPP system on any size/scale', '401(k)', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Professional development assistance', 'Monday to Friday', 'Java: 3 years (Preferred)', 'SQL: 3 years (Preferred)', 'Python: 3 years (Preferred)', 'data modeling: 3 years (Preferred)', ""Bachelor's (Preferred)"", 'Yes', 'Yes: H-1B work authorization', 'Yes: Immigrant visa sponsorship (e.g., green card sponsorship)', 'www.ames-it-solutions.com', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-09-24 13:33:26
Senior. Data Engineer (Remote),Gannett,3.1 out of 5,New York State,"[""•You'll build, maintain and optimize our BigQuery data-lake infrastructure using technologies listed below."", '•Expect to work on ingesting new data sources from initial discovery & data architecture, through ETL authoring, operationalizing using Airflow DAGs, and post launch lifecycle.', '•Research and test new big-data technologies and tools.', '•Advanced SQL queries, and modeling.', '•Help drive the roadmap of Data Platform engineering.', '•Proactively engage vendors with required features to meet our roadmap and needs.', '•Leverage the full value out our vendor integrations and APIs.', '•Optimize BigQuery and ingest ETL resources to decrease spend & increase performance.', '•50% - Platform development – Updating and evolving our tools and services.', '•50% - Platform Support – working with business stakeholder teams on projects, adhoc requests, troubleshooting issues & answering questions', '•Google Cloud Platform', '•BigQuery', '•Airflow', '•Kubernetes', '•Docker', '•Python, Scala, Java, Bash', '•Singer.io', '•Qubole', '•Github', '•Looker', '•Bachelor’s degree or equivalent experience', '•5+ years experience in big data centric position', '•Expertise in at least one scripting/programming language', '•Deep SQL knowledge/experience', '•Experience with managing cloud solutions', '•Experience in complex pipeline task management (Airflow, Argo, etc…)', '•Experience with Kubernetes']",2020-09-24 13:33:26
Data Conversion Engineer,Collaborative Solutions,3.5 out of 5,"Tampa, FL 33607","['Creation, support and maintenance of multiple versions of ETL solutions', 'Track issues and risks while communicating status and escalating concerns to management', 'Work directly with Consulting Services team to support data conversion efforts from customer legacy systems into Workday tenants', 'Ideally 3-5 years of coding experience', 'Expertise with ETL Platforms', 'Experienced with SQL on RDBMS and data interchange formats', 'Demonstrated expertise with web services technologies', 'Working knowledge of Java and C# programming', 'Project experience in a technical or techno-functional role on one or more ERP is a plus', 'B.A. / B.S., Management Information Systems, Industrial Engineering, Computer Science, or other engineering discipline preferred', 'Superior detail orientation, organization, and analytical skills', 'Ability to operate effectively in a dynamic, growing, ecosystem with minimal supervision']",2020-09-24 13:33:26
Data Engineer,Sema4,3 out of 5,"New York, NY 10003","['401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Life insurance', 'Paid time off', 'Tuition reimbursement', 'Vision insurance', 'Monday to Friday', 'SQL: 3 years (Preferred)', 'Python: 3 years (Required)']",2020-09-24 13:33:26
Data Engineer II,Staples,3.5 out of 5,"Lincolnshire, IL 60069","['Experience with Unix/Linux shell scripting', 'Experience with PL-SQL Programming', 'Experience with standard Unix/Linux editing, text manipulation, and search tools', 'Experience with input files (standard csv, delimited, fixed width, and JSON)', 'Experience with single and multi-dimension data sets like Microsoft SSAS, Tabular', 'ETL design, development, and performance tuning on Oracle/SQL Server', 'Experience with Data Visualization tools like Power BI, Tableau, and SSRS', 'Big Data tools including Sqoop, Spark, Hive SQL, and Pig', 'Microsoft SQL Server 2012 or above']",2020-09-24 13:33:26
BI Data Engineer (Tableau Data Visualization Developer),Roseburg Forest Products,3.5 out of 5,"Springfield, OR 97477","['Design, develop, test, and deploy Business Intelligence analytics and reporting solutions through Tableau', 'Lead the design, development, and maintenance of data integration, services, etc. to provide the right data to the right place at the right time', 'Ensure designed systems are highly reliable, self-recovering, and require little or no supporting manpower', 'Collaborate with business stakeholders to develop an understanding of their business and operational processes to develop Tableau interfaces and reports and develop self-service reporting solutions', 'Develop dashboards visualizing a wide variety of topics', 'Manage solution enhancement/defect backlog lists and continuously deliver agreed upon improvements through design, development and testing', 'Evaluate new and existing data streams for data analysis and presentation proof of concept development', 'Train users on how to use solutions through user focused documentation including written and video documentation', 'Mentor and develop technical competency of junior team members', 'Perform and/or lead necessary tuning of database and ETL systems and objects to ensure timing and performance goals are met', 'Collaborate with existing and prospective users to define Data Warehousing and Business Intelligence requirements', '3+ years’ experience in Tableau', 'Hands on experience with SQL and non-SQL databases like Oracle, SQLServer, or similar', 'Hands on experience with Data Marts for Reporting, Dashboards and Analytics', 'Proficient relational database experience. The individual must have an excellent command of SQL. (MS SQL Server preferred)', '3+ years of experience in data integration, ETL, and data management or comparable positions that handle large/complex data sets, developing automation,', 'Proficient in understanding of data management practices, data architecture principles, and data governance process', 'Knowledge of Tableau best practices in performance tuning and user-centric design, proactive alerts, etc', 'Proficient in understanding of data mapping and lineage strategies', 'Excellent written communication and presentation skills', 'Bachelor’s degree in Computer Science, Information Technology, Mathematics, or related area of study; or equivalent combination of education and/or relevant work experience', 'Tableau Certification is a big plus but not required']",2020-09-24 13:33:26
Data Engineer,mPulse Mobile,4.4 out of 5,"Encino, CA 91436","['Model Integrity and Collaboration', 'Drive Innovation and Thought Leadership', 'Support Decision Making at All Levels', 'Create Value for Clients by Empowering Consumers', 'Improve Customer Experience Through Simple Design', 'Celebrate Success… Often', 'Working with the data science and data analytics team to refine and develop data science and analytics (DSA) product roadmap', 'Support Redshift cluster management including monitoring, performance tuning, and optimization', 'Responsible for data loads and data extracts via Airflow DAG and python code.', 'Engaging in exploratory A/B studies to extract data features and determine the relative value of multiple data types', 'Building rich and interactive data visualizations to display findings from A/B studies, to guide and inform exploratory data analysis, and to deepen customer engagement', 'Understanding and applying data mining techniques, including NLP, clustering algorithms and regression analysis to generate deep insight and discover effective solutions to challenging problems', '2-5 years of experience in a corporate, start-up, or research environment', '2-5 years of experience mentoring data analysts (corporate) or graduate students (academia)', '2-5 years of experience in Airflow DAG creation, debugging and maintenance', '2-5 years of experience in PostgreSQL and Elasticsearch', 'Strong background and solid skills in interactive data visualization (Tableau, Django, Shiny, D3.js)', 'Experience in research methods, exploratory data analysis, and machine learning', 'Intense intellectual curiosity – strong desire to always be learning', 'Analytical, creative, and innovative approach to solving difficult problems', '4 year Bachelor of Science or BA Degree in Computer Science, Computer Engineering or other related field', '2 years of direct experience as a data engineer or working directing in data engineering / data science.', '1 years of experience with Python (Pandas, NumPy, sciKit-learn), SQL and R', 'US Citizen', 'Please note, due to the requirements of this position, responses may automatically disqualify you from moving forward in the application process. Please review minimum qualifications thoroughly before applying.', 'Customer Focused', 'Attention to Detail', 'Independent Self-Starter', 'Highly Organized', 'Critical Thinker', 'Problem Solver', 'Excellent Communicator', 'Ability to Prioritize', 'Team Work & Collaboration', 'Multi-Tasker with Strong Sense of Urgency', 'Enjoy Flexible PTO and flexible work hours', 'Full Vision, Dental and Healthcare - all individual premiums paid by mPulse!', '401K Program with a 4% match', '3 Weeks Paid Maternity/Paternity Leave', 'Weekly team lunches to celebrate victories', 'Paid Parking as well as Car Pooling incentives', 'Laptop fitness stations', 'Ping pong conference table and Foosball', 'Free snacks and drinks']",2020-09-24 13:33:26
BI Data Engineer (Tableau Data Visualization Developer),Roseburg Forest Products Co.,3 out of 5,"Springfield, OR 97477",[],2020-09-24 13:33:26
Data Annotation Specialist,Tesla,3.5 out of 5,"San Mateo, CA 94402","['You will use the Autopilot labeling interface to label images critical to training our deep neural networks.', 'You will interact with the computer vision engineers on the Autopilot team to help us improve on the design of an efficient labeling interface.', 'You will be expected to gain basic computer vision and machine learning knowledge to better understand how the labels are used by our learning algorithms, as this will allow you to make more judgement calls on difficult edge cases that might come up during labeling.', 'High School diploma or evidence of exceptional ability.', 'Passionate and curious about technology.', 'Available to work overtime as needed.', 'Able to work in a fast paced environment, learn quickly and be able to prioritize assignments.', 'Proficient computer skills utilizing keyboard/mouse.', 'Detail-oriented and patient.', 'Communicate clearly using excellent written and verbal skills.', 'Must be reliable, have good initiative, committed and quality focused.', 'Proficient in Microsoft Office Suite is a plus.', ""Available for work schedule of 9:00am – 5:00pm M-F at Tesla's San Mateo Office.""]",2020-09-24 13:33:26
Data Engineer,Edward-Elmhurst Health,3.9 out of 5,"Warrenville, IL 60555","['Database Design and PerformanceWith oversight from more senior Data Engineers, designs and develops analytic data repositories (data warehouse, data marts, data lakes).Implements and maintains database security in accordance with Security policies.', 'ETL/ELT Design and DevelopmentWith oversight from more senior Data Engineers, designs and develops ETL/ELT processes to acquire, manipulate and store data.Tests and documents programs according to team standards.Prepares ETL/ELT solutions for deployment following established change management guidelines.', 'BI Technology Management and InteroperabilityImplements new or upgrades existing analytics software and servers with support of more senior Data Engineers.Troubleshoots moderately complex technical issues and resolves problems related to analytics tools.Keeps abreast of new features available in the team’s chosen set of databases and analytics tools.', 'Required Education and/or Experience:', ""Bachelor's degree or higher in Computer Science/Engineering, Information Systems, or relevant course of study or commensurate experience"", '3+ years of programming experience with a solid background in software development life cycle practices', '3+ years of experience writing and tuning SQL queries and stored procedures', 'Solid understanding of data warehouse architectures and ETL/ELT processes.', 'Preferred Education and/or Experience:', '3+ years of experience working with healthcare data and has an understanding of clinical workflows and billing practices', 'Exposure to Agile/Scrum development methodologies', 'Experience working with the following tools/technologies:Epic – Caboodle Development and AdministrationMicrosoft SQL Server DBMSETL Software (SSIS, Informatica, others)Source Code Repositories (TFS, Git, others)Microsoft Power BI, SSAS, SSRS, TableauData Lake architecture and cloud data platforms', '3+ Years of relevant experience.', 'Preferred License/Certifications:', 'SQL Server (DBMS/SSIS)', 'Epic Caboodle Development and Administration']",2020-09-24 13:33:26
Data Engineer (Junior and Mid),ICF,3.5 out of 5,"Fairfax, VA 22031","['Extract, transform, and load (ETL) processing routines and data feeds to transmit data to and from clients and subcontractors; create necessary data structures or data models to support data at all stages; and design and implement custom data analytic and BI/reporting products.', 'Perform extensive data profiling and analysis based on the client’s data', 'Work with UI teams and/or client to define BI and reporting requirements', 'Developer custom reports and data visualization products', 'Support project delivery on Data Warehouse/BI projects for external and internal clients, including partnering with ICF subject matter experts on project execution', 'Bachelor’s degree (e.g., Computer Science, Engineering or related discipline)', '6-8 years’ experience developing database ETL environments with business intelligence applications such as Talend, Informatica', '3+ years’ experience with services AWS Glue, Lambda, Microsoft Azure Data Factory, Google Cloud Data Flow', '6+ years’ experience in SQL and procedural programming', '6+ years of experience working with databases and BI tools such as Tableau, PowerBI', 'US Citizen or Permanent Lawful Resident (Green Card Holder) preferred. Employment must be compliant with eligibility for Public Trust Clearance due to Government Contract.', 'Understand ETL concepts of data flow, data enrichment, data consolidation, change data capture and transformation', 'Understand database concepts of referential integrity, indexes and keys and table metadata', 'Demonstrated experience showing strong critical thinking and problem solving skills paired with a desire to take initiative', 'Proficient with data warehouse design and development and big data systems', 'Proficient with one or more programming languages such as Java or Python', 'Knowledge of Big Data integration tools such as Storm, and Spark, AWS Kinesis, Kafka a plus', 'Experience with DevOps tools like Jenkins/Git to assist development process', 'Experience with agile development process', 'Comprehensive health benefits', 'Generous vacation and retirement plans', 'Employee support program', 'Participation in charity initiatives', 'SQL, BI, Talend, Informatica, Tableau, PowerBI', 'Spark, AWS Kinesis, Storm, Kafka', 'Jenkins/Git', 'Agile', 'AWS, Azure, Google Cloud Platform']",2020-09-24 13:33:26
Principal Data Engineer,GLG,3.7 out of 5,"Austin, TX","['Cleanse, normalize and enhance quality for both the existing operational systems as well as new data sources that flow through the data platform.', 'Explore and introduce data that enriches our existing data sources, perform analysis to understand and articulate the value of the augmentation and enhancement.', 'Help architect and select the right tools and technologies to provide data movement and organization that is well organized, secure and performant.', 'Coach and educate other engineers across the entire organization on how take advantage of a central repository.', 'Work the latest approaches to creating physical and virtual data layers, for example Apache Spark, Azure Data Lake, S3, etc.', 'Lead with the cloud, focus on engineering and leverage services as opposed to installing and maintaining infrastructure.', 'Partner with the business users to understand their business processes and requirements for data storage, accesses and impact.', 'Focus on predictive analytics, next generation tools and approaches that find insight in our data.', 'At least 10 years of experience as a data engineer, data architect, data modeler, etc, designing and implementing data systems including data warehouses, operational data stores and long-term storage mechanisms.', 'A desire to participate in all aspects of the development lifecycle from inception to implementation and support.', 'Must have expertise in SQL and Python.', 'Experience using Data Engineering and Data Science libraries including PyTorch, Matplotlib, Numpy, SciPy, Pandas, Seaborn, TensorFlow, etc. is required', 'Experience with 3 or more of the following:Apache SparkHadoopPythonData ScienceStatistics', 'Solid communication skills and the ability to present and visualize business processes, data flow and systems architecture.', 'Must be able to work with vague requirements to drive impactful solutions.', 'Data governance experience is preferred.']",2020-09-24 13:33:26
Entry Level - Associate Data Scientist,IBM,3.9 out of 5,United States,"['Implement and validate predictive and prescriptive models, create and maintain statistical models with a focus on big data.', 'Incorporate a variety of statistical and machine learning techniques in your projects.', 'Write programs to cleanse and integrate data in an efficient and reusable manner.', 'Use leading edge and open-source tools such as Python, R, and TensorFlow, combined with IBM tools and our AI application suites.', 'Work in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.', 'Communicate with internal and external clients to understand and define business needs and appropriate modelling techniques to provide analytical solutions.', 'Evaluate modelling results and communicate the results to technical and non-technical audiences.', 'Ability to look at things differently, debug, troubleshoot, design and implement solutions to complex technical issues.', 'Strong technical and analytical abilities, a knack for driving impact and growth, and experience with a programming/scripting in a language such as Java or Python.', 'Basic understanding of statistical programming in a language such as R, Python, or SAS, SPSS, MATLAB.', 'Basic understanding of Cloud (AWS, Azure, etc.)', 'Excellent verbal and written communication skills.', 'Work or internship experience using data science tools in a corporate environment.', 'Interest in, understanding of, or experience with Design Thinking and Agile Development Methodologies', 'Willingness to travel up to 100% of the time.']",2020-09-24 13:33:26
REMOTE JOB | Data Integration Engineer (HL7 & Clinical),iknowvate technologies,N/A,"Charlotte, NC","['4+ years of Data Engineering an/or Integration experience', 'Operational experience in clinical health care information systems, specifically with HL7 data, including experience integrating large, complex, mission-critical systems.', 'Experience with object-oriented programming languages, specifically Java', 'In-depth understanding and practical knowledge of relational databases (MySQL)', 'Comfort working with UNIX/Linux systems specifically working at the command line.']",2020-09-24 13:33:26
BI Data Engineer (Tableau Data Visualization Developer),Roseburg Forest Products,3.5 out of 5,"Springfield, OR 97477","['Design, develop, test, and deploy Business Intelligence analytics and reporting solutions through Tableau', 'Lead the design, development, and maintenance of data integration, services, etc. to provide the right data to the right place at the right time', 'Ensure designed systems are highly reliable, self-recovering, and require little or no supporting manpower', 'Collaborate with business stakeholders to develop an understanding of their business and operational processes to develop Tableau interfaces and reports and develop self-service reporting solutions', 'Develop dashboards visualizing a wide variety of topics', 'Manage solution enhancement/defect backlog lists and continuously deliver agreed upon improvements through design, development and testing', 'Evaluate new and existing data streams for data analysis and presentation proof of concept development', 'Train users on how to use solutions through user focused documentation including written and video documentation', 'Mentor and develop technical competency of junior team members', 'Perform and/or lead necessary tuning of database and ETL systems and objects to ensure timing and performance goals are met', 'Collaborate with existing and prospective users to define Data Warehousing and Business Intelligence requirements', '3+ years’ experience in Tableau', 'Hands on experience with SQL and non-SQL databases like Oracle, SQLServer, or similar', 'Hands on experience with Data Marts for Reporting, Dashboards and Analytics', 'Proficient relational database experience. The individual must have an excellent command of SQL. (MS SQL Server preferred)', '3+ years of experience in data integration, ETL, and data management or comparable positions that handle large/complex data sets, developing automation,', 'Proficient in understanding of data management practices, data architecture principles, and data governance process', 'Knowledge of Tableau best practices in performance tuning and user-centric design, proactive alerts, etc', 'Proficient in understanding of data mapping and lineage strategies', 'Excellent written communication and presentation skills', 'Bachelor’s degree in Computer Science, Information Technology, Mathematics, or related area of study; or equivalent combination of education and/or relevant work experience', 'Tableau Certification is a big plus but not required']",2020-09-24 13:34:07
Data Engineer,mPulse Mobile,4.4 out of 5,"Encino, CA 91436","['Full Vision, Dental and Healthcare - all individual premiums paid by mPulse!', '401K Program with a 4% match', '3 Weeks Paid Maternity/Paternity Leave', 'Weekly team lunches to celebrate victories', 'Paid Parking as well as Car Pooling incentives', 'Model Integrity and Collaboration', 'Drive Innovation and Thought Leadership', 'Support Decision Making at All Levels', 'Create Value for Clients by Empowering Consumers', 'Improve Customer Experience Through Simple Design', 'Celebrate Success… Often', 'Working with the data science and data analytics team to refine and develop data science and analytics (DSA) product roadmap', 'Support Redshift cluster management including monitoring, performance tuning, and optimization', 'Responsible for data loads and data extracts via Airflow DAG and python code.', 'Engaging in exploratory A/B studies to extract data features and determine the relative value of multiple data types', 'Building rich and interactive data visualizations to display findings from A/B studies, to guide and inform exploratory data analysis, and to deepen customer engagement', 'Understanding and applying data mining techniques, including NLP, clustering algorithms and regression analysis to generate deep insight and discover effective solutions to challenging problems', '2-5 years of experience in a corporate, start-up, or research environment', '2-5 years of experience mentoring data analysts (corporate) or graduate students (academia)', '2-5 years of experience in Airflow DAG creation, debugging and maintenance', '2-5 years of experience in PostgreSQL and Elasticsearch', 'Strong background and solid skills in interactive data visualization (Tableau, Django, Shiny, D3.js)', 'Experience in research methods, exploratory data analysis, and machine learning', 'Intense intellectual curiosity – strong desire to always be learning', 'Analytical, creative, and innovative approach to solving difficult problems', '4 year Bachelor of Science or BA Degree in Computer Science, Computer Engineering or other related field', '2 years of direct experience as a data engineer or working directing in data engineering / data science.', '1 years of experience with Python (Pandas, NumPy, sciKit-learn), SQL and R', 'US Citizen', 'Please note, due to the requirements of this position, responses may automatically disqualify you from moving forward in the application process. Please review minimum qualifications thoroughly before applying.', 'Customer Focused', 'Attention to Detail', 'Independent Self-Starter', 'Highly Organized', 'Critical Thinker', 'Problem Solver', 'Excellent Communicator', 'Ability to Prioritize', 'Team Work & Collaboration', 'Multi-Tasker with Strong Sense of Urgency', 'Enjoy Flexible PTO and flexible work hours', 'Full Vision, Dental and Healthcare - all individual premiums paid by mPulse!', '401K Program with a 4% match', '3 Weeks Paid Maternity/Paternity Leave', 'Weekly team lunches to celebrate victories', 'Paid Parking as well as Car Pooling incentives', 'Laptop fitness stations', 'Ping pong conference table and Foosball', 'Free snacks and drinks']",2020-09-24 13:34:07
BI Data Engineer (Tableau Data Visualization Developer),Roseburg Forest Products Co.,3 out of 5,"Springfield, OR 97477",[],2020-09-24 13:34:07
Data Annotation Specialist,Tesla,3.5 out of 5,"San Mateo, CA 94402","['You will use the Autopilot labeling interface to label images critical to training our deep neural networks.', 'You will interact with the computer vision engineers on the Autopilot team to help us improve on the design of an efficient labeling interface.', 'You will be expected to gain basic computer vision and machine learning knowledge to better understand how the labels are used by our learning algorithms, as this will allow you to make more judgement calls on difficult edge cases that might come up during labeling.', 'High School diploma or evidence of exceptional ability.', 'Passionate and curious about technology.', 'Available to work overtime as needed.', 'Able to work in a fast paced environment, learn quickly and be able to prioritize assignments.', 'Proficient computer skills utilizing keyboard/mouse.', 'Detail-oriented and patient.', 'Communicate clearly using excellent written and verbal skills.', 'Must be reliable, have good initiative, committed and quality focused.', 'Proficient in Microsoft Office Suite is a plus.', ""Available for work schedule of 9:00am – 5:00pm M-F at Tesla's San Mateo Office.""]",2020-09-24 13:34:07
Data Engineer,Edward-Elmhurst Health,3.9 out of 5,"Warrenville, IL 60555","['Database Design and PerformanceWith oversight from more senior Data Engineers, designs and develops analytic data repositories (data warehouse, data marts, data lakes).Implements and maintains database security in accordance with Security policies.', 'ETL/ELT Design and DevelopmentWith oversight from more senior Data Engineers, designs and develops ETL/ELT processes to acquire, manipulate and store data.Tests and documents programs according to team standards.Prepares ETL/ELT solutions for deployment following established change management guidelines.', 'BI Technology Management and InteroperabilityImplements new or upgrades existing analytics software and servers with support of more senior Data Engineers.Troubleshoots moderately complex technical issues and resolves problems related to analytics tools.Keeps abreast of new features available in the team’s chosen set of databases and analytics tools.', 'Required Education and/or Experience:', ""Bachelor's degree or higher in Computer Science/Engineering, Information Systems, or relevant course of study or commensurate experience"", '3+ years of programming experience with a solid background in software development life cycle practices', '3+ years of experience writing and tuning SQL queries and stored procedures', 'Solid understanding of data warehouse architectures and ETL/ELT processes.', 'Preferred Education and/or Experience:', '3+ years of experience working with healthcare data and has an understanding of clinical workflows and billing practices', 'Exposure to Agile/Scrum development methodologies', 'Experience working with the following tools/technologies:Epic – Caboodle Development and AdministrationMicrosoft SQL Server DBMSETL Software (SSIS, Informatica, others)Source Code Repositories (TFS, Git, others)Microsoft Power BI, SSAS, SSRS, TableauData Lake architecture and cloud data platforms', '3+ Years of relevant experience.', 'Preferred License/Certifications:', 'SQL Server (DBMS/SSIS)', 'Epic Caboodle Development and Administration']",2020-09-24 13:34:07
Data Engineer (Junior and Mid),ICF,3.5 out of 5,"Fairfax, VA 22031","['Comprehensive health benefits', 'Generous vacation and retirement plans', 'Employee support program', 'Extract, transform, and load (ETL) processing routines and data feeds to transmit data to and from clients and subcontractors; create necessary data structures or data models to support data at all stages; and design and implement custom data analytic and BI/reporting products.', 'Perform extensive data profiling and analysis based on the client’s data', 'Work with UI teams and/or client to define BI and reporting requirements', 'Developer custom reports and data visualization products', 'Support project delivery on Data Warehouse/BI projects for external and internal clients, including partnering with ICF subject matter experts on project execution', 'Bachelor’s degree (e.g., Computer Science, Engineering or related discipline)', '6-8 years’ experience developing database ETL environments with business intelligence applications such as Talend, Informatica', '3+ years’ experience with services AWS Glue, Lambda, Microsoft Azure Data Factory, Google Cloud Data Flow', '6+ years’ experience in SQL and procedural programming', '6+ years of experience working with databases and BI tools such as Tableau, PowerBI', 'US Citizen or Permanent Lawful Resident (Green Card Holder) preferred. Employment must be compliant with eligibility for Public Trust Clearance due to Government Contract.', 'Understand ETL concepts of data flow, data enrichment, data consolidation, change data capture and transformation', 'Understand database concepts of referential integrity, indexes and keys and table metadata', 'Demonstrated experience showing strong critical thinking and problem solving skills paired with a desire to take initiative', 'Proficient with data warehouse design and development and big data systems', 'Proficient with one or more programming languages such as Java or Python', 'Knowledge of Big Data integration tools such as Storm, and Spark, AWS Kinesis, Kafka a plus', 'Experience with DevOps tools like Jenkins/Git to assist development process', 'Experience with agile development process', 'Comprehensive health benefits', 'Generous vacation and retirement plans', 'Employee support program', 'Participation in charity initiatives', 'SQL, BI, Talend, Informatica, Tableau, PowerBI', 'Spark, AWS Kinesis, Storm, Kafka', 'Jenkins/Git', 'Agile', 'AWS, Azure, Google Cloud Platform']",2020-09-24 13:34:07
Principal Data Engineer,GLG,3.7 out of 5,"Austin, TX","['Cleanse, normalize and enhance quality for both the existing operational systems as well as new data sources that flow through the data platform.', 'Explore and introduce data that enriches our existing data sources, perform analysis to understand and articulate the value of the augmentation and enhancement.', 'Help architect and select the right tools and technologies to provide data movement and organization that is well organized, secure and performant.', 'Coach and educate other engineers across the entire organization on how take advantage of a central repository.', 'Work the latest approaches to creating physical and virtual data layers, for example Apache Spark, Azure Data Lake, S3, etc.', 'Lead with the cloud, focus on engineering and leverage services as opposed to installing and maintaining infrastructure.', 'Partner with the business users to understand their business processes and requirements for data storage, accesses and impact.', 'Focus on predictive analytics, next generation tools and approaches that find insight in our data.', 'At least 10 years of experience as a data engineer, data architect, data modeler, etc, designing and implementing data systems including data warehouses, operational data stores and long-term storage mechanisms.', 'A desire to participate in all aspects of the development lifecycle from inception to implementation and support.', 'Must have expertise in SQL and Python.', 'Experience using Data Engineering and Data Science libraries including PyTorch, Matplotlib, Numpy, SciPy, Pandas, Seaborn, TensorFlow, etc. is required', 'Experience with 3 or more of the following:Apache SparkHadoopPythonData ScienceStatistics', 'Solid communication skills and the ability to present and visualize business processes, data flow and systems architecture.', 'Must be able to work with vague requirements to drive impactful solutions.', 'Data governance experience is preferred.']",2020-09-24 13:34:07
Entry Level - Associate Data Scientist,IBM,3.9 out of 5,United States,"['Implement and validate predictive and prescriptive models, create and maintain statistical models with a focus on big data.', 'Incorporate a variety of statistical and machine learning techniques in your projects.', 'Write programs to cleanse and integrate data in an efficient and reusable manner.', 'Use leading edge and open-source tools such as Python, R, and TensorFlow, combined with IBM tools and our AI application suites.', 'Work in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.', 'Communicate with internal and external clients to understand and define business needs and appropriate modelling techniques to provide analytical solutions.', 'Evaluate modelling results and communicate the results to technical and non-technical audiences.', 'Ability to look at things differently, debug, troubleshoot, design and implement solutions to complex technical issues.', 'Strong technical and analytical abilities, a knack for driving impact and growth, and experience with a programming/scripting in a language such as Java or Python.', 'Basic understanding of statistical programming in a language such as R, Python, or SAS, SPSS, MATLAB.', 'Basic understanding of Cloud (AWS, Azure, etc.)', 'Excellent verbal and written communication skills.', 'Work or internship experience using data science tools in a corporate environment.', 'Interest in, understanding of, or experience with Design Thinking and Agile Development Methodologies', 'Willingness to travel up to 100% of the time.']",2020-09-24 13:34:07
REMOTE JOB | Data Integration Engineer (HL7 & Clinical),iknowvate technologies,N/A,"Charlotte, NC","['4+ years of Data Engineering an/or Integration experience', 'Operational experience in clinical health care information systems, specifically with HL7 data, including experience integrating large, complex, mission-critical systems.', 'Experience with object-oriented programming languages, specifically Java', 'In-depth understanding and practical knowledge of relational databases (MySQL)', 'Comfort working with UNIX/Linux systems specifically working at the command line.']",2020-09-24 13:34:07
Data Engineer,Calm,4.2 out of 5,United States,"['Competitive salary and equity', 'Unlimited PTO', 'We pay your medical, dental, & vision insurance premiums', '401K', 'Commuter benefits', 'Life insurance and disability benefits', 'Apple equipment', 'Build data integrations within our data platform and between partners', 'Write well-tested, production ready code in Python, Go, and/or SQL', 'Improve the efficiency, reliability, and latency of our data system', 'Create automated, highly reliable data pipelines', 'Help define and craft our data model', 'Onboard onto Airflow and Redshift and assist with improvements and maintenance', 'Define, design, and build data testing and quality frameworks', 'Test all code written and ensure production readiness before shipping', 'Work cross-functionally with our product, marketing and growth teams on complex and exciting projects that propel Calm’s business', ""Stays up-to-date with high-potential new technologies, and can evaluate and present to the team for Calm's use case"", 'Extensive experience working with at least one data processing tool such as Spark, Redshift/Snowflake, Airflow/Luigi, etc', 'Basic working knowledge of other big data technologies', 'Experience building and maintaining critical, reliable ETL pipelines', 'Experience writing production-level code in Python or Go', 'Fluent in SQL', 'Great communicator who can easily break down complex concepts to non-technical stakeholders', 'Excellent sense of how to drive business impact', 'Experience working with data scientists, analysts and can understand their needs', 'Bonus points if you have some devops related-experience working with, e.g., kubernetes, terraform, etc.', 'Competitive salary and equity', 'Unlimited PTO', 'We pay your medical, dental, & vision insurance premiums', '401K', 'Commuter benefits', 'Life insurance and disability benefits', 'Apple equipment', 'Opportunity to work with a product focused on making the world happier and healthier', 'And much more!']",2020-09-24 13:34:07
Senior Data Engineer,GLG,3.7 out of 5,"Austin, TX","['Cleanse, normalize and enhance quality for both the existing operational systems as well as new data sources that flow through the data platform.', 'Explore and introduce data that enriches our existing data sources, perform analysis to understand and articulate the value of the augmentation and enhancement.', 'Help architect and select the right tools and technologies to provide data movement and organization that is well organized, secure and performant.', 'Coach and educate other engineers across the entire organization on how take advantage of a central repository.', 'Work the latest approaches to creating physical and virtual data layers, for example Apache Spark, Azure Data Lake, S3, etc.', 'Lead with the cloud, focus on engineering and leverage services as opposed to installing and maintaining infrastructure.', 'Partner with the business users to understand their business processes and requirements for data storage, accesses and impact.', 'Focus on predictive analytics, next generation tools and approaches that find insight in our data.', 'At least 10 years of experience as a data engineer, data architect, data modeler, etc, designing and implementing data systems including data warehouses, operational data stores and long-term storage mechanisms.', 'A desire to participate in all aspects of the development lifecycle from inception to implementation and support.', 'Must have expertise in SQL and Python.', 'Experience using Data Engineering and Data Science libraries including PyTorch, Matplotlib, Numpy, SciPy, Pandas, Seaborn, TensorFlow, etc. is required', 'Experience with 3 or more of the following:Apache SparkHadoopPythonData ScienceStatistics', 'Solid communication skills and the ability to present and visualize business processes, data flow and systems architecture.', 'Must be able to work with vague requirements to drive impactful solutions.', 'Data governance experience is preferred.']",2020-09-24 13:34:07
BI Data Engineer Sr,"Insight Enterprises, Inc.",3.6 out of 5,"Tempe, AZ 85284","['Founded in 1988 in Tempe, Arizona', '11,000+ teammates in 21 countries providing Insight Intelligent Technology Solutions™ for organizations across the globe', '$9.2 billion in revenue in 2018*', 'Ranked #430 on the 2019 Fortune 500, #14 on the 2019 CRN Solution Provider 500', '2019 Adobe Americas Partner of the Year, 2019 Cisco Global-Americas Partner of the Year, 2019 Intel IoT Solutions Partner of the Year, Microsoft U.S. Azure Partner Choice Award for Data/AI, Microsoft Azure Expert Managed Services Provider', 'Ranked #23 on the 2019 Fortune 50 Best Workplaces in Technology, #70 on the 2019 Fortune 100 Best Workplaces for Diversity, and #7 on the Phoenix Business Journal 2019 list of Best Places to Work (Extra Large Business)', 'Signatory of the United Nations (UN) Global Compact and Affiliate Member of the Responsible Business Alliance', 'Proforma to include PCM, Inc. for fiscal year ended Dec. 31, 2018']",2020-09-24 13:34:07
Data Engineer,Root Insurance Company,3.6 out of 5,"Columbus, OH 43215","['Work with product, actuarial, and engineering teams to understand and scope new features for our environment', 'Design & develop data structures that support downstream analysis', 'Design & develop sustainable, fast ETL processes using SQL', 'Provide peer review for teammates on their change requests', 'Create processes to identify, prioritize, and illustrate data quality issues and remediation efforts.', 'Design solutions which help us to reach our overall goals', 'Help to ensure data quality and meet data delivery SLA’s', 'At least 3 years of experience in the insurance industry is strongly preferred', 'Experience using technologies listed above is preferred', 'Solid SQL skills. Ability to transform data without the use of an ETL tool.', 'Experience using version control tools like GIT', 'Familiarity with programming languages like Ruby or Python', 'Familiarity with DevOps & Agile processes']",2020-09-24 13:34:07
Data Engineer,Ruby Receptionists HQ,N/A,"Portland, OR","['Writing queries to pull and analyze data for all departments across the company', 'Interpreting data schemas to translate into insightful KPIs, dashboards, and reports', 'Loading data from source systems into Snowflake', 'Writing and maintaining reports in Looker and legacy reports in Logi Analytics', 'Migrating existing reports from legacy systems to Looker', 'Syncing data across platforms using a variety of tools', 'Partnering with internal stakeholders to gather requirements to assist with the design and creation of reports and dashboards', 'Help to maintain and improve data infrastructure', 'You enjoy telling stories using data and visualization', 'You are driven by analytics and problem-solving', 'You effectively communicate with your co-workers and can quickly address and resolve issues as they arise', 'You have a strong business acumen and ability to foster cross departmental partnerships', 'You thrive in the fast-paced environment of a growth-stage company, and possess a scrappy, hands-on, roll-up-your-sleeves approach', 'Advanced SQL skills', 'Prior experience with BI Tools such as Looker and Logi Analytics', '3-5 years of experience in a data warehouse environment preferred', 'Advanced proficiency with Microsoft Excel', 'Experience using R, Python or other analytics languages', 'Prior experience with Snowflake or AWS Redshift', 'Advanced statistical knowledge and core mathematical ability']",2020-09-24 13:34:07
Senior Data Engineer,DSMH LLC,N/A,"Peoria, IL 61603","['Experience:design and implementing data persistence & process solutions, 10 years (Required)', 'Monday to Friday', 'design and implementing data persistence & process solutions: 10 years (Required)', 'AWS Certifications', 'Temporarily due to COVID-19']",2020-09-24 13:34:07
Data Annotation Specialist,Tesla,3.5 out of 5,"San Mateo, CA 94402","['You will use the Autopilot labeling interface to label images critical to training our deep neural networks.', 'You will interact with the computer vision engineers on the Autopilot team to help us improve on the design of an efficient labeling interface.', 'You will be expected to gain basic computer vision and machine learning knowledge to better understand how the labels are used by our learning algorithms, as this will allow you to make more judgement calls on difficult edge cases that might come up during labeling.', 'High School diploma or evidence of exceptional ability.', 'Passionate and curious about technology.', 'Available to work overtime as needed.', 'Able to work in a fast paced environment, learn quickly and be able to prioritize assignments.', 'Proficient computer skills utilizing keyboard/mouse.', 'Detail-oriented and patient.', 'Communicate clearly using excellent written and verbal skills.', 'Must be reliable, have good initiative, committed and quality focused.', 'Proficient in Microsoft Office Suite is a plus.', ""Available for work schedule of 9:00am – 5:00pm M-F at Tesla's San Mateo Office.""]",2020-09-24 13:34:49
Data Engineer,Edward-Elmhurst Health,3.9 out of 5,"Warrenville, IL 60555","['Database Design and PerformanceWith oversight from more senior Data Engineers, designs and develops analytic data repositories (data warehouse, data marts, data lakes).Implements and maintains database security in accordance with Security policies.', 'ETL/ELT Design and DevelopmentWith oversight from more senior Data Engineers, designs and develops ETL/ELT processes to acquire, manipulate and store data.Tests and documents programs according to team standards.Prepares ETL/ELT solutions for deployment following established change management guidelines.', 'BI Technology Management and InteroperabilityImplements new or upgrades existing analytics software and servers with support of more senior Data Engineers.Troubleshoots moderately complex technical issues and resolves problems related to analytics tools.Keeps abreast of new features available in the team’s chosen set of databases and analytics tools.', 'Required Education and/or Experience:', ""Bachelor's degree or higher in Computer Science/Engineering, Information Systems, or relevant course of study or commensurate experience"", '3+ years of programming experience with a solid background in software development life cycle practices', '3+ years of experience writing and tuning SQL queries and stored procedures', 'Solid understanding of data warehouse architectures and ETL/ELT processes.', 'Preferred Education and/or Experience:', '3+ years of experience working with healthcare data and has an understanding of clinical workflows and billing practices', 'Exposure to Agile/Scrum development methodologies', 'Experience working with the following tools/technologies:Epic – Caboodle Development and AdministrationMicrosoft SQL Server DBMSETL Software (SSIS, Informatica, others)Source Code Repositories (TFS, Git, others)Microsoft Power BI, SSAS, SSRS, TableauData Lake architecture and cloud data platforms', '3+ Years of relevant experience.', 'Preferred License/Certifications:', 'SQL Server (DBMS/SSIS)', 'Epic Caboodle Development and Administration']",2020-09-24 13:34:49
Data Engineer (Junior and Mid),ICF,3.5 out of 5,"Fairfax, VA 22031","['Comprehensive health benefits', 'Generous vacation and retirement plans', 'Employee support program', 'Extract, transform, and load (ETL) processing routines and data feeds to transmit data to and from clients and subcontractors; create necessary data structures or data models to support data at all stages; and design and implement custom data analytic and BI/reporting products.', 'Perform extensive data profiling and analysis based on the client’s data', 'Work with UI teams and/or client to define BI and reporting requirements', 'Developer custom reports and data visualization products', 'Support project delivery on Data Warehouse/BI projects for external and internal clients, including partnering with ICF subject matter experts on project execution', 'Bachelor’s degree (e.g., Computer Science, Engineering or related discipline)', '6-8 years’ experience developing database ETL environments with business intelligence applications such as Talend, Informatica', '3+ years’ experience with services AWS Glue, Lambda, Microsoft Azure Data Factory, Google Cloud Data Flow', '6+ years’ experience in SQL and procedural programming', '6+ years of experience working with databases and BI tools such as Tableau, PowerBI', 'US Citizen or Permanent Lawful Resident (Green Card Holder) preferred. Employment must be compliant with eligibility for Public Trust Clearance due to Government Contract.', 'Understand ETL concepts of data flow, data enrichment, data consolidation, change data capture and transformation', 'Understand database concepts of referential integrity, indexes and keys and table metadata', 'Demonstrated experience showing strong critical thinking and problem solving skills paired with a desire to take initiative', 'Proficient with data warehouse design and development and big data systems', 'Proficient with one or more programming languages such as Java or Python', 'Knowledge of Big Data integration tools such as Storm, and Spark, AWS Kinesis, Kafka a plus', 'Experience with DevOps tools like Jenkins/Git to assist development process', 'Experience with agile development process', 'Comprehensive health benefits', 'Generous vacation and retirement plans', 'Employee support program', 'Participation in charity initiatives', 'SQL, BI, Talend, Informatica, Tableau, PowerBI', 'Spark, AWS Kinesis, Storm, Kafka', 'Jenkins/Git', 'Agile', 'AWS, Azure, Google Cloud Platform']",2020-09-24 13:34:49
Principal Data Engineer,GLG,3.7 out of 5,"Austin, TX","['Cleanse, normalize and enhance quality for both the existing operational systems as well as new data sources that flow through the data platform.', 'Explore and introduce data that enriches our existing data sources, perform analysis to understand and articulate the value of the augmentation and enhancement.', 'Help architect and select the right tools and technologies to provide data movement and organization that is well organized, secure and performant.', 'Coach and educate other engineers across the entire organization on how take advantage of a central repository.', 'Work the latest approaches to creating physical and virtual data layers, for example Apache Spark, Azure Data Lake, S3, etc.', 'Lead with the cloud, focus on engineering and leverage services as opposed to installing and maintaining infrastructure.', 'Partner with the business users to understand their business processes and requirements for data storage, accesses and impact.', 'Focus on predictive analytics, next generation tools and approaches that find insight in our data.', 'At least 10 years of experience as a data engineer, data architect, data modeler, etc, designing and implementing data systems including data warehouses, operational data stores and long-term storage mechanisms.', 'A desire to participate in all aspects of the development lifecycle from inception to implementation and support.', 'Must have expertise in SQL and Python.', 'Experience using Data Engineering and Data Science libraries including PyTorch, Matplotlib, Numpy, SciPy, Pandas, Seaborn, TensorFlow, etc. is required', 'Experience with 3 or more of the following:Apache SparkHadoopPythonData ScienceStatistics', 'Solid communication skills and the ability to present and visualize business processes, data flow and systems architecture.', 'Must be able to work with vague requirements to drive impactful solutions.', 'Data governance experience is preferred.']",2020-09-24 13:34:49
Entry Level - Associate Data Scientist,IBM,3.9 out of 5,United States,"['Implement and validate predictive and prescriptive models, create and maintain statistical models with a focus on big data.', 'Incorporate a variety of statistical and machine learning techniques in your projects.', 'Write programs to cleanse and integrate data in an efficient and reusable manner.', 'Use leading edge and open-source tools such as Python, R, and TensorFlow, combined with IBM tools and our AI application suites.', 'Work in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.', 'Communicate with internal and external clients to understand and define business needs and appropriate modelling techniques to provide analytical solutions.', 'Evaluate modelling results and communicate the results to technical and non-technical audiences.', 'Ability to look at things differently, debug, troubleshoot, design and implement solutions to complex technical issues.', 'Strong technical and analytical abilities, a knack for driving impact and growth, and experience with a programming/scripting in a language such as Java or Python.', 'Basic understanding of statistical programming in a language such as R, Python, or SAS, SPSS, MATLAB.', 'Basic understanding of Cloud (AWS, Azure, etc.)', 'Excellent verbal and written communication skills.', 'Work or internship experience using data science tools in a corporate environment.', 'Interest in, understanding of, or experience with Design Thinking and Agile Development Methodologies', 'Willingness to travel up to 100% of the time.']",2020-09-24 13:34:49
REMOTE JOB | Data Integration Engineer (HL7 & Clinical),iknowvate technologies,N/A,"Charlotte, NC","['4+ years of Data Engineering an/or Integration experience', 'Operational experience in clinical health care information systems, specifically with HL7 data, including experience integrating large, complex, mission-critical systems.', 'Experience with object-oriented programming languages, specifically Java', 'In-depth understanding and practical knowledge of relational databases (MySQL)', 'Comfort working with UNIX/Linux systems specifically working at the command line.']",2020-09-24 13:34:49
Data Engineer,Calm,4.2 out of 5,United States,"['Competitive salary and equity', 'Unlimited PTO', 'We pay your medical, dental, & vision insurance premiums', '401K', 'Commuter benefits', 'Life insurance and disability benefits', 'Apple equipment', 'Build data integrations within our data platform and between partners', 'Write well-tested, production ready code in Python, Go, and/or SQL', 'Improve the efficiency, reliability, and latency of our data system', 'Create automated, highly reliable data pipelines', 'Help define and craft our data model', 'Onboard onto Airflow and Redshift and assist with improvements and maintenance', 'Define, design, and build data testing and quality frameworks', 'Test all code written and ensure production readiness before shipping', 'Work cross-functionally with our product, marketing and growth teams on complex and exciting projects that propel Calm’s business', ""Stays up-to-date with high-potential new technologies, and can evaluate and present to the team for Calm's use case"", 'Extensive experience working with at least one data processing tool such as Spark, Redshift/Snowflake, Airflow/Luigi, etc', 'Basic working knowledge of other big data technologies', 'Experience building and maintaining critical, reliable ETL pipelines', 'Experience writing production-level code in Python or Go', 'Fluent in SQL', 'Great communicator who can easily break down complex concepts to non-technical stakeholders', 'Excellent sense of how to drive business impact', 'Experience working with data scientists, analysts and can understand their needs', 'Bonus points if you have some devops related-experience working with, e.g., kubernetes, terraform, etc.', 'Competitive salary and equity', 'Unlimited PTO', 'We pay your medical, dental, & vision insurance premiums', '401K', 'Commuter benefits', 'Life insurance and disability benefits', 'Apple equipment', 'Opportunity to work with a product focused on making the world happier and healthier', 'And much more!']",2020-09-24 13:34:49
Senior Data Engineer,GLG,3.7 out of 5,"Austin, TX","['Cleanse, normalize and enhance quality for both the existing operational systems as well as new data sources that flow through the data platform.', 'Explore and introduce data that enriches our existing data sources, perform analysis to understand and articulate the value of the augmentation and enhancement.', 'Help architect and select the right tools and technologies to provide data movement and organization that is well organized, secure and performant.', 'Coach and educate other engineers across the entire organization on how take advantage of a central repository.', 'Work the latest approaches to creating physical and virtual data layers, for example Apache Spark, Azure Data Lake, S3, etc.', 'Lead with the cloud, focus on engineering and leverage services as opposed to installing and maintaining infrastructure.', 'Partner with the business users to understand their business processes and requirements for data storage, accesses and impact.', 'Focus on predictive analytics, next generation tools and approaches that find insight in our data.', 'At least 10 years of experience as a data engineer, data architect, data modeler, etc, designing and implementing data systems including data warehouses, operational data stores and long-term storage mechanisms.', 'A desire to participate in all aspects of the development lifecycle from inception to implementation and support.', 'Must have expertise in SQL and Python.', 'Experience using Data Engineering and Data Science libraries including PyTorch, Matplotlib, Numpy, SciPy, Pandas, Seaborn, TensorFlow, etc. is required', 'Experience with 3 or more of the following:Apache SparkHadoopPythonData ScienceStatistics', 'Solid communication skills and the ability to present and visualize business processes, data flow and systems architecture.', 'Must be able to work with vague requirements to drive impactful solutions.', 'Data governance experience is preferred.']",2020-09-24 13:34:49
BI Data Engineer Sr,"Insight Enterprises, Inc.",3.6 out of 5,"Tempe, AZ 85284","['Founded in 1988 in Tempe, Arizona', '11,000+ teammates in 21 countries providing Insight Intelligent Technology Solutions™ for organizations across the globe', '$9.2 billion in revenue in 2018*', 'Ranked #430 on the 2019 Fortune 500, #14 on the 2019 CRN Solution Provider 500', '2019 Adobe Americas Partner of the Year, 2019 Cisco Global-Americas Partner of the Year, 2019 Intel IoT Solutions Partner of the Year, Microsoft U.S. Azure Partner Choice Award for Data/AI, Microsoft Azure Expert Managed Services Provider', 'Ranked #23 on the 2019 Fortune 50 Best Workplaces in Technology, #70 on the 2019 Fortune 100 Best Workplaces for Diversity, and #7 on the Phoenix Business Journal 2019 list of Best Places to Work (Extra Large Business)', 'Signatory of the United Nations (UN) Global Compact and Affiliate Member of the Responsible Business Alliance', 'Proforma to include PCM, Inc. for fiscal year ended Dec. 31, 2018']",2020-09-24 13:34:49
Data Engineer,Root Insurance Company,3.6 out of 5,"Columbus, OH 43215","['Work with product, actuarial, and engineering teams to understand and scope new features for our environment', 'Design & develop data structures that support downstream analysis', 'Design & develop sustainable, fast ETL processes using SQL', 'Provide peer review for teammates on their change requests', 'Create processes to identify, prioritize, and illustrate data quality issues and remediation efforts.', 'Design solutions which help us to reach our overall goals', 'Help to ensure data quality and meet data delivery SLA’s', 'At least 3 years of experience in the insurance industry is strongly preferred', 'Experience using technologies listed above is preferred', 'Solid SQL skills. Ability to transform data without the use of an ETL tool.', 'Experience using version control tools like GIT', 'Familiarity with programming languages like Ruby or Python', 'Familiarity with DevOps & Agile processes']",2020-09-24 13:34:49
Data Engineer,Ruby Receptionists HQ,N/A,"Portland, OR","['Writing queries to pull and analyze data for all departments across the company', 'Interpreting data schemas to translate into insightful KPIs, dashboards, and reports', 'Loading data from source systems into Snowflake', 'Writing and maintaining reports in Looker and legacy reports in Logi Analytics', 'Migrating existing reports from legacy systems to Looker', 'Syncing data across platforms using a variety of tools', 'Partnering with internal stakeholders to gather requirements to assist with the design and creation of reports and dashboards', 'Help to maintain and improve data infrastructure', 'You enjoy telling stories using data and visualization', 'You are driven by analytics and problem-solving', 'You effectively communicate with your co-workers and can quickly address and resolve issues as they arise', 'You have a strong business acumen and ability to foster cross departmental partnerships', 'You thrive in the fast-paced environment of a growth-stage company, and possess a scrappy, hands-on, roll-up-your-sleeves approach', 'Advanced SQL skills', 'Prior experience with BI Tools such as Looker and Logi Analytics', '3-5 years of experience in a data warehouse environment preferred', 'Advanced proficiency with Microsoft Excel', 'Experience using R, Python or other analytics languages', 'Prior experience with Snowflake or AWS Redshift', 'Advanced statistical knowledge and core mathematical ability']",2020-09-24 13:34:49
Senior Data Engineer,DSMH LLC,N/A,"Peoria, IL 61603","['Monday to Friday', 'design and implementing data persistence & process solutions: 10 years (Required)', 'AWS Certifications', 'Temporarily due to COVID-19']",2020-09-24 13:34:49
Data Engineer - ETL and Integrations,Shipt,3.4 out of 5,"Minneapolis, MN","['Develop and maintain pipelines responsible for sending or ingesting large amounts of', 'Partner with external vendors on building, enhancing and maintaining business solutions.', 'Help evolve our data model & infrastructure for new retailers and verticals', 'Collaborate with other teams across the organization (e.g., Retail Partner Success,', 'Keep the big picture in mind so that our architectural patterns can better', 'Build and experiment with different tools and tech, and share your learnings', '2+ years of experience as a Data Engineer/Architect', 'Strong spoken and written communication.', 'Thrives on engaging directly with business partners to build an in-depth understanding of business needs and deliver innovative solutions.', 'Proficiency in Python is required (this is our primary language)', 'Proficiency in SQL is required (we use PostgreSQL and Redshift)', 'Proficiency with REST APIs', 'A keen attention to detail', ""A Bachelor's Degree in a technical field or equivalent work experience""]",2020-09-24 13:34:49
Senior Data Engineer,HelioCampus Inc,N/A,Remote,"['Competitive salary, based on experience and bonus program', 'Comprehensive benefits package includes medical, dental, vision, life and disability insurance', '401K with company match', '5+ weeks of paid time off including holidays and vacation', 'Perform SQL development, unit testing and deployment of ETL solutions', 'Design complex data workflow solutions and data models based on user requirements', 'Develop ETL using open source tools and commercial solutions such as Oracle Data Integrator (ODI), Informatica.', 'Performs design and code review functions for the development projects', 'Mentor and coach other ETL developers', 'Research and recommends alternative actions to resolve problems', 'Analyze trends in performance to proactively prevent problems', 'Troubleshoot ETL issues in real-time and diagnoses the root cause', 'Understanding of data warehouse concepts and structures', 'Experience developing complex SQL queries and analyze data, systems integration experience', 'Experience with data mapping, and the ability to design and develop ETL solutions', 'Experience with translation of requirements into data model specifications', 'Ability to multi-task, ability to troubleshoot problems in real-time and diagnose the root cause', 'Desire to join a small, growing company where the sky is the limit on opportunity', 'Attitude of self-starter and ability to explore and find solutions with minimal supervision', 'Competitive salary, based on experience and bonus program', 'Comprehensive benefits package includes medical, dental, vision, life and disability insurance', '401K with company match', '5+ weeks of paid time off including holidays and vacation']",2020-09-24 13:34:49
Data Analytics Engineer,Medium,4 out of 5,"San Francisco, CA 94107","['Work on high impact projects that improve data availability and quality, and provide reliable access to data for the rest of the business.', 'You’ll be the go-to Looker expert at the company, and will help bridge the gap between understanding business needs and knowing how to design efficient, usable data models.', 'Work with engineers, product managers, and data scientists to understand data needs and implement data exploration tools and dashboards', 'Build data expertise and own data quality for allocated areas of ownership.', 'You’ll help define the self-serve data strategy at Medium, advocate for best practices, lead trainings, and investigate new technologies.', 'Design, architect, and support new and existing ETL pipelines and Looker data models, and recommend improvements and modifications.', 'Analyze, debug and maintain critical data pipelines. Tune SQL queries and Snowflake data warehouse configurations to improve performance while keeping costs in mind.', 'Identify and help triage infra issues with our ETL infrastructure.', 'You have 2+ years of software engineering and/or data analytics experience.', 'You have experience with schema design and dimensional data modeling.', 'You have experience writing and optimizing large, complex SQL and ETL processes, particularly on column-oriented databases and event-based data structures.', 'You have designed and built data models in Looker, and you know how to balance trade-offs between performance and usability.', 'You have a BS in Computer Science / Software Engineering or equivalent experience.', 'Knowledge and experience using Spark', 'Proficiency with Python', 'Experience with Snowflake']",2020-09-24 13:34:49
Spring 2021 CBS Sports Data Engineering Intern,CBS,3.9 out of 5,United States,"['Performing exploratory and data gap analysis on core sports data', 'Building out real-time predictive data pipelines', 'Building out visualization dashboards', 'Building out new data features for sports gambling insights.', ""This is a paid internship and can also be for university credit if it meets your university's guidelines"", 'A sports fanatic - you are really sad when your favorite team(s) loses, you can break down matchups across different leagues, you have a strong opinion about which activities should be deemed a sport.', 'Good understanding of data structures, algorithms, object oriented design and patterns.', 'Intern must be a student currently enrolled in an accredited college, university or bootcamp', 'Must be at least 18 years old', 'Experience with sport data research', 'Experience building web applications for data visualization', 'Technology experiences with: AWS, SageMaker, Python, NodeJS, Lambda, API Gateway, DynamoDB & RDS']",2020-09-24 13:35:31
Data Engineer - Junior Associate,Home Partners of America Inc,N/A,"Chicago, IL 60606","['Assist in the maintenance and implementation of the ETL processes (SQL and Python).', 'Create ETL transformation documentation and troubleshoot transformation errors.', 'Collaborate with the Data Engineering team and other users to validate consistency of data.', 'Create a notification plan to alert all parties when there is a data integrity or a feed issue.', 'Troubleshoot website data feed issues and resolve them in a timely manner.', 'Work closely with the Brokerage Operations on setting up new feeds and maintaining existing ones.', 'Be comfortable working on a small team.', 'Communicate with business heads and other departments about issues and concerns.', 'Create logical and innovative solutions to complex problems.', 'Undergraduate degree or Master’s Degree in Computer Science, Engineering, or commensurate technical experience.', 'Ability to think critically and ask pointed questions.', 'SQL server (or any other SQL flavor) experience.', '0-2 years of experience in a technical role.', 'Demonstrated interest in learning scripting languages (Python).', 'Demonstrated ability to manage multiple projects simultaneously, work under pressure, work independently and meet deadlines.', 'Bonus: AWS experience and experience in writing SQL stored procedures, functions, views, and scheduled jobs.']",2020-09-24 13:35:31
Data Engineer,Pricesenz,N/A,"Irving, TX","['Maintain high levels of integrity and dependability', 'Maintain a focus on results & quality.', 'Works well in a team environment and effectively manage work activities', 'Project a professional demeanor and appearance', 'Be extremely flexible and adaptable', 'Demonstrates the ability to function and stay focused on constant pressure, fast-growing and ever-changing organization', 'Python, Java: 1 year (Required)', 'Big Data: 1 year (Required)', 'Tableau: 1 year (Required)', 'Can you work on W2? If yes, What is your Visa status?', 'Temporarily due to COVID-19']",2020-09-24 13:35:31
Data Analytics Engineer,Cubesmart,3.4 out of 5,"Malvern, PA 19355","['Develop, maintain and improve data generation and ingestion pipelines (data engineering – 40%)Collaborate with marketers, data scientists, and analysts to develop, maintain and improve data ingestion pipelines; write internal R or Python tooling packages for analysts to use.Develop and maintain complex SQL queries; pull and join data from disparate sources and perform data transformations, in support of data science and analytics projects.Evaluate marketing technologies for their data gathering capability; validate and consolidate diverse sources of data such as Salesforce.com, DialogTech, and Adobe', 'Develop and implement analytics applications (data analytics – 40%)Work with Data Scientists and Analysts to develop, productionize and deploy machine learning algorithms, including the company’s innovative proprietary Pricing and Revenue Management System.Create and maintain standard (daily, weekly or monthly) and ad hoc performance reports', 'Conduct ad hoc analytics (ad hoc support – 20%)Provide strategic data and analytics support to develop and evaluate growth opportunities.Perform ad hoc analysis to discover business insights to enhance marketing programs and optimize pricing systems.', 'BA/BS in a technical discipline or equivalent (e.g., Computer Science, Engineering, Math).', 'Strong in writing complex SQL queries against relational database systems.', 'Proficient in SQL and Python; experience with R strongly preferred.', '3+ years of work experience in providing data support for or focusing on data engineering on analytics teams.', 'Experience with developing and/or implementing machine learning algorithms a plus.', 'A passion for learning new technologies and methodologies in general.', 'High-quality of collaboration, independence, attention to details, and organizational skill', 'Demonstrated ability to understand business context and apply that understanding to the codes / systems / processes you develop.', 'A strong commitment to quality and continuous improvement.', 'Ability to work independently and interface effectively with both technical and non-technical teammates', 'Strong listening and communication skills are essential.']",2020-09-24 13:35:31
Sr Data Engineer,AIG,3.7 out of 5,"Charlotte, NC","['Design and build end to end data flows using modern technologies and adhering to enterprise standards. This includes but not limited to data cleansing, data mapping, data transformation and data standardization techniques.', 'Developing an ecosystem to support business teams in managing and using their data.', 'Pursue a rigorous, disciplined approach to software development process and automation.', 'Develop, test and maintain build and deployment scripts in CI/CD framework/tools to automate and streamline deployment processes.', 'A keen eye for encryption and data security.', 'Implement strong data governance and quality solutions.', 'Research, suggest, and apply new promising technologies, strategies and ways to solve technical issues.', 'Strong hands-on experience with SQL and Stored Procedure database development using leading databases like Snow Flake, Oracle, Postgres is required; Experience in handling large data warehouse is required', 'Experience with Cloud technologies (e.g. AWS), Cloud data warehouses (Snowflake/ Redshift) and Big data technologies like spark/data Bricks would be highly preferable', 'Amazon Web Services - S3, EMR, Athena, Glue, Kinesis etc., CI /CD – Jenkins, GitHub, JFrog etc.,', 'Experience with one of the ETL technologies like Talend is highly preferable.', 'Programming Languages like java Script , Python', 'Data Modeling, Data Governance and Data Quality processes', 'SQL, NoSQL and BI experience', 'Data Visualization (MicroStrategy, Power BI, Tableau)', 'Financial domain experience', 'Linux and Windows server concepts', 'Bias for Action and Service Orientated.', 'Strong strategic development and project execution skills, with proven ability to deliver key tasks on time and on budget.', 'Exceptional communication skills, including ability to develop and present clear and concise analysis and recommendations to senior management.', 'Strong analytical skills.', 'Proven ability to dissect complex business issues, performs research and analysis, and synthesize conclusions into a value-maximizing strategy.', 'Strong business acumen with a proven track record of making sound judgments backed by strong analytical skills.', 'Comprehensive awareness of the business and regulatory environment.', '8+ years of experience', ""Bachelor's Degree"", 'Product leadership with scope of influence', 'Ability to mentor others']",2020-09-24 13:35:31
"Sr Engineer, Data & Analytics",Comcast,3.7 out of 5,"Philadelphia, PA 19103","['Utilizes resources, SQL optimization skills, quality assurance, troubleshooting skills, and subject matter expertise to find and solve moderate to major development problems in SQL Server, OBIEE, and Tableau. Able to troubleshoot, perform root cause analysis, and determine/recommend short and long term solutions to management.', 'Supports the established deployment process, including completing code reviews in GitHub', 'Creates technical documentation (internal) using understanding of internal business areas and processes as well as working knowledge of database design, data manipulation, ETL, implementation, information storage & retrieval, and data flow & analysis.', 'Preemptively recognize and resolve technical issues utilizing knowledge of policies and processes.', 'Optimize data sources and processing rules to ensure appropriate data quality of all products utilizing trouble-shooting, design, and development skills along with cross systems technical knowledge.', 'Solves critical issues and shares knowledge such as trends, aggregate, quantity volume regarding specific data sources.', 'Acts as a subject matter expert in one or more technical areas; such as data architecture, data engineering or data manipulation within big data systems like Hadoop and SQL.', 'Serves as a team leader within a work group or on cross-functional teams; accepts team lead stretch assignments, acts as a resource for colleagues with less experience.', 'Acts as a liaison between business owners and technical associates to ensure the data collected and processed is both actionable and relevant to the end goals.', 'Determines appropriateness of data for storage and optimum storage organization. Determines how tables relate to each other and how fields interact within the tables to develop relational models.', 'Collaborates with technology and platform management partners to optimize data sourcing and processing rules to ensure appropriate data quality.', 'Consistent exercise of independent judgment and discretion in matters of significance.', 'Regular, consistent and punctual attendance. Must be able to work nights and weekends, variable schedule(s) as necessary.', 'Other duties and responsibilities as assigned.', 'Bachelors Degree', 'Computer Science or related field', 'Current or prior Comcast Business experience highly preferred, including subject matter expertise in Business Services Sales, Retention, and legacy processes.', 'Generally requires 5-8 years related experience.']",2020-09-24 13:35:31
"Hiring Data Engineer/ Full-Stack Developers- San Jose, USA",Scry Analytics,N/A,"San Jose, CA 95134","['designing and customizing software with the aim of optimizing operational efficiency, which includes building analytics tools to optimize key business performance metrics;', 'analyze user needs, which includes building the infrastructure required for optimal extraction, transformation, and loading of data using SQL and Cloud Computing ‘big data’ technologies;', 'identifying, designing, and implementing internal process improvements, such as re-designing infrastructure for greater scalability;', 'creating optimal data pipeline architecture; creating data tools for analytics and data scientist team members that assist them in building and optimizing our product;', 'keeping our data separated and secure across national boundaries through multiple data centers and Cloud Computing regions; working with stakeholders to strive for greater functionality in our data systems;', 'and utilizing knowledge of Optical Character Recognition, number corrections, object detection and counting, neural networks, data and statistical analysis, and machine learning methods to perform the duties described above.', 'Master’s degree in Computer Science or a related field,', 'two (2) years of relevant experience and should be based in the U.S.', 'This experience should include two (2) years of experience with designing and developing computer software applications using Object-oriented design and programming;', 'Python;', 'algorithm design and development;', 'neural network frameworks;', 'Linux Operating System; data engineering; statistical data analysis;', 'Machine Learning, including Bayesian modeling, multivariate and logistic regression, support vector machines, cluster analysis, decision and regression trees, random forest, neural networks and ensemble methods;', 'and analyzing large, complex, multi-dimensional data sets and developing analytic solutions.', '8 hour shift', 'Day shift', 'Monday to Friday', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'Temporarily due to COVID-19']",2020-09-24 13:35:31
Data Visualization Engineer,"Tagup, Inc.",N/A,"Somerville, MA","['Build innovative and powerful visualizations of our customers and their data.', 'Work with our engineering team to define user needs and help with the creation of creative data visualization to provide the best user experience possible.', 'Prototype and develop new ideas and participate in all parts of the product lifecycle from research to release.', 'Support general company data visualization needs, including print and web materials', '3+ years of experience working in an analytical environment, including demonstrable data, analytics, reporting, visualization and problem-solving skills', '2+ years of experience working with D3.js', 'Experience working with very large datasets', 'Experience interfacing with business customers, gathering requirements and gaining a deep-dive understanding of key data', 'Strong written, verbal, and visual communication skills to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation', 'Experience with other data visualization libraries/solutions (Chart.js, Raphael.js, Tableau etc.)', 'Working knowledge of modern JavaScript libraries/frameworks (Vue.js preferred)', 'Experience with MongoDB and/or InfluxDB']",2020-09-24 13:35:31
Data Engineer,Rackspace,3.8 out of 5,Remote,"['Build complex ETL code', 'Work on Data and Analytics Tools in the Cloud', 'Develop code using Python, Scala, R languages', 'Work with technologies such as Spark, Hadoop, Kafka, etc.', 'Build complex Data Engineering workflows', 'Create complex data solutions and build data pipelines', 'Establish credibility and build impactful relationships with our customers to enable them to be cloud advocates', 'Capture and share industry best practices amongst the community', 'Attend and present valuable information at Industry Events', 'Drive the engagements with customers from the architectural pillar, from design to delivery, create runbooks etc.', '15+ Years of Data-warehouse and Analytic system development and deployment experience', '10+ years of experience in database architectures and data pipeline development', '8+ years of experience in modern data ware housing platform using cloud native technologies', '5+ years of experience in delivering Azure/GCP/AWS Data Solutions.', 'Demonstrated knowledge of software development tools and methodologies', 'Presentation skills with a high degree of comfort speaking with executives, IT management, and developers', 'Excellent communication skills with an ability to right level conversations', 'Demonstrated ability to adapt to new technologies and learn quickly', 'Experience with Google Cloud Services such as Streaming + Batch, BigQuery, BigTable, DataStudio, DataPrep, Pub/Sub , Cloud Storage, Cloud Dataflow, Data Proc, DataFlow, DFunc, Big Query & Big Table', 'knowledge and proven use of contemporary data mining, cloud computing and data management tools including but not limited to Microsoft Azure, AWS Cloud, Google Cloud, hadoop, HDFS, MapR and spark.', 'Design and configuration of data movement, streaming and transformation (ETL) technologies such as Informatica, Nifi, Kafka, Storm, Sqoop, SSIS, Alteryx, Pentaho, Alooma, Airflow.', 'Creation of descriptive, predictive and prescriptive analytics solutions using Azure Stream Analytics, Azure Analysis Services, Data Lake Analytics, HDInsight, HDP, Spark, Databricks, MapReduce, Pig, Hive, Tez, SSAS.', 'Design and configuration of data movement, streaming and transformation (ETL) technologies such as Azure Data Factory, HDF, Nifi, Kafka, Storm, Sqoop, SSIS, LogicApps, Signiant, Aspera, Alteryx, Pentaho, Alooma, Airflow.', 'Large scale design, implementation and operations of OLTP, OLAP, DW and NoSQL data storage technologies such as SQL Server, Azure SQL, Azure SQL DW, PostgreSQL, CosmosDB, RedisCache, Azure Data Lake Store, Hadoop, Hive, MySQL, Neo4j, Cassandra, HBase', 'Experience working within an agile development process (Scrum, Kanban, etc)', 'Expertise in data estate workloads like HDInsight, Hadoop, Cloudera, Spark, Python.', 'Familiarity with CI/CD concepts', 'Strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external organizations and virtual teams.', 'Knowledge or hands-on experience with data visualization and/or data sciences.', 'Hands on experience with Azure/GCP projects.', 'Cloud certifications such as GCP Professional Data Engineer or Microsoft Data / AI certifications.', 'Technical degree required; Computer Science or Math background desired', 'This is a virtual role', 'The candidate needs to be based in US or Canada', 'This role would require 25 - 30% travel']",2020-09-24 13:35:31
Data Engineer - Remote,Thresher,N/A,"Arlington, VA 22201","['Work with business, product, and engineering teams to build, extend, and maintain data integration services and ETL data pipelines.', 'Design, implement, and maintain relational databases structures and document stores.', 'Extract, transform, and load text data in a variety of written languages.', 'Design and create proof-of-concepts, prototypes, and production-quality solutions.', 'Collaborate with subject matter experts and data scientists to fully understand requirements and help propose solutions.', 'Contribute to our software solutions in your area of expertise, and share your knowledge and experience with the team, so we can all contribute at a higher level.', 'Operate in a collaborative agile environment with a focus on transparency and team success.', 'Proficiency with relational databases and SQL', 'Proficiency with document stores and data warehouses', 'Proficiency in ETL processes and technologies', 'Understanding of software engineering best practices', 'Commitment to delivering high-quality solutions', 'Familiarity with PostgreSQL and Elasticsearch, or similar technologies', 'Familiarity with designing for a cloud environment', 'Enthusiasm for Scrum and agile methodologies', 'Enthusiasm for problem-solving', 'Interest and ability to take initiative', 'Ability to communicate and collaborate in a diverse and distributed team', 'Ability to convey complex topics concisely and clearly', 'Ability and willingness to learn new things', 'Ability to succeed in a remote work environment', 'Five or more years of relevant work experience']",2020-09-24 13:35:31
Data Integration Engineer,Zenaide,N/A,"Santa Clara, CA 95054","['8 hour shift', 'Bonus pay', 'relevant: 10 years (Required)', 'Temporarily due to COVID-19']",2020-09-24 13:35:31
Data Engineer,Kar Global,3.2 out of 5,"Carmel, IN 46032","['Collaborate with business partners to understand processes and the relationship to data velocity, availability, and quality', 'Identify improvement areas to enhance existing data processes and offerings', 'Design and recommend modern data warehousing solutions', 'Implement simple, intuitive data engineering and visual solutions', 'Mentor others to improve analytical skillsets across the organization', 'Design solutions with a focus on cloud, PaaS, SaaS, and serverless services', 'Data Warehouse and Business Intelligence experience', 'Strong problem-solving skills, with the ability to analyze and break down problems', 'Advanced SQL and RDBMS experience (ex. Snowflake, RedShift, Oracle, SQL Server, MySQL, etc.)', 'Experience engineering data ingestion and transformation solutions (ex. Azure Data Factory, Informatica, SSIS, Talend, Pentaho, Python, Databricks, stored procedures, etc.)', 'Advanced ability to visualize data (Tableau experience preferred)', 'Understanding and practice of Agile and DevOps principles', 'Experience with cloud warehousing and analytics (ex. Snowflake, Redshift, BigQuery)', 'Experience with semi-structured and unstructured data', 'OOP or functional programming experience (ex. Python, Java, C++, Scala, R, etc.)', 'Working knowledge of message queuing and stream processing', 'We’re a technology company delivering next generation tools to accelerate and simplify remarketing.', 'We’re an analytics company leveraging data to inform and empower our customers with clear, actionable insights.', 'And we’re an auction company powering the world’s most advanced and integrated mobile, digital and physical auction marketplaces.', 'Competitive compensation', 'Insurance coverage that includes medical, dental, vision and life insurance', 'Flexible spending account', 'Wellness program', '401(k) with employer match', 'Employee stock purchase program', 'Paid holidays and generous paid time off', 'Paid parental leave', 'Learning and development resources']",2020-09-24 13:35:31
Senior Data Engineer - Alexa,Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['Job', 'Company', 'Bachelor’s degree in Computer Science, Mathematics, Statistics, Finance, related technical field, or equivalent work experience.', '3-5 years of years of relevant work experience in analytics, data engineering, business intelligence, market research or related field, and 7-10 years professional experience', 'Experience gathering business requirements, and designing data system solutions to meet customer needs', 'Experience using SQL, ETL and databases in a business environment with large-scale, complex datasets', 'Design, implement, and support a platform providing ad hoc access to large datasets', 'Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL', 'Manage AWS Resources', 'Model data and metadata for ad hoc and pre-built reporting', 'Interface with business customers, gathering requirements and delivering complete reporting solutions', 'Own the design, development, and maintenance of datasets to drive key business decisions', 'Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation', 'Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers', 'Participate in strategic & tactical planning discussions, including annual budget processes', 'Graduate degree in computer science, business, mathematics, statistics, economics, or other quantitative field', 'Both technically deep and business savvy enough to interface with all levels and disciplines within the organization', 'Demonstrated ability to coordinate projects across functional teams, including engineering, IT, product management, marketing, finance, and operations', 'Knowledge of Advanced SQL and a programming language', 'Experience with data visualization using Tableau or similar tools', 'Experience with large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies', 'Proven track record of successful communication of analytical outcomes through written communication, including an ability to effectively communicate with both business and technical teams']",2020-09-24 13:35:31
Data Engineer,The New York Times,4 out of 5,"New York, NY","['Run and support a production enterprise data platform', 'Design and develop data models', 'Work with languages like Java, Python, Go, Bash, and SQL', 'Build batch and streaming data pipelines with tools such as Spark, Airflow, and cloud-based data services like Google’s BigQuery, Dataproc, and Pub/Sub', 'Develop processes for automating, testing, and deploying your work', 'Make an impact by supporting our original, independent and deeply reported journalism.', 'We provide competitive health, dental, vision and life insurance for employees and their families', 'We support responsible retirement planning with a generous 401(k) company match.', 'We offer a generous parental-leave policy, which we recently expanded in response to employee feedback. Birth mothers receive 16 weeks fully paid; non gestational parents receive 10 weeks, also fully paid.', 'We are committed to career development, supported by a formal mentoring program and $8,000 annual tuition reimbursement.', 'We have frequent panel discussions and talks by a wide variety of news makers and industry leaders.', 'Join a community committed to the richness of diversity, experiences and talents in the world we cover, supported by a variety of employee resource groups.']",2020-09-24 13:35:31
Sr. Data Engineer,Datasys Consulting & Software Inc.,N/A,"San Francisco, CA","['Extensive experience with Cloud, Dataware ETL, Data Visualization, and reporting', 'Hands-on batch and bean airflow, spark and high', 'Experience in Google Cloud data products, IOT Architecture, and Realtime data-streaming', 'Must know Python, Scala, SQL DB', 'Capacity Planning and customer-facing in some cases', 'Also, must have experience in Machine Learning', 'Google Platform Certification or any google certification', 'Google Cloud: 5 years (Required)', 'SQL Data Base: 2 years (Preferred)', 'Data warehousing/Lake: 4 years (Preferred)', 'Data Visualization: 2 years (Preferred)', 'ETL: 4 years (Required)']",2020-09-24 13:35:31
Data Engineer,Pricesenz,N/A,"Irving, TX","['Experience:Python, Java, 1 year (Required)Big Data, 1 year (Required)Tableau, 1 year (Required)', 'Maintain high levels of integrity and dependability', 'Maintain a focus on results & quality.', 'Works well in a team environment and effectively manage work activities', 'Project a professional demeanor and appearance', 'Be extremely flexible and adaptable', 'Demonstrates the ability to function and stay focused on constant pressure, fast-growing and ever-changing organization', 'Python, Java: 1 year (Required)', 'Big Data: 1 year (Required)', 'Tableau: 1 year (Required)', 'Can you work on W2? If yes, What is your Visa status?', 'Temporarily due to COVID-19']",2020-09-24 13:36:16
Data Center Operations Engineer,DTN,3.1 out of 5,"Omaha, NE 68114","['$52,000.00 - $57,000.00 per year', 'Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Employee discount', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Referral program', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', 'Experience:Windows, 2 years (Required)Linux, 2 years (Required)', 'Education:Associate (Required)', 'DTN is a global leader providing insights and analytics to our customers to feed, fuel, and protect the world. We help people make critical business decisions that impact the agriculture, oil and gas, trading, and weather industries.', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Employee discount', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Referral program', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Night shift', 'Windows: 2 years (Required)', 'Linux: 2 years (Required)', 'Associate (Required)', 'Overnight (Required)', 'Temporarily due to COVID-19']",2020-09-24 13:36:16
Sr Data Engineer,AIG,3.7 out of 5,"Charlotte, NC","['Design and build end to end data flows using modern technologies and adhering to enterprise standards. This includes but not limited to data cleansing, data mapping, data transformation and data standardization techniques.', 'Developing an ecosystem to support business teams in managing and using their data.', 'Pursue a rigorous, disciplined approach to software development process and automation.', 'Develop, test and maintain build and deployment scripts in CI/CD framework/tools to automate and streamline deployment processes.', 'A keen eye for encryption and data security.', 'Implement strong data governance and quality solutions.', 'Research, suggest, and apply new promising technologies, strategies and ways to solve technical issues.', 'Strong hands-on experience with SQL and Stored Procedure database development using leading databases like Snow Flake, Oracle, Postgres is required; Experience in handling large data warehouse is required', 'Experience with Cloud technologies (e.g. AWS), Cloud data warehouses (Snowflake/ Redshift) and Big data technologies like spark/data Bricks would be highly preferable', 'Amazon Web Services - S3, EMR, Athena, Glue, Kinesis etc., CI /CD – Jenkins, GitHub, JFrog etc.,', 'Experience with one of the ETL technologies like Talend is highly preferable.', 'Programming Languages like java Script , Python', 'Data Modeling, Data Governance and Data Quality processes', 'SQL, NoSQL and BI experience', 'Data Visualization (MicroStrategy, Power BI, Tableau)', 'Financial domain experience', 'Linux and Windows server concepts', 'Bias for Action and Service Orientated.', 'Strong strategic development and project execution skills, with proven ability to deliver key tasks on time and on budget.', 'Exceptional communication skills, including ability to develop and present clear and concise analysis and recommendations to senior management.', 'Strong analytical skills.', 'Proven ability to dissect complex business issues, performs research and analysis, and synthesize conclusions into a value-maximizing strategy.', 'Strong business acumen with a proven track record of making sound judgments backed by strong analytical skills.', 'Comprehensive awareness of the business and regulatory environment.', '8+ years of experience', ""Bachelor's Degree"", 'Product leadership with scope of influence', 'Ability to mentor others']",2020-09-24 13:36:16
"Sr Engineer, Data & Analytics",Comcast,3.7 out of 5,"Philadelphia, PA 19103","['Utilizes resources, SQL optimization skills, quality assurance, troubleshooting skills, and subject matter expertise to find and solve moderate to major development problems in SQL Server, OBIEE, and Tableau. Able to troubleshoot, perform root cause analysis, and determine/recommend short and long term solutions to management.', 'Supports the established deployment process, including completing code reviews in GitHub', 'Creates technical documentation (internal) using understanding of internal business areas and processes as well as working knowledge of database design, data manipulation, ETL, implementation, information storage & retrieval, and data flow & analysis.', 'Preemptively recognize and resolve technical issues utilizing knowledge of policies and processes.', 'Optimize data sources and processing rules to ensure appropriate data quality of all products utilizing trouble-shooting, design, and development skills along with cross systems technical knowledge.', 'Solves critical issues and shares knowledge such as trends, aggregate, quantity volume regarding specific data sources.', 'Acts as a subject matter expert in one or more technical areas; such as data architecture, data engineering or data manipulation within big data systems like Hadoop and SQL.', 'Serves as a team leader within a work group or on cross-functional teams; accepts team lead stretch assignments, acts as a resource for colleagues with less experience.', 'Acts as a liaison between business owners and technical associates to ensure the data collected and processed is both actionable and relevant to the end goals.', 'Determines appropriateness of data for storage and optimum storage organization. Determines how tables relate to each other and how fields interact within the tables to develop relational models.', 'Collaborates with technology and platform management partners to optimize data sourcing and processing rules to ensure appropriate data quality.', 'Consistent exercise of independent judgment and discretion in matters of significance.', 'Regular, consistent and punctual attendance. Must be able to work nights and weekends, variable schedule(s) as necessary.', 'Other duties and responsibilities as assigned.', 'Bachelors Degree', 'Computer Science or related field', 'Current or prior Comcast Business experience highly preferred, including subject matter expertise in Business Services Sales, Retention, and legacy processes.', 'Generally requires 5-8 years related experience.']",2020-09-24 13:36:16
"Hiring Data Engineer/ Full-Stack Developers- San Jose, USA",Scry Analytics,N/A,"San Jose, CA 95134","['designing and customizing software with the aim of optimizing operational efficiency, which includes building analytics tools to optimize key business performance metrics;', 'analyze user needs, which includes building the infrastructure required for optimal extraction, transformation, and loading of data using SQL and Cloud Computing ‘big data’ technologies;', 'identifying, designing, and implementing internal process improvements, such as re-designing infrastructure for greater scalability;', 'creating optimal data pipeline architecture; creating data tools for analytics and data scientist team members that assist them in building and optimizing our product;', 'keeping our data separated and secure across national boundaries through multiple data centers and Cloud Computing regions; working with stakeholders to strive for greater functionality in our data systems;', 'and utilizing knowledge of Optical Character Recognition, number corrections, object detection and counting, neural networks, data and statistical analysis, and machine learning methods to perform the duties described above.', 'Master’s degree in Computer Science or a related field,', 'two (2) years of relevant experience and should be based in the U.S.', 'This experience should include two (2) years of experience with designing and developing computer software applications using Object-oriented design and programming;', 'Python;', 'algorithm design and development;', 'neural network frameworks;', 'Linux Operating System; data engineering; statistical data analysis;', 'Machine Learning, including Bayesian modeling, multivariate and logistic regression, support vector machines, cluster analysis, decision and regression trees, random forest, neural networks and ensemble methods;', 'and analyzing large, complex, multi-dimensional data sets and developing analytic solutions.', '8 hour shift', 'Day shift', 'Monday to Friday', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'Temporarily due to COVID-19']",2020-09-24 13:36:16
Data Visualization Engineer,"Tagup, Inc.",N/A,"Somerville, MA","['Build innovative and powerful visualizations of our customers and their data.', 'Work with our engineering team to define user needs and help with the creation of creative data visualization to provide the best user experience possible.', 'Prototype and develop new ideas and participate in all parts of the product lifecycle from research to release.', 'Support general company data visualization needs, including print and web materials', '3+ years of experience working in an analytical environment, including demonstrable data, analytics, reporting, visualization and problem-solving skills', '2+ years of experience working with D3.js', 'Experience working with very large datasets', 'Experience interfacing with business customers, gathering requirements and gaining a deep-dive understanding of key data', 'Strong written, verbal, and visual communication skills to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation', 'Experience with other data visualization libraries/solutions (Chart.js, Raphael.js, Tableau etc.)', 'Working knowledge of modern JavaScript libraries/frameworks (Vue.js preferred)', 'Experience with MongoDB and/or InfluxDB']",2020-09-24 13:36:16
Data Engineer,Rackspace,3.8 out of 5,Remote,"['Build complex ETL code', 'Work on Data and Analytics Tools in the Cloud', 'Develop code using Python, Scala, R languages', 'Work with technologies such as Spark, Hadoop, Kafka, etc.', 'Build complex Data Engineering workflows', 'Create complex data solutions and build data pipelines', 'Establish credibility and build impactful relationships with our customers to enable them to be cloud advocates', 'Capture and share industry best practices amongst the community', 'Attend and present valuable information at Industry Events', 'Drive the engagements with customers from the architectural pillar, from design to delivery, create runbooks etc.', '15+ Years of Data-warehouse and Analytic system development and deployment experience', '10+ years of experience in database architectures and data pipeline development', '8+ years of experience in modern data ware housing platform using cloud native technologies', '5+ years of experience in delivering Azure/GCP/AWS Data Solutions.', 'Demonstrated knowledge of software development tools and methodologies', 'Presentation skills with a high degree of comfort speaking with executives, IT management, and developers', 'Excellent communication skills with an ability to right level conversations', 'Demonstrated ability to adapt to new technologies and learn quickly', 'Experience with Google Cloud Services such as Streaming + Batch, BigQuery, BigTable, DataStudio, DataPrep, Pub/Sub , Cloud Storage, Cloud Dataflow, Data Proc, DataFlow, DFunc, Big Query & Big Table', 'knowledge and proven use of contemporary data mining, cloud computing and data management tools including but not limited to Microsoft Azure, AWS Cloud, Google Cloud, hadoop, HDFS, MapR and spark.', 'Design and configuration of data movement, streaming and transformation (ETL) technologies such as Informatica, Nifi, Kafka, Storm, Sqoop, SSIS, Alteryx, Pentaho, Alooma, Airflow.', 'Creation of descriptive, predictive and prescriptive analytics solutions using Azure Stream Analytics, Azure Analysis Services, Data Lake Analytics, HDInsight, HDP, Spark, Databricks, MapReduce, Pig, Hive, Tez, SSAS.', 'Design and configuration of data movement, streaming and transformation (ETL) technologies such as Azure Data Factory, HDF, Nifi, Kafka, Storm, Sqoop, SSIS, LogicApps, Signiant, Aspera, Alteryx, Pentaho, Alooma, Airflow.', 'Large scale design, implementation and operations of OLTP, OLAP, DW and NoSQL data storage technologies such as SQL Server, Azure SQL, Azure SQL DW, PostgreSQL, CosmosDB, RedisCache, Azure Data Lake Store, Hadoop, Hive, MySQL, Neo4j, Cassandra, HBase', 'Experience working within an agile development process (Scrum, Kanban, etc)', 'Expertise in data estate workloads like HDInsight, Hadoop, Cloudera, Spark, Python.', 'Familiarity with CI/CD concepts', 'Strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external organizations and virtual teams.', 'Knowledge or hands-on experience with data visualization and/or data sciences.', 'Hands on experience with Azure/GCP projects.', 'Cloud certifications such as GCP Professional Data Engineer or Microsoft Data / AI certifications.', 'Technical degree required; Computer Science or Math background desired', 'This is a virtual role', 'The candidate needs to be based in US or Canada', 'This role would require 25 - 30% travel']",2020-09-24 13:36:16
Data Engineer - Remote,Thresher,N/A,"Arlington, VA 22201","['Compensation is competitive and includes 20 days of vacation, 9 federal holidays, 9 days of sick leave.', 'We cover 100% of health care premiums as well as the premiums for short and long-term disability plus life insurance.', 'We match your contributions to a SIMPLE IRA.', 'Work with business, product, and engineering teams to build, extend, and maintain data integration services and ETL data pipelines.', 'Design, implement, and maintain relational databases structures and document stores.', 'Extract, transform, and load text data in a variety of written languages.', 'Design and create proof-of-concepts, prototypes, and production-quality solutions.', 'Collaborate with subject matter experts and data scientists to fully understand requirements and help propose solutions.', 'Contribute to our software solutions in your area of expertise, and share your knowledge and experience with the team, so we can all contribute at a higher level.', 'Operate in a collaborative agile environment with a focus on transparency and team success.', 'Proficiency with relational databases and SQL', 'Proficiency with document stores and data warehouses', 'Proficiency in ETL processes and technologies', 'Understanding of software engineering best practices', 'Commitment to delivering high-quality solutions', 'Familiarity with PostgreSQL and Elasticsearch, or similar technologies', 'Familiarity with designing for a cloud environment', 'Enthusiasm for Scrum and agile methodologies', 'Enthusiasm for problem-solving', 'Interest and ability to take initiative', 'Ability to communicate and collaborate in a diverse and distributed team', 'Ability to convey complex topics concisely and clearly', 'Ability and willingness to learn new things', 'Ability to succeed in a remote work environment', 'Five or more years of relevant work experience']",2020-09-24 13:36:16
Data Integration Engineer,Zenaide,N/A,"Santa Clara, CA 95054","['Pay:', '$75.00 - $95.00 per hour', 'Experience:relevant, 10 years (Required)', '8 hour shift', 'Bonus pay', 'relevant: 10 years (Required)', 'Temporarily due to COVID-19']",2020-09-24 13:36:16
Data Engineer,Kar Global,3.2 out of 5,"Carmel, IN 46032","['Competitive compensation', 'Insurance coverage that includes medical, dental, vision and life insurance', 'Flexible spending account', 'Wellness program', '401(k) with employer match', 'Employee stock purchase program', 'Paid holidays and generous paid time off', 'Paid parental leave', 'Collaborate with business partners to understand processes and the relationship to data velocity, availability, and quality', 'Identify improvement areas to enhance existing data processes and offerings', 'Design and recommend modern data warehousing solutions', 'Implement simple, intuitive data engineering and visual solutions', 'Mentor others to improve analytical skillsets across the organization', 'Design solutions with a focus on cloud, PaaS, SaaS, and serverless services', 'Data Warehouse and Business Intelligence experience', 'Strong problem-solving skills, with the ability to analyze and break down problems', 'Advanced SQL and RDBMS experience (ex. Snowflake, RedShift, Oracle, SQL Server, MySQL, etc.)', 'Experience engineering data ingestion and transformation solutions (ex. Azure Data Factory, Informatica, SSIS, Talend, Pentaho, Python, Databricks, stored procedures, etc.)', 'Advanced ability to visualize data (Tableau experience preferred)', 'Understanding and practice of Agile and DevOps principles', 'Experience with cloud warehousing and analytics (ex. Snowflake, Redshift, BigQuery)', 'Experience with semi-structured and unstructured data', 'OOP or functional programming experience (ex. Python, Java, C++, Scala, R, etc.)', 'Working knowledge of message queuing and stream processing', 'We’re a technology company delivering next generation tools to accelerate and simplify remarketing.', 'We’re an analytics company leveraging data to inform and empower our customers with clear, actionable insights.', 'And we’re an auction company powering the world’s most advanced and integrated mobile, digital and physical auction marketplaces.', 'Competitive compensation', 'Insurance coverage that includes medical, dental, vision and life insurance', 'Flexible spending account', 'Wellness program', '401(k) with employer match', 'Employee stock purchase program', 'Paid holidays and generous paid time off', 'Paid parental leave', 'Learning and development resources']",2020-09-24 13:36:16
Senior Data Engineer - Alexa,Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['Bachelor’s degree in Computer Science, Mathematics, Statistics, Finance, related technical field, or equivalent work experience.', '3-5 years of years of relevant work experience in analytics, data engineering, business intelligence, market research or related field, and 7-10 years professional experience', 'Experience gathering business requirements, and designing data system solutions to meet customer needs', 'Experience using SQL, ETL and databases in a business environment with large-scale, complex datasets', 'Design, implement, and support a platform providing ad hoc access to large datasets', 'Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL', 'Manage AWS Resources', 'Model data and metadata for ad hoc and pre-built reporting', 'Interface with business customers, gathering requirements and delivering complete reporting solutions', 'Own the design, development, and maintenance of datasets to drive key business decisions', 'Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation', 'Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers', 'Participate in strategic & tactical planning discussions, including annual budget processes', 'Graduate degree in computer science, business, mathematics, statistics, economics, or other quantitative field', 'Both technically deep and business savvy enough to interface with all levels and disciplines within the organization', 'Demonstrated ability to coordinate projects across functional teams, including engineering, IT, product management, marketing, finance, and operations', 'Knowledge of Advanced SQL and a programming language', 'Experience with data visualization using Tableau or similar tools', 'Experience with large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies', 'Proven track record of successful communication of analytical outcomes through written communication, including an ability to effectively communicate with both business and technical teams']",2020-09-24 13:36:16
Data Engineer,The New York Times,4 out of 5,"New York, NY","['Make an impact by supporting our original, independent and deeply reported journalism.', 'We provide competitive health, dental, vision and life insurance for employees and their families', 'We support responsible retirement planning with a generous 401(k) company match.', 'Birth mothers receive 16 weeks fully paid; non gestational parents receive 10 weeks, also fully paid.', 'Run and support a production enterprise data platform', 'Design and develop data models', 'Work with languages like Java, Python, Go, Bash, and SQL', 'Build batch and streaming data pipelines with tools such as Spark, Airflow, and cloud-based data services like Google’s BigQuery, Dataproc, and Pub/Sub', 'Develop processes for automating, testing, and deploying your work', 'Make an impact by supporting our original, independent and deeply reported journalism.', 'We provide competitive health, dental, vision and life insurance for employees and their families', 'We support responsible retirement planning with a generous 401(k) company match.', 'We offer a generous parental-leave policy, which we recently expanded in response to employee feedback. Birth mothers receive 16 weeks fully paid; non gestational parents receive 10 weeks, also fully paid.', 'We are committed to career development, supported by a formal mentoring program and $8,000 annual tuition reimbursement.', 'We have frequent panel discussions and talks by a wide variety of news makers and industry leaders.', 'Join a community committed to the richness of diversity, experiences and talents in the world we cover, supported by a variety of employee resource groups.']",2020-09-24 13:36:16
Sr. Data Engineer,Datasys Consulting & Software Inc.,N/A,"San Francisco, CA","['Experience:Google Cloud, 5 years (Required)SQL Data Base, 2 years (Preferred)Data warehousing/Lake, 4 years (Preferred)Data Visualization, 2 years (Preferred)ETL, 4 years (Required)', 'Extensive experience with Cloud, Dataware ETL, Data Visualization, and reporting', 'Hands-on batch and bean airflow, spark and high', 'Experience in Google Cloud data products, IOT Architecture, and Realtime data-streaming', 'Must know Python, Scala, SQL DB', 'Capacity Planning and customer-facing in some cases', 'Also, must have experience in Machine Learning', 'Google Platform Certification or any google certification', 'Google Cloud: 5 years (Required)', 'SQL Data Base: 2 years (Preferred)', 'Data warehousing/Lake: 4 years (Preferred)', 'Data Visualization: 2 years (Preferred)', 'ETL: 4 years (Required)']",2020-09-24 13:36:16
Data Engineer,AlgoLIFT,N/A,"Los Angeles, CA","['Support data integrations with clients', 'Author and support data integrations with Ad Networks and other data providers', 'Maintain and improve various other ETL processes', 'Automate data integrity validation processes', 'At least 3 years of full time engineering', 'Significant knowledge of SQL and Python', 'Direct experience with data pipeline engineering']",2020-09-24 13:36:16
Data Engineer,Datastrong,N/A,"Washington, DC","['BenefitsCompensation plan consisting of a competitive base salary and an uncapped bonus', '100% Health coverage for employees with Vision and Dental options', 'Paid holidays and vacation with a generous leave policy', 'Commute reimbursement', 'Professional development and educational tuition assistance', 'Flexible spending account options', '401(k) retirement plan with complimentary financial advisory services', 'Strong SQL', 'Experience with ETL tools', 'Experience with Reporting/Analytics tools (MicroStrategy, Tableau, PowerBI, Cognos, Busines Objects, etc.) is a plus', 'Data manipulation & analysis', 'Unstructured data management', 'Experience with Cloud Technologies (S3, Redshift, lambda, AWS, etc.) is a plus', 'Bachelor’s Degree in Statistics, Mathematics, Computer Science, Management Information Systems, Engineering, Business Analytics disciplines, or related area', '3+ years of experience with ETL and data integration, data quality analysis, statistical analysis and/or modeling', 'Active Secret or Top-Secret US Government clearance', 'Compensation plan consisting of a competitive base salary and an uncapped bonus', '100% Health coverage for employees with Vision and Dental options', 'Paid holidays and vacation with a generous leave policy', 'Commute reimbursement', 'Professional development and educational tuition assistance', 'Flexible spending account options', '401(k) retirement plan with complimentary financial advisory services']",2020-09-24 13:36:16
Data Engineer,Princeton University,4.3 out of 5,"Princeton, NJ 08542","['Collect and prepare data for some of our major projects, including OpenPrecincts and partisan gerrymandering analyses in various states.', 'Compile datasets on a state-by-state basis, combining census data, precinct-level results, and other information using GIS software.', 'Assist in the preparation of mainstream media content, professional reports, in-depth analysis, and possible peer-reviewed publications.', 'Other duties as assigned.', 'Bachelors degree in computer science or related technical field.', 'Experience with the following technologies:Data Science/Scripting Language (Python, R, Stata, etc.)GIS Software (QGIS, ArcGIS, etc.)', 'Understanding of how underrepresentation impacts policy decisions in the U.S.', 'Understanding of web scraping, APIs, and other data acquisition processes', 'Familiarity with Amazon Web Services is preferred']",2020-09-24 13:36:59
Data Engineer,SQAIT INC,N/A,"Charlotte, NC","['8 hour shift', 'Should be work on our W2', 'Likely']",2020-09-24 13:36:59
Data Analytic Engineer,FacilityConneX,N/A,"Nashua, NH",[],2020-09-24 13:36:59
Sr. Data Engineer,Datasys Consulting & Software Inc.,N/A,"San Francisco, CA","['Experience:Google Cloud, 5 years (Required)SQL Data Base, 2 years (Preferred)Data warehousing/Lake, 4 years (Preferred)Data Visualization, 2 years (Preferred)ETL, 4 years (Required)', 'Extensive experience with Cloud, Dataware ETL, Data Visualization, and reporting', 'Hands-on batch and bean airflow, spark and high', 'Experience in Google Cloud data products, IOT Architecture, and Realtime data-streaming', 'Must know Python, Scala, SQL DB', 'Capacity Planning and customer-facing in some cases', 'Also, must have experience in Machine Learning', 'Google Platform Certification or any google certification', 'Google Cloud: 5 years (Required)', 'SQL Data Base: 2 years (Preferred)', 'Data warehousing/Lake: 4 years (Preferred)', 'Data Visualization: 2 years (Preferred)', 'ETL: 4 years (Required)']",2020-09-24 13:36:59
Data Engineer,Cognizant Technology Solutions,3.9 out of 5,"Bethlehem, PA",[],2020-09-24 13:36:59
Python Engineer (Data Management/Machine Learning),Ryzen Solutions Inc.,4.7 out of 5,"Cupertino, CA","['Experience:Python, 1 year (Preferred)', 'Health insurance', 'Monday to Friday', 'Python: 1 year (Preferred)', '3 - 4 months', '5 - 6 months', 'One location', 'No']",2020-09-24 13:36:59
Data Engineer,Datastrong,N/A,"Washington, DC","['BenefitsCompensation plan consisting of a competitive base salary and an uncapped bonus', '100% Health coverage for employees with Vision and Dental options', 'Paid holidays and vacation with a generous leave policy', 'Commute reimbursement', 'Professional development and educational tuition assistance', 'Flexible spending account options', '401(k) retirement plan with complimentary financial advisory services', 'Strong SQL', 'Experience with ETL tools', 'Experience with Reporting/Analytics tools (MicroStrategy, Tableau, PowerBI, Cognos, Busines Objects, etc.) is a plus', 'Data manipulation & analysis', 'Unstructured data management', 'Experience with Cloud Technologies (S3, Redshift, lambda, AWS, etc.) is a plus', 'Bachelor’s Degree in Statistics, Mathematics, Computer Science, Management Information Systems, Engineering, Business Analytics disciplines, or related area', '3+ years of experience with ETL and data integration, data quality analysis, statistical analysis and/or modeling', 'Active Secret or Top-Secret US Government clearance', 'Compensation plan consisting of a competitive base salary and an uncapped bonus', '100% Health coverage for employees with Vision and Dental options', 'Paid holidays and vacation with a generous leave policy', 'Commute reimbursement', 'Professional development and educational tuition assistance', 'Flexible spending account options', '401(k) retirement plan with complimentary financial advisory services']",2020-09-24 13:36:59
"Data Engineer, Associate","JPMorgan Chase Bank, N.A.",3.9 out of 5,"Lewisville, TX 75067","['Job', 'Company', 'Expertise in application data and infrastructure architecture disciplines', 'Implement business and IT data requirements through new data strategies and designs across data platforms', 'In depth knowledge of Data protection, replication, reconciliation, and distribution', 'Experience in Data Modeling: ERWin ,', 'Experience working on 1 or more NoSQL Databases such as Cassandra, DynamoDB, Elastic Search', 'Proficiency in one or more Database Platforms / Language: SQL, Hadoop, Cassandra and Hive', 'In Depth Knowledge of Kafka and Kafka Streams Platform , API Gateway', 'Familiarity with Agile engineering practices', 'In Depth Knowledge of AWS Bigdata ecosystem including AWS Glue', 'Experience working with PCI Data is a plus']",2020-09-24 13:36:59
Data Engineer,Equifax,3.6 out of 5,"St. Louis, MO 63146","['We offer excellent compensation packages with high-reaching market salaries, 401k matching, along with the works: comprehensive healthcare packages, schedule flexibility, collaborative work spaces, work from home opportunities, paid time off, and organizational growth potential', 'Grow at your own pace through online courses at Learning @ Equifax', 'Develop strategies, standards and best practices in the areas of data wrangling, data visualization and data integration and lead adoption throughout analytical platforms', 'Lead analysis of internal and external data assets in consultation with internal stakeholders', 'Develop new processes to create metrics to track the ongoing quality across Equifax data assets', 'Design new methodologies and execute investigative data analyses of moderate complexity in response to business request for internal and external customers', 'Develop and Collaborate extensively with Data, Analytics, and Technology leads to ensure the seamless consumption of insights generated from Equifax’s new big data analytical platform.', 'Stay current with rapidly developing Big Data technologies landscape and share knowledge internally and with customers. Prototype and integrate tools into Cambrian environment and lead adoption of tools through Data and Analytics.', '5+ years of work experience in building, loading, transforming and analyzing data within and across database platforms and other data stores is required.', '5+ years of scripting/coding experience required. Proficiency in one or more of the following languages: Python, R, SQL, SAS', 'Proficiency in SQL and data visualization techniques and tools (Tableau, Spotfire, Excel, etc)', 'Bachelor’s degree in Computer Science, Statistics, Economics, or equivalent quantitative field with heavy emphasis on programming required', 'Accountability', 'Bravery', 'Curiosity', 'Collaboration', 'Think and act differently', 'Trust', 'Ownership', 'Decide-Execute-Ship']",2020-09-24 13:36:59
Data Engineer,Rackspace,3.8 out of 5,Remote,"['Build complex ETL code', 'Work on Data and Analytics Tools in the Cloud', 'Develop code using Python, Scala, R languages', 'Work with technologies such as Spark, Hadoop, Kafka, etc.', 'Build complex Data Engineering workflows', 'Create complex data solutions and build data pipelines', 'Establish credibility and build impactful relationships with our customers to enable them to be cloud advocates', 'Capture and share industry best practices amongst the community', 'Attend and present valuable information at Industry Events', 'Drive the engagements with customers from the architectural pillar, from design to delivery, create runbooks etc.', '15+ Years of Data-warehouse and Analytic system development and deployment experience', '10+ years of experience in database architectures and data pipeline development', '8+ years of experience in modern data ware housing platform using cloud native technologies', '5+ years of experience in delivering Azure/GCP/AWS Data Solutions.', 'Demonstrated knowledge of software development tools and methodologies', 'Presentation skills with a high degree of comfort speaking with executives, IT management, and developers', 'Excellent communication skills with an ability to right level conversations', 'Demonstrated ability to adapt to new technologies and learn quickly', 'Experience with Google Cloud Services such as Streaming + Batch, BigQuery, BigTable, DataStudio, DataPrep, Pub/Sub , Cloud Storage, Cloud Dataflow, Data Proc, DataFlow, DFunc, Big Query & Big Table', 'knowledge and proven use of contemporary data mining, cloud computing and data management tools including but not limited to Microsoft Azure, AWS Cloud, Google Cloud, hadoop, HDFS, MapR and spark.', 'Design and configuration of data movement, streaming and transformation (ETL) technologies such as Informatica, Nifi, Kafka, Storm, Sqoop, SSIS, Alteryx, Pentaho, Alooma, Airflow.', 'Creation of descriptive, predictive and prescriptive analytics solutions using Azure Stream Analytics, Azure Analysis Services, Data Lake Analytics, HDInsight, HDP, Spark, Databricks, MapReduce, Pig, Hive, Tez, SSAS.', 'Design and configuration of data movement, streaming and transformation (ETL) technologies such as Azure Data Factory, HDF, Nifi, Kafka, Storm, Sqoop, SSIS, LogicApps, Signiant, Aspera, Alteryx, Pentaho, Alooma, Airflow.', 'Large scale design, implementation and operations of OLTP, OLAP, DW and NoSQL data storage technologies such as SQL Server, Azure SQL, Azure SQL DW, PostgreSQL, CosmosDB, RedisCache, Azure Data Lake Store, Hadoop, Hive, MySQL, Neo4j, Cassandra, HBase', 'Experience working within an agile development process (Scrum, Kanban, etc)', 'Expertise in data estate workloads like HDInsight, Hadoop, Cloudera, Spark, Python.', 'Familiarity with CI/CD concepts', 'Strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external organizations and virtual teams.', 'Knowledge or hands-on experience with data visualization and/or data sciences.', 'Hands on experience with Azure/GCP projects.', 'Cloud certifications such as GCP Professional Data Engineer or Microsoft Data / AI certifications.', 'Technical degree required; Computer Science or Math background desired', 'This is a virtual role', 'The candidate needs to be based in US or Canada', 'This role would require 25 - 30% travel']",2020-09-24 13:36:59
Data Engineer with SQL,soho square solutions,N/A,"New York, NY","['Experience:SQL, 4 years (Required)Data Engineer, 7 years (Required)', 'SQL: 4 years (Required)', 'Data Engineer: 7 years (Required)']",2020-09-24 13:36:59
"Data Engineer, Life Science Services",Komodo Health,4 out of 5,"San Francisco, CA","['Collaborated with data scientists to design, develop, and implement data data pipelines and data processing code for shared tooling.', 'Worked with Product to help prototype new analytics offerings.', 'Created automation systems and tools to configure, monitor, and orchestrate self-service solutions to non-technical internal stakeholders.', 'Delivered high-value data analytics projects that existing data products cannot cover.', 'Advocated for good engineering practices within the team via documentation and code reusability.', 'Python or Scala development, proficiency with at least one of them is required.', 'Data processing platforms such as Spark, Amazon EMR, Google DataProc, Hadoop/MapReduce, etc.', 'Data warehouse, modeling, and SQL experience such as Snowflake, Redshift, or BigQuery.', 'Ability to work as part of a cross-functional collaborative team in a fast-paced environment.', 'Strong business acumen demonstrated by a good understanding of how analytics insights tie into business goals.', 'Keenly analytical mindset and the ability to solve complex problems with limited supervision.', 'High motivation, work ethic, and self-discipline to organize and complete tasks.', 'Cholangiocarcinoma Foundation & Komodo Health partner to fight cancer', ""Komodo Health's 'Meet a Dragon' series"", ""Komodo Health's $50M Series C funding led by Andreessen Horowitz, Joined by Oak HC/FT"", ""Komodo's Values that Drive our Culture"", ""In Conversation with Dr. Arif Nathoo, Komodo Health's CEO""]",2020-09-24 13:36:59
Senior Data Engineer,AT&T,3.8 out of 5,"El Segundo, CA 90245","['Gather, analyze, and interpret a wide variety of data to identify causal relationships, trigger points, performance issues and predictions on customer sales behavior, subscriber churn, and product engagement for our Video products.', 'Be a bridge between data engineering and the business, enabling insight that can empower better decision-making.', 'Develop self-service data tools, and other visual aids in support of findings.', 'Advise business partners with regards to patterns and relationships in the data to recommend business direction or outcomes', 'Ensure meaningful client value is delivered through a mix of data analyses, insights, skills capabilities and original thinking.', '3-5 years of experience in data analytics or related field', 'BS/BA in business, math, statistics, computer science or related quantitative fields; Advanced Degree preferred', 'Coding proficiency in in SQL(CTE), Python required', 'MPP/Cloud data warehouse solutions (Snowflake, Redshift, BigQuery, Vertica, Teradata etc).', 'Must possess working knowledge with sourcing and modeling data from application APIs.', 'Motivated to explore new technologies and learn and can do so with minimal guidance.', 'Tableau,Airflow,Grafana,DBT experiences preferred.', 'Experience in large media, technology, ecommerce, or other subscription-based company is a plus']",2020-09-24 13:36:59
"Specialist, Data Engineer",3M,4 out of 5,"Maplewood, MN","['Job', 'Company', 'Supporting manufacturing locations globally by creating and supporting data reporting and analytics so users in various manufacturing roles can make optimal decisions.', 'In this role, you will collect and document requirements for data access and KPI reporting, then lead the development for the report, either within a scrum framework or on a project team.', 'Joining a high-profile rapid-response team for key reporting projects and contribute expertise as needed', 'Maintain a high degree of integrity and an established reputation for completing difficult projects', 'Bachelor’s degree or higher (completed and verified prior to start) from an accredited institution', 'Ten (10) combined years experience in SAP data warehouse, HANA, and BI Reporting and Analytics', 'Strong knowledge of 3M legacy data systems (GEDW, MES, etc)', 'Experience with the agile process and scrum development teams', 'Experience with enterprise report development with minimally defined, complex requirements', 'Experience with Cloud access and development for manufacturing reporting', 'Possesses knowledge and understanding of Manufacturing and Supply Chain and business unit organizations', 'Strong proficiency with analytical tools – Business Objects, Power BI, Web Intelligence, SQL', 'Experience with SCPA and SAP Supply Chain Service Reports']",2020-09-24 13:36:59
Senior Data Engineer,ION IP Optical Networks,N/A,"New York, NY","['Develop infrastructure for data pipelines, ETL and database systems, analytic tools, and signal processing software to support the data analytics team.', 'Provide support for day-to-day activities that may involve data loading and extraction, system and data sources integration and maintenance.', 'Contribute in production efforts involving system development to support analytics.', 'Interact with data providers and test team across the product portfolio.', 'Collaborate with various functional teams in the organization to deliver crisp, effective and reliable solutions in situations of considerable complexity.', 'M.S. or Ph.D. in computer science / electrical engineering / physics / similar quantitative fields.', '2+ years industry experience in data engineering.', 'Strong programming experience in Python.', 'Familiarity with the design, development, and management of data infrastructure, ETL pipelines, data warehousing and integration with analytics platforms.', 'Familiarity with SQL and working in Linux environment, version control software such as git, and Bash scripting are desired.', 'Strong experience in ETL framework, data warehouse enterprise infrastructure development from design, optimization, to deployment and operation.', 'Proficiency in SQL, significant experience in MySQL, PostgreSQL, Oracle.', 'Experience in platforms such as PDF Solutions, Proligent, TIBCO Spotfire, Tableau, JMP.', 'Experience in ETL/data frameworks such as Luigi, Airflow, PySpark is desired.', 'Experience in deployment of database host servers and IT infrastructure is desirable.']",2020-09-24 13:36:59
Data Analytics Enablement - Data Engineer,Northrop Grumman,4 out of 5,"Melbourne, FL",[],2020-09-24 13:37:42
Data Engineer,HEB,4.3 out of 5,"San Antonio, TX 78204","['What are the Perks?A robust Benefits plan with coverage starting Day One', 'Dental, vision, life, and other insurance plans; flexible spending accounts; short term / long term disability coverage', 'Partner Care Team, for any time you have healthcare or coverage questions', '10% off H-E-B brand products in-store and online', 'Eligibility to participate in 401(k)', 'Opportunity to become a “Partner-Owner” after 12 months', 'Work with HEB Digital teams to provide data solutions for e-commerce, supply chain, store operations, finance, and marketing reporting and analytics platforms', 'Contribute to existing data platforms and implement new technologies', 'Develop a deep understanding of HEB’s data and become a domain expert', 'Ensure data is distributed in a timely and accurate manner', 'Make data discoverable and accessible to business users', '2+ years of data engineering experience', 'Proficient with data technologies (e.g. Spark, Kinesis, Kafka, Airflow, Oracle, PostgreSQL, Redshift, Presto, etc.)', 'Experienced with designing and developing ETL data pipelines using tools such as Airflow, Nifi, or Kafka.', 'Strong understanding of SQL and data modeling', 'Understanding of Linux, Amazon Web Services (or other cloud platforms), Python, Docker, and Kubernetes', 'Experienced with common software engineering tools (e.g., Git, JIRA, Confluence, or similar)', ""Bachelor's degree in computer science or comparable field or equivalent experience"", 'A proven understanding and application of computer science fundamentals: data structures, algorithms, design patterns, and data modeling', 'A robust Benefits plan with coverage starting Day One', 'Dental, vision, life, and other insurance plans; flexible spending accounts; short term / long term disability coverage', 'Partner Care Team, for any time you have healthcare or coverage questions', 'Telehealth offers 24/7 access to board-certified doctors by phone', 'Partner Guidance allows free counselor visits', 'Funeral leave, jury duty, and military pay (subject to applicable law)', 'Maternal / paternal leave for new parents, including adoptions', '10% off H-E-B brand products in-store and online', 'Eligibility to participate in 401(k)', 'Opportunity to become a “Partner-Owner” after 12 months', 'H-E-B is one of the largest, independently owned food retailers in the nation, operating over 400 stores throughout Texas and Mexico, with annual sales generating over $25 billion', 'We hire talented people (109,000+ Partners), and give them autonomy to be creative in how they impact the business', 'We’re a Partner-driven company with a Bold Promise – Because People Matter', 'We embrace Diversity and Inclusion as core values, and support them with thriving company-wide programs', 'We’re a truly original Texas-based company that created the Spirit of Giving to help Texas communities every day', 'Once eligible, our Partners become Owners in the company. “Partner-owned” means our most important resources—People—drive the innovation, growth, and success that make H-E-B The Greatest Retailing Company']",2020-09-24 13:37:42
Data Engineer – Fans First (Boston),Spotify,4.3 out of 5,"Boston, MA","['Build large-scale batch and real-time data pipelines with data processing frameworks like Scalding, Scio, Storm, Spark and the Google Cloud Platform.', 'Leverage best practices in continuous integration and delivery.', 'Help drive optimization, testing and tooling to improve data quality.', 'Collaborate with other engineers, ML experts and stakeholders, taking learning and leadership opportunities that will arise every single day.', 'Work in cross functional agile teams to continuously experiment, iterate and deliver on new product objectives.', 'You are comfortable being flexible on a small team, occasionally crossing disciplines to contribute on the backend (Java/apollo micro-services).', 'You know how to work with high volume heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, and Cassandra.', 'You know how to write distributed, high-volume services in Java or Scala.', 'You are knowledgeable about data modeling, data access, and data storage techniques.', 'You have professional experience working in a product-driven environment.', 'You care about agile software processes, data-driven development, reliability, and responsible experimentation.', 'You understand the value of collaboration within teams.']",2020-09-24 13:37:42
Data Engineer - Channel Store Migration,Foverobrains,N/A,"San Francisco, CA","['Channel store is foundation of all the processes executed for billing, payment processing and reporting and includes following components:', 'Subscription management', 'Subscription processing/invoicing', 'Calculation of partner and Roku revenue share', 'Financial reconciliation and reporting', 'External partner Reporting', 'Legacy partner payouts', 'TRC Premium Service payout calculation', 'Legacy partner contract management (revenue share % management)', 'Roku Pay engineering will be migrating legacy channel store into new platform and it is essential to validate and certify all above processes with before channel store go live. Due to size of this effort, we would like to have this contractor help test all the processes in new channel store QA environment, fix code in case of failure, and help migrate to production.', 'Existing code base need to be tested and fixed it if needed:', 'External partner facing reports', 'Financial Report', 'Tax Reports', 'TRC Premium Service payout calculation', 'Other scripts', '5-7 years of experience (flexible)', 'Data migration, data testing experience', 'ETL understanding and test automation experience', 'SQL experience', 'Python', 'Understanding of Hive – big data platform', 'Redshift, Kafka, Hadoop']",2020-09-24 13:37:42
Data Specialist,Construction Journal,N/A,Remote,"['Heavy outbound calling to owners, architects, engineers, and general contractors to obtain specific construction project information.', 'Developing relationships with Construction Managers, Architects, and Engineers to obtain notice of construction projects in conception and planning phases.', 'Collect, process, and input information provided from public offices of zoning notices, site plan approvals, newspaper articles for potential construction projects being considered.', 'Obtaining, plans, specifications, and bidders/plan holders list on out to bid projects.', 'Computer Proficiency with ability to type 55 WPM.', 'Professional work ethic and can-do attitude.', 'Excellent written and verbal communication skills.', 'Strong organizational skills with the ability to meet daily and weekly deadlines.', 'Ability to work independently in a fast-paced environment that also requires strong team work.', 'Advanced education preferred or previous industry work experience.', 'Knowledge in the construction industry is a plus, but is not a requirement.']",2020-09-24 13:37:42
Project Data Science and Machine Learning Engineer 2021,Lutron Electronics,3.5 out of 5,"Coopersburg, PA 18036","['Develop, validate and implement predictive models and machine-learning algorithms.', 'Analyze data to extract valuable insights with the goal to innovate our products, improve customer experience or marketing techniques.', 'Enhance data collection procedures by assessing the effectiveness and accuracy of data sources and data gathering techniques.', 'Work closely with data engineers and business analysts to process, clean, and verify the integrity of data used for analysis', 'identify opportunities for leveraging data to drive business solutions and help establish near-term and long-term strategies.', 'Communicate complex ideas across all levels of organization using clear data- visualizations techniques', 'PhD or Master’s degree or in Mathematics, Statistics, Computer Science or related field.', 'Relevant industry experience in working with large data sets and building statistical models and developing algorithm.', 'Demonstrable experience in applying data science techniques', 'Proficient with analytical tools like Jupyter Notebooks, Python, R, and supporting libraries as well as querying and scripting tools.', 'Adept at communicating verbally & visually, connecting the dots, breaking down complex problems into simpler units.']",2020-09-24 13:37:42
Data Engineer,Chef Software,N/A,"Seattle, WA","['Take ownership for designing, developing and maintaining scalable data pipelines and data models.', 'Lead the data engineering work of the platform architecture team, helping to define and guide the work of others.', 'Provide technical expertise and leadership as a member of the data engineering team.', 'Design, construct, install, test and maintain data management systems.', 'Develop data ingestion and integrations processes.', 'Ensure that all systems meet the business/company requirements as well as industry best practices.', 'Integrate up-and-coming data management and software engineering technologies into existing data structures.', 'Develop set processes for data mining, data modeling, data ingestion, and data production.', 'Contribute to the design of new product offerings based on data analytics.', 'Create custom software components and analytics applications.', 'Research new uses for existing data; design experiments and analysis to answer key business questions.', 'Employ an array of technologies, languages and tools to connect systems together.', 'Collaborate with members of your team (eg, architects and engineers) on project goals.', 'Recommend different ways to constantly improve data reliability and quality.', 'You have a minimum of a Bachelors’ degree in Computer Science, Data Science, or related field, plus 5 years of experience (or equivalent combination of education and experience). Masters degree in a relevant field is advantageous.', 'You have demonstrable software development skills in at least one language such as Rust, Go, C#, C++, Ruby or Java.', 'You have expertise in architecting, designing and implementing data solutions in a cloud-native environment (AWS preferred).', 'You have experience with a variety of data technologies and structures that includes relational databases, NoSQL and graph.', 'You’re well-versed in working with big data.', 'You have excellent analytical and problem-solving skills.', 'You like to dive in, learn new things, and want to build awesome products.', 'You have experience building and operating high-performance data systems.', 'Working experience with Containers and Container orchestration tools such as Docker and Kubernetes is a huge plus.', 'You’ve had experience working with APIs (graph, specifically).', 'You enjoy collaborating closely with product management and internal engineering teams to understand their complex issues, solve their problems and elicit frequent feedback on the solutions you provide', 'You believe quality is part of the development process and not an afterthought']",2020-09-24 13:37:42
"Staff Data Engineer - Global Merchant Depository, Data Product Development",Visa,3.9 out of 5,"Palo Alto, CA","['Minimum of 5-7 years’ experience in production ETL pipelines, utilizing big data engineering techniques that enable statistical solutions to solve business problems', 'Post graduate degree in Computer Science/ Engineering, Information Science or a related discipline with strong technical experiences highly desired', 'Previous exposure to financial services, credit cards or merchant analytics is a plus, but not required', 'Extensive experience with SQL and big data technologies (Hadoop, Python , Java, Spark, Hive etc.) tools for large scale data processing, data transformation and machine learning pipelines', 'Experience with one or more of NLP, Machine learning (clustering, classification, neural nets) is required', 'Familiarity or experience with data mining and statistical modeling (e.g., regression modeling, clustering techniques, decision trees, etc.) is required', 'Ability to orient data engineering to the business needs of internal clients', 'Demonstrated analytical rigor with a strong attention to detail']",2020-09-24 13:37:42
Data Engineer,USAN,N/A,"Norcross, GA 30071","['Competitive compensation', 'Comprehensive benefits', 'From $85,000.00 per year', '401(k)', 'Dental insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'Experience with query languages: SQL, Oracle, etc.', 'Experience with AWS cloud resources: S3, Lambda', 'Experience with Cloud-centric data stores: Snowflake preferred', 'Experience with data visualization tools: Tableau preferred', 'Experience with Python', 'Experience writing complex SQL queries', 'Experience working with large data sets and optimizing compute efficiency', 'Ability to compose clear and comprehensive technical documentation', 'Experience performing root cause analysis and identify opportunities for improvement.', 'Strong time management and organizational skills', 'Design, develop and maintain data marts according to architectural standards', 'Migrate data from legacy data warehouses into a data lake', 'Create metric based Tableau dashboards following data visualization best practices', 'Troubleshoot and resolve incidents related to data quality and ETL', 'Work with internal and external customers to enable data understanding', 'Competitive compensation', 'Comprehensive benefits', 'Team centric work environment', '401(k)', 'Dental insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'On call', ""Bachelor's (Required)"", 'SQL: 2 years (Required)', 'Python: 1 year (Required)', 'AWS: 1 year (Required)', 'https://www.usan.com/', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-09-24 13:37:42
Data Scientist,BICP,5 out of 5,"Portland, OR","['$130,000.00 - $140,000.00 per year', 'Benefits:', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Role responsibilities matrix: 70% Data Science & 30% Product Management', 'Productionalized experience with cluster modelling, decision tree models, and variable importance analysis', 'Possess end-to-end data expertise including data sourcing, consolidation, integration, manipulation and visualization', 'Fluent/highly adept in SQL, Python, R', 'Ability to connect data science logic/applications with business goals and objectives', 'Upgrade and performance tune Tableau dashboards', 'Strong interpersonal and communication skills.', 'Ability to initiate and drive projects or technical implementations as needed', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Monday to Friday', 'Analytics: 3 years (Required)', 'Management: 1 year (Preferred)', 'SQL: 2 years (Required)', 'Python: 1 year (Required)', ""Bachelor's (Required)"", 'United States (Required)', 'Temporarily due to COVID-19']",2020-09-24 13:37:42
"Software Engineer, Data",Brex,N/A,Remote,"['Competitive compensation', 'Health, dental, and vision insurance', 'Basic life insurance, short-term disability, and long-term disability coverage', 'Generous vacation time', 'Generous monthly stipend to make working from home comfortable', '401(k) (US only)', 'Competitive compensation', 'Health, dental, and vision insurance', 'Basic life insurance, short-term disability, and long-term disability coverage', 'Generous vacation time', 'Parental leave', 'Daily lunches & snacks prepared by our food team', 'One time stipend to create your dream home office', 'Generous monthly stipend to make working from home comfortable', '401(k) (US only)', 'One Medical corporate membership (US only)', 'Build and maintain robust, observable data pipelines.', 'Build and own our data lake and data warehouse solutions.', 'Design and build user-friendly data platforms upon which data scientists can easily test and deploy models to production.', 'Scope, design and build tools for internal users to increase their efficiency ten-fold.', 'Design and implement customer facing data services and products from end to end.', 'Work closely with analysts and data scientists to deeply understand business problems and be a guiding voice in architecting the solutions.', 'Maintain a strong data driven culture within the company by interacting with diverse internal functions.', 'Experience with data pipelines and data warehousing, such as Big Query and Snowflake.', 'Low tolerance for system failures and a desire to build easily maintainable pipelines and services.', 'A level of independence that allows end-to-end ownership of the products and tools you build.', 'Keen product sense and customer empathy that leads to user-friendly products.', 'Desire to improve the engineering bar for the whole team.', 'Ability to devise creative workarounds to difficult project roadblocks.', 'Great sense of ownership and the desire to relentlessly chase down issues in systems you own.', 'Thriving in a collaborative environment, filled with a diverse group of people with different expertise and backgrounds (we currently have over 15 nationalities represented, with more than ½ the company working in a country different from the one they grew up in).', 'We work in an environment where it matters to make the right design decisions the first time, and as a result, take on less technical debt than other companies.', 'Product is a highly collaborative initiative across multiple teams. Data engineers are expected to understand the business and have input towards our long term vision.', 'We believe in two equal track career growths between senior individual contributors and managers. We want people to contribute where they feel most impactful.', 'We believe in small, accountable and autonomous teams of amazing people, eager to learn, teach and constantly improve our way of working.', 'People have a strong sense of ownership and accountability for what they’re building. What we build today will be the foundation for dozens of other systems in the future.', 'We are very frank on discussing technical matters. If one disagrees with how things are being done, we encourage them to speak up and help us get to the truth faster.']",2020-09-24 13:37:42
Data Analytics Engineer,Ohio State University Medical Center,4.1 out of 5,"Columbus, OH 43210","['$78600.00', 'Salary Range Max', '$121830.00']",2020-09-24 13:37:42
Data Engineer,University of Michigan,4.3 out of 5,"Ann Arbor, MI","['This will be filled at the lead level salary range of $95,000 - $110,000.', 'Generous time off', 'A retirement plan that provides two-for-one matching contributions with immediate vesting', 'Many choices for comprehensive health insurance', 'Life insurance', 'Long-term disability coverage', 'Flexible spending accounts for healthcare and dependent care expenses', 'Lead efforts to automate work for our Curation team (35%)Take a usage and needs inventory for current and non-existing scripts; create a strategy to reduce the number of scripts requiredMove current scripts for curation into source controlIntroduce automated testing for high impact scriptsIntroduce trigger-based automation to lower manual effortsCollaborate across units and departments to author high-usage tools that reduce time to curate, increasing throughput for curation', 'Create data pipelines consuming APIs from government agencies (25%)Create data pipelines as code, which are kept in source control, are modular and maintainable, and uses automated testingImplement data pipelines using a DevSecOps mindset, with automated deployment of environments and configurations', 'Teach Data Engineering methods to our Curation team (15%)Teach curators how to use source control, automated testing, and trigger based automation for current scripts the curators writeTeach modern data engineering methods (e.g. Python, R, data logistics tools) to curators who are interested in Data EngineeringTeach how to create automated acceptance tests for data manipulation code', 'Troubleshoot data pipeline, data manipulation scripts, and data encoding issues (25%)Read both software and infrastructure logs to find clues to errorsFind the root cause of complex errorsResolve errors by refactoring current systems to create higher resiliency', ""Bachelor's degree in computer science, a related field, or equivalent experience"", 'Seven or more years experience in software development, data engineering, or combination including:Five or more years experience in one or more programming language (Python/Java/C++)Two or more years experience consuming data from APIs using publish and subscribe architectureTwo or more years experience using either R or Python for data management, or equivalent experienceTwo or more years experience using regular expressions to validate data', 'Demonstrate understanding the reliability, scalability, and performance aspects of data structures and data pipelines', 'Collaboration skills for working within an Agile software development team', 'Familiarity with Social Sciences and academic research', 'Experience converting legacy scripting to more robust processing', 'Experience on a software team that deploys to production multiple times daily', 'Experience with statistics, data visualization, analytics, or machine learning', 'Experience working with SQL integration services or ETL tools', 'Experience with replication and partitioning data for transactional, batch, or streaming systems', 'Experience with NoSQL, Graph Databases, Spark, or Kafka', 'Experience with indexers such as Elasticsearch, Solr', 'Generous time off', 'A retirement plan that provides two-for-one matching contributions with immediate vesting', 'Many choices for comprehensive health insurance', 'Life insurance', 'Long-term disability coverage', 'Flexible spending accounts for healthcare and dependent care expenses', 'Various learning resources and tuition reimbursement']",2020-09-24 13:37:42
Data Engineer,Rock Central,N/A,"Detroit, MI 48226","[""Bachelor's degree in computer science, information technology, or a related field or equivalent experience"", '3 years of experience working with database tools', '3 years of programming experience using Python and C#', '3 years of experience working with SQL server integration services or ETL tools', '3 years of experience working with data integration tools', 'Proficiency in the Microsoft Office suite', 'Experience working with ETL tools', 'Knowledge of data integration tools', 'Software programming languages, such as Python and C#', 'Design and support the new and evolving sources of data being brought into the data warehouse', 'Work closely with data architects and follow best practices for data management consumption', 'Work closely with business analysts to work through business requirements and develop processes to provide the needed data visibility via the data warehouse and reporting platform', 'Model application layer and metadata design', 'Design and create automated applications and reporting solutions', 'Work closely with front-end developers to ensure data is being brought in and data integrity is being maintained', 'Monitor and troubleshoot performance issues on the data warehouse servers']",2020-09-24 13:37:42
"Data Scientist, Healthcare Map",Komodo Health,4 out of 5,"San Francisco, CA","['Closely collaborated with Data Engineers and Product Managers to establish and implement new data products.', 'Transformed data from medical claims and publically available data sets to create ""canonical data objects"" that represent real world entities, such as payer, patient or provider, and which will be used across the organization as sources of truth.', 'Gained deep knowledge and understanding of medical claims data and the core entities of the US healthcare system.', ""Analyzed Komodo's healthcare data to characterize individual datasets and assess their relative importance and completeness."", 'Building internal tools and dashboards to analyze coverage and completeness of Komodo data assets.', 'Using natural language processing and statistical modeling to group disparate health care organizations.', 'Grouping multiple data claims into a concept of a visit, to help improve analytics.', 'Collaborating with the Data Strategy team to identify gaps in our coverage and assess sample data of new sources that could fit in these gaps.', 'Contributing to cross functional effort to clean up and remap various claims data sources.', 'Keenly analytical mindset and the ability to unearth the necessary context to solve complex problems.', 'Strong knowledge of statistics and data science approaches.', 'Data Intuition on how to join data sets together without natural id, how to get insights from complex data sets.', 'Basic understanding of ML and modeling.', 'Experience writing SQL queries and / or scripting with Python.', 'Experience working with and improving messy data sets.', 'Collaborative mindset and desire to pitch in where help is needed the most.', 'Cholangiocarcinoma Foundation & Komodo Health partner to fight cancer', ""Komodo Health's 'Meet a Dragon' series"", ""Komodo Health's $50M Series C funding led by Andreessen Horowitz, Joined by Oak HC/FT"", ""Komodo's Values that Drive our Culture"", ""In Conversation with Dr. Arif Nathoo, Komodo Health's CEO""]",2020-09-24 13:37:42
"Data Scientist, Healthcare Map",Komodo Health,4 out of 5,"San Francisco, CA","['Closely collaborated with Data Engineers and Product Managers to establish and implement new data products.', 'Transformed data from medical claims and publically available data sets to create ""canonical data objects"" that represent real world entities, such as payer, patient or provider, and which will be used across the organization as sources of truth.', 'Gained deep knowledge and understanding of medical claims data and the core entities of the US healthcare system.', ""Analyzed Komodo's healthcare data to characterize individual datasets and assess their relative importance and completeness."", 'Building internal tools and dashboards to analyze coverage and completeness of Komodo data assets.', 'Using natural language processing and statistical modeling to group disparate health care organizations.', 'Grouping multiple data claims into a concept of a visit, to help improve analytics.', 'Collaborating with the Data Strategy team to identify gaps in our coverage and assess sample data of new sources that could fit in these gaps.', 'Contributing to cross functional effort to clean up and remap various claims data sources.', 'Keenly analytical mindset and the ability to unearth the necessary context to solve complex problems.', 'Strong knowledge of statistics and data science approaches.', 'Data Intuition on how to join data sets together without natural id, how to get insights from complex data sets.', 'Basic understanding of ML and modeling.', 'Experience writing SQL queries and / or scripting with Python.', 'Experience working with and improving messy data sets.', 'Collaborative mindset and desire to pitch in where help is needed the most.', 'Cholangiocarcinoma Foundation & Komodo Health partner to fight cancer', ""Komodo Health's 'Meet a Dragon' series"", ""Komodo Health's $50M Series C funding led by Andreessen Horowitz, Joined by Oak HC/FT"", ""Komodo's Values that Drive our Culture"", ""In Conversation with Dr. Arif Nathoo, Komodo Health's CEO""]",2020-09-24 13:38:24
Data Center Engineer,NSC Global Ltd,2.7 out of 5,"Raritan, NJ","['The network environment includes global Enterprise Data Centers and sites with emerging technologies (e.g. SDN, SDDC and Virtualization) as well as foundational network services (e.g. Data routing / switching, WLAN, IPAM, remote access, load balancing) within a complex and multi-vendor environment. The role is technical and will be responsible for providing hands on support for NOC technicians across the globe.', 'Perform assessments of Data center hardware environments as part of day to day responsibility.', 'Identify gaps and performance improvement opportunities based on engineering standards and market best practices.', 'Network Vulnerability remediation for data center activities.', 'Network Software Interface:Cisco command line experience a must!!!Console connectionsManagement connectionsFamiliar with common remote access hardware / software (Digi / AnyDesk, TeamViewer, etc.)Able to gather network information via common CLI commands', 'In-depth cabling & data center routing / switching knowledge:End of Row, Top of Rack, etc.Hot and Cold rows', 'Cabling Infrastructure knowledge:Copper Patch Panels, Copper Limitation, RJ45 EndsFiber LIU, SC / LC Fiber Ends, Single / Multi Mode Fiber', 'Participate in network infrastructures solutions (hands-on engineering, configuration, testing, deployment and initial support)', 'Involvement in supporting changes and oversight including off hours & weekends.', 'Minimum of 6-8 years of experience in network infrastructure solutions managing Data center of very large enterprise network.', 'Ability to configure / implement simple network changes.', 'Broad technical knowledge and experience with converged infrastructure, switching / routing in a large and complex network, DHCP, DNS, IP (Schema, subnetting, summarization) IP management tools, network management applications, advanced WAN routing, WAN / LAN / Wireless LAN topologies, MPLS and other WAN technologies, , traffic shaping / QoS, EIGRP / BGP), firewalls, technology', 'Knowledge of Routing and Switching systems; Fair understanding of Routing Protocols (OSPF, EIGRP, and BGP) and Gateway Redundancy Protocols (HSRP, VRRP, and GLRP)', ""Knowledge of VoIP, Multicast, STP, VTP and Virtual LAN's and Trunking (VLAN's); Network Security (ACL's, IPSec Tunnels), Firewalls (Security Appliances), Net-flow, IPSLA, and VPN technologies"", 'Ability to effectively prioritize and execute in a high-pressure environment.', 'Desired vendor certifications strongly preferred (CCNP)', '6 years of hands-on experience with three or more Cisco platforms', 'Experience with non-Cisco products and technologies such as Arista, F5.', 'Proficiency in Microsoft office products & network tools.', 'Proven ability to work independently', 'Proven analytical, problem solving, organizational and time management skills', 'Good communication (written and oral) and interpersonal skills', 'Good organizational, multi-tasking, and time-management skills']",2020-09-24 13:38:24
Software Engineer - Entry level,SoftSages Technology Inc,N/A,"Dublin, OH","['java: 1 year (Preferred)', ""Master's (Preferred)"", 'Multiple locations', 'Fully Remote']",2020-09-24 13:38:24
Data Scientist / Engineer - Machine Learning (Entry-Level) -- EOSL,Georgia Tech Research Institute,4.2 out of 5,"Atlanta, GA 30318","['Develop innovative algorithms and apply machine learning/deep learning methods to EW applications', 'Run simulations and algorithm optimizations', 'Curate data and write automation scripts', 'Write and perform software tests supporting software verification and document outcomes', 'Perform other duties as assigned', ""A Bachelor's degree in Electrical engineering, computer engineering, computer science, or a related technical field."", 'A Master’s degree in Electrical engineering, computer engineering, computer science, or a related technical field and three (3) years of relevant full-time experience after completion of that degree,', 'A Master’s degree in Electrical engineering, computer engineering, computer science, or a related technical field and five (5) years of relevant full-time experience after completion of a Bachelor’s degree, or', 'A Doctoral degree in Electrical engineering, computer engineering, computer science, or a related technical field.', 'Experience with machine learning and/or genetic programming methods through full-time employment, coursework, internship, student employment, or freelance', 'Experience with Python (including numPy, sciPy, pandas, matplotlib) and C++', 'Experience with Linux and Git', 'Experience with Evolutionary Multi-objective Algorithm Design Engine (EMADE) tool set', 'Experience with Modeling and Simulation (M&S)', 'Experience with Matlab, Fortran, or Ada', ""A Master's degree in electrical engineering, computer engineering, computer science, or a related technical field""]",2020-09-24 13:38:24
Data Science Engineer,BIOINTELLISENSE INC,N/A,Remote,"['Developing ML models from time-series sensor and bio-signal data', 'Running data science experiments at scale on Google Cloud infrastructure', 'Mentoring junior members of team in technical areas', 'Developing and reviewing system architecture to optimize the balance across cloud vs. edge processing.', 'BS in related field', 'Masters or Ph.D. helpful, but not required', '7+ years of cloud-based data science or algorithm experience', 'Being able to work under pressure in a startup environment']",2020-09-24 13:38:24
Interface Engineer,Bridgecr LLC,N/A,United States,"['Bi-directional, cross-platform communication and management of data between disparate systems', 'Designing, creating, testing system integration workflows', 'Data extraction, parsing, translation, mapping, and aggregation', 'Ability to pick up new technology quickly and adapt in a growth environment', 'Deliver software on-time, in scope, and make accurate estimates', 'Demonstrable, progressive experience as a SE using Hl7, TCP, file or APIs for 5 or more years', 'Daily maintenance and management of production interfaces', 'JavaScript development experience (Node.js, Deno, etc)', 'Experience with writing queries, reading from and writing to SQL or Postgres databases', 'Experience creating readable/testable code and debugging connectivity issues between systems', 'Experience working in a team environment using agile sprint methodologies and tools including Jira, Git, and Slack.', 'Healthcare domain knowledge', 'Integration platform as a service', 'Salesforce APIs', 'HL7 v 2.x, CCDA, FHIR, REST, X12']",2020-09-24 13:38:24
Data Engineer,Intellibee Inc,N/A,"Atlanta, GA","['Certified Azure Data Engineer with 5+ working experience in Hadoop & Spark.', 'Databricks knowledge is an added', 'Hadoop & Spark: 6 years (Required)', 'Databricks knowledge: 5 years (Required)']",2020-09-24 13:38:24
Data Science and Forensics Engineer,LOCKHEED MARTIN CORPORATION,4 out of 5,"Fort Worth, TX 76137","['Reading, Writing, and Applying Structured Query Language', 'Reading, Interpreting, and Writing eXtensible Markup', 'Techniques in data analysis, data extraction, data mining', 'Manipulation of data using Microsoft Excel and/or Access']",2020-09-24 13:38:24
Data Engineer (Full Time; Multiple Openings),RingCentral,2.8 out of 5,"Denver, CO","['Job', 'Company', 'Creating and maintaining optimal data pipeline architecture', 'Assembling large, complex data sets that meet functional / non-functional business requirements', 'Building the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources', 'Building analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics', 'Creating data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader', 'Working with data and analytics experts to strive for greater functionality in our data systems', 'Participate in on-call rotation to support data pipelines and tools.']",2020-09-24 13:38:24
Big Data Engineer,"Reddaiah, Inc",N/A,"Rockville, MD 20850","['Pay:', 'Up to $80.00 per hour', 'Analyze system requirements and design responsive algorithms and solutions.', 'Use big data and cloud technologies to produce production quality code.', 'Engage in performance tuning and scalability engineering.', 'Work with team, peers and management to identify objectives and set priorities.', 'Perform related SDLC engineering activities like sprint planning and estimation.', 'Work effectively in small agile teams.', 'Provide creative solutions to problems.', 'Identify opportunities for improvement and execute.', 'Strong experience with one or more programming languages like Scala/Java or Python.', 'Experience with cloud based Big Data technologies.', 'Proficiency in Spark SQL, AWS EMR, S3.', 'Experience with Spark.', 'Experience in spark execution model', 'Ability to troubleshoot slow or failing spark jobs', 'Understand shuffling, partitions etc.', 'Ability to push the frontier of technology and independently pursue better alternatives.', 'Monday to Friday', 'Yes', 'www.reddaiah.com', 'Temporarily due to COVID-19']",2020-09-24 13:38:24
Sr Data Engineer,"7-Eleven, Inc.",3.6 out of 5,"Irving, TX 75063","['Who we are', 'How we lead', 'Be Customer Obsessed', 'Be Courageous with Your Point of View', 'Challenge the Status Quo', 'Act Like an Entrepreneur', 'Have an “It Can Be Done” Attitude', 'Do the Right Thing', 'Be Accountable', 'About This Opportunity', 'Developing and implementing different aggregations, features and builds data pipelines to solve different problems related to supply chain management, dynamic pricing, customer preferance etc', 'Participating in designing new data applications', 'Code deployments, Dev Ops, Reviews', '7-10 years of work experience, Education- Masters preferred', 'Expert knowledge of Big Data technologies including but not limited to Python and/or Databricks', 'Strong Analytical and problem solving skills', 'Knowledgeable in cloud platforms (preferable AWS: both traditional EC2 and serverless Lambda), micro-services architecture, CI/CD solutions (including Docker), DevOps principles, message queue syste', 'Proficiency in API security frameworks, token management and user access control including OAuth, JWT, etc', 'Solid foundation and understanding of relational and NoSQL database princples']",2020-09-24 13:38:24
Advisory Data Engineer,ZOLL LifeVest,3.5 out of 5,"Pittsburgh, PA","['Develop infrastructure that supports machine learning from large sets of ECG and other signal data.', 'Research and integrate distributed storage and processing frameworks.', 'Collaborate with engineers, physicians, and data scientists to build data analysis pipelines and execute machine learning projects.', 'Scope out work, resources and time required to complete projects.', 'Lead development and implementation of process, tools, and best practices across the R&D organization', 'B.S in Computer Science or similar technical field of study or equivalent practical experience.', 'Minimum of 13 years practical solution development experience.', 'Proficiency with one or more general purpose programming languages (C++, Python).', 'Proficiency with Hadoop/MapReduce.', 'Familiarity with machine learning tools and techniques.', 'Experience with cloud-based distributed systems.', 'Minimum of 13 years of experience using data management tools, including SQL/DBMS.', 'Minimum of 13 years of experience architecting, designing, building and operating production big data/stream processing and/or large enterprise data stores.', 'Demonstrated track record of delivering correct and performant solutions.', 'Communication skills in verbal and written English.', 'The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.', 'The noise level in the work environment is usually quiet.', 'The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.', 'While performing the duties of this Job, the employee is regularly required to sit and talk or hear. The employee is occasionally required to stand and walk. The employee must occasionally lift and/or move up to 25 pounds.']",2020-09-24 13:38:24
Data Engineer,Qlarion Inc.,N/A,"Richmond, VA","['$100,000.00 - $110,000.00 per year', 'Benefits:', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Flexible Schedule', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Referral Program', 'Relocation Assistance', 'Retirement Plan', 'Tuition Reimbursement', 'Vision Insurance', 'U.S. Citizenship or Green Card Holder.', 'Our U.S. Govt. clients contractually require us to hire ONLY U.S. Citizens or Green Card Holders for their projects.', 'A clear concise Resume NOT more than 5 pages long', 'Education: BS Computer Science or BS Engineering or a BS Degree in a related field', 'At least 4 years of experience using Talend Data Integration (or similar tool) as a developer', 'At least 1 year experience designing and developing data quality (DQ) routines using DQ and ETL tools such as Informatica, SAP, or IBM.', 'Preferred at least 1 year experience using Tableau Prep', 'At least 1 year experience defining/implementing an Enterprise Data Warehouse using best practices', 'Experience using ETL tools in a data analyses, data engineering or similar role.', 'A Demonstrated working knowledge of database schema, objection management, data modeling & architecture, and data warehouse design.', 'Excellent written or oral communication skills', 'Analytical skills and a general business understanding', 'Knowledge of Structured Query Language (SQL) and Transact-SQL (T-SQL)', 'Experience defining/implementing an Enterprise Data Warehouse using best practices', 'Experience working directly with clients to define their requirements, document them, and to support and troubleshoot issues as they arise', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Flexible Schedule', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Referral Program', 'Relocation Assistance', 'Retirement Plan', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'Talend Data Integration(or similar tool) as a developer: 4 years (Required)', 'Tableau Prep : 1 year (Preferred)', 'ETL tools in a data analyses, data engineering similar role: 1 year (Preferred)', ""Bachelor's (Required)"", 'Are you a U.S. Citizen or Green Card holder?', 'A job for which military experienced candidates are encouraged to apply', 'A “Fair Chance” job (you or the employer follow Fair Chance hiring practices when performing background checks)', 'A job for which all ages, including older job seekers, are encouraged to apply', 'A job for which people with disabilities are encouraged to apply', 'qlarion.com', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-09-24 13:38:24
Data Engineer II,"LBMC, PC",5 out of 5,"Nashville, TN 37027","['Work with large, complex data sets', 'Solve complex, non-routine analysis problems, applying out-of the box thinking and analytical methods', 'Design and build ETL solutions in on-premise and cloud technologies', 'Design and build solutions using SQL database technologies, Azure Common Data Services, SQL Server Analysis Services (Tabular model)', 'Communicate with small clients regarding project and task status', 'Work with internal team members; effectively communicate with them in sharing, completing, and reviewing work', 'Provide documentation to clients for custom solutions built or technologies being deployed', 'Provide pre-sales technical support to sales team, including product demonstration, project scope and specifications and client deliverables, as well as sales support calls and meetings', 'Provide thought leadership and LBMC brand awareness to the marketplace through participation in forums, user groups, and speaking in data platform and analytics-related conferences', 'Bachelor’s degree required, preferably Computer Science, MIS, CIS, or Analytics-related', '4+ years’ experience in business intelligence, data engineering, or analytics-related roles', '4+ years’ experience writing SQL, preferably experience in T-SQL', 'Demonstration of relational database concepts and data structures', 'Demonstration of relational and dimensional data modeling', 'Experience with data quality initiatives, scrubbing data, and preparing data', 'Experience with data integration/ ETL tools, specifically Microsoft Azure Data Factory and/or SSIS', 'Experience with cloud services, specifically Microsoft Azure', 'Experience with a programming language such as C#, JavaScript, or PHP', 'Experience with Python and R a plus', 'Perform under stressful and changing circumstances', 'Willingness to learn new technologies and techniques', 'Communicate effectively orally and in writing', 'Establish effective work relationships with clients, team members, vendors, recruiting candidates, and referral partners', 'Tenacious problem solver; an overcomer mindset', 'Ability to understand and synthesize complex requirements', 'Attitude of humility and service', 'Intellectually curious, lifelong learner']",2020-09-24 13:38:24
Data Engineer,TapRecruit,N/A,New York State,"['Comprehensive healthcare plans', 'Flexible PTO policy', '401k retirement plan', 'Commuter benefits', 'Build scalable data pipelines that integrate multiple data sources (both internal and external APIs).', 'Generate fault-resistant data extraction and transformation processes with monitoring.', 'Prototyping data products and productionalizing data models', 'Improve engineering standards by developing internal tools that will be used by the data and engineering teams', 'Write code that is maintainable and includes relevant tests. Maintain and advocate for these standards through code review within the data and engineering teams.', '4+ years of experience building large-scale software applications with Python', 'Expert-level understanding of SQL and common relational database systems', 'Excellent debugging and data flow optimization skills', 'Experience querying and setting up NoSQL databases (ElasticSearch, MongoDB)', 'Familiarity with containerized development workflows', 'Desirable: Experience deploying data pipelines through AWS', 'Comprehensive healthcare plans', 'Flexible PTO policy', '401k retirement plan', 'Commuter benefits', 'Remote-friendly team and open to more flexible work arrangements']",2020-09-24 13:38:24
Engineer- Interiors DOE,Alaska Airlines,3.9 out of 5,"Seattle, WA 98194",[],2020-09-24 13:39:05
Big Data Engineer,Reed Technologies,N/A,"Phoenix, AZ","['Pay:', '$45.00 - $50.00 per hour', 'Monday to Friday', 'Bigdata: 5 years (Required)']",2020-09-24 13:39:05
Mobile Operating Engineer (Data Center),JLL,3.8 out of 5,"Arlington, TX",[],2020-09-24 13:39:05
20GA590 Life Science Automation Engineers (Validation and Commissioning),Mason-Grey Corporation,N/A,"Vacaville, CA","['Pay:', '$55.00 - $95.00 per hour', 'Benefits:', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Generate and execute Validation life cycle documentation such as Systems Commissioning, Installation Qualification (IQ), Operational Qualification (OQ), Validation Summary Reports, and Deviations reports for Manufacturing and process Equipment & Utilities as per client GES guidelines.', 'Have expertise working with the Emerson DeltaV Process Control System and Emerson Syncade Manufacturing Execution System. Configuration within DeltaV or Syncade is not part of this requirement.', 'Perform Commissioning of Process Equipment, Utilities, HVAC Systems and Control Temperature Units in process rooms areas as per GMP requirements of the Client’s operations.', 'Analyze and interpret validation test data to determine whether systems or processes have met validation criteria or to identify root causes of deviations.', 'Generate Deviation Reports, perform root cause investigation and document Corrective And Preventive Actions (CAPA).', 'Dental insurance', 'Health insurance', 'Vision insurance', '8 hour shift', 'pharmaceutical / biotech validation: 5 years (Required)', ""Bachelor's (Required)"", 'Multiple locations']",2020-09-24 13:39:05
Sr AWS Data Engineer,"LogiSolve, LLC",N/A,"Midwest, WY","['Working knowledge of software best practices across development life cycle including agile methodologies in a lean-agile environment', 'Solid understanding of the Linux OS', 'Expertise in Big Data technologies, specifically Hive, Hue, and Impala/Presto', 'Experience with streaming technologies like Kinesis and search technologies like ElasticSearch', 'Experience with in-memory computing using Python, PySpark, or Scala', 'Experience with designing and building solutions for ingestion and transformation of data that generate actionable insights', 'Experience with DevOps, CI/CD implementations of the following technologies: Docker or Jenkins or Test Driven Development patterns', 'Expert knowledge on source controls systems like Git and Bitbucket', 'Good understanding of Data Warehouse, Data Lake, and Data Mart concepts', 'Good knowledge on AWS ecosystem - S3, Lambda, Glue, EMR, Athena, Cloud Formation, etc.', 'Experience with building solutions to integrate with data visualization tools like Tableau', 'Experience using SQL queries in a business environment with large-scale, complex datasets']",2020-09-24 13:39:05
Software Engineer - Data & Analytics,John Deere,4 out of 5,"Moline, IL 61265","['Collaborate with other software engineers and analysts to drive design, and development within Data & Analytics (D&A) Suites of Apps', 'Contribute to technical analysis and design of solutions to improve quality, and performance', 'Lead root cause analysis and resolution of production support issues', 'Mentor junior developers and performing code pairing with other members of the team, as well as proper code reviews with team members', 'Lead and participate in efforts to modernize the products technology stack', 'Provide technical guidance on DevOps-related tasks, activities, and initiatives', '7 or more years in the design, development, testing, and integration of high complex software solutions in (Data & Analytics) Java web development with Spring and Restful APIs', '4 or more years of experience in an applications development environment, and varied database experience (e.g. HANA, DB2, Mongo, Oracle, MySQL), data management and infrastructure capabilities and constraints', '2 or more years of experience in an Agile/Scrum team environment', '2 or more years of experience leveraging DevSecOps and lean development principles', '1 or more years of experience working with full-stack design patterns, and designing loosely coupled architectures', '2 or more years of experience working with Test Driven Development, and Unit Test Frameworks', '5 or more years of experience with software development full stack', 'Strong interpersonal communications, negotiation, and conflict resolution skills', 'Willingness to initially work remote and travel up to 25% when the environment allows', 'Functional knowledge in one or more SAP modules and/or products (MM, PP, SD, QM)', 'Experience with AWS economies of scale, while designing cloud hosted Big Data applications Exposure to system execution/quality monitoring tools, like AppDynamics, Focus Run or Grafana', 'Experience working in a fast-paced, team environment while managing competing priorities', ""Bachelor's degree in IT, Computer Science, Computer Engineering or equivalent experience in a related career field""]",2020-09-24 13:39:05
Staff Data Engineer,Fanatics Inc.,3.7 out of 5,"Tampa, FL","['Establish partnerships with stakeholders to develop an understanding of their needs and long-term vision', 'Provide solution oversight for engineers, analysts and administrators including architecture, design collaboration, code reviews and prioritization of work', 'Develop analytical tools (dashboards, reports, etc.) to help users monitor core KPIs, provide proactive alerts/notifications, and facilitate exploratory analysis when needed', 'Promote ongoing adoption of business intelligence content through an emphasis on user experience, iterative design refinement and regular training', 'Empower customers to develop information driven insights through extensive self-service business intelligence training', 'Participate in architecting ingestion and modeling of new data sources, including creation of Source-to-Target specifications which serve to document data lineage and as a mapping to inform ETL/ELT construction', 'Architect frameworks for data pipeline orchestration (e.g. scheduling, configurations, dependency chaining, etc.) that facilitate error handling, notification, restartability and expedient data movement', 'Create, deploy and manage data models which fulfill requirements but also balance simplicity, performance, flexibility and scalability', 'Assist in ongoing administration and refinement of processes and environments, both data pipeline and analytics. To include performance tuning, maintenance, upgrades and release management.', '7+ years working on data solutions initiatives within a BI/analytics context', '5+ years working with best-of-breed BI tools (SAP BusinessObjects, MicroStrategy, IBM Cognos, etc.)', 'Experience designing and developing data models, integrating data from multiple sources, building ETL pipelines, and supporting all aspects of the development lifecycle', 'Experience with/understanding of Big Data technologies such as Hadoop, Amazon EMR, Pig, Hive, Spark, and Redshift a plus', 'Must have expert level SQL programming knowledge and experience', 'Comprehensive understanding of cloud-based infrastructures/approaches and the nuances involved in achieving the scalability cloud offers but in a secure fashion', 'Experience with data lakes, open source technologies', 'Thorough understanding of data warehouse methodologies and concepts', 'Exposure to Java or Scala a plus', 'Possess technical aptitude and a desire to learn new technologies', 'Capable of taking ownership of and accountability for deliverables', 'Able to work in a collaborative environment to support rapid development and delivery of results', 'Exhibit an understanding of business problems and translate those into creative, innovative and practical solutions that deliver high quality services to the business', 'Willing to wear may hats and be flexible with a varying nature of tasks and responsibilities']",2020-09-24 13:39:05
Sr. Data Engineer,S5 Stratos,N/A,"Dallas-Fort Worth, TX","['Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Develop and automate large scale, high-performance data processing systems (batch and/or streaming)', 'Translate business needs into data models: implement data strategies, build data flows and develop conceptual data models.', 'Implement deployment and infrastructure automation strategies.', 'Build data support for our experimentation efforts, solving problems from statistical test automation to building real-time M/L pipelines', 'Automate manual processes, optimize data delivery, and re-design infrastructure for greater scalability.', 'Promote data modeling standardization, define, and drive adoption of the standards.', 'Build analytics and reporting tools that utilize the data pipeline to provide results and business value to make data-driven decisions.', 'Maintain and improve upon our existing ETL pipeline', 'Perform routine maintenance tasks and upgrades of our server architecture', 'Work with stakeholders to assist with data-related technical issues and support data infrastructure needs.', 'Apply best practices for testing and deployment in an agile environment.', 'Contribute to shared Data Engineering tooling & standards to improve engineering productivity across the company', 'Expert-level understanding of relational databases (columnar and row-based)', 'Expertise in SQL is a must.', 'Proven hands-on experience building complex ETLs in a business environment with large-scale, complex datasets', 'Experience with processing data at scale streaming and batch', 'Scripting experience in python and bash shell required', 'Fully proficient in pipeline building and job automations', '2+ years experience building data solutions in the cloud (AWS, GCP)', 'Proficiency with Git', 'Experience building RESTful APIs', 'Experience with containerization tools (Docker/Kubernetes) - nice to have', 'Experience with error handling and data validation', 'Experience working in GCP, AWS or other cloud-based environments', 'Bachelors in Computer Science, Engineering or similar', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'SQL: 3 years (Required)', 'Dallas-Fort Worth, TX (Preferred)', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Team-oriented -- cooperative and collaborative', 'www.s5stratos.com']",2020-09-24 13:39:05
"Sr. Data Engineer (INFORMATICA, Teradata, Hadoop, cloudera Required)",CLS Bank International,2.8 out of 5,"McLean, VA","['Pay:', '$80.00 - $85.00 per hour', 'Benefits:', 'Health insurance', 'Health insurance', 'Monday to Friday', 'Likely', 'Fully Remote']",2020-09-24 13:39:05
"Data Engineer I, Mastercard Launch (2021)",MasterCard,4.1 out of 5,"Arlington, VA","['To be uploaded as one document:', 'To be uploaded as a separate document:', ""Designing processes to extract, transform, and load (ETL) terabytes of data into Mastercard's analytics platform"", ""Sourcing data from clients, government and other third party data sources, and Mastercard's transaction data warehouse"", 'Working across multiple teams, both internal and external, in order to determine the data requirements and business logic applicable to each data set', 'Tackling big data problems across various industries', 'Strategic problem solving with exceptional peers who are also passionate about data', 'Creative freedom to innovate with new technologies and to explore a variety of solutions', 'Staffing on external-facing consulting projects where you will have the opportunity to work directly with clients', 'Flexibility to work on many new and challenging projects across diverse industries', 'A dynamic environment where you will have an impact and make an immediate difference', 'An immediate opportunity for increased responsibility, leadership, and professional growth', 'Committed mentoring and training by an experienced and driven leadership team', 'Cross-functional collaboration with others throughout Mastercard', 'Desire to work with data and help businesses make better data-driven decisions', 'Excellent written and verbal communication skills', 'Strong troubleshooting and problem solving capabilities', 'Demonstrated analytical and quantitative skills', ""Bachelor's/Master's degree with an established history of academic success"", 'Understanding of relational databases, SQL, and ETL Processes', 'Hands-on experience with the ETL process, SQL, and SSIS']",2020-09-24 13:39:05
Cloud/Data Engineer,Nasdaq,3.8 out of 5,"New York, NY 10036","['$120,000.00 - $130,000.00 per year', 'Benefits:', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Tuition reimbursement', 'Vision insurance', 'Optimize data lake performance by identifying and resolving production and application development problems.', 'Act as Data Steward, ensuring Data Governance best practices with developers. Help investigate and resolve data anomalies including data quality issues and ambiguous data definitions. Recommend data integrity checks and controls to ensure data quality.', 'Define data/information architecture standards, structure, attributes and nomenclature of data elements, and applies accepted data content standards to technology projects.', 'Develop data retention practices and system lifecycle for Nasdaq’s index applications based on Nasdaq’s data retention policies.', 'Hands-on ability to set up reporting tools and build reports and ad hoc functionality, giving users’ access to their data.', 'Experience with master data management, data governance, data security, data quality and related tools desired.', 'Create and maintain optimal data pipeline architecture.', 'Assemble large, complex data sets that meet functional / non-functional business requirements', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.', 'Work with QA Test analyst to ensure test coverage (Including Integration & Regression testing)', 'Develop new program logic and/or assembles standard logic modules to create new applications', 'Good understanding of Big data technologies – Spark SQL', 'Programming SPARK in Scala & proficiency in SQL to write complex SQL queries', 'Strong data analysis and troubleshooting skills', 'Domain knowledge of Capital Market is plus', 'Knowledge of shell scripts and other languages including Python, R, Java is plus', 'At least 2 years of hands on experience on Big Data Engineering on AWS', 'Minimum 1 year experience with Spark, Scala', 'Experience with relational databases (Preferably Oracle)', 'Good knowledge of Linux OS and Shell scripting', 'Experience working on complex distributed information systems', 'Experience with version control systems, preferable SVN, git.', 'Strong work ethic in a mission-critical 24x7 diverse environment with multiple vendor/customer relationships.', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Tuition reimbursement', 'Vision insurance', 'Monday to Friday', 'SQL: 1 year (Required)', 'Big Data Engineering on AWS: 2 years (Required)', ""Bachelor's (Required)"", 'New York, NY 10036 (Required)', 'Temporarily due to COVID-19']",2020-09-24 13:39:05
BI Engineer,3I Associates,N/A,"Redmond, WA","['Pay:', '$38.00 - $76.00 per hour', 'Strong SQL Server Experience', 'Highly Proficient in Stored Procedures, ADF', 'Spark and Python is a must.', 'Experience in Databricks needed', '8 hour shift', 'Azure Data Bricks: 2 years (Required)']",2020-09-24 13:39:05
Sr. Data Engineer,Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['Bachelor’s degree in Computer Science, Engineering, Mathematics, or a related field', '5+ Years of Data Warehouse Experience with Oracle, Redshift, PostgreSQL, etc Demonstrated strength in SQL, data modeling, ETL development, and data warehousing', 'Extensive experience working with AWS with a strong understanding of Redshift, EMR, Athena, Aurora, DynamoDB, Kinesis, Lambda, S3, EC2, etc.', 'Experience in maintaining data warehouse systems and working on large scale data transformation using EMR, Hadoop, Hive, or other Big Data technologies', 'Experience mentoring other Data Engineers', 'Experience with hardware provisioning, forecasting hardware usage, and managing to a budget', 'Extensive Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)', 'Strong interpersonal skills and the ability to communicate complex technology solutions to senior leadership, gain alignment, and drive progress']",2020-09-24 13:39:05
ACE Engineer,Pharmavite LLC,3.4 out of 5,"San Fernando, CA 91340","['Comprehensive onboarding and training', 'Structured assignments including: Engineering, Team Lead, Quality, and/or Continuous Improvement as preparation for a Manufacturing Department Lead position', 'Coaching and work guidance from strong department leaders and managers', 'Mentoring and exposure with senior leaders - in Operations and across Pharmavite', 'Participation in Pharmavite events to gain knowledge of market, industry and our end-to-end business', 'Leadership and career development support', 'Effective communicator and positive influencer on others; leads by example', 'Demonstrated ability to partner and collaborate with others to get work done', 'Track record of coaching and leading others', 'Proven track record for solving problems from analyzing root causes to identifying solutions', 'Knowledge of core manufacturing processes and methodologies', 'Strong drive for results; is known for ""raising the bar"" with own performance The ideal candidate is recognized as a technical talent and a natural leader who is known for high performance, strong partnerships, and leading from any level. You have core knowledge about manufacturing and related methodologies, and are seeking hands-on experience to launch your career into manufacturing management. You enjoy building relationships and collaborating to achieve company objectives. You seek to be better every day and seek out coaching and mentoring to improve your performance and enhance your capabilities. The ideal candidate also has passion for the health and wellness industry.In order to take on these challenges, you\'ll need to have:', 'BS in Engineering, Operations & Supply Chain Management, Manufacturing Management or related technical degree (e.g. Sciences, Life Sciences)', 'At least 1 experience/project in a manufacturing/operations setting is preferred']",2020-09-24 13:39:05
Sr Data Engineer,Chewy,2.7 out of 5,"Fort Lauderdale, FL 33316","[""Lead the strategy, design, execution, system configuration and operations of the business's marketing databases, marketing automation solutions, and tracking performance in order to plan, report and conduct analyses"", 'Monitor data pipelines for accuracy, missing data, enhancements, changes, and billing volumes to ensure all data is captured and processed accurately and when needed', 'Work with cross-functional stakeholders in defining and documenting company-wide single sources of truth to ensure consistent and high-quality data', 'Reconcile data issues and alerts between various systems, finding opportunities to innovate and drive improvements', 'Own and document data pipelines and data lineage', '4-6 years of Data Engineering experience with 2+ years of experience in working with marketing data engineering.', '3+ years professional Python experience', 'Experience in SQL, data warehouse, performance tuning and ETL pipelines', 'Experience with ML practices and production systems', 'Understanding of link tracking, pixels/tags, Google Analytics, and marketing attribution', 'Heavy experience in cloud computing technology like AWS, Google Cloud, etc.', 'Experience in Tableau, Looker, or similar visualization / business intelligence platform', 'Position may require travel', ""PyTorch, JavaScript, D3.js & Restful API's"", 'Snowflake, Vertica, Postgres, etc.', 'Python library build and execution following OOP concepts', 'Exposure to Apache Airflow or other DAG frameworks', 'MarTech Knowledge', 'Media Mix Modelling and Marketing Attribution hands-on experience']",2020-09-24 13:39:05
ACE Engineer,Pharmavite LLC,3.4 out of 5,"San Fernando, CA 91340","['Comprehensive onboarding and training', 'Structured assignments including: Engineering, Team Lead, Quality, and/or Continuous Improvement as preparation for a Manufacturing Department Lead position', 'Coaching and work guidance from strong department leaders and managers', 'Mentoring and exposure with senior leaders - in Operations and across Pharmavite', 'Participation in Pharmavite events to gain knowledge of market, industry and our end-to-end business', 'Leadership and career development support', 'Effective communicator and positive influencer on others; leads by example', 'Demonstrated ability to partner and collaborate with others to get work done', 'Track record of coaching and leading others', 'Proven track record for solving problems from analyzing root causes to identifying solutions', 'Knowledge of core manufacturing processes and methodologies', 'Strong drive for results; is known for ""raising the bar"" with own performance The ideal candidate is recognized as a technical talent and a natural leader who is known for high performance, strong partnerships, and leading from any level. You have core knowledge about manufacturing and related methodologies, and are seeking hands-on experience to launch your career into manufacturing management. You enjoy building relationships and collaborating to achieve company objectives. You seek to be better every day and seek out coaching and mentoring to improve your performance and enhance your capabilities. The ideal candidate also has passion for the health and wellness industry.In order to take on these challenges, you\'ll need to have:', 'BS in Engineering, Operations & Supply Chain Management, Manufacturing Management or related technical degree (e.g. Sciences, Life Sciences)', 'At least 1 experience/project in a manufacturing/operations setting is preferred']",2020-09-24 13:39:48
Sr Data Engineer,Chewy,2.7 out of 5,"Fort Lauderdale, FL 33316","['Job', 'Company', ""Lead the strategy, design, execution, system configuration and operations of the business's marketing databases, marketing automation solutions, and tracking performance in order to plan, report and conduct analyses"", 'Monitor data pipelines for accuracy, missing data, enhancements, changes, and billing volumes to ensure all data is captured and processed accurately and when needed', 'Work with cross-functional stakeholders in defining and documenting company-wide single sources of truth to ensure consistent and high-quality data', 'Reconcile data issues and alerts between various systems, finding opportunities to innovate and drive improvements', 'Own and document data pipelines and data lineage', '4-6 years of Data Engineering experience with 2+ years of experience in working with marketing data engineering.', '3+ years professional Python experience', 'Experience in SQL, data warehouse, performance tuning and ETL pipelines', 'Experience with ML practices and production systems', 'Understanding of link tracking, pixels/tags, Google Analytics, and marketing attribution', 'Heavy experience in cloud computing technology like AWS, Google Cloud, etc.', 'Experience in Tableau, Looker, or similar visualization / business intelligence platform', 'Position may require travel', ""PyTorch, JavaScript, D3.js & Restful API's"", 'Snowflake, Vertica, Postgres, etc.', 'Python library build and execution following OOP concepts', 'Exposure to Apache Airflow or other DAG frameworks', 'MarTech Knowledge', 'Media Mix Modelling and Marketing Attribution hands-on experience']",2020-09-24 13:39:48
Data Scientist / Engineer,AWM SMART SHELF,N/A,United States,"['Identifies business trends and problems through complex big data analysis.', 'Interprets results from our proprietary data capture engine using variety of techniques, ranging from simple data aggregation via statistical analysis to data-mining independently.', 'Designs and develops sophisticated charts and methods to visually demonstrate data results for AWM’s Sales Team and customers.', 'Designs, develops and implements the most valuable business solutions for the organization.', 'Prepares big data, implements data models and develops database solutions to support the business offerings.', 'Is experienced with, and knowledgeable in, industry-standard software and tools such as reporting services and business intelligence software.', ""Requires bachelor's degree in a related field. master's degree or higher (PhD) is preferred"", 'Requires 3-5+ years of related experience.', 'Computer science degree is strongly preferred, though experience and/or other degrees may be substituted - MOOCs will be evaluated on a case-by-case basis', 'Strong computer vision skills, including non-trivial on-the-job experience', 'Machine learning is a requirement', 'Experience with surveillance analytics is a plus', 'Hardware optimization is a plus', 'Camera knowledge is a plus', 'Video Analytics', 'Object and person recognition experience are requirements', 'Able to work well on a development team and produce good code according to company’s standards', 'Experience working with other developers using Git/GitHub or another relatively similar version control system', 'Works well in a fast-paced environment learning new things', 'Likes to be challenged on engaging work vs. zoning out and simply collecting a paycheck', 'Takes initiative', 'Responsible', 'Smart and quick learner', 'Good team player and willing to take direction from others', 'Willing and able to collaborate with other developers', 'Disciplined (the culture is fun but not a goof off mentality as there is important work to get done)', 'Employee stock option plan participation', 'Paid vacation and sick time provided', 'Health benefits', 'Opportunity for growth']",2020-09-24 13:39:48
Data Engineer,Espire Services,N/A,"Arlington, VA","['Actively develop and maintain data pipelines and workflows that are the foundation of our polling and modeling: problem scoping, data cleaning, analysis, and testing', 'Work closely with partners to acquire, clean, and load new datasets', 'Collaborate with and support the work of the data scientists to produce deliverables', 'Develop data acquisition and management protocols', 'Implement quality assurance protocols', 'Develop workflows and automate processes using Python or other scripting languages', 'Create, maintain, and organize technical documentation for all data collection, cleaning, and analyses to inform both internal external users about data products and methodology', 'Oversee data linking process including standardization and documentation', 'Support the development of data governance processes and monitor compliance with governance policies and procedures', 'Take the lead role in data transfer operations', 'Work with agency partners to identify data fields that would be valuable for linking to databases and identify potential impediments to linkage and standardization of fields', 'Scripting and coding to automate and monitor data management processes', 'Assist with maintenance and development of internal Analytics data architecture', 'Exercise independent judgement and original thinking in support of data projects', 'Design, write, and disseminate innovative and visually appealing reports', 'Work with internal team members and external partners to support data collection and analysis and understand reporting needs', 'Manage technical consultant(s)', '2 years of experience applying data and advanced analytics tools', '2 years using SQL professionally & proficiency with R or Python (or ability to learn)', 'Top Secret clearance.', 'Experience deploying or monitoring data pipelines in a cloud platform', 'Demonstrated high proficiency in statistical analysis software including utilizing Power BI, Alteryx, Python, or R. Solid technical skills across a wide variety of tools and data platforms.', 'Ability to connect APIs', 'Previous experience integrating data; familiarity with technical issues (e.g. cleaning, merging, standardizing, documenting, and securing)', 'Experience with applied data analysis', 'Experience working on applied data projects that involve working with diverse organizations to collect, analyze, and interpret data', 'Deep understanding of data quality issues with applied experience in addressing data issues for quality assurance', 'Ability to develop relationships with collaborators, program providers, funders, community partners and others', 'Excellent writing and presentation skills with a successful track record of communicating complex concepts to diverse audiences', 'Able to successfully prioritize and manage multiple critical projects simultaneously and complete them in a timely manner with extreme accuracy', 'A desire to thrive in a fast-paced work environment and implement creative solutions to unique problems and any such conduct is strictly prohibited.', 'Experience supporting MISO/IO missions', 'Familiarity with basic principles of research design', 'Experience using SQL to manipulate & analyze data stored in relational databases', 'Ability to develop comprehensive software applications.', 'Familiarity with data visualization including experience with common visualization software (e.g., R, Tableau, Power BI)', 'Possession of excellent oral and written communication skills', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'developing and using APIs : 2 years (Required)', 'SQL, Azure, S3,R, PowerBI, JSON format and Agile development: 2 years (Preferred)', 'Top Secret (Required)', 'Multiple locations', 'Fully Remote']",2020-09-24 13:39:48
Data Engineer,Micron,3.8 out of 5,"Boise, ID","['Build & maintain data/solution pipelines that feed machine learning models', 'Work in a technical team through development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.', 'Create custom software components and analytics applications', 'Create/Maintain CI/CD pipelines of machine leaning models', 'Participate in agile delivery team', 'Excellent SQL skills (Do you dream in SQL?)', '1-3+ years of experience data modeling', '1-3+ years using ETL tools (SSIS, NiFi, Matillion, Fivetran)', 'Excellent analytical thinking, interpersonal, oral and written communication skills', 'Proficiency in the MS office suite.', 'Ability to prioritize and manage work to critical project timelines in a fast-paced environment', 'Familiar with Test-Driven development and Continuous Integration.', 'Interest in learning data science topics including predictive modeling and machine learning', 'Experience developing in with AWS, AZURE, GCP, Snowflake', 'Strong scripting and programming skills in one of the following, Python, C#, R', 'Experience with CI/CD tools (Jenkins, Git, Docker, Kubernetes)', 'Bachelor’s Degree in Computer Science, Business Analytics, or related field']",2020-09-24 13:39:48
Widget Engineer (Entry Level),Sezzle,N/A,Minnesota,"['Maintaining and integrating our Widget on new merchant websites', 'Improving and optimizing the Widget products UI & backend server and data structure', 'Partner with the product team to scope out and build new features (such as banner ads, pop-ups)', 'Leading a team of developers who will own building out core features of the Widget', 'Cross-team collaboration with Marketing, Sales, Support and other departments to ensure alignment on project scope, product updates, and deployment timelines', 'Tackle ad hoc projects', '1-2yrs of experiencing building a web and/or mobile app, ideally in JavaScript', 'Experience using HTM and CSS', 'Experience managing remote projects / teams.', 'Experience with e-commerce platforms such as Shopify, WooCommerce, Magento', 'Experience with Golang / Go', 'A+ character. We are team-first here at Sezzle.', ""A hard-working mentality. It's early and there is still a lot to build."", 'An excellent communicator.', ""A fun attitude. Life's too short. We can have fun while we work hard on cool things."", 'Smarts. We need people that are smart enough to make decisions on their own and also smart enough to know when they need input from others.', 'Competitive salary and benefits', 'Generous stock options', 'Medical, dental and vision insurance', 'Life and long term disability insurance', 'Collaborative workspace', 'Commuter benefits, full-stocked kitchen, weekly lunches and much more!', 'Headquartered in the North Loop area of Minneapolis with easy access to public transportation and right on the MetroLine', ""The opportunity to join Minneapolis's fastest growing startup alongside a team of motivated and driven individuals""]",2020-09-24 13:39:48
Junior Data Engineer,NICE,N/A,"Austin, TX 78754","['Developing, testing, and deploying changes to our analysis apps', 'Enhancing and configuring our data pipelines', 'Troubleshooting issues that occur with existing deliverables', 'Maintaining existing or developing new reports that integrate into our service catalog', 'Ensuring support documentation and training materials remain up-to-date', 'Working in a scrum team to complete product features each sprint', 'MSSQL, T-SQL', 'Tableau, MicroStrategy', 'Hadoop, Spark, Airflow, Ansible', 'Python, C#, .NET Core', 'Docker, Kubernetes, Helm', 'Git, Bitbucket, Jenkins, Postman', 'AWS', 'Minimum 1-year experience as a BI reporting specialist, DBA, or data-centric software developer', 'Solid experience with RDBMS applications (SQL Server preferred) OR the Hadoop ecosystem', 'Good communication skills and experience working with cross-functional teams', 'Exposure to the concepts of data warehouse design', 'Exposure to ETL and data integration processes']",2020-09-24 13:39:48
Data Engineer,Elation Health,2 out of 5,"San Francisco, CA","['Collaborate with our Implementation, Onboarding, Engineering, and Operations teams to perform data imports that migrate large datasets of patient data into Elation', 'Arm yourself with an expert understanding of the current Elation ecosystem of tools and process so that you can develop, build, and utilize systems and tools of your own design to improve the experience of data import activities at Elation', 'Undertake technical troubleshooting of existing tools and process to successfully debug issues with data import activities', 'Collaborate with other engineering teams to build out pipelines for data imports (and more!)', ""Identify gaps in Elation's current data pipelines and develop strategies and tools that apply autonomy and speed to those workflows"", ""Work as a champion for data security and patient privacy by marrying Elation's security principles to the tools and process that you build"", 'Proven track record of solving data focused problems and building tools to enhance data workflows', 'Prior experience working with (& building) data transformation tool sets & generalist ETL', 'Proficient skill programming in Python', 'Passion for improvement and growth in all that you do', 'Strong analytical, troubleshooting, and communication skills', 'Prior experience creating advanced data pipelines', 'Prior experience working with Airflow', 'Prior experience working with Django', 'Prior experience working in a healthcare focused space', 'Prior experience working in Amazon Web Services']",2020-09-24 13:39:48
Data Operations Engineer (No C2C),Calypso Way,N/A,"Denver, CO","['Experience in setting up production Hadoop clusters with optimum configurations.', 'Drive automation of Hadoop deployments, cluster expansion and maintenance operations.', 'Manage Hadoop cluster, monitoring alerts and notification.', 'Job scheduling, monitoring, debugging and troubleshooting.', 'Monitoring and management of the cluster in all respects, notably availability, performance and security.', 'Data transfer between Hadoop and other data stores (incl. relational database).', 'Set up a High Availability/Disaster Recovery environment.', 'Debug/Troubleshoot environment failures/downtime.', 'Performance tuning of YARN, Hadoop clusters and Hadoop Map Reduce routines.', 'Experience with Kafka, SPARK etc.', 'Experience working with AWS big data technologies (EMR, Redshift, S3, Glue, Kinesis, Dynamodb, and Lambda)', 'Good knowledge on creation of Volumes, Security group rules, Key pairs, Floating IPs, Images and Snapshots and Deploying Instances on AWS.', 'Experience configuring and/or integrating with monitoring and logging solutions such as syslog, ELK (Elastic, Logstash, and Kibana).', 'Strong UNIX/Linux systems administration skills, including configuration, troubleshooting and automation', 'Knowledge of Airflow, NiFi, Streamsets, etc.', 'Knowledge of container virtualization', 'Monday to Friday', 'Data engineering: 5 years (Preferred)', 'Multiple locations']",2020-09-24 13:39:48
Data Reporting Engineer,Pricesenz,N/A,"Irving, TX","['Experience in Data analytics Experience with Big Data technologies Experience in Python and R programming language·', 'Experience in building dashboards real-time and batch Experience with Distributed Data platforms (HDFS, Elasticsearch, Splunk, Casandra)', 'Experience in working with NoSql and in-memory databases ·', 'Experience of Kafka and experience with cross DC replication Experience with Docker and Kubernetes·', 'Experience with in-memory caches like Redis / Akka Distributed data Experience with CI/CD process - GIT (Bitbucket), Jenkins, Jira, Confluence Google drive suite services (Google Docs, Google Sheets, etc.)', 'Monday to Friday', 'Elasticsearch: 3 years (Required)', 'Big Data: 3 years (Required)', 'Python : 3 years (Required)', 'R programming: 3 years (Required)']",2020-09-24 13:39:48
Data Engineer (remote),Thrivent,3.9 out of 5,"Dallas, TX","['Job', 'Company', 'Oversee and direct efforts to identify information and technology solutions that enable business needs and strategies.', 'Own and define DevOps pipelines and release management for data engineering', 'Apply business knowledge and experience to effectively advise others on technology as an enabler.', 'Lead efforts to analyze IT industry and market trends and determine potential impacts.', 'Develop concepts and constructs necessary to create technology-enabled business systems.', 'Influence technology direction and provide thought leadership and execution to large complex efforts.', 'Utilize breadth of technical understanding and dive deep when necessary.', 'Consult on and manage initiatives to ensure alignment across multiple business and IT areas.', 'Proactively mitigate risks across multiple assets, information domains, technologies and platforms.', 'Provide leadership, mentoring and technical guidance to others to drive initiatives.', 'Facilitate communications that involve obtaining cooperation and agreement on issues that may be complex or controversial.', 'Utilize negotiation and persuasion to come to agreement and to effectively form partnerships.', 'Act as a change agent to continuously improve and move the organization forward.', 'Accountable to successfully deliver the right results on initiatives in a timely and effective manner.', 'Direct the work of others to lead initiatives that cross multiple assets, technologies, platforms, departments and vendors.', 'Ability to work within a diverse team of skillsets and experience levels to deliver results.', 'Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business, or related field.', '10+ years of experience in Technology related field including 3+ years prior lead experience.', 'Expert knowledge of predictive analytics, statistical modeling, advanced mathematics, data integration concepts, business intelligence and data warehousing and implementing large systems', 'Implement and configure data platforms including but not limited to Hadoop, Spark, Kafka and batch integration is preferred.', 'Working Experience developing data processes with Java, Python, R or other scripting languages preferred.']",2020-09-24 13:39:48
Data Engineer,"Herman Miller, Inc.",4 out of 5,United States,"['Assist end users in reporting and analysis tools.', 'Collaborate with Analytics and Business Teams to improve data models that feed business intelligence tools, increase data accessibility, and foster data-driven decision making across the organization.', 'Define company data assets (data models).', 'Design data integrations and data quality framework.', 'Develop and maintain scalable data pipelines and build out new API integrations to support continuing increases in data volume and complexity.', 'Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for the key stakeholders and business processes that depend on it.', 'Perform data analysis to troubleshoot data-related issues and assist in the resolution of data issues.', 'Work closely with a team of Application Developers, Architects, and Analysts.', 'Work closely with all Business Units and Software teams to develop strategy for long-term data platform architecture.', 'Write unit/integration tests and document work.', 'Perform additional responsibilities as requested to achieve business objectives.', ""A Bachelor's degree in Computer Science or a related technical field."", 'Fully proficient retail and online retail data engineering abilities, typically gained through five years of working with Python/Java, SQL, working schema design, and dimensional data modeling.', 'At least five years of experience, or and equivalent combination of education and experience.', 'Experience designing, building, and maintaining data processing systems.', 'Experience working with cloud services and cloud data warehouses.', 'Experience with Snowflake, Matillion, Tableau, Business Objectives, and Net Suite (desirable).', 'The ability to manage and communicate data warehouse plans to internal clients.', 'Expert knowledge of best practices and IT operations in an always-up, always-available service.', 'Experience with or knowledge of Agile Software Development methodologies.', 'Advanced problem-solving and troubleshooting skills with the ability to identify and solve complex business needs.', 'The ability to be process-oriented with great documentation skills.', 'Excellent oral and written communication skills with a keen sense of customer service.', 'The ability to perform all essential job functions of the position with or without accommodations.']",2020-09-24 13:39:48
Data Engineer,DraftKings,4.2 out of 5,"Boston, MA 02116","['Design processes that support data transformation and structures, metadata, dependency and workload management', 'Work with product owners and tech leads to implement high quality, production-grade data pipelines and ETL processes', 'Partner with our Audit Regulatory team to help build tools to provide actionable insights into key business metrics', 'Leverage your strong communication skills and experience working with global teams to be an evangelist for data engineering across the organization', 'Be flexible and able to rapidly adapt. We roll out products very quickly and priority management is key', 'Be key to driving a focus on performance analysis, optimization, and tuning', '2 - 4 years of hands-on experience in aspects of business intelligence and data engineering, including data warehousing, delivery, and operations', 'The ability to test, build and optimize data pipelines, transformations, architectures, and data sets leveraging new technologies', 'Strong knowledge in a variety of data engines (for example, SQL Server, MySQL, Amazon Aurora, Redshift) is required. Snowflake experience is a big plus', 'A solid understanding of dimensional modeling is required', 'Excellent communications skills (verbal and written) and interpersonal skills to effectively communicate with both business and technical teams', 'Experience with data reporting tools (e.g., Tableau), data cataloging tools (e.g., Alation) and data logging/monitoring tools (e.g., Datadog) is preferred', 'Experience working in AWS, Terraform, Python, and with database replication tools/services (e.g., DMS, Attunity) is preferred', 'Experience in the Regulatory, Financial or i-Gaming industry is desirable']",2020-09-24 13:39:48
"IT062034 - Engineer, Data",Invitation Homes,3.2 out of 5,"Dallas, TX 75201","['must be an expert in SQL development, database design, data flow and analysis activities', 'using SSIS, defines and builds data pipelines that will enable faster, better, data-informed decision-making within the business', 'creates Business Intelligence solutions using Microsoft SQL Server BI Stack', 'must have a delivery first mentality and a firm grasp of Agile Development methodology', 'must demonstrate the ability to work as a team member', ""Manages his position by maintaining databases optimized for performance, implementing schema changes, and maintaining data architecture standards across all of the business's databases."", 'Tasked with designing and developing scalable ETL packages from the business source systems and the development of ETL routines in order to populate databases from sources and also to create aggregates.', 'Leads innovation through exploration, benchmarking, making recommendations, and implementing data technologies.', 'Responsible for performing thorough testing and validation in order to support the accuracy of data transformations and data verification. The Data Engineer strives to ensure proper data governance and quality across the Data and Analytics organization and the business as a whole.', 'Support analytics where he/she performs ad-hoc analyses of data stored in source and Data Warehouse databases. Further, he/she writes SQL scripts, stored procedures, functions, and views.', 'Will troubleshoot data issues and present solutions to these issues. He/she proactively analyzes and evaluates the databases in order to identify and recommend improvements and optimization.', 'Will analyze complex data elements and systems, data flow, dependencies, and relationships in order to contribute to conceptual physical and logical data models.', 'Perform other duties as assigned', ""Required to have a bachelor's degree in Computer Science, Applied Mathematics, Engineering, or any other technology related field. An equivalent of the same in working experience is also accepted for the position."", 'A candidate for the position will have as at least 5 years of working experience as a database engineering support personnel or a database engineering administrator within a fast-paced a complex business setting.', 'The candidate must demonstrate experience working with large and complex data sets', ""A suitable candidate will also have had experience in the creation and debugging of database applications critical to the business's mission."", 'The candidate will have strong working and conceptual knowledge of building and maintaining physical and logical data models and experience with business intelligence tools.', 'Experienced in design, implementation and maintenance of SQL Server databases', 'Experienced in design, deployment and maintenance of complex ETL processes using SSIS', 'Adept at providing ongoing maintenance support through SQL query tuning and optimization', 'Ability to maintain and enhance OLAP cube artifacts using SSAS', 'Experienced in design and deployment of complex reports using SSRS', 'Well versed in working in a Visual Studio in source-controlled development environment', 'Excellent customer service and interpersonal skills; ability to relate to and get along with others', 'Professional verbal and written communication skills', 'Strong organizational and time-management skills', 'Ability to multi-task and maintain flexibility and creativity in a variety of situations', 'Ability to analyze and resolve problems', 'Ability to set and meet goals and consistently meet deadlines', 'Ability to maintain confidentiality', 'Must maintain professional appearance.', 'Ability to be at work on a regular and consistent basis; Overtime may be required for this position.', 'This position will spend long hours sitting and using office equipment and computers.', 'The position may also entail light lifting of supplies and materials occasionally, up to and including 20 pounds in addition to reaching, stooping, standing, and walking.', 'This position requires the ability to talk, hear, compare, compute, compile, copy, analyze, coordinate, synthesize, negotiate and communicate.', 'Reasonable accommodations may be made to enable individuals with disabilities to perform the essential job functions.', ""Required to have a bachelor's degree in Computer Science, Applied Mathematics, Engineering, or any other technology related field. An equivalent of the same in working experience is also accepted for the position."", 'A candidate for the position will have as at least 5 years of working experience as a database engineering support personnel or a database engineering administrator within a fast-paced a complex business setting.', 'The candidate must demonstrate experience working with large and complex data sets', ""A suitable candidate will also have had experience in the creation and debugging of database applications critical to the business's mission."", 'The candidate will have strong working and conceptual knowledge of building and maintaining physical and logical data models and experience with business intelligence tools.', 'Experienced in design, implementation and maintenance of SQL Server databases', 'Experienced in design, deployment and maintenance of complex ETL processes using SSIS', 'Adept at providing ongoing maintenance support through SQL query tuning and optimization', 'Ability to maintain and enhance OLAP cube artifacts using SSAS', 'Experienced in design and deployment of complex reports using SSRS', 'Well versed in working in a Visual Studio in source-controlled development environment', 'Excellent customer service and interpersonal skills; ability to relate to and get along with others', 'Professional verbal and written communication skills', 'Strong organizational and time-management skills', 'Ability to multi-task and maintain flexibility and creativity in a variety of situations', 'Ability to analyze and resolve problems', 'Ability to set and meet goals and consistently meet deadlines', 'Ability to maintain confidentiality', 'Must maintain professional appearance.', 'Ability to be at work on a regular and consistent basis; Overtime may be required for this position.', 'This position will spend long hours sitting and using office equipment and computers.', 'The position may also entail light lifting of supplies and materials occasionally, up to and including 20 pounds in addition to reaching, stooping, standing, and walking.', 'This position requires the ability to talk, hear, compare, compute, compile, copy, analyze, coordinate, synthesize, negotiate and communicate.', 'Reasonable accommodations may be made to enable individuals with disabilities to perform the essential job functions.']",2020-09-24 13:39:48
GRADUATE ENGINEER/DWO,"City of Houston, TX",3.8 out of 5,"Houston, TX","['Subject to change', 'Solid oral and written communication skills', 'Experience with process engineering for drinking water treatment', 'Able to handle multiple, competing, and changing priorities', 'Proficiency with Microsoft Office 365, including:Excel, Word, Outlook, Visio, Teams, SharePoint', 'Experience with Business Intelligence (BI) software and Management Systems including:MS Power BI, MS Project, Infor, LIMS, GIMS, WIMS', 'Experience with CAD and ArcGIS mapping software', 'Experience with computer scripting and querying Languages, including:Python, R, SQL, Power Query', 'Strong interpersonal skills, team player attitude, and the ability to establish excellent working relationships at diverse levels.']",2020-09-24 13:39:48
Data Engineer (Boston/Remote),Reify Health,N/A,Remote,"['Support the development and international expansion of our next-generation, privacy-aware, Kappa-style data architecture using Kafka, PostgreSQL, AWS, and Confluent Platform.', 'Prototype new algorithms or intelligence modules to support forthcoming data products.', 'Support our analytics team by building, scaling, and integrating data ingestion and ETL processes.', 'Frequently communicate your efforts to Head of Data and other technical/non-technical stakeholders in clear written, verbal, or presentation form.', 'Become intimately familiar with HIPAA, GDPR, and other applicable regulatory frameworks and how they influence our architecture and development decisions.', 'Live our data philosophy, which focuses on ethical decision making, being aware of how biased data (and assumptions) can affect results (and people), and being laser-focused on business needs.', 'At least 4 years of professional work experience in a role at a startup company dealing with regulated data (such as healthcare).', 'Deep practical experience with AWS (Redshift, S3, MSK, etc.), Kafka, and distributed systems.', 'Expertise in Clojure or Python in the context of data applications.', 'Demonstrated ability to rapidly develop and/or convert data science projects into modules that can be readily integrated into an existing product.', 'Experience with systems engineering, orchestration (e.g. Terraform), and awareness of the nuances of testing and deploying distributed data architecture at scale (particularly with probabilistic output).', 'Notable open-source contributions to software used by the data engineering or data science communities.', 'Advanced degree in a related field.', 'Competitive Salary and Stock Options: Salary and stock options commensurate to your experience and expertise.', 'Comprehensive Health and Wellness Coverage: 100% premium coverage for you (and >50% for your dependents) for: a top-tier health plan covering you in all 50 states (with option of HSA) dental, vision, disability (short-term and long-term), and basic term life insurance (for your entire tenure at Reify). We enable 24/7 access to doctor by phone or online via telemedicine coverage.', 'Retirement Plan: 401(k) plan with employer matching program.', 'Company-provided Workstation: You will receive a brand new MacBook Pro laptop to use for work.', 'Location Flexibility: You can work from anywhere in the U.S. compatible with an EST work schedule. Additionally, we fly remoters in for company summits and team events, filled with fun activities, good food, and many opportunities to get to know your colleagues better.', 'Vacation and Holiday Flexibility: Generous paid-time-off policy that accrues with your tenure at Reify which includes holiday flexibility and parental leave.']",2020-09-24 13:40:33
"Clinical Data Engineer - Enterprise Data & Analytics, Full-time days",Flagler Hospital,3.6 out of 5,"Saint Augustine, FL 32086",[],2020-09-24 13:40:33
Data Lake Engineer (remote),Thrivent,3.9 out of 5,United States,"['Job', 'Company', 'Oversee and direct efforts to identify information and technology solutions that enable business needs and strategies.', 'Own and define DevOps pipelines and release management for data engineering', 'Apply business knowledge and experience to effectively advise others on technology as an enabler.', 'Lead efforts to analyze IT industry and market trends and determine potential impacts.', 'Develop concepts and constructs necessary to create technology-enabled business systems.', 'Influence technology direction and provide thought leadership and execution to large complex efforts.', 'Utilize breadth of technical understanding and dive deep when necessary.', 'Consult on and manage initiatives to ensure alignment across multiple business and IT areas.', 'Proactively mitigate risks across multiple assets, information domains, technologies and platforms.', 'Provide leadership, mentoring and technical guidance to others to drive initiatives.', 'Facilitate communications that involve obtaining cooperation and agreement on issues that may be complex or controversial.', 'Utilize negotiation and persuasion to come to agreement and to effectively form partnerships.', 'Act as a change agent to continuously improve and move the organization forward.', 'Accountable to successfully deliver the right results on initiatives in a timely and effective manner.', 'Direct the work of others to lead initiatives that cross multiple assets, technologies, platforms, departments and vendors.', 'Ability to work within a diverse team of skillsets and experience levels to deliver results.', 'Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business, or related field.', '3+ years of experience in Technology related field including prior lead experience.', 'Expert knowledge of predictive analytics, statistical modeling, advanced mathematics, data integration concepts, business intelligence and data warehousing and implementing large systems.', 'Implement and configure data platforms including but not limited to Hadoop, Spark, Kafka and batch integration is preferred.', 'Working Experience developing data processes with Java, Python, R or other scripting languages preferred.']",2020-09-24 13:40:33
Data Engineer,Overhaul,4 out of 5,"Austin, TX","['Create, test and maintain optimal data pipeline architectures', 'Identify and develop data set processes for data modelling, minding and production', 'Build the infrastructure required for optimal extraction, transformation and loading of large data sets', 'Spark fresh ideas that are infused in our culture and our products', 'Relevant B.S. degree (Engineering, Science, Computer Systems Engineering, Software Engineering, Business Information Systems, Information Technology, Data Analytics)', '3+ years in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets', 'You have an innovative mindset and hands-on experience with AWS and Snowflake', 'Experience using Looker', 'Proven work experience as a Data Engineer or similar role', 'Collaborative, communicative, and consultative work style', 'Detail-oriented with the ability to effectively manage multiple competing priorities', 'Ability to succeed in a fast-paced, innovative, and rapidly evolving industry and business organization', 'Excellent time-management skills', 'Competitive starting base salary with performance-based increases', 'Progressive advancement opportunity and career mobility', 'Employee Stock Options Program', 'Casual dress']",2020-09-24 13:40:33
Big Data & Informatica Engineer,CLS Bank International,2.8 out of 5,"Reston, VA","['Experience in the Financial, and information management needs are a plus', 'Experience in Financial Services industry is a plus', 'Demonstrated flexibility and adaptability to changes – Agile methodology experience with Jira', 'Demonstrated ability to manage multiple priorities and deadlines', 'Ability to work independently or as part of a team', 'Experience with Attunity CDC and Kafka', 'Health insurance', 'Monday to Friday', 'More than 1 year', 'Likely', 'No: Not providing sponsorship for this job']",2020-09-24 13:40:33
Quality Engineer,Topre America Corporation,N/A,"Cullman, AL 35057","['Communicate Internally and with Customers on Quality Issues', 'Protect line from non-conforming product', 'PPAP of New Product or Design changes', 'Continual Improvement of internal parts', 'Track Cost of Quality', 'Generate and Track Quality Alerts', 'Ensure a safe work place for TAC employees and Customers inside facility', ""Responsible for making regular visits to customer's facilities."", 'Develops a thorough understanding of customers QA system, organization chart, procedures, and line processes. Develops plans, following and prepares for customers PPAP requirements.', 'Calculates and evaluates Cp and Cpk values.', 'Analyzes plant and customers problems. Develops countermeasure for same. Gives feedback to suppliers on quality problems.', 'Develops and initiates standards and methods for inspection, testing, and evaluation. Develops inspection standard, check sheets and process control standards.', 'Gives detailed line audits on critical lines.', 'Develops any receiving / inspection plans for purchased parts.', 'Sets up R&R studies for any new gauges if required.', 'Devises sampling procedures and designs and develops form and instructions for recording, evaluating, and reporting quality and reliability data.', 'Review blueprint drawing and / or read standards to determine part disposition.', 'Knows critical points for each part, based on part function; distribute information to others.', 'Establishes programs to evaluate precisions and accuracy of production equipment and testing, measurement, and analytical equipment and facilities.', 'Develops and implements methods and procedures for disposition of discrepant material and devises methods to assess cost and responsibility.', 'Performs supplier audits.', 'Directs workers engaged in measuring and testing product and tabulating data concerning materials, product, or process quality reliability.', 'Assists other TAC departments (MFG, ENG, etc.) in determining part disposition, root causes of problem, or appropriate countermeasure.', 'Determines responsibility and disposition of materials written up on Quality Alert and assures prompt return.', 'Follows up on Quality Alerts to ensure good countermeasure.', 'Complies and writes training material and conducts training session on quality control activities.', 'Support departmental A3 goals.', 'Analytical - Synthesizes complex or diverse information; Collects and researches data; Uses intuition and experience to complement data.', 'Design - Generates creative solutions; Translates concepts and information into images; Uses feedback to modify designs; Applies design principles; Demonstrates attention to detail.', 'Problem Solving - Identifies and resolves problems in a timely manner; Gathers and analyzes information skillfully; Develops alternative solutions; Works well in-group problem solving situations; Uses reason even when dealing with emotional topics.', 'Project Management - Coordinates projects; Communicates changes and progress; Completes projects on time and budget.', 'Technical Skills - Strives to continuously build knowledge and skills; Shares expertise with others.', 'Customer Service - Manages difficult or emotional customer situations; Responds promptly to customer needs; Solicits customer feedback to improve service; Responds to requests for service and assistance; Meets commitments.', ""Interpersonal Skills - Focuses on solving conflict, not blaming; Maintains confidentiality; Listens to others without interrupting; Keeps emotions under control; Remains open to others' ideas and tries new things."", 'Oral Communication - Speaks clearly and persuasively in positive or negative situations; Listens and gets clarification; Responds well to questions; Demonstrates group presentation skills; Participates in meetings.', 'Written Communication - Writes clearly and informatively; Edits work for spelling and grammar; Varies writing style to meet needs; Presents numerical data effectively; Able to read and interpret written information.', ""Teamwork - Balances team and individual responsibilities; Exhibits objectivity and openness to others' views; Gives and welcomes feedback; Contributes to building a positive team spirit; Puts success of team above own interests; Supports everyone's efforts to succeed."", 'Visionary Leadership - Displays passion and optimism; Inspires respect and trust.', 'Change Management - Develops workable implementation plans; Communicates changes effectively; Builds commitment and overcomes resistance; Prepares and supports those affected by change; Monitors transition and evaluates results.', 'Leadership - Exhibits confidence in self and others; Accepts feedback from others.', 'Quality Management - Looks for ways to improve and promote quality; Demonstrates accuracy and thoroughness.', 'Cost Consciousness - Works within approved budget; Develops and implements cost saving measures; Contributes to profits and revenue; Conserves organizational resources.', 'Ethics - Treats people with respect; Keeps commitments; Inspires the trust of others; Works with integrity and ethically; Upholds organizational values.', ""Organizational Support - Follows policies and procedures; Completes administrative tasks correctly and on time; Supports organization's goals and values."", 'Judgement - Displays willingness to make decisions; Exhibits sound and accurate judgment; Supports and explains reasoning for decisions; Includes appropriate people in decision-making process; Makes timely decisions.', 'Motivation - Demonstrates persistence and overcomes obstacles.', 'Planning/Organizing - Prioritizes and plans work activities; Uses time efficiently; Plans for additional resources; Sets goals and objectives; Organizes or schedules other people and their tasks; Develops realistic action plans.', 'Professionalism - Approaches others in a tactful manner; Reacts well under pressure; Treats others with respect and consideration regardless of their status or position; Accepts responsibility for own actions; Follows through on commitments.', 'Quality - Demonstrates accuracy and thoroughness; Looks for ways to improve and promote quality; Applies feedback to improve performance; Monitors own work to ensure quality.', 'Quantity - Completes work in timely manner; Works quickly.', 'Safety and Security - Observes safety and security procedures; Determines appropriate action beyond guidelines; Reports potentially unsafe conditions; Uses equipment and materials properly.', 'Adaptability - Adapts to changes in the work environment; Manages competing demands; Changes approach or method to best fit the situation; Able to deal with frequent change, delays, or unexpected events.', 'Attendance/Punctuality - Is consistently at work and on time; Ensures work responsibilities are covered when absent; Arrives at meetings and appointments on time.', 'Dependability - Follows instructions, responds to management direction; Takes responsibility for own actions; Keeps commitments; Commits to long hours of work when necessary to reach goals. Completes tasks on time or notifies appropriate person with an alternate plan.', 'Initiative - Seeks increased responsibilities; Takes independent actions and calculated risks; Looks for and takes advantage of opportunities; Asks for and offers help when needed.', ""Innovation - Displays original thinking and creativity; Meets challenges with resourcefulness; Generates suggestions for improving work; Develops innovative approaches and ideas; Presents ideas and information in a manner that gets others' attention."", '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Retirement plan', 'Vision insurance', 'Day shift', 'Monday to Friday', 'On call', 'Overtime', 'Weekends', 'Bonus pay', 'Microsoft Office: 3 years (Preferred)', 'Customer Service: 3 years (Preferred)', 'Microsoft Word: 3 years (Preferred)', 'Communication Skills: 3 years (Preferred)', 'Data Collection: 3 years (Preferred)', 'One location', 'Only full-time employees eligible', 'No']",2020-09-24 13:40:33
DATA ENGINEER,Bangura Solutions,N/A,Remote,"['Develop a Data Migration Strategy and document, which covers business/data quality requirements, sources of data from the legacy systems.', 'Manage the data cleansing and migration work-stream.', 'Oversee the implementation of interfaces.', 'Lead the data work-stream in developing various mappings and process flows using SQL and other business intelligence tools to migrate data from the Legacy systems.', 'Develop Test plans, scripts an execution test cases for Systems End to End testing and UAT.', 'Housing', 'Data Cleansing', 'Data Migration', 'Interfaces', 'Full data lifecycle of project.', 'Excel for data cleansing and migration', 'Experience of data migration from Northgate OHMS', 'Experience of Housing, Local Council, Repairs, Asset Management interfaces', 'Experience of Oracle and SQL Server', 'Experience of managing Junior Staff', 'Full understanding of data protection practice and GDPR', 'Database administration experience and understanding of data management']",2020-09-24 13:40:33
Data Engineer,Autodesk,4.1 out of 5,"San Francisco, CA","['Maintain/ develop a scalable database/ data warehouse through connecting disparate data tables housed across numerous organizational systems and different business lines', 'Maintain/ develop the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies', 'Optimize and maintain scripts on present data warehouses and present ETL', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader', 'Create and update financial models for decision support of new revenue-generating programs and initiatives', ""Bachelor's degree computer science, information systems, applied mathematics or a related discipline"", '5+ years of experience', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Experience with transforming, developing data structures, metadata, dependency and data workflows to support an Analytics function', 'Experience with salesforce administration', 'Experience with object-oriented/object function scripting languages: Python, Java, C++ etc.', 'Expertise in gathering data through multiple sources through API calls and scripting languages', 'Preference given to those with financial modeling experience']",2020-09-24 13:40:33
Lead or Sr. Data Engineer,Lenora Systems Inc,N/A,"St. Louis, MO","['6-8 yrs. experienced Sr. Data Engineer with AWS, Informatica Power Center, Teradata and Unix skills', '8 Years of experience in Informatica Development and database (Min 4 years of experience in Teradata).', 'Good Knowledge on DWH concepts Ability to gather requirements and convert business requirements to technical requirements.', 'Prepare technical specifications documents.', 'Experience of developing ETL application using Informatica PowerCenter (development experience, not just support experience).', 'Involved in creating the mappings in order to extract the data from source to target using Informatica designer.', 'Evaluate all functional requirements and map documents and perform troubleshoot on all development processes', 'Documents all technical specifications and associate project deliverables.', 'Design all test cases to provide support to all systems and perform unit tests.', 'Should analysis the data and develop understand the ETL specifications.', 'Develop mappings if required Develop Informatica 9x & 10x mapping, session and workflow.', 'Involved in creating the sessions, command tasks, workflows using the workflow designer.', 'Good at working with transformations including complex transformations Involved in building AutoSys to schedule the ETL Workflows.', 'Familiar with Stored Procedures and implementing them in the ETL jobs of Informatica. Worked on the HLD and LLD document.', 'Very good at UNIX and LINUX shell scripting Strong Database Experience with strong knowledge of writing complex SQL scripts as well as SQL tuning.', 'Extensively worked with Informatica performance tuning involving source level, target level and map level bottlenecks.', 'Ability to meet deadlines and handle multiple tasks, decisive with strong leadership qualities, flexible in work schedules and possess good communication skills.', 'Team player, Motivated, able to grasp things quickly with analytical and problem solving skills.', 'Comprehensive technical, oral, written and communicational skills', 'Should have Strong Analytical and interpersonal skills with good written and verbal communication.']",2020-09-24 13:40:33
Data Scientist,"Ames IT and Numeric Solutions, LLC",N/A,"El Monte, CA 91731","['Formulates and leads guided, multifaceted analytic studies against large volumes of data.', 'Interprets and analyzes data using exploratory mathematic and statistical techniques based on the scientific method.', 'Coordinates research and analytic activities utilizing various data points (unstructured and structured) and employ programming to clean, massage, and organize the data.', 'Experiments against data points, provide information based on experiment results and provide previously undiscovered solutions to command data challenges.', 'Leads all data experiments tasked by the Data Science Team.', 'Coordinates with Data Engineers to build data environments providing data identified by Data Analysts, Data Integrators, Knowledge Managers, and Intel Analysts.', 'Develops methodology and processes for prioritization and scheduling of projects.', 'Analyzes problems and determines root causes.', 'Defines company data assets (data models), spark, sparkSQL, and hiveSQL jobs to populate data models.', 'Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.', 'Advanced analytical knowledge of data', 'Conducting big data analysis', 'Data conditioning', 'Programming advanced computing', 'Developing algorithms', 'Developing software and data models', 'Executing predictive analytics', 'Master’s degree in Operations Research, Industrial Engineering, Applied Mathematics, Statistics, Physics, Computer Science, or related fields', '2-3 years of professional experience', 'Proficient with one or more programming languages (Java, C++, Python, R, etc.)', 'Demonstrated experience applying data science methods to real-world data problems', 'Experience utilizing visualization tools to take advantage of the growing volume of available information', '401(k)', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Professional development assistance', 'Monday to Friday', 'R: 2 years (Preferred)', 'sql: 3 years (Preferred)', 'Python: 3 years (Preferred)', 'data visualization : 3 years (Preferred)', 'Big Data: 1 year (Preferred)', 'Yes', 'www.ames-it-solutions.com', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-09-24 13:40:33
Data Engineer,Cisco Systems,4.1 out of 5,"San Jose, CA",[],2020-09-24 13:40:33
Petroleum Engineer,US Department of the Interior,4.2 out of 5,"Anchorage, AK","['Job family (Series)0881 Petroleum EngineeringSimilar jobsEngineers, PetroleumPetroleum Engineers', 'Engineers, Petroleum', 'Petroleum Engineers', ""RequirementsRequirementsConditions of EmploymentYou must be a U.S. Citizen.You will be subject to a background/suitability investigation/determinationYou will be required to have federal payments made by Direct Deposit.You must submit ALL required documents and a completed questionnaire.Selective Service: If you are a male applicant born after December 31, 1959, you must certify that you have registered with the Selective Service system, or are exempt from having to do so under the Selective Service Law. See http://www.sss.gov/.You will be required to complete a Financial Disclosure.QualificationsTo qualify for this position you must meet the (1) Basic Educational Requirements AND (2) Specialized Experience for the grade to which you are applying.Petroleum Engineer, 0881A. Degree: Professional Engineering. To be acceptable, the curriculum must: (1) be in a school of engineering with at least one curriculum accredited by the Accreditation Board for Engineering and Technology (ABET) as a professional engineering curriculum; or (2) include differential and integral calculus and courses (more advanced than first-year physics and chemistry) in five of the following seven areas of engineering science or physics: (a) statics, dynamics; (b) strength of materials (stress-strain relationships); (c) fluid mechanics, hydraulics; (d) thermodynamics; (e) electrical fields and circuits; (f) nature and properties of materials (relating particle and aggregate structure to properties); and (g) any other comparable area of fundamental engineering science or physics, such as optics, heat transfer, soil mechanics, or electronics.-OR-B. Combination of education and experience: College-level education, training, and/or technical experience that furnished (1) a thorough knowledge of the physical and mathematical sciences underlying professional engineering, and (2) a good understanding, both theoretical and practical, of the engineering sciences and techniques and their applications to one of the branches of engineering. The adequacy of such background must be demonstrated by one of the following listed in the link below: https://www.opm.gov/policy-data-oversight/classification-qualifications/general-schedule-qualification-standards/0800/files/all-professional-engineering-positions-0800.pdf(2) Specialized Experience:GS-13To qualify for the GS-13, you must possess at least one full year of specialized experience equivalent to at least the GS-12 grade level in the Federal service, or comparable experience not gained through Federal service. Specialized experience is experience that equipped the applicant with the particular knowledge, skills, and abilities to perform successfully the duties of the position, and that is typically in or related to the work of the position to be filled. Specialized experience is defined as demonstrated experience: 1) identifying process safety risks and gaps in integrity management; 2) discussing process safety concepts and how they apply to different systems; 3) assisting in developing or evaluating new safety technology to assess the overall risk of utilization; and 4) applying barrier management principles. Must meet all.GS-14To qualify for the GS-14, you must possess at least one full year of specialized experience equivalent to at least the GS-13 grade level in the Federal service, or comparable experience not gained through Federal service. Specialized experience is experience that equipped the applicant with the particular knowledge, skills, and abilities to perform successfully the duties of the position, and that is typically in or related to the work of the position to be filled. Specialized experience is defined as demonstrated experience: 1) identifying process safety risks and gaps in integrity management; 2) communicating or presenting process safety concepts and how they apply to different systems utilized on the Outer Continental Shelf (OCS); 3) developing or evaluating new safety technology to assess the overall risk of utilization; and 4) applying barrier management principles to integrity management through the system's life cycle. Must meet all.Additional information on the qualification requirements is outlined in the OPM Qualification Standards Handbook of General Schedule Positions and is available at OPM's website: https://www.opm.gov/qualifications/standards/indexes/num-ndx.aspAll qualification requirements must be met by the closing date of this announcement.Merit Promotion candidates must also meet Time-in-Grade requirements by the closing date of the announcement.EducationEducation: If this position requires specific educational course work to qualify, or you are qualifying based in whole or part on education, you are required to provide transcripts as proof of meeting the requirements.Foreign Education: Education completed in colleges or universities outside the United States may be used to meet the specific educational requirements as stated above. You must provide acceptable documentation that the foreign education is comparable to that received in an accredited educational institution in the United States. For more information on how foreign education is evaluated, visit: http://www.opm.gov/policy-data-oversight/classification-qualifications/general-schedule-qualification-policies/#url=e4Additional informationApplicants who include vulgar, offensive, or inappropriate language or information in their application package will be ineligible for further consideration for this position.Identification of promotion potential in this announcement does not constitute a commitment or an obligation on the part of management to promote the employee selected at some future date. Promotion will depend upon administrative approval and the continuing need for and performance of higher-level duties.The application contains information subject to the Privacy Act (P.L. 93-579, 5 USC 552a). The information is used to determine qualifications for employment, and is authorized under Title 5, USC, Section 3302 and 3361.Important Note: All Department of the Interior (DOI) employees are subject to the conflict of interest restrictions imposed upon all employees of the Executive Branch of the Federal Government and may be required to file a Financial Disclosure Report. In addition, DOI employees, GS-15 and above, who work in the Office of the Secretary; along with the Bureau of Ocean Energy Management (BOEM) and the Bureau of Safety and Environmental Enforcement (BSEE) employees (at ALL grade levels), are further restricted concerning their interests in Federal lands and resources administered or controlled by the Department of the Interior. This includes holding stock in energy corporations which lease Federal lands (e.g.: oil, gas, coal, alternative energy resources, etc.). If you have any such investments you should contact the DOI, BOEM or BSEE Ethics Office before accepting employment. DOI employees are held to the highest level of integrity. Employees must be objective and impartial in the performance of their work. All potential issues (e.g.: work-related interactions with friends, family members, or previous employers) must be disclosed at the time of application or during the interview process.NOTICE: This employer participates in E-Verify and will utilize your Form I-9 information to confirm you are authorized to work in the U.S.A preliminary background check must be completed before a new employee can begin work with the U.S. Department of the Interior. The preliminary background check consists of a search of Office of Personnel Management and Department of Defense background investigation files and an FBI National Criminal History Fingerprint Check; it may take up to 3 weeks to complete. If selected for this position, you will be extended a tentative offer of employment pending a satisfactory background check. Current Federal employees or individuals with an existing completed background investigation may not be required to undergo another background check; these will be handled on a case-by-case basis in coordination with the Bureau security office.How You Will Be EvaluatedYou will be evaluated for this job based on how well you meet the qualifications above.Once the application process is complete, we will review your application to ensure you meet the job requirements. To determine if you are qualified for this job, a review of your resume, supporting documentation and responses to the online questionnaire will be made. Your responses to the online assessment will be used to measure the degree to which your background matches the requirements for this position. However, your resume must support your responses to the scored occupational questionnaire, or your score may be lowered. The best qualified candidates will be identified for referral to the hiring manager and may be invited for an interview.Your answers to the on-line assessment will be used to evaluate your competencies in the following areas:Problem Solving- Identifies and analyzes problems; uses sound engineering principles and reasoning to derive conclusions; finds alternative, executable solutions to complex problems; distinguishes between relevant and irrelevant information to make logical judgements. Identifies process safety risks and gaps in integrity management. Understands how to utilizes industry recognized standards when required and during technology assessments.Petroleum Engineer- Knowledge of, and skill in applying, expertise in advanced engineering theories, principles, concepts, standards, and methods sufficient to provide expert advice to senior colleagues and/or agency officials responsible for broad program operations and provide significant and innovative recommendations for advancing programs and or methods.Teamwork- Skill in coordinating teams to review, analyze, and contribute to high-level technical and operational assessments.Interpersonal Skills- Ability to communicate effectively and professionally, both orally and in writing, and work cooperatively with other OCS stakeholders and industry representatives.DUE WEIGHTPlease submit 1) a copy of your most recent performance appraisal/evaluation and 2) a list of any awards (e.g. superior performance awards, special act or achievement awards, quality step increase, etc.) you received in the last 5 years. Any performance appraisal/evaluation and award documentation you provide will be forwarded to the selecting official. The selecting official will review this documentation and give it due weight consideration during the overall selection process.If you do not have your most recent performance appraisal/evaluation, please submit a statement as to why it is not available. Please indicate if any prior performance appraisals/evaluations were at an acceptable level.To preview the assessment questionnaire click: https://apply.usastaffing.gov/ViewQuestionnaire/10919959Background checks and security clearanceSecurity clearanceOtherDrug test requiredNoPosition sensitivity and riskModerate Risk (MR)Trust determination processSuitability/Fitness"", 'You must be a U.S. Citizen.', 'You will be subject to a background/suitability investigation/determination', 'You will be required to have federal payments made by Direct Deposit.', 'You must submit ALL required documents and a completed questionnaire.', 'Selective Service: If you are a male applicant born after December 31, 1959, you must certify that you have registered with the Selective Service system, or are exempt from having to do so under the Selective Service Law. See http://www.sss.gov/.', 'You will be required to complete a Financial Disclosure.', 'Required DocumentsRequired DocumentsYour resume must contain information sufficient to make a valid determination that you fully meet the specialized experience requirements as stated in this vacancy announcement and OPM qualification standards for each grade level(s) for which you are applying. It is strongly recommended that you use the USAJobs Resume Builder as it was designed to ensure that your resume includes the standard information needed. The Resume Builder is available at https://help.usajobs.gov/index.php/How_to_create_your_resumeYour application package must include: (1) Resume showing relevant experience as written in your own words; (2) Completed online Assessment Questionnaire; (3) SF-50\'s showing (1) your highest FPL, and (2) most current SF-50 noting position, grade level, tenure, and duty station. Please note that all SF-50\'s submitted must show that you are a status candidate or eligible under this announcement. Please refer to the eligibility in the online questionnaire for more information; (3) College transcript (if applicable) for verification of qualifying education. Unofficial transcripts are acceptable; (4) Certificates, license, etc. (if applicable); (5) Form DD-214 OR VA letter and Standard Form 15, if eligible under VEOA or VRA; (6) Proof of eligibility if applying under a special appointing authority; (7) Current or former Government employees are strongly encouraged to submit a recent performance appraisal.NOTE: Applicants claiming eligibility under VEOA or VRA, must submit a copy of your DD-214, ""Certificate of Release or Discharge from Active Duty,"" (Member 4 copy is preferred), showing the dates of active duty, type of discharge, and character of service (must be honorable); OR acceptable proof of verification of your preference (i.e., official document, dated 1991 or later, from the Department of Veterans Affairs, or from a branch of the Armed Forces, certifying that the veterans total combined serviced-connected disability rating is 10% or more).NOTE: Applicants claiming eligibility based on 30% or more service connected disability, you are required to submit documentation that is indicated on the SF-15 as acceptable proof of verification of your preference (i.e., official document, dated 1991 or later, from the Department of Veterans Affairs, or from a branch of the Armed Forces, certifying that the veterans total combined serviced-connected disability rating is 30% or more.You will find additional information on the following topics: (1) e-Verify; (2) Selective Service; (3) CTAP/ICTAP; (4) Education - accreditation; (5) Foreign education; (6) Veterans preference; (7) Special appointing authority documentation; and more can be found on our web site: https://www.bsee.gov/careers/usajobs-assistance.If you are claiming CTAP/ICTAP eligibility, you must submit proof by the closing date of the announcement that you meet the requirements of 5 CFR 330.605(a) for CTAP and 5 CFR 330.704 for ICTAP or you will not receive priority consideration. The proof includes a copy of the agency notice, your most recent Performance Rating, and your most recent SF-50 noting current position, grade level, and duty station. To be considered well-qualified and exercise selection priority for this vacancy, you must earn a minimum score of 85 or above (prior to the assignment of veteran\'s preference) on the rating criteria for this position.If you are relying on your education to meet qualification requirements:Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education.Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.', 'BenefitsBenefitsA career with the U.S. Government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Learn more about federal benefits.Review our benefitsEligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time, or intermittent. Contact the hiring agency for more information on the specific benefits offered.', 'Career transition (CTAP, ICTAP, RPL)Federal employees who meet the definition of a ""surplus"" or ""displaced"" employee.', 'Family of overseas employeesFamily members of a federal employee or uniformed service member who is, or was, working overseas.', 'Federal employees - Competitive serviceCurrent or former competitive service federal employees.', 'Federal employees - Excepted serviceCurrent excepted service federal employees.', 'Individuals with disabilities', 'Land & base managementCertain current or former term or temporary federal employees of a land or base management agency.', 'Military spouses', 'Peace Corps & AmeriCorps Vista', 'Special authoritiesIndividuals eligible under a special authority not listed above, but defined in the federal hiring regulations.', 'Veterans']",2020-09-24 13:40:33
Sr. Data Engineer,Slack,3.9 out of 5,California,"['Design, implement and build pipelines that deliver data with measurable quality under the SLA', 'Partner with Data Engineers, Data architects, domain specialists, data analysts and other teams to build foundational data sets that are trusted, well understood, aligned with business strategy and enable self-service', 'Be a champion of the overall strategy for data governance, security, privacy, quality and retention that will satisfy business policies and requirements', 'Own and document data pipelines and data lineage', 'Identify, document and promote best practices', 'Support and Maintain analytics tech ecosystem (data warehouse, ETL and BI tools)', 'BS or MS degree in Computer Science or Engineering field.', 'At least 8 years or more of work experience in data management disciplines including data integration, modeling, optimization and data quality, and/or other areas directly relevant to data engineering responsibilities and tasks.', 'At least 4 years of experience working in multi-functional teams and collaborating with business partners in Sales or Marketing in support of a departmental and/or multi-departmental data management and analytics initiative that involve working with data generated by product and business systems.', 'Very strong experience in working with product usage data.', 'Solid experience in dimensional modeling, supporting data warehouse, scaling and optimizing, performance tuning and ETL pipelines', 'Deep understanding of relational as well as big data setup', 'Problem solver with good interpersonal skills with ability to make sound sophisticated decisions in a fast-paced, technical environment.', 'Ability to work on multiple areas like Data pipeline ETL, Data modeling & design, writing complex SQL queries etc. . Preferred: Prior experience with ETL tools (eg Informatica, Matillion, Snaplogic), Hive, Presto, Dimensional Modeling.', 'Hands-on experience with Data Warehouse technologies (Snowflake, Redshift) and Big Data technologies (e.g Hadoop, Hive, Spark)', 'Proficiency with programming languages is a big plus (e.g. Python)', 'Capable of planning and executing on both short-term and long-term goals individually and with the team.', 'Passionate about various data technologies including but not limited to SQL/No SQL/MPP databases etc.', 'Excellent written and verbal communication and interpersonal skills, able to effectively collaborate with technical and business partners', 'Excellent understanding of trade-offs', 'Demonstrated ability to navigate between big-picture and implementation details']",2020-09-24 13:40:33
"Data Engineer, Analytics, Intern",Facebook,4.2 out of 5,"Menlo Park, CA","['Architect, implement and deploy new data models and data processes in production', 'Perform data analysis to generate business insights', 'Interface with Engineers, Product Managers and Product Analysts to understand product goals and data needs', 'Build data expertise and own data quality for allocated areas of ownership', 'Manage data warehouse plans for a product or a group of products', 'Support critical data processes running in production', 'Currently has, or is in the process of obtaining, a Bachelors or Masters degree in Computer Science, Mathematics, or related technical field', 'Programming knowledge in Python or Java', 'Knowledge of SQL', 'Knowledge of database systems', 'Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment']",2020-09-24 13:40:33
"Data Engineer, Datasets Team",EARNEST RESEARCH,N/A,"New York, NY 10010","['Creative problem solving', 'A high level of enthusiasm and proactivity', 'Attention to detail', 'The ability to succinctly communicate ideas', 'The ability to produce high-quality work under tight timelines', 'A willingness to take ownership of work', 'The ability to work as part of a team and effectively with others', 'Extract and process raw data at scale (including writing scripts, calling APIs, writing SQL/Spark, etc.)', 'Process unstructured data into a form suitable for analysis', 'Work closely with product owners and data analysts to gather and understand requirements', 'Interface with Data Platform engineers and give valuable feedback that guides tooling', 'Participate in code reviews and design discussions, give and receive constructive feedback', 'Create, extend and own data pipelines that power the company’s products', 'Ensure high Data Quality and pipeline stability', 'Experience processing large amounts of structured and semi-structured data', 'Programming experience in Python, SQL and Bash', '2+ years writing and maintaining ETL at a terabyte level scale', '1+ years experience working with Hadoop applications (Spark)', 'Experience with version control systems (Git)', 'Code-based data orchestrator such as Apache Airflow, Dagster, Luigi', 'Knowledge of aws, emr, redshift/snowflake', 'Spark-Scala / PySpark Experience', 'Experience with Docker containerization', 'Strong knowledge of and experience with statistics', 'Enthusiasm for Open Source', 'Data Warehouse modeling experience', 'Experience with or willingness to learn functional programming (Haskell)', 'Experience using Data Build Tool (DBT)', 'Experience automating Data Quality checks either through DBT, Great Expectations or company tooling', '100% company paid medical plan options (additional medical, dental and vision plans available too!)', '401K retirement plans', 'Flexible and generous time off', 'Generous Parental Leave Policies', 'Pre-tax savings plans for public transportation and parking expenses', 'Regular company happy hours, lunches & events']",2020-09-24 13:40:33
Data Engineer,Cisco Systems,4.1 out of 5,"San Jose, CA",[],2020-09-24 13:41:15
Petroleum Engineer,US Department of the Interior,4.2 out of 5,"Anchorage, AK","['Job family (Series)0881 Petroleum EngineeringSimilar jobsEngineers, PetroleumPetroleum Engineers', 'Engineers, Petroleum', 'Petroleum Engineers', ""RequirementsRequirementsConditions of EmploymentYou must be a U.S. Citizen.You will be subject to a background/suitability investigation/determinationYou will be required to have federal payments made by Direct Deposit.You must submit ALL required documents and a completed questionnaire.Selective Service: If you are a male applicant born after December 31, 1959, you must certify that you have registered with the Selective Service system, or are exempt from having to do so under the Selective Service Law. See http://www.sss.gov/.You will be required to complete a Financial Disclosure.QualificationsTo qualify for this position you must meet the (1) Basic Educational Requirements AND (2) Specialized Experience for the grade to which you are applying.Petroleum Engineer, 0881A. Degree: Professional Engineering. To be acceptable, the curriculum must: (1) be in a school of engineering with at least one curriculum accredited by the Accreditation Board for Engineering and Technology (ABET) as a professional engineering curriculum; or (2) include differential and integral calculus and courses (more advanced than first-year physics and chemistry) in five of the following seven areas of engineering science or physics: (a) statics, dynamics; (b) strength of materials (stress-strain relationships); (c) fluid mechanics, hydraulics; (d) thermodynamics; (e) electrical fields and circuits; (f) nature and properties of materials (relating particle and aggregate structure to properties); and (g) any other comparable area of fundamental engineering science or physics, such as optics, heat transfer, soil mechanics, or electronics.-OR-B. Combination of education and experience: College-level education, training, and/or technical experience that furnished (1) a thorough knowledge of the physical and mathematical sciences underlying professional engineering, and (2) a good understanding, both theoretical and practical, of the engineering sciences and techniques and their applications to one of the branches of engineering. The adequacy of such background must be demonstrated by one of the following listed in the link below: https://www.opm.gov/policy-data-oversight/classification-qualifications/general-schedule-qualification-standards/0800/files/all-professional-engineering-positions-0800.pdf(2) Specialized Experience:GS-13To qualify for the GS-13, you must possess at least one full year of specialized experience equivalent to at least the GS-12 grade level in the Federal service, or comparable experience not gained through Federal service. Specialized experience is experience that equipped the applicant with the particular knowledge, skills, and abilities to perform successfully the duties of the position, and that is typically in or related to the work of the position to be filled. Specialized experience is defined as demonstrated experience: 1) identifying process safety risks and gaps in integrity management; 2) discussing process safety concepts and how they apply to different systems; 3) assisting in developing or evaluating new safety technology to assess the overall risk of utilization; and 4) applying barrier management principles. Must meet all.GS-14To qualify for the GS-14, you must possess at least one full year of specialized experience equivalent to at least the GS-13 grade level in the Federal service, or comparable experience not gained through Federal service. Specialized experience is experience that equipped the applicant with the particular knowledge, skills, and abilities to perform successfully the duties of the position, and that is typically in or related to the work of the position to be filled. Specialized experience is defined as demonstrated experience: 1) identifying process safety risks and gaps in integrity management; 2) communicating or presenting process safety concepts and how they apply to different systems utilized on the Outer Continental Shelf (OCS); 3) developing or evaluating new safety technology to assess the overall risk of utilization; and 4) applying barrier management principles to integrity management through the system's life cycle. Must meet all.Additional information on the qualification requirements is outlined in the OPM Qualification Standards Handbook of General Schedule Positions and is available at OPM's website: https://www.opm.gov/qualifications/standards/indexes/num-ndx.aspAll qualification requirements must be met by the closing date of this announcement.Merit Promotion candidates must also meet Time-in-Grade requirements by the closing date of the announcement.EducationEducation: If this position requires specific educational course work to qualify, or you are qualifying based in whole or part on education, you are required to provide transcripts as proof of meeting the requirements.Foreign Education: Education completed in colleges or universities outside the United States may be used to meet the specific educational requirements as stated above. You must provide acceptable documentation that the foreign education is comparable to that received in an accredited educational institution in the United States. For more information on how foreign education is evaluated, visit: http://www.opm.gov/policy-data-oversight/classification-qualifications/general-schedule-qualification-policies/#url=e4Additional informationApplicants who include vulgar, offensive, or inappropriate language or information in their application package will be ineligible for further consideration for this position.Identification of promotion potential in this announcement does not constitute a commitment or an obligation on the part of management to promote the employee selected at some future date. Promotion will depend upon administrative approval and the continuing need for and performance of higher-level duties.The application contains information subject to the Privacy Act (P.L. 93-579, 5 USC 552a). The information is used to determine qualifications for employment, and is authorized under Title 5, USC, Section 3302 and 3361.Important Note: All Department of the Interior (DOI) employees are subject to the conflict of interest restrictions imposed upon all employees of the Executive Branch of the Federal Government and may be required to file a Financial Disclosure Report. In addition, DOI employees, GS-15 and above, who work in the Office of the Secretary; along with the Bureau of Ocean Energy Management (BOEM) and the Bureau of Safety and Environmental Enforcement (BSEE) employees (at ALL grade levels), are further restricted concerning their interests in Federal lands and resources administered or controlled by the Department of the Interior. This includes holding stock in energy corporations which lease Federal lands (e.g.: oil, gas, coal, alternative energy resources, etc.). If you have any such investments you should contact the DOI, BOEM or BSEE Ethics Office before accepting employment. DOI employees are held to the highest level of integrity. Employees must be objective and impartial in the performance of their work. All potential issues (e.g.: work-related interactions with friends, family members, or previous employers) must be disclosed at the time of application or during the interview process.NOTICE: This employer participates in E-Verify and will utilize your Form I-9 information to confirm you are authorized to work in the U.S.A preliminary background check must be completed before a new employee can begin work with the U.S. Department of the Interior. The preliminary background check consists of a search of Office of Personnel Management and Department of Defense background investigation files and an FBI National Criminal History Fingerprint Check; it may take up to 3 weeks to complete. If selected for this position, you will be extended a tentative offer of employment pending a satisfactory background check. Current Federal employees or individuals with an existing completed background investigation may not be required to undergo another background check; these will be handled on a case-by-case basis in coordination with the Bureau security office.How You Will Be EvaluatedYou will be evaluated for this job based on how well you meet the qualifications above.Once the application process is complete, we will review your application to ensure you meet the job requirements. To determine if you are qualified for this job, a review of your resume, supporting documentation and responses to the online questionnaire will be made. Your responses to the online assessment will be used to measure the degree to which your background matches the requirements for this position. However, your resume must support your responses to the scored occupational questionnaire, or your score may be lowered. The best qualified candidates will be identified for referral to the hiring manager and may be invited for an interview.Your answers to the on-line assessment will be used to evaluate your competencies in the following areas:Problem Solving- Identifies and analyzes problems; uses sound engineering principles and reasoning to derive conclusions; finds alternative, executable solutions to complex problems; distinguishes between relevant and irrelevant information to make logical judgements. Identifies process safety risks and gaps in integrity management. Understands how to utilizes industry recognized standards when required and during technology assessments.Petroleum Engineer- Knowledge of, and skill in applying, expertise in advanced engineering theories, principles, concepts, standards, and methods sufficient to provide expert advice to senior colleagues and/or agency officials responsible for broad program operations and provide significant and innovative recommendations for advancing programs and or methods.Teamwork- Skill in coordinating teams to review, analyze, and contribute to high-level technical and operational assessments.Interpersonal Skills- Ability to communicate effectively and professionally, both orally and in writing, and work cooperatively with other OCS stakeholders and industry representatives.DUE WEIGHTPlease submit 1) a copy of your most recent performance appraisal/evaluation and 2) a list of any awards (e.g. superior performance awards, special act or achievement awards, quality step increase, etc.) you received in the last 5 years. Any performance appraisal/evaluation and award documentation you provide will be forwarded to the selecting official. The selecting official will review this documentation and give it due weight consideration during the overall selection process.If you do not have your most recent performance appraisal/evaluation, please submit a statement as to why it is not available. Please indicate if any prior performance appraisals/evaluations were at an acceptable level.To preview the assessment questionnaire click: https://apply.usastaffing.gov/ViewQuestionnaire/10919959Background checks and security clearanceSecurity clearanceOtherDrug test requiredNoPosition sensitivity and riskModerate Risk (MR)Trust determination processSuitability/Fitness"", 'You must be a U.S. Citizen.', 'You will be subject to a background/suitability investigation/determination', 'You will be required to have federal payments made by Direct Deposit.', 'You must submit ALL required documents and a completed questionnaire.', 'Selective Service: If you are a male applicant born after December 31, 1959, you must certify that you have registered with the Selective Service system, or are exempt from having to do so under the Selective Service Law. See http://www.sss.gov/.', 'You will be required to complete a Financial Disclosure.', 'Required DocumentsRequired DocumentsYour resume must contain information sufficient to make a valid determination that you fully meet the specialized experience requirements as stated in this vacancy announcement and OPM qualification standards for each grade level(s) for which you are applying. It is strongly recommended that you use the USAJobs Resume Builder as it was designed to ensure that your resume includes the standard information needed. The Resume Builder is available at https://help.usajobs.gov/index.php/How_to_create_your_resumeYour application package must include: (1) Resume showing relevant experience as written in your own words; (2) Completed online Assessment Questionnaire; (3) SF-50\'s showing (1) your highest FPL, and (2) most current SF-50 noting position, grade level, tenure, and duty station. Please note that all SF-50\'s submitted must show that you are a status candidate or eligible under this announcement. Please refer to the eligibility in the online questionnaire for more information; (3) College transcript (if applicable) for verification of qualifying education. Unofficial transcripts are acceptable; (4) Certificates, license, etc. (if applicable); (5) Form DD-214 OR VA letter and Standard Form 15, if eligible under VEOA or VRA; (6) Proof of eligibility if applying under a special appointing authority; (7) Current or former Government employees are strongly encouraged to submit a recent performance appraisal.NOTE: Applicants claiming eligibility under VEOA or VRA, must submit a copy of your DD-214, ""Certificate of Release or Discharge from Active Duty,"" (Member 4 copy is preferred), showing the dates of active duty, type of discharge, and character of service (must be honorable); OR acceptable proof of verification of your preference (i.e., official document, dated 1991 or later, from the Department of Veterans Affairs, or from a branch of the Armed Forces, certifying that the veterans total combined serviced-connected disability rating is 10% or more).NOTE: Applicants claiming eligibility based on 30% or more service connected disability, you are required to submit documentation that is indicated on the SF-15 as acceptable proof of verification of your preference (i.e., official document, dated 1991 or later, from the Department of Veterans Affairs, or from a branch of the Armed Forces, certifying that the veterans total combined serviced-connected disability rating is 30% or more.You will find additional information on the following topics: (1) e-Verify; (2) Selective Service; (3) CTAP/ICTAP; (4) Education - accreditation; (5) Foreign education; (6) Veterans preference; (7) Special appointing authority documentation; and more can be found on our web site: https://www.bsee.gov/careers/usajobs-assistance.If you are claiming CTAP/ICTAP eligibility, you must submit proof by the closing date of the announcement that you meet the requirements of 5 CFR 330.605(a) for CTAP and 5 CFR 330.704 for ICTAP or you will not receive priority consideration. The proof includes a copy of the agency notice, your most recent Performance Rating, and your most recent SF-50 noting current position, grade level, and duty station. To be considered well-qualified and exercise selection priority for this vacancy, you must earn a minimum score of 85 or above (prior to the assignment of veteran\'s preference) on the rating criteria for this position.If you are relying on your education to meet qualification requirements:Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education.Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.', 'BenefitsBenefitsA career with the U.S. Government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Learn more about federal benefits.Review our benefitsEligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time, or intermittent. Contact the hiring agency for more information on the specific benefits offered.', 'Career transition (CTAP, ICTAP, RPL)Federal employees who meet the definition of a ""surplus"" or ""displaced"" employee.', 'Family of overseas employeesFamily members of a federal employee or uniformed service member who is, or was, working overseas.', 'Federal employees - Competitive serviceCurrent or former competitive service federal employees.', 'Federal employees - Excepted serviceCurrent excepted service federal employees.', 'Individuals with disabilities', 'Land & base managementCertain current or former term or temporary federal employees of a land or base management agency.', 'Military spouses', 'Peace Corps & AmeriCorps Vista', 'Special authoritiesIndividuals eligible under a special authority not listed above, but defined in the federal hiring regulations.', 'Veterans']",2020-09-24 13:41:15
Sr. Data Engineer,Slack,3.9 out of 5,California,"['Design, implement and build pipelines that deliver data with measurable quality under the SLA', 'Partner with Data Engineers, Data architects, domain specialists, data analysts and other teams to build foundational data sets that are trusted, well understood, aligned with business strategy and enable self-service', 'Be a champion of the overall strategy for data governance, security, privacy, quality and retention that will satisfy business policies and requirements', 'Own and document data pipelines and data lineage', 'Identify, document and promote best practices', 'Support and Maintain analytics tech ecosystem (data warehouse, ETL and BI tools)', 'BS or MS degree in Computer Science or Engineering field.', 'At least 8 years or more of work experience in data management disciplines including data integration, modeling, optimization and data quality, and/or other areas directly relevant to data engineering responsibilities and tasks.', 'At least 4 years of experience working in multi-functional teams and collaborating with business partners in Sales or Marketing in support of a departmental and/or multi-departmental data management and analytics initiative that involve working with data generated by product and business systems.', 'Very strong experience in working with product usage data.', 'Solid experience in dimensional modeling, supporting data warehouse, scaling and optimizing, performance tuning and ETL pipelines', 'Deep understanding of relational as well as big data setup', 'Problem solver with good interpersonal skills with ability to make sound sophisticated decisions in a fast-paced, technical environment.', 'Ability to work on multiple areas like Data pipeline ETL, Data modeling & design, writing complex SQL queries etc. . Preferred: Prior experience with ETL tools (eg Informatica, Matillion, Snaplogic), Hive, Presto, Dimensional Modeling.', 'Hands-on experience with Data Warehouse technologies (Snowflake, Redshift) and Big Data technologies (e.g Hadoop, Hive, Spark)', 'Proficiency with programming languages is a big plus (e.g. Python)', 'Capable of planning and executing on both short-term and long-term goals individually and with the team.', 'Passionate about various data technologies including but not limited to SQL/No SQL/MPP databases etc.', 'Excellent written and verbal communication and interpersonal skills, able to effectively collaborate with technical and business partners', 'Excellent understanding of trade-offs', 'Demonstrated ability to navigate between big-picture and implementation details']",2020-09-24 13:41:15
"Data Engineer, Analytics, Intern",Facebook,4.2 out of 5,"Menlo Park, CA","['Architect, implement and deploy new data models and data processes in production', 'Perform data analysis to generate business insights', 'Interface with Engineers, Product Managers and Product Analysts to understand product goals and data needs', 'Build data expertise and own data quality for allocated areas of ownership', 'Manage data warehouse plans for a product or a group of products', 'Support critical data processes running in production', 'Currently has, or is in the process of obtaining, a Bachelors or Masters degree in Computer Science, Mathematics, or related technical field', 'Programming knowledge in Python or Java', 'Knowledge of SQL', 'Knowledge of database systems', 'Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment']",2020-09-24 13:41:15
"Data Engineer, Datasets Team",EARNEST RESEARCH,N/A,"New York, NY 10010","['100% company paid medical plan options (additional medical, dental and vision plans available too!)', '401K retirement plans', 'Flexible and generous time off', 'Generous Parental Leave Policies', 'Creative problem solving', 'A high level of enthusiasm and proactivity', 'Attention to detail', 'The ability to succinctly communicate ideas', 'The ability to produce high-quality work under tight timelines', 'A willingness to take ownership of work', 'The ability to work as part of a team and effectively with others', 'Extract and process raw data at scale (including writing scripts, calling APIs, writing SQL/Spark, etc.)', 'Process unstructured data into a form suitable for analysis', 'Work closely with product owners and data analysts to gather and understand requirements', 'Interface with Data Platform engineers and give valuable feedback that guides tooling', 'Participate in code reviews and design discussions, give and receive constructive feedback', 'Create, extend and own data pipelines that power the company’s products', 'Ensure high Data Quality and pipeline stability', 'Experience processing large amounts of structured and semi-structured data', 'Programming experience in Python, SQL and Bash', '2+ years writing and maintaining ETL at a terabyte level scale', '1+ years experience working with Hadoop applications (Spark)', 'Experience with version control systems (Git)', 'Code-based data orchestrator such as Apache Airflow, Dagster, Luigi', 'Knowledge of aws, emr, redshift/snowflake', 'Spark-Scala / PySpark Experience', 'Experience with Docker containerization', 'Strong knowledge of and experience with statistics', 'Enthusiasm for Open Source', 'Data Warehouse modeling experience', 'Experience with or willingness to learn functional programming (Haskell)', 'Experience using Data Build Tool (DBT)', 'Experience automating Data Quality checks either through DBT, Great Expectations or company tooling', '100% company paid medical plan options (additional medical, dental and vision plans available too!)', '401K retirement plans', 'Flexible and generous time off', 'Generous Parental Leave Policies', 'Pre-tax savings plans for public transportation and parking expenses', 'Regular company happy hours, lunches & events']",2020-09-24 13:41:15
Data Engineer,Strive Health,4.5 out of 5,"Denver, CO","['use cloud-native infrastructure and modern software development methodologies', 'share ideas freely to keep our software and processes accessible, scalable, and sustainable', 'iterate frequently on our software and our processes to enhance outcomes for ourselves and our users', 'experiment with emerging technologies to accommodate the expanding scope of this ambitious project', 'celebrate each other’s success', 'oversee bringing new source systems into the Strive’s Data Platform using various cutting-edge technologies', 'have ability to dig into the data and understand business logic within the source system data', 'build and perform data validation tests to ensure quality via data pipeline', 'balance tasks and priorities between multiple client projects and internal initiatives; ensure assigned tasks are executed efficiently and according to project requirements and timelines', 'are an expert in Structured Query Language (SQL)', 'have experience working with EMR\\EHR systems and an understanding of the healthcare clinical domain', 'have exposure to Extract, Transform and Load (ETL) concepts and processes', 'have a working knowledge of database principles, processes, technologies and tools', 'have a working knowledge with structured and unstructured data', 'have an experience with processing HL7 messages, CCD documents, and EDI X12 Claims files.', 'have a familiarity with development methodologies, including the AGILE development approaches', 'are able to code and comprehend code around technologies that deal with acquiring data', 'have an experience working with Hadoop and other Big Data Technologies', 'have exposure to programming languages such as Python, C#, or Java', 'have 5+ years’ experience in healthcare/technology related field']",2020-09-24 13:41:15
Data/Telecom Engineer 8 hrs Prob Information and Technology Dept.,Beaverton School District,4.2 out of 5,"Beaverton, OR 97003","['Hourly Salary Range:', '$37.87804 to $49.91569', '247 day – for candidates new to the District or current employees on a less than a current 260 day calendar, the first year of employment will be offered on a 248 day calendar, with winter break and spring break unpaid while earning vacation days.Every year thereafter effective July 1st, the 247 day would move to a 260 day calendar.', '260 day – for candidates currently on a 260 day calendar, this position would remain on a 260 day calendar']",2020-09-24 13:41:15
Data Engineer (remote),Thrivent Financial,3.9 out of 5,"Dallas, TX 75204","['Oversee and direct efforts to identify information and technology solutions that enable business needs and strategies.', 'Own and define DevOps pipelines and release management for data engineering', 'Apply business knowledge and experience to effectively advise others on technology as an enabler.', 'Lead efforts to analyze IT industry and market trends and determine potential impacts.', 'Develop concepts and constructs necessary to create technology-enabled business systems.', 'Influence technology direction and provide thought leadership and execution to large complex efforts.', 'Utilize breadth of technical understanding and dive deep when necessary.', 'Consult on and manage initiatives to ensure alignment across multiple business and IT areas.', 'Proactively mitigate risks across multiple assets, information domains, technologies and platforms.', 'Provide leadership, mentoring and technical guidance to others to drive initiatives.', 'Facilitate communications that involve obtaining cooperation and agreement on issues that may be complex or controversial.', 'Utilize negotiation and persuasion to come to agreement and to effectively form partnerships.', 'Act as a change agent to continuously improve and move the organization forward.', 'Accountable to successfully deliver the right results on initiatives in a timely and effective manner.', 'Direct the work of others to lead initiatives that cross multiple assets, technologies, platforms, departments and vendors.', 'Ability to work within a diverse team of skillsets and experience levels to deliver results.', 'Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business, or related field.', '10+ years of experience in Technology related field including 3+ years prior lead experience.', 'Expert knowledge of predictive analytics, statistical modeling, advanced mathematics, data integration concepts, business intelligence and data warehousing and implementing large systems', 'Implement and configure data platforms including but not limited to Hadoop, Spark, Kafka and batch integration is preferred.', 'Working Experience developing data processes with Java, Python, R or other scripting languages preferred.']",2020-09-24 13:41:15
Software Engineer (Fullstack),6 River Systems,N/A,"Waltham, MA","['Competitive compensation packages and Shopify RSUs', 'Company-paid health, dental, and vision coverage for all employees', 'Paid holidays, vacation/sick time, and parental leave', 'Annual 401k contribution from the company', '$85,000.00 - $105,000.00 per year', 'Benefits:', '401(k)', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Employee discount', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Parental leave', 'Professional development assistance', 'Referral program', 'Vision insurance', 'Develop new features across multiple domains (browser, cloud, and bots) as we build:', 'Performant, resilient, horizontally scalable back-end web servers', 'Real-time views of orders, inventory, and overall efficiency', 'Efficient workflows for collaborative robots driven by behavior trees', 'Create scripts and data migration plans to integrate with existing frameworks and databases', 'Work with a squad of 4-6 awesome Software Engineers, embedded QA, and a Product Manager to build end-to-end solutions', 'Scrappy, yet thoughtful approach to problem solving', 'Practical experience designing and developing scalable software', 'Interest in working with a variety of technologies, including:', 'TypeScript or JavaScript', 'NodeJS', 'PostgreSQL Databases', 'Object Oriented Programming (SOLID)', 'Knowledge of:', 'Relational databases and data modeling', 'Networking (HTTP)', 'Microservices Architecture', 'Docker, Kubernetes, GCloud', 'Interest in behavior trees and real-world applications for robots', 'Commitment to rigorous testing and validation (we write lots of unit tests)', 'Entrepreneurial spirit of a start-up combined with the stability of a global commerce company', 'Competitive compensation packages and Shopify RSUs', 'Company-paid health, dental, and vision coverage for all employees', 'Paid holidays, vacation/sick time, and parental leave', 'Annual 401k contribution from the company', 'Lifestyle spending account', '401(k)', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Employee discount', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Parental leave', 'Professional development assistance', 'Referral program', 'Vision insurance', 'Monday to Friday', 'Fully Remote', 'Dependable -- more reliable than spontaneous', 'People-oriented -- enjoys interacting with people and working on group projects', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Achievement-oriented -- enjoys taking on challenges, even if they might fail', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'A job for which military experienced candidates are encouraged to apply', 'A job for which all ages, including older job seekers, are encouraged to apply', 'Open to applicants who do not have a college diploma', 'https://6river.com', 'Only full-time employees eligible']",2020-09-24 13:41:15
Data Engineer,Caserta,N/A,United States,[],2020-09-24 13:41:15
Data Engineer Co-Op,Bayer,4.2 out of 5,"Chesterfield, MO","['Integrate, transform, validate and reconcile large amounts of data;', 'Assemble and evaluate data such that new insights, solutions and visualizations can be derived;', 'Support the exploratory data analysis, data cleaning and processing;', 'Perform data discoveries to understand data formats, source systems, file sizes and engage with business partners in this discovery process;', 'Identify trends, data quality issues, anomalies across large data sets, particularly in the area of machine data and other agronomic management practices;', 'Be accountable for and ensure solutions meet business requirements;', 'Write robust and well-documented research code;', 'Engage with diverse research groups to understand their models and products and develop solutions to meet their data needs.', 'Currently enrolled in a Bachelor’s degree with a focus in Math, Statistics, Information’s Systems Management, Computer Science or Geographic Information Systems(GIS);', 'Development experience with recent experience in Python, R and SQL;', 'Experience with working with geospatial datasets/GIS;', 'Experience working with cloud tools such as AWS and Domino data science platform;', 'Demonstrated experience with global multi-disciplinary teams and learning the science;', 'Creative, proactive, bold and out-of-box thinking.']",2020-09-24 13:41:15
Data Engineer,X-Mode Social,5 out of 5,Virginia,"['Medical, Dental and Vision', '15 Days of PTO (Paid Time Off)', 'Write Spark, Python/Scala, and SQL to perform ETL on billions of location records per day', 'Implement ETL pipelines in AWS (EMR/Glue) to support feature stores for analysis and machine learning use cases.', 'Write complex SQL, including geospatial, to fulfill customer requests for analysis', 'Build dashboards to surface data-driven insights', '3-5 years of data engineering or relevant industry experience', '1+ years experience and working proficiency with Spark', ""Bachelor's Degree in Computer Science or related technical areas like Math, Statistics, and/or other Engineering degrees"", 'Strong proficiency with Python', 'Advanced proficiency with SQL, comfortable with complex joins', 'Familiarity with Scala preferred', 'Knowledge of AWS data engineering products (S3, RDS, EMR, Glue, Athena...) is a plus', 'Experience with spatial data, joins and operations is a plus', 'Self-initiative and an entrepreneurial mindset', 'Strong communication skills', 'Passion for data', 'Cool people, solving cool problems.', 'Competitive Salary', 'Medical, Dental and Vision', '15 Days of PTO (Paid Time Off)', 'We value your input. This is a chance to get in on the ""ground floor"" of a growing company']",2020-09-24 13:41:15
Wind Engineer,Cermak Peterka Petersen (CPP),N/A,"Windsor, CO","['Assembles project information and initial project planning', 'Oversees and carries out daily duties of assigned project(s)', 'Coordinates with drafting/design group, model shop, and wind tunnel personnel to ensure accuracy of drawings, models, and data', 'Develops test plans, analyzes data, and prepares reports', 'Interacts with clients on a regular basis', 'Contributes to continual process development of systems and techniques', 'Masters or Ph.D. in Wind Engineering or related field', '1-3 years engineering experience in field of Wind Engineering or related field', 'Strong English-language communication and interpersonal skills', 'Experience in programming in a number of environments (e.g. Matlab, LabVIEW, Fortran, etc.)', 'Must be able to work both independently as well as part of a team']",2020-09-24 13:41:15
Data Engineer 1,Dexcom,3.3 out of 5,"San Diego, CA","['Hands-On development 75% of daily activities', 'Work with our Data Architect to build robust data pipelines for our Enterprise Environment via Java (Scala) in a virtualized environment', 'Execute on technical requirements and document new ones when needed', 'Monitor NoSQL performance and optimize table indexes to increase query performance', 'Participate in on-call rotation for data pipeline support in a GCP environment', 'Support QA: diagnosing and resolving bugs', 'Apply best practices for testing and deployment in an agile environment', 'Understanding the technical architecture of internally developed applications', 'Protect the confidentiality and security of client data', 'Understand business processes and requirements from the business', 'Review and develop dbs schema while ensuring database(s) performance is efficient and optimized', 'Work both independently and as part of a team', 'Manage code via Github/Bamboo and work tasks within JIRA', 'Hands-On development 75% of daily activities', 'Demonstrated experience and ability to develop in Java (Scala) – Primary role', 'Demonstrated experience as a DBA supporting a Production environment – Secondary role', 'Knowledge of traditional and modern data warehouse methodologies', 'Proven ability to learn new tools and technology', 'Expert level SQL with the ability to create and evaluate complex SQL statements, stored procedures, and index tables', 'Experience developing, deploying, and supporting ETL workflows', 'Demonstrated ability to work in a fast paced and changing environment with short deadlines, interruptions, and multiple tasks/projects occurring at once', ""Bachelor's degree in Computer Science, Information Systems, Mathematics or Engineering from an accredited academic university, or an equivalent combination of education and experience"", 'Experience with GCP infrastructure deployments – application resource management in GCP environment(s)', 'Experience developing and deploying libraries for database(s) interaction layer', 'Experience with PostgreSQL', 'Experience with GCP services (Dataflow/PubSub/Airflow/Spanner)', 'Prior medical device experience', 'Typically requires a Bachelor’s degree in a technical discipline, and a minimum of 0-2 years related experience.', 'Up to 25%', 'Applies basic technical understanding with the knowledge to develop process and design experiments. Possesses theoretical knowledge, but is learning the industry and requirements of applied science. Understands organizational and functional processes and policies.', 'Demonstrates potential for technical proficiency. Works on problems of basic scope in which analysis of situation or data requires a review of data factors. Exercises judgment within defined procedures and practices to determine appropriate action.', 'Follows standard practices and procedures in analyzing situations or data from which answers can be readily obtained.', 'Normally receives instructions on all work and work output it supervised.']",2020-09-24 13:41:15
Data Engineer,Claremont Mckenna College,4 out of 5,"Claremont, CA 91711","['Organize reliable and efficient operations of campus data integrations and tools used to implement the integrations', 'Lead configuration, management, and access control for SaaS deployments.', 'Conduct design architect reviews, gap analysis and assessment when required.', 'Develop Interfaces using middleware technologies.', 'Develop a comprehensive understanding of internal customer business needs, system functionality and business processes.', 'Plan, implement, and maintain tools for exchanging data and reporting.', 'Design configurations for management and access control for student data and other campus information systems.', 'Independently and proactively monitor critical services and take appropriate action to resolve issues.', 'Produce dashboards and reports that support operations across the College.', 'Create and maintain needed documentation.', 'Create and maintain optimal data pipeline architecture.', 'Assemble data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes and optimizing data delivery, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using query languages and cloud technologies.', 'Build analytics tools that utilize the data pipeline to provide actionable insights into the colleges operations.', 'Take and follow directions.', 'Work cooperatively with others.', 'Receive and respond appropriately to constructive criticism.', 'Display a positive attitude.', 'Balance multiple tasks and priorities.', 'Performs other essential duties and tasks specific to the position.', 'Experience working with relational databases, query authoring as well as working familiarity with a variety of databases.', 'Experience building and optimizing data pipelines, architectures and/or data sets.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Experience building processes supporting data transformation, data structures, and metadata.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Technical understanding and experience with single sign-on and multi-factor authentication.', 'Background knowledge of TCP/IP, DNS, HTTP, SQL, Active Directory, Linux, Bash.', 'Dell Boomi Developer or Administrator Certifications', 'Workday Developer or Report Writing Certifications', 'Advanced working knowledge of a query language (SQL).', 'Strong problem-solving and critical thinking skills to develop and test hypotheses.', 'Desire and willingness to keep up with constantly changing cloud offerings by reading widely, attending conferences and networking with other IT professionals.', 'Ability to communicate technical concepts in simple terms.', 'Demonstrate effective, accurate and clear communication with excellent/strong verbal, written, interpersonal, reading, phone, and customer service skills. Follow all written and verbal instructions, asking questions as needed for clarification of projects/tasks/duties/assignments.', 'Prioritize and perform multiple projects/tasks, meet deadlines/timelines, respond to others in a timely manner, and work both independently and as a collaborative member of the College with a high standard of integrity and ethics, in support of the College’s strategic vision and the division’s/department’s annual goals.']",2020-09-24 13:41:15
Signal/Image Processing and Data Analysis Engineer,MIT Lincoln Laboratory,4.2 out of 5,"Lexington, MA",[],2020-09-24 13:42:00
Data Engineer,Princeton University,4.3 out of 5,"Princeton, NJ 08542","['Collect and prepare data for some of our major projects, including OpenPrecincts and partisan gerrymandering analyses in various states.', 'Compile datasets on a state-by-state basis, combining census data, precinct-level results, and other information using GIS software.', 'Assist in the preparation of mainstream media content, professional reports, in-depth analysis, and possible peer-reviewed publications.', 'Other duties as assigned.', 'Bachelors degree in computer science or related technical field.', 'Experience with the following technologies:Data Science/Scripting Language (Python, R, Stata, etc.)GIS Software (QGIS, ArcGIS, etc.)', 'Understanding of how underrepresentation impacts policy decisions in the U.S.', 'Understanding of web scraping, APIs, and other data acquisition processes', 'Familiarity with Amazon Web Services is preferred']",2020-09-24 13:42:00
Data Engineer,SQAIT INC,N/A,"Charlotte, NC","['8 hour shift', 'Should be work on our W2', 'Likely']",2020-09-24 13:42:00
Data Analytic Engineer,FacilityConneX,N/A,"Nashua, NH",[],2020-09-24 13:42:00
Sr. Data Engineer,Datasys Consulting & Software Inc.,N/A,"San Francisco, CA","['Extensive experience with Cloud, Dataware ETL, Data Visualization, and reporting', 'Hands-on batch and bean airflow, spark and high', 'Experience in Google Cloud data products, IOT Architecture, and Realtime data-streaming', 'Must know Python, Scala, SQL DB', 'Capacity Planning and customer-facing in some cases', 'Also, must have experience in Machine Learning', 'Google Platform Certification or any google certification', 'Google Cloud: 5 years (Required)', 'SQL Data Base: 2 years (Preferred)', 'Data warehousing/Lake: 4 years (Preferred)', 'Data Visualization: 2 years (Preferred)', 'ETL: 4 years (Required)']",2020-09-24 13:42:00
Data Engineer,Cognizant Technology Solutions,3.9 out of 5,"Bethlehem, PA",[],2020-09-24 13:42:00
Python Engineer (Data Management/Machine Learning),Ryzen Solutions Inc.,4.7 out of 5,"Cupertino, CA","['Health insurance', 'Monday to Friday', 'Python: 1 year (Preferred)', '3 - 4 months', '5 - 6 months', 'One location', 'No']",2020-09-24 13:42:00
Data Engineer,Datastrong,N/A,"Washington, DC","['BenefitsCompensation plan consisting of a competitive base salary and an uncapped bonus', '100% Health coverage for employees with Vision and Dental options', 'Paid holidays and vacation with a generous leave policy', 'Commute reimbursement', 'Professional development and educational tuition assistance', 'Flexible spending account options', '401(k) retirement plan with complimentary financial advisory services', 'Strong SQL', 'Experience with ETL tools', 'Experience with Reporting/Analytics tools (MicroStrategy, Tableau, PowerBI, Cognos, Busines Objects, etc.) is a plus', 'Data manipulation & analysis', 'Unstructured data management', 'Experience with Cloud Technologies (S3, Redshift, lambda, AWS, etc.) is a plus', 'Bachelor’s Degree in Statistics, Mathematics, Computer Science, Management Information Systems, Engineering, Business Analytics disciplines, or related area', '3+ years of experience with ETL and data integration, data quality analysis, statistical analysis and/or modeling', 'Active Secret or Top-Secret US Government clearance', 'Compensation plan consisting of a competitive base salary and an uncapped bonus', '100% Health coverage for employees with Vision and Dental options', 'Paid holidays and vacation with a generous leave policy', 'Commute reimbursement', 'Professional development and educational tuition assistance', 'Flexible spending account options', '401(k) retirement plan with complimentary financial advisory services']",2020-09-24 13:42:00
Data Science Design Engineer,ASML,3.9 out of 5,"Wilton, CT 06897","['Working in a multi-disciplinary team of data scientists, physicists, computer scientists, and system architects to build Big Data platforms and data processing pipelines.', 'Developing and implementing complex data analytics solutions leveraging cutting-edge/open source software frameworks and tools.', 'Independent and creative investigation, modeling and development of data-driven Machine Learning, pattern recognition, feature extraction, model evaluation methods, algorithms and pipelines.', 'Working closely with domain experts to find and validate causal relations and to interpret predictive models.', 'Currently pursuing PhD or Masters or Bachelors in Computer Science/Computational Data Science/Information & Data Science/Business Analytics or equivalent field.', 'Good understanding of statistics, software system design and distributed architectures.', 'Class project/experience in building data and feature extraction pipelines (ETL, both batch- and stream-data processing) in a relevant context.', 'Knowledge in secure deployment of data science models and building efficient APIs for them.', 'Experience or affinity with signal and image processing is needed; in addition, we highly value experience with finding causality in signals, capturing uncertainty in models, Bayesian modeling, interactive visualization and user interaction.', 'Knowledge in Statistical Modeling and Predictive Modeling, Deep Learning, excellent coding skills using state-of-the-art machine learning libraries (e.g. Python/R) is desired.', 'Thinks creative, out of the box, self-going, fast learner, good coder and designer', 'Can observe and respond to people and situations and interact with others encountered in the course of work.', 'Can learn and apply new information or skills.', 'Must be able to read and interpret data, information, and documents.', 'Strong customer focus and commitment to customer satisfaction through prioritization, quality, efficiency and professionalism.', 'Ability to complete assignments with attention to detail and high degree of accuracy.', 'Proven ability to perform effectively in a demanding environment with changing workloads and deadlines.', 'Result driven-demonstrate ownership and accountability.', 'Identifies bottlenecks and drives improvements.', 'Work independently or as part of a team and follow through on assignments with minimal supervision.', 'Demonstrate open, clear, concise and professional communication.', 'Ability to establish and maintain cooperative working relationships with manager, co-workers and customer.', 'Work according to a strict set of procedures within the provided timelines.', 'Routinely required to sit; walk; talk; hear; use hands to keyboard, finger, handle, and feel; stoop, kneel, crouch, twist, reach, and stretch. Occasionally required to move around the campus.', 'Occasionally lift and/or move up to 20 pounds.', 'May require travel dependent on business needs.', 'Specific vision abilities required by this job include close vision, color vision, peripheral vision, depth perception, and ability to adjust focus.']",2020-09-24 13:42:00
"Data Engineer, Associate","JPMorgan Chase Bank, N.A.",3.9 out of 5,"Lewisville, TX 75067","['Job', 'Company', 'Expertise in application data and infrastructure architecture disciplines', 'Implement business and IT data requirements through new data strategies and designs across data platforms', 'In depth knowledge of Data protection, replication, reconciliation, and distribution', 'Experience in Data Modeling: ERWin ,', 'Experience working on 1 or more NoSQL Databases such as Cassandra, DynamoDB, Elastic Search', 'Proficiency in one or more Database Platforms / Language: SQL, Hadoop, Cassandra and Hive', 'In Depth Knowledge of Kafka and Kafka Streams Platform , API Gateway', 'Familiarity with Agile engineering practices', 'In Depth Knowledge of AWS Bigdata ecosystem including AWS Glue', 'Experience working with PCI Data is a plus']",2020-09-24 13:42:00
Campground Data Engineer,The Dyrt,N/A,Oregon,"['Are great communicators — Effective communication is key to how we work. We value patience and empathy in our product planning, support, and day-to-day relations.', 'Work well both collaboratively and independently — We come together to pair on tricky problems and architecture, then dive deep on individual tasks.', 'Are ready to learn and share knowledge — Everyone comes to our company with their own set of skills and experiences. Cross-training, code review, mentorship, and curiosity all help us build better products.', 'Evolve and maintain campground data processing pipelines, combining public, private, and user-contributed data', 'Use natural language processing to extract relevant highlights and amenity information from campground review text', 'Coordinate manual data review and improvement projects using internal staff, community crowdsourcing, or mechanical turk', 'Make use of photo geotags and computer vision (via Amazon Rekognition / GCP Vision AI) to infer information about campground amenities.', 'Improve techniques for matching and deduplication between multiple data sources', 'Import public data on national and state parks, forests, and recreation areas to provide a better search experience', '4+ years of professional experience in data engineering, data science, software development, or related field', 'Strong backend programming skills in one or more languages', 'Experience creating and maintaining data ETL pipelines or other complex data import systems', 'Fluency with SQL and relational schema design', 'A friendly working relationship with CSVs', 'Advanced degree in math, statistics, computer science, information science, or related field', 'Experience working with geospatial datasets and GIS analysis', 'Experience applying machine learning techniques to real world problems', 'Familiarity with Elasticsearch']",2020-09-24 13:42:00
Data Engineer,Advanced Centers for Cancer Care,N/A,"South Bend, IN 46601","['Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'Build and own “one source of truth” data sets to facilitate consistency and efficiency in extracting and analyzing data from disparate data sources', 'Ensure data integrity by developing and executing necessary processes and controls around the flow of data', 'Innovate and improve efficiency of managing data to allow for greater speed and accuracy of producing analyses, metrics, and insights', 'Collaborate with internal and external teams to understand business needs/issues, troubleshoot problems, conduct root cause analysis, and develop cost effective resolutions for data anomalies.', 'Provide input into data governance initiatives\u202fto enhance current systems, ensure development of efficient application systems, influence the development of data policy, and support overall corporate and business goals', 'Utilize technology to analyze data from applicable systems to review data processes, identify issues, and determine actions to resolve or escalate problems that require data, system, or process improvement', 'Verify accuracy of table changes and data transformation processes. Test changes prior to deployment as appropriate.', 'Recommend and implement enhancements that standardize and streamline processes, assure data quality and reliability, and reduce processing time to meet client expectations', 'Communicate progress and completion to project team. Escalate roadblocks that may impact delivery schedule', 'Stay up-to-date on data engineering and data science trends and developments', 'Follow company policy and procedures which protect sensitive data and maintain compliance with established security standards and best practices', 'Additional duties as assigned to ensure client and company success', 'Bachelor’s degree in Computer Science, Computer Engineering, Mathematics, or related field, or 3 plus years of relevant work experience.', 'Experience working with relational database structures, SQL and/or flat files and performing table joins, web crawling, and web development.', 'Proficiency in one or more of the following programming languages: PHP, Java, or Python and a familiarity with Node.js', 'Natural curiosity about what’s hidden in the data through exploration, attention to detail, and ability to see the big picture – similar to putting together a 10,000-piece puzzle.', 'Resourceful in getting things done, self-starter, and productive working independently or collaboratively – ours is a fast-pace entrepreneurial environment with performance expectations and deadlines.', 'Ability to learn quickly and contribute ideas that make the team, processes, and solutions better', 'Ability to communicate your ideas (verbal and written) so that team members and clients can understand them', 'Ability to defend your professional decisions and organize proof that your ideas and processes are correct', 'Familiar with various data management methodologies, data exploration techniques, data quality assurance practices, and data discovery/ visualization tools', 'Experience working with commercial relational database systems such as electronic medical records or other clinical systems, customer relationship management software, or accounting systems', 'Prior experience supporting business intelligence operations, managing technical, business, and process metadata related to data warehousing', 'Experience working in healthcare is a plus', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'One location', 'https://www.ac3health.com/', 'Waiting period may apply', 'Temporarily due to COVID-19']",2020-09-24 13:42:00
Data Engineer - Junior Level,USAA,3.9 out of 5,"Euless, TX 76039",[],2020-09-24 13:42:00
Radar Technician - Alaska,In-depth Engineering Corporation,4.2 out of 5,"Fairbanks, AK 99701","['Substantial pay differential provided for short term intense effort.', 'Other benefits include life insurance, health and disability insurance, reimbursed tuition, and paid travel to and from CONUS for dependents and partners.', 'In-Depth Engineering provides a competitive package of salary and benefits, including medical, dental, and vision coverage, a Safe Harbor 401(k) program, generous Paid Time Off (PTO), STD, LTD, life insurance, and tuition assistance for higher education.', 'Support validation of end-item ATPs and equipment, including Special Inspection Equipment (SIE), Special Test Equipment (STE), Support and Diagnostic Equipment (TMDE)', 'Perform analysis to evaluate, document, troubleshoot, and correct Radar anomalies found during testing.', 'Ensure operational readiness to aid in the execution of the Operation Verification Tests identified within Acceptance Testing.', 'Identify required data, data acquisition plans and test parameters, setting up equipment to conform to these specifications.', 'Inspect, diagnose, maintain, and operate test setups and equipment to detect malfunctions.', 'Record and interpret test data on parts, assemblies, and mechanisms.', 'Adjust, repair or replace faulty components of test setups, equipment, copper and FO cables.', 'Operate and calibrate computer systems and devices to comply with test requirements and to perform data acquisition and analysis.', 'Ensure operational readiness to aid in the execution of Integration & Test Activities.', 'Knowledge of network test equipment used to evaluate and correct operational failures', 'Must Be a US Citizen', 'Candidates must have at least an active DOD security clearance at secret level', 'Data Analysis capability including familiarity with Matlab, C++ and Unix']",2020-09-24 13:42:00
20GA590 Life Science Automation Engineers (Validation and Commissioning),Mason-Grey Corporation,N/A,"Vacaville, CA","['Pay:', '$55.00 - $95.00 per hour', 'Benefits:', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Generate and execute Validation life cycle documentation such as Systems Commissioning, Installation Qualification (IQ), Operational Qualification (OQ), Validation Summary Reports, and Deviations reports for Manufacturing and process Equipment & Utilities as per client GES guidelines.', 'Have expertise working with the Emerson DeltaV Process Control System and Emerson Syncade Manufacturing Execution System. Configuration within DeltaV or Syncade is not part of this requirement.', 'Perform Commissioning of Process Equipment, Utilities, HVAC Systems and Control Temperature Units in process rooms areas as per GMP requirements of the Client’s operations.', 'Analyze and interpret validation test data to determine whether systems or processes have met validation criteria or to identify root causes of deviations.', 'Generate Deviation Reports, perform root cause investigation and document Corrective And Preventive Actions (CAPA).', 'Dental insurance', 'Health insurance', 'Vision insurance', '8 hour shift', 'pharmaceutical / biotech validation: 5 years (Required)', ""Bachelor's (Required)"", 'Multiple locations']",2020-09-24 13:42:00
Senior Data Analytics Engineer,ThriftBooks,2.9 out of 5,"Seattle, WA","['Competitive salary', '3 weeks PTO to start', 'Medical, dental, vision', '401k', 'Build and enhance beautifully-crafted data warehouse models with dbt', ""Listen to customers as they explain the problems they're trying to solve"", 'Troubleshoot data anomalies with engineering teams', 'Build visualizations and pull data for people', 'Educate and empower your customers to self-serve', 'Investigate and propose the use of new, relevant technologies', 'Manage a cloud-based data warehouse', 'Craft data requirements for the engineering teams', 'A love for (and experience with) modeling data. dbt experience a big plus.', 'The ability to break large problems into small, testable, deployable solutions Proven track record of delighting data consumer.', 'Experience writing performant SQL on large data sets', 'Some experience with BI visualizations - we use Power BI & Mode Analytics', 'Near-obsession with all-things data', 'Software engineering background - C#, JavaScript, React, PowerShell, Python are all part of our environment', 'Experience with Snowflake, dbt, Snowplow, DevOps, Elastic, Spark, Statistics', 'Experience with data storage technologies outside of our regular stack', 'Autonomy', 'Ownership of the analytics domain', 'Competitive salary', '3 weeks PTO to start', 'Medical, dental, vision', '401k', 'Flexible work schedules', 'Work with nice, fun people', 'FREE BOOKS!']",2020-09-24 13:42:00
Lead Data Science Engineer,Janus AI,N/A,"Chicago, IL","['$84,392.00 - $174,628.00 per year', 'Benefits:', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Vision insurance', 'Work collaboratively with our customer team and product owners as part of our engineering team to create a robust data pipeline that derives actionable insights from our customers’ claim data', 'Help create a data science pipeline that is version-controlled, robust, scalable, and creates reproducible results', 'Understand the business purpose that the data science team serves and use that understanding to guide decision-making', 'Test and maintain deployed data science models and pipelines to ensure continued performance and improvement', 'Provide input on how to improve software both architecturally and functionally', '5+ years experience building ML based applications, preferably in a SaaS environment', 'An informed understanding of the tools available for each component of the ML development lifecycle, including, but not limited to:', 'Data versioning (e.g. DVC, Kedro)', 'Model versioning and hosting (e.g. MLFlow)', 'Orchestration (e.g. Airflow, Prefect, KubeFlow)', 'Practical experience with both data definition and data manipulation using SQL databases', 'Experience building, deploying, and maintaining production-ready data pipelines and models', 'Justifies modeling and data transformation choices with sound mathematical and empirical reasoning', 'Experience developing both discriminative and generative models for regression and classification problems.', 'Ability to design experiments to test causal hypotheses in a cost-effective manner', 'Creates data visualizations that non-data science stakeholders can understand', 'Understanding and experience developing data-science pipelines in a cloud environment (AWS, Azure, GCP, etc.)', 'Practical experience working with distributed computing frameworks (e.g. Spark, Dask)', 'Familiarity with common techniques in the explainable AI literature (e.g. SHAP, LIME)', 'Experience with Bayesian modeling and hyperparameter tuning', 'Python (scikit-learn, numpy, scipy, jupyter)', 'ML development lifecycle (Kedro, MLFLow)', 'Orchestration (Airflow, Prefect)', 'Distributed computing (Spark, Dask)', 'AWS Toolset', 'Containerization (Docker, Kubernetes, etc.)', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'machine learning development for a software application: 5 years (Required)', 'Fully Remote', 'Yes']",2020-09-24 13:42:45
Lead Data Architect/Engineer,Zest AI,N/A,"Burbank, CA","['Robust healthcare plans, matching 401K and unlimited vacation time', 'Weekly company wide “all hands” meetings', 'Design and implement robust end-to-end ETL pipelines', 'Architect and develop and maintain enterprise data warehouse', 'Create and manage ETL data pipelines (sourcing data from databases, streaming data, various web APIs, etc.)', 'Integrate data from data warehouse into 3rd party tools to make data actionable', 'Provide ongoing maintenance and enhancements to the data pipeline', 'Ensure data quality through automated testing', 'Collaborate with analysts, engineers and business users to design solutions', 'Research innovative technologies and make continuous improvements', 'Work with our Data Science, Product and Business Analytics teams to define requirements, design and build the next generation of our product roadmap features', 'Identify and evangelize programming best practices with the Data Engineering and Modeling teams', 'Work closely with Analysis to ensure quality & availability of data in the Data Warehouse along with support of our Business Intelligence platform', 'Minimum 4 years as a Data Engineer designing, developing and maintaining enterprise-grade data warehouse solutions consisting of structured and unstructured data', 'Proficiency with building data pipelines using ETL/data preparation tools', 'Experience with web APIs and data integrations across internal and external systems', 'Knowledge of Python, Java or other modern languages', 'Experience Apache technologies such as Flink and Kafka', 'Good understanding of database architecture and best practices', 'Understanding of data science and machine learning technologies a plus', 'People – the best part of Zest', 'Robust healthcare plans, matching 401K and unlimited vacation time', 'Weekly company wide “all hands” meetings', 'Virtual weekly happy hours, sometimes casual and other times with a focus around topics like racial discrimination and LGBTQ+ history', 'Employee care packages to make WFH more enjoyable']",2020-09-24 13:42:45
Data Scientist,Triplebyte,5 out of 5,California,"['Competitive salary and stock options package', 'Open vacation policy', 'Employer paid health, vision and dental insurance', '401(k) plan with matching', 'Pre-tax commuter benefits', 'Psychometrics', 'Recommender systems', 'Time series analysis', 'Survival analysis', 'Bayesian inference', 'Probabilistic programming']",2020-09-24 13:42:45
Data Engineer,Hudson River Trading,3.5 out of 5,"New York, NY 10005","['Strong programming experience in Python', 'Demonstrated ability to work with data', ""Data infrastructure experience - you know how to really store data; and no, we don't mean saving an Excel file on your desktop (everyone knows that's messy and it should be in a nicely named folder)"", 'Track record of working successfully in a collaborative environment', 'Top-notch communication skills', 'You have a minimum of 2-3 years of experience working in data infrastructure', ""Bachelor's degree in computer science, math or a related field"", ""You enjoy being part of an amazing team but don't mind working alone on a difficult problem"", 'You can analyze and fix problems quickly', 'You really like to work with people who motivate you and make you better', 'In your spare time you: code, tinker, read, explore, break things, and have an insatiable curiosity for all things computer related']",2020-09-24 13:42:45
Data Engineer Summer Intern,The Chemours Company,3.7 out of 5,"Wilmington, DE 19801","['Competitive Compensation', 'Paid Site Holidays and Paid Day of Service', 'Temporary Housing Assistance', 'Developing data pipelines using the full range of platform capabilities in Microsoft Azure', 'Writing data movement routines in Python and SQL', 'Participating in data modeling discussions', 'Current enrollment at an accredited university as a sophomore or above', 'Pursuing an undergraduate degree in Computer Science, Data Science, or similar fields', 'Experience with SQL and Python', 'Experience with Microsoft Azure', '3.0 GPA or above', 'Competitive Compensation', 'Paid Site Holidays and Paid Day of Service', 'Temporary Housing Assistance', 'Learning and Development Opportunities', 'Strong Inclusion a Diversity Initiatives']",2020-09-24 13:42:45
Data Center Design Engineer (JoinOCI-Ns2),Oracle,3.8 out of 5,"Ashburn, VA",[],2020-09-24 13:42:45
Software or Machine Learning Engineer - Entry Level,Apple,4.2 out of 5,"Santa Clara Valley, CA 95014","['Software Roles:', 'Proficiency with C/C++/Java', 'Familiarity with Objective-C/Cocoa', 'Experience with UNIX and/or OS X preferred', 'Strong analytical and problem solving skills', 'Excellent written and verbal communication skills', 'Machine Learning Roles:', 'Experience in machine learning, deep learning, search, natural language processing, data science, or computer vision', 'Experience in one of the following languages: Python, Java, C++', 'Strong analytical and problem solving skills', 'Strong background in algorithms and data structures']",2020-09-24 13:42:45
Data Engineer,United Federal Credit Union,3.5 out of 5,"Saint Joseph, MI 49085","['Build, develop and maintain data models, reporting systems, data automation systems, dashboards and performance metrics that support key business decisions using various technologies including Snowflake, Matillion, SQL, SSRS, SSIS, Tableau, Python, and R. Time: 40%', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Time: 20%', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Time: 20%', 'Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs. Time: 10%', 'Learns new technologies to implement within existing infrastructure. Time: 10%', ""Bachelor's degree, preferably in Computer Science or Information Systems, or two years of related work experience required."", 'A minimum of 3 years professional Information Systems or analytical experience required, preferably in the financial industry.', 'A minimum of 2 years of Advanced SQL programming, data modeling, ETL development knowledge required.', 'A minimum of 2 years work experience with data analysis, business intelligence, and analytics.', 'Demonstrated ability in creating technical solutions to solve complex business problems.', 'Strong working knowledge of relational data models, database design, and data modeling concepts', 'Working knowledge of SQL to support and maintain a cloud-based data warehouse (CDW)', 'Able to highlight issues/problems and convey complex thoughts, written and oral, in a clear, concise, and timely manner', 'Comfort in using a wide range of interpretive analysis tools (e.g., trend analysis, spreadsheets, comparisons, graphs, summary versus detail charts, drill-down, correlations, maps, exception analysis)', 'Superior research and analytical skills', 'Excellent organizational skills', 'Problem Solving', 'Drive for Results', 'Time Management', 'Dealing with Ambiguity', 'Demonstrates Courage', 'Interpersonal Savvy', 'Integrity & Trust', 'Customer Focus', 'Self-Development', 'Business Acumen', 'Ability to conduct appropriate market research, analyze findings and provide meaningful reports relative to existing and/or potential Credit Union needs', 'Ability to work under pressure', 'Proven problem-solving abilities', 'Ability to understand and relate activities to strategic objectives', 'Ability to concentrate in a multi-task environment', 'Ability to maintain a positive attitude and professional image', 'All available general office equipment as needed', 'All available computer software and hardware as needed', 'PC, scanner and accessories', 'Marketing related word and graphic software', 'Website software and scripting language', 'Research tools and services', 'Daily, personal/written/phone contact with Business Intelligence Manager', 'As necessary, personal/written/phone contact with other department managers', 'As necessary, personal/written/phone contact with Credit Union staff', 'Daily, personal/written/phone contact with vendors', 'Occasional, personal/written/phone contact with community agencies and consultants']",2020-09-24 13:42:45
Data Engineer - Teem,iOFFICE,4.4 out of 5,"Sandy, UT 84070","['Work with internal customers to understand business processes and gather project requirements', 'Research and identify best-in-class infrastructure and solutions for delivering actionable reporting', 'Own the data pipeline infrastructure, ETL processes and data warehouse schemas', 'Clean and transform data from new APIs and existing sources all the way through to the reporting output', 'Monitor performance of data processes and optimize where necessary', 'Troubleshoot data integrity and data availability issues', 'Perform data validation tests to ensure quality', 'Perform ad-hoc analysis and present results to internal and external customers', 'Build and maintain the data dictionary and promote data literacy throughout the organization', 'Experience designing star schemas, aggregate tables and reporting views', 'Experience integrating data sets and writing ETL jobs to populate a data warehouse; proficiency with Talend products is beneficial', 'Experience with reporting tools, especially cloud solutions such as Looker', 'Experience with data governance and metadata management principles', 'Expert SQL skills', 'Excellent communication and documentation skills, with the ability to explain an architecture or analysis to a non-expert audience', 'Familiarity or ability to learn distributed streaming platforms such as Apache Kafka', 'Familiarity with cloud computing services', 'Familiarity with unstructured data such as JSON', 'Competency or strong desire to learn Java or Python programming']",2020-09-24 13:42:45
Sr. Database Engineer,Benefitfocus,3.1 out of 5,Remote,"['Implements high priority application software and infrastructure covering database design, epic, feature and story development, re-usable code, components and application functionality.', 'Works with senior engineers and architects to define the application architecture and create software design for key elements of the application.', 'Evaluates performance of key elements of the application functionality and tunes the performance to cover the range of customer use.', 'As the technical lead for a project, works with the scrum team to assist developers and monitor their progress against project milestones. Performs tech design reviews and code reviews for the scrum teams. Provides scheduling estimates and assists with the scheduling process.', 'Provides input to managers on the performance of team members for use in their reviews and participates in the interview process for new candida', 'Monitoring databases and related systems to ensure optimized performance.', 'Writing new support programs and scripts to increase data storage capacity.', 'Performing debugging procedures on database scripts and programs, as well as resolving conflicts.', 'Mentoring database engineers and providing them with technical support.', 'Adhering to best practices in securely storing, backing up, and archiving data.', 'Documenting processes related to database design, configuration, and performance.', 'Keeping abreast of developments and best practices in database engineering.', ""Bachelor's degree in information systems, information technology, computer science, or similar."", 'Applicable licensing, certification, and registration.', ""A minimum of five years' experience in database engineering using Oracle."", 'In-depth knowledge of Structured Query Language (SQL) and PL/SQL.', 'Extensive experience with database technologies and architecture.', 'Sound knowledge of best practices in database engineering and data security.', 'Strong organizational skills and attention to detail.', 'Exceptional problem-solving and critical thinking skills.', 'Excellent collaboration and communication skills.']",2020-09-24 13:42:45
Data Engineer,ServiceChannel,3.9 out of 5,"Pleasanton, CA 94588","['Data Discovery - analyzing data values and data patterns to identify the relationships that link disparate data elements into logical units of information, or ""business objects"" (such as customer (subscriber), service provider, work orders, etc.). Identify the transformation rules that have been applied to a source system to populate a target such as transactional entities, operational data store or data warehouse. Create and maintain technical documentation', 'Data Architecture and Modeling - Create conceptual, logical and physical data models. Define data attributes, including domain constraints and privacy attributes. Discover, explore, and visualize the structure of data sources. Discover or identify relationships between disparate data sources. Compare and normalize the structures of various data sources to address data analytics, data mining, data warehouse and reporting requirements. Perform peer code review when assigned', 'Data Engineering and Data Warehouse – Build extensible data acquisition and integration solutions to meet the functional and non-functional requirements of the business. Implement processes and logic to extract, transform, and distribute data across one or more data stores from a wide variety of sources. Optimize data integration platform to provide optimal performance under increasing data volumes. Participate in research and development of recommendations regarding database components, including hardware, database systems, ETL software, metadata management tools and database design solutions.', 'Data Governance/Stewardship – Ensures the quality, completeness and accuracy of data definitions within developed codes. Identifies and manages the resolution of data quality and data security issues, such as uniqueness, integrity, accuracy, consistency, privacy and completeness in a cost-effective and timely fashion. Identify procedures for disaster recovery and data archiving to ensure effective protection and integrity of data assets.', 'Data Quality - Ensure the stability, integrity and efficiency of data access and data quality across the organization via ongoing database support and maintenance. Ensure data reconciliation unit testing procedures that will prove accuracy and correctness of data being processed.', 'Database Architecture, Administration and Development - Work with database development staff and DBAs to develop database architectures, coding standards, and quality assurance policies and procedures. Participate in testing and implementing database design and functionality, and tuning for performance.', 'Metadata - support information governance by providing reporting and traceability on data movement, modeling and business intelligence applications, as required by regulatory requirements. Analyze and view the impact of changes to the current information model, avoiding potentially disruptive modifications to existing processes.', 'Customer Implementation and Production Support – Assist Customer Implementation and Customer Success teams as Data SME during troubleshooting issues.', ""Bachelor's Degree in Computer Science, related field or equivalent experience (including completed courses in relevant areas such as computer science, computer languages, etc."", 'Strong understanding of database structures, theories, principles and practices, and hands-on experience with business requirements gathering, data analysis and data modeling', 'Strong experience managing/maintaining database schema in source code control', '3+ years of experience related work experience which deals with following data domain - customer, service provider, service orders, invoices and other related attributes.', '3+ years of experience in analyzing and developing data requirements and data specifications; hands-on experience in documenting understanding and analysis of databases and data models.', '3+ years of experience in creating, mapping and documenting data within organization (source, targets, transformation rules, etc.); Experience with any off the shelf ETL technology to build mappings to extract and transform data. Understanding of ETL technology architecture; Understanding of ETL Repository. Worked on transformations to cleanse, format, join, aggregate and route data to appropriate targets. Perform error handling/trapping using ETL mappings or corresponding techniques. Experience using Workflow management to build and run workflows; Experience with performance tuning ETL mappings and workflow; Designed error handling strategies for use in a workflow. Worked with ETL logs and debugger for troubleshooting', '4+ years of hands-on experience in writing SQL for querying databases. Ability to extract information from databases using complex query statements and advanced database tools.', 'Ability to work independently while working on multiple projects', 'Strong problem-solving and communication skills', 'Strong analytical, prioritizing, interpersonal, problem-solving, presentation, project management (from conception to completion) & planning skills', 'Demonstrated collaborative skills and ability to work well within a team', 'Ability to work in a fast-paced and deadline-oriented environment', 'Self-motivated with critical attention to detail, deadlines and reporting. Able to successfully work on problems of limited to diverse scope involving task specific or cross-functional teams.', 'Ability to analyze business processes, best practices, data lifecycles, and standard operating procedures', 'Facility management data domain knowledge/experience', 'Experience in cloud ETL and near-time data integration technology', '3+ years of hands-on experience in logical data modeling', '2+ years hands-on technical experience with designing, building, installing, configuring and supporting database servers including database tuning and troubleshooting experience', 'Advanced ETL techniques: Understanding structure and use of parameters. Experience using Lookup transformation. Applied memory optimization techniques', 'Worked with various relational and MPP database platforms', 'Experience with version control tools & release management', 'Applied experience in secure file transfer protocol (sFTP), web services integrations, Salesforce, and JIRA']",2020-09-24 13:42:45
Lead Data Engineer,keywordsolutions,N/A,"Dearborn, MI","['Pay:', '$43.00 - $60.00 per hour', 'Temporarily due to COVID-19']",2020-09-24 13:42:45
Data Engineer,"Double Line, Inc.",N/A,"Austin, TX 78758","['Think creatively and help other data experts on the team figure out the solution to really tough data load or transformation problems', 'Leverage SQL and/or ETL development, data mapping, and data modeling experience to manage and organize our customer education data', 'Be obsessed about continuously improving our approach and doing it better and faster the next time', 'Consultancy experience with a focus on Agile practices', 'AWS and Azure Cloud', 'Python or similar scripting languages', 'AWS Quicksight, Tableau, Power BI, or other visualization tools', 'Soak up knowledge from the existing team of experts in the first 30 days', 'Bring fresh eyes to our processes and techniques and bring new ideas to the table in the first 2 months', ""Grow your skills so much that you're ready to teach the next new hire by 2021"", 'A mission-driven company with a long-term focus on helping the world by untangling the technical messes that hold back education in our country', 'A home where your voice matters, and you can effect real change', ""A company who cares about you, makes sure you're engaged with exciting work and provides medical benefits, 401k, and a great culture.""]",2020-09-24 13:42:45
Data Scientist - Software Engineer - Fulltime Role,Suncloud LLC,N/A,"Boston, MA","['401(k)', 'Health insurance', 'Design, build, and maintain a highly scalable web analytics platform', 'Ensure that the platform meets business requirements and industry practices for security and privacy', 'Integrate new technologies and data science methodologies into existing platform', 'Collaborate with the Panalgo solutions team on building and validating data science features', 'Building, evaluating, and discussing machine learning pipelines; works with BHE Solutions team to ensure the platform can support specific customer projects', 'Bachelor’s degree in Computer Science, Engineering, Math, or related technical/science field', '5+ years of software engineering experience', '2 years data science / machine learning experience', 'Significant experience with Python', 'Professional experience with the “PyData” stack – e.g. NumPy, pandas, matplotlib, Jupyter Notebook', 'Experience with Java and Apache Spark', '401(k)', 'Health insurance', 'Monday to Friday', 'Data Science: 3 years (Required)', 'Software Development: 5 years (Required)', 'Machine Learning: 2 years (Required)', ""Bachelor's (Required)""]",2020-09-24 13:42:45
Data Engineer,BetterUp,4.3 out of 5,California,"['A competitive compensation plan with opportunity for advancement', 'Full coverage for medical, dental and vision insurance', 'Employer Paid Life, AD&D, STD and LTD insurance', 'Flexible paid time off', 'Per year:', '13 paid holidays', 'Data Accessibility: Collected data should be accessible, or appropriately inaccessible, to all services, products, and people of the organization.', 'Data Approachability: Data should be intuitively familiar to the observer.', 'Data Awareness: Cultivate a community of data-conscious practitioners.', 'Data Unifier: Architect, assemble, assimilate, clean, and conform large, complex datasets to deliver business insights and power product experiences.', 'Data Advocate: Weave data into decision-making and drive cross-functional data-oriented approaches and solutions.', 'Data Protector: Design and build reliable, scalable data infrastructure with leading privacy and security techniques to safe guard data.', 'Data Builder: Own the end-to-end data stack including event collection, data governance, data integrations, and modeling.', 'Data Custodian: Ensure consistency and quality through metrics, documentation, processes, data testing, and training.', 'Experience with analytic databases (e.g. Snowflake).', 'Advanced knowledge of SQL and experience with relational databases.', 'Hands-on experience developing data pipelines. We use (e.g. dbt, Airflow, Stitch Data / Singer specs) .', 'Hands-on experience with event streams and stream processing (e.g. Kafka, Spark, Data Bricks, Segment).', 'Decoupling transactional or source systems from business intelligence reporting (e.g. dimensional modeling).', 'Experience with creating high-quality, fast services and projects in Python.', 'Experience with modern business intelligence and product reporting tools (e.g. Mode, Looker, Periscope).', 'Access to BetterUp coaching; one for you and one for a friend or family member', 'A competitive compensation plan with opportunity for advancement', 'Full coverage for medical, dental and vision insurance', 'Employer Paid Life, AD&D, STD and LTD insurance', 'Flexible paid time off', 'Per year:', 'Holiday charitable contribution of your choice on behalf of BetterUp', '401(k) self contribution']",2020-09-24 13:42:45
Data Engineer,Brightside,3.5 out of 5,Arizona,"['Create and maintain optimal data pipeline and data lake architecture', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and data tool technologies', 'Build analytics tools that utilize the data pipeline to provide actionable insights into key business performance metrics', 'Identify key metrics that need definition and measurement for meaningful outcomes', 'Partner with stakeholders and data team member to build out metrics/dashboards', 'Continuously promote data-driven decision-making and actively contribute to organizational development and ongoing optimization', 'B.S Degree in Mathematics, Statistics, Computer Science, Analytics, Economics, or a related quantitative field or extensive relevant work experience', '4+ years of professional experience in data engineering', 'Must have hands-on experience with AWS RDS, DocumentDB, Snowflake, Fivetran and Talend', 'Ability to design and build highly scalable data pipelines and data lake infrastructure', 'Experience with AWS service is required in RDS, DynamoDB, EC2, S3', 'Experience with SQL and NoSQL databases, including MySQL, MongoBD, etc.', 'Experience with data pipeline and workflow management tools in Fivetran and Talend', ""Experience building and optimizing 'big data' pipelines, architectures and data sets"", 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement', 'Strong analytic skills related to working with unstructured datasets', 'Experience with scripting tools (like JavaScript, Python, Ruby, etc.)', 'Must have the ability to work independently and to collaborate with a larger team', 'Must be eager, self-motivated, and a quick-learner', 'Experience with Establishing PCI standard implementation, automating PCI and HIPAA compliance tasks, Multi Factor Authentication', 'Experience with DevOps practices in CI/CD (Docker, Kubernetes) a big plus', 'Strong problem-solving and analytical skills', 'Giving & receiving meaningful feedback is part of our growth mind set & culture - both are in your wheelhouse', 'Ability to build and maintain positive working relationships with leadership across the organization', 'Ability to deal effectively with ambiguous situations', 'Results-oriented with a willingness to take initiative and get the job done', 'Proficiency in business requirement elicitation and documentation', 'Medical, Dental & Vision', 'Paid Time Off & Company Holidays', '401(k)', 'Short & Long Term Disability', 'To be in an environment to learn and grow your own financial wellness', 'A remote, inclusive work environment']",2020-09-24 13:43:30
Data Center Engineer I,"JPMorgan Chase Bank, N.A.",3.9 out of 5,"Totowa, NJ","['Job', 'Company', 'Ability to identify problems and clearly communicate strategic solutions to clients', 'Desire to develop a working knowledge of change management, corporate IT audit processes, IT risk management, technical problem resolution, operations systems, and data sources knowledge', 'Strong initiative and desire to learn', 'Ability to effectively collaborate with team members and clients to achieve common goals', 'Good knowledge of Windows/MAC OS with the ability to carry out root cause analysis', 'Working knowledge of Microsoft Office products', 'Strong analytical and problem resolution skills', 'Understanding of information technology concepts in a working or academic environment', 'General knowledge of a physical IT infrastructure (server, networking, storage)', 'Some understanding of network concepts (switching, routing, perimeter security)', 'Some understanding of operating systems (Windows, Linux, AIX)']",2020-09-24 13:43:30
Data Engineer 3,PayPal,3.9 out of 5,"San Jose, CA 95131","['Job', 'Company', 'Developing, maintaining, and managing advanced reporting, analytics, dashboards and other BI solutions.', 'Performing and documenting data analysis, data validation, and data mapping/design.', 'Reviewing and improving existing systems and collaborating with teams to integrate new systems.', 'Conducting unit tests and developing database queries to analyze the effects and troubleshoot any issues.', 'A solid understanding of SQL, rational databases, and normalization. Will be expected to write DDL and DML as needed including: create tables, create views, analyze execution plans, and create indexes.', 'Degree in Mathematics, Computer Science, Information Systems, or related field.', 'Relevant work experience.', 'A solid understanding of SQL, rational databases, and normalization.', 'Experience in database schema design preferred.', 'Proficiency in use of query and reporting analysis tools.', 'Competency in Excel (macros, pivot tables, etc.)', 'Extensive experience in developing, maintaining and managing Tableau driven dashboards & analytics and working knowledge of Tableau administration/architecture.', 'Experience with Power Query, Power Pivot, SQL, Power BI a plus', 'Ability to utilize a diversity of software packages, applications and automated systems for collecting and managing data', 'Minimum Experience: Bachelor’s degree and 6-9 years of directly applicable experience; Master’s degree and 4+ years experience preferred.', 'Excellent written and verbal communication skills.', 'Self-starter demonstrates independence, initiative and follow-through. Delivers on time while meeting quality objectives and customer expectations', 'Work across the company to drive to decisions, build consensus and bridge gaps. Builds rapport, credibility and relationships with multiple stakeholders. Great team player.', 'Must be detail-oriented, conscientious, thorough and accurate', 'Must be able to step back and analyze at a broader level, while still being detailed oriented, conscientious, thorough and accurate', 'Strong interpersonal skills, diplomacy, and client service-oriented attitude and mindset', 'Ability to work globally and cross-functionally and lead change in a fast-paced environment', 'Proven ability to function well independently as well as in a team', 'Be comfortable in a fast paced and dynamic environment with a high degree of accuracy', 'Comfortable working in a fluid environment where roles and responsibilities are still evolving', 'Good project management and reporting skills', 'Ability to facilitate group discussions and run meetings', 'Ability to handle multiple projects under pressure', 'Well-developed sense of urgency and follow through', 'Ability to resolve complex issues and settle disputes equitably', 'Ability to determine when to escalate to management and identify the right stakeholders for decision making', 'Proficient with tools such as Power Point, Microsoft Project, MS Word, Excel, Access and Visio']",2020-09-24 13:43:30
Data Center Operations Engineer,Facebook,4.2 out of 5,"Fort Worth, TX","[""Work within Facebook's ticketing system in support of the health of Facebook's server fleet"", 'First point of contact for break fix technicians', 'Accountable for assisting with projects (new capacity as well as retrofits) and repairs throughout the data center', 'Understand and initial analysis to debug hardware, and Linux OS related issues', 'Demonstrate personal leadership Identifying and helping to create documentation for the global data center knowledge base', 'Assist with process improvements and best practices in data center operations', 'Participate in on-call rotation (once a month on call for a week after hours, first point of contact)', ""Bachelor's degree in a technical field or certification"", 'Knowledge of Linux and server hardware repairs', 'Experience modifying and developing in Python, SQL, and/or shell scripting', 'Working conceptual knowledge of technologies such as HTTP, DNS, RAID, and DHCP']",2020-09-24 13:43:30
Lead Data Science Engineer,Janus AI,N/A,"Chicago, IL","['Work collaboratively with our customer team and product owners as part of our engineering team to create a robust data pipeline that derives actionable insights from our customers’ claim data', 'Help create a data science pipeline that is version-controlled, robust, scalable, and creates reproducible results', 'Understand the business purpose that the data science team serves and use that understanding to guide decision-making', 'Test and maintain deployed data science models and pipelines to ensure continued performance and improvement', 'Provide input on how to improve software both architecturally and functionally', '5+ years experience building ML based applications, preferably in a SaaS environment', 'An informed understanding of the tools available for each component of the ML development lifecycle, including, but not limited to:', 'Data versioning (e.g. DVC, Kedro)', 'Model versioning and hosting (e.g. MLFlow)', 'Orchestration (e.g. Airflow, Prefect, KubeFlow)', 'Practical experience with both data definition and data manipulation using SQL databases', 'Experience building, deploying, and maintaining production-ready data pipelines and models', 'Justifies modeling and data transformation choices with sound mathematical and empirical reasoning', 'Experience developing both discriminative and generative models for regression and classification problems.', 'Ability to design experiments to test causal hypotheses in a cost-effective manner', 'Creates data visualizations that non-data science stakeholders can understand', 'Understanding and experience developing data-science pipelines in a cloud environment (AWS, Azure, GCP, etc.)', 'Practical experience working with distributed computing frameworks (e.g. Spark, Dask)', 'Familiarity with common techniques in the explainable AI literature (e.g. SHAP, LIME)', 'Experience with Bayesian modeling and hyperparameter tuning', 'Python (scikit-learn, numpy, scipy, jupyter)', 'ML development lifecycle (Kedro, MLFLow)', 'Orchestration (Airflow, Prefect)', 'Distributed computing (Spark, Dask)', 'AWS Toolset', 'Containerization (Docker, Kubernetes, etc.)', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'machine learning development for a software application: 5 years (Required)', 'Fully Remote', 'Yes']",2020-09-24 13:43:30
Lead Data Architect/Engineer,Zest AI,N/A,"Burbank, CA","['Design and implement robust end-to-end ETL pipelines', 'Architect and develop and maintain enterprise data warehouse', 'Create and manage ETL data pipelines (sourcing data from databases, streaming data, various web APIs, etc.)', 'Integrate data from data warehouse into 3rd party tools to make data actionable', 'Provide ongoing maintenance and enhancements to the data pipeline', 'Ensure data quality through automated testing', 'Collaborate with analysts, engineers and business users to design solutions', 'Research innovative technologies and make continuous improvements', 'Work with our Data Science, Product and Business Analytics teams to define requirements, design and build the next generation of our product roadmap features', 'Identify and evangelize programming best practices with the Data Engineering and Modeling teams', 'Work closely with Analysis to ensure quality & availability of data in the Data Warehouse along with support of our Business Intelligence platform', 'Minimum 4 years as a Data Engineer designing, developing and maintaining enterprise-grade data warehouse solutions consisting of structured and unstructured data', 'Proficiency with building data pipelines using ETL/data preparation tools', 'Experience with web APIs and data integrations across internal and external systems', 'Knowledge of Python, Java or other modern languages', 'Experience Apache technologies such as Flink and Kafka', 'Good understanding of database architecture and best practices', 'Understanding of data science and machine learning technologies a plus', 'People – the best part of Zest', 'Robust healthcare plans, matching 401K and unlimited vacation time', 'Weekly company wide “all hands” meetings', 'Virtual weekly happy hours, sometimes casual and other times with a focus around topics like racial discrimination and LGBTQ+ history', 'Employee care packages to make WFH more enjoyable']",2020-09-24 13:43:30
Big Data Engineer,Enhance IT,3.4 out of 5,"Atlanta, GA","['Interviewing potential consultants to ensure all onboarding employees will be successful in Big Data domains prior to each onboarding', 'The design, development and maintenance of our best-in-class Big Data/Hadoop development training materials', 'Training, guiding and mentoring junior to mid-level developers', 'Preparing mock interview situations to enhance the esteemed learning process provided by the company', 'Acting as a primary resource for individuals working on a variety of projects throughout the US', 'Interacting with our Executive and Sales team to ensure that projects and employees are appropriately matched', 'Prepping consultants for interviews for specific assignments involving development and implementation of Hadoop and other environments', 'Hadoop development and implementation', 'Strong in Object Oriented Development in Scala/Java platform', 'Hands on experience in big data technologies including Scala or Spark, Hadoop, Hive, HDFS.', 'Strong SQL skills and experience', 'Designing, building, installing, configuring and supporting Big Data Clusters Spark/Kafka', 'Translate complex functional and technical requirements into detail design Implementing ETL process for integration of data from disparate sources', 'Cloud Experience is a plus', '5+ Years of professional experience in the IT Industry', 'Bachelor’s Degree in the Computer Science field', 'Good knowledge in back-end programming, specifically Java/Scala', 'Good knowledge of database structures, theories, principles and practices', 'Analytical and problem-solving skills', 'Proven understanding with Hadoop, Spark, Kafka, Hive, and HBase', 'Good aptitude in multi-threading and concurrency concepts', 'Able to work in Atlanta, Georgia', 'Big Data: 5 years (Required)', 'No']",2020-09-24 13:43:30
Data Scientist,Triplebyte,5 out of 5,California,"['Psychometrics', 'Recommender systems', 'Time series analysis', 'Survival analysis', 'Bayesian inference', 'Probabilistic programming']",2020-09-24 13:43:30
Data Engineer,Hudson River Trading,3.5 out of 5,"New York, NY 10005","['Strong programming experience in Python', 'Demonstrated ability to work with data', ""Data infrastructure experience - you know how to really store data; and no, we don't mean saving an Excel file on your desktop (everyone knows that's messy and it should be in a nicely named folder)"", 'Track record of working successfully in a collaborative environment', 'Top-notch communication skills', 'You have a minimum of 2-3 years of experience working in data infrastructure', ""Bachelor's degree in computer science, math or a related field"", ""You enjoy being part of an amazing team but don't mind working alone on a difficult problem"", 'You can analyze and fix problems quickly', 'You really like to work with people who motivate you and make you better', 'In your spare time you: code, tinker, read, explore, break things, and have an insatiable curiosity for all things computer related']",2020-09-24 13:43:30
Data Engineer Summer Intern,The Chemours Company,3.7 out of 5,"Wilmington, DE 19801","['Developing data pipelines using the full range of platform capabilities in Microsoft Azure', 'Writing data movement routines in Python and SQL', 'Participating in data modeling discussions', 'Current enrollment at an accredited university as a sophomore or above', 'Pursuing an undergraduate degree in Computer Science, Data Science, or similar fields', 'Experience with SQL and Python', 'Experience with Microsoft Azure', '3.0 GPA or above', 'Competitive Compensation', 'Paid Site Holidays and Paid Day of Service', 'Temporary Housing Assistance', 'Learning and Development Opportunities', 'Strong Inclusion a Diversity Initiatives']",2020-09-24 13:43:30
Data Center Design Engineer (JoinOCI-Ns2),Oracle,3.8 out of 5,"Ashburn, VA",[],2020-09-24 13:43:30
Software or Machine Learning Engineer - Entry Level,Apple,4.2 out of 5,"Santa Clara Valley, CA 95014","['Job', 'Company', 'Software Roles:', 'Proficiency with C/C++/Java', 'Familiarity with Objective-C/Cocoa', 'Experience with UNIX and/or OS X preferred', 'Strong analytical and problem solving skills', 'Excellent written and verbal communication skills', 'Machine Learning Roles:', 'Experience in machine learning, deep learning, search, natural language processing, data science, or computer vision', 'Experience in one of the following languages: Python, Java, C++', 'Strong analytical and problem solving skills', 'Strong background in algorithms and data structures']",2020-09-24 13:43:30
Data Engineer,United Federal Credit Union,3.5 out of 5,"Saint Joseph, MI 49085","['Build, develop and maintain data models, reporting systems, data automation systems, dashboards and performance metrics that support key business decisions using various technologies including Snowflake, Matillion, SQL, SSRS, SSIS, Tableau, Python, and R. Time: 40%', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Time: 20%', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Time: 20%', 'Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs. Time: 10%', 'Learns new technologies to implement within existing infrastructure. Time: 10%', ""Bachelor's degree, preferably in Computer Science or Information Systems, or two years of related work experience required."", 'A minimum of 3 years professional Information Systems or analytical experience required, preferably in the financial industry.', 'A minimum of 2 years of Advanced SQL programming, data modeling, ETL development knowledge required.', 'A minimum of 2 years work experience with data analysis, business intelligence, and analytics.', 'Demonstrated ability in creating technical solutions to solve complex business problems.', 'Strong working knowledge of relational data models, database design, and data modeling concepts', 'Working knowledge of SQL to support and maintain a cloud-based data warehouse (CDW)', 'Able to highlight issues/problems and convey complex thoughts, written and oral, in a clear, concise, and timely manner', 'Comfort in using a wide range of interpretive analysis tools (e.g., trend analysis, spreadsheets, comparisons, graphs, summary versus detail charts, drill-down, correlations, maps, exception analysis)', 'Superior research and analytical skills', 'Excellent organizational skills', 'Problem Solving', 'Drive for Results', 'Time Management', 'Dealing with Ambiguity', 'Demonstrates Courage', 'Interpersonal Savvy', 'Integrity & Trust', 'Customer Focus', 'Self-Development', 'Business Acumen', 'Ability to conduct appropriate market research, analyze findings and provide meaningful reports relative to existing and/or potential Credit Union needs', 'Ability to work under pressure', 'Proven problem-solving abilities', 'Ability to understand and relate activities to strategic objectives', 'Ability to concentrate in a multi-task environment', 'Ability to maintain a positive attitude and professional image', 'All available general office equipment as needed', 'All available computer software and hardware as needed', 'PC, scanner and accessories', 'Marketing related word and graphic software', 'Website software and scripting language', 'Research tools and services', 'Daily, personal/written/phone contact with Business Intelligence Manager', 'As necessary, personal/written/phone contact with other department managers', 'As necessary, personal/written/phone contact with Credit Union staff', 'Daily, personal/written/phone contact with vendors', 'Occasional, personal/written/phone contact with community agencies and consultants']",2020-09-24 13:43:30
Data Engineer - Teem,iOFFICE,4.4 out of 5,"Sandy, UT 84070","['Work with internal customers to understand business processes and gather project requirements', 'Research and identify best-in-class infrastructure and solutions for delivering actionable reporting', 'Own the data pipeline infrastructure, ETL processes and data warehouse schemas', 'Clean and transform data from new APIs and existing sources all the way through to the reporting output', 'Monitor performance of data processes and optimize where necessary', 'Troubleshoot data integrity and data availability issues', 'Perform data validation tests to ensure quality', 'Perform ad-hoc analysis and present results to internal and external customers', 'Build and maintain the data dictionary and promote data literacy throughout the organization', 'Experience designing star schemas, aggregate tables and reporting views', 'Experience integrating data sets and writing ETL jobs to populate a data warehouse; proficiency with Talend products is beneficial', 'Experience with reporting tools, especially cloud solutions such as Looker', 'Experience with data governance and metadata management principles', 'Expert SQL skills', 'Excellent communication and documentation skills, with the ability to explain an architecture or analysis to a non-expert audience', 'Familiarity or ability to learn distributed streaming platforms such as Apache Kafka', 'Familiarity with cloud computing services', 'Familiarity with unstructured data such as JSON', 'Competency or strong desire to learn Java or Python programming']",2020-09-24 13:43:30
Sr. Database Engineer,Benefitfocus,3.1 out of 5,Remote,"['Implements high priority application software and infrastructure covering database design, epic, feature and story development, re-usable code, components and application functionality.', 'Works with senior engineers and architects to define the application architecture and create software design for key elements of the application.', 'Evaluates performance of key elements of the application functionality and tunes the performance to cover the range of customer use.', 'As the technical lead for a project, works with the scrum team to assist developers and monitor their progress against project milestones. Performs tech design reviews and code reviews for the scrum teams. Provides scheduling estimates and assists with the scheduling process.', 'Provides input to managers on the performance of team members for use in their reviews and participates in the interview process for new candida', 'Monitoring databases and related systems to ensure optimized performance.', 'Writing new support programs and scripts to increase data storage capacity.', 'Performing debugging procedures on database scripts and programs, as well as resolving conflicts.', 'Mentoring database engineers and providing them with technical support.', 'Adhering to best practices in securely storing, backing up, and archiving data.', 'Documenting processes related to database design, configuration, and performance.', 'Keeping abreast of developments and best practices in database engineering.', ""Bachelor's degree in information systems, information technology, computer science, or similar."", 'Applicable licensing, certification, and registration.', ""A minimum of five years' experience in database engineering using Oracle."", 'In-depth knowledge of Structured Query Language (SQL) and PL/SQL.', 'Extensive experience with database technologies and architecture.', 'Sound knowledge of best practices in database engineering and data security.', 'Strong organizational skills and attention to detail.', 'Exceptional problem-solving and critical thinking skills.', 'Excellent collaboration and communication skills.']",2020-09-24 13:43:30
Data Engineer,COTA,3.9 out of 5,"Boston, MA","['Develop and maintain various data ETL processes and the data warehouse', 'Implement quality monitoring to report on the accuracy and relevancy of processed data', 'Perform specialized data investigations to support analytics and custom reporting scenarios', 'Understand the available architectures and technologies, assess available options for new features', 'As part of a team, own data-centric processes, develop alerts for errors and service issues, and respond to alerts', 'Participate in code reviews with a goal of understanding the overall data pipeline and ensuring data quality', ""Holds a Bachelor's degree in Computer Science, Information Systems, or related major, or equivalent work experience"", 'Able to write well-documented, reusable, and testable code', 'Ability to write complex SQL queries for ETL or reporting', 'Strong working knowledge of Postgres or other relational databases', 'Proficiency in distributed version control systems such as git', 'Proficiency working as part of an Agile development team', 'Ability to interact and communicate effectively with colleagues on requirements and set expectations accordingly', 'Ability to work independently as well as with a team']",2020-09-24 13:44:12
Data Engineer III,SurveyMonkey,4.1 out of 5,"Portland, OR 97209","['Design, architect and build data pipes to support existing data models', 'Data quality: build quality checks in the end to end data pipelines', 'Build new Data models (fact vs dimension). Write performant/idempotent transformations in Snowflake sql.', 'Build data pipeline using Python scripting (in a modular/loop context) Write well-tested, production ready code in Python and/or Snowflake SQL', 'Hands-on experience implementing ETL (or ELT) best practices', 'Translate business requirements, to technical specifications, form project scope, and deliver deployable code.', 'Write complex data engineering Snowflake - SQL jobs that perform sophisticated queries on the entirety of our datasets', '5+ years experience in data engineering in Snowflake or SQL server', 'Experience in scheduling, automating and deploying production data pipelines using Airflow/Luigi, etc', 'Experience with tools such as dbt, matallion or other similar technologies', 'Experience with transforming, developing data structures, metadata, dependency and data workflows to support an Analytics function', 'In depth knowledge of Datalakes, EDW concepts, data modeling (star, snowflake and galaxy schemas)', '3+ years writing code in any OOP capable language, ideally Python', 'Job scheduling and workload management tools (Airflow etc)', 'Experience with ETL tools (Talend, Informatica, Matillion, Fivetran, DBT etc.)']",2020-09-24 13:44:12
Data Engineer,Govini,2.5 out of 5,"Pittsburgh, PA","[""Define and lead Govini's data lifecycle strategy across data acquisition, data ingestion, data cleansing, normalization and linkage"", 'Identify data sources, assess their value and quality and estimate the level of effort required to integrate into existing data model, infrastructure and products', 'Ensure key entities within datasets are identified, resolved and linked to existing entities within the current master data repository', 'Apply various techniques to produce solutions to large-scale optimization problems, including data pre-processing, indexing, blocking, field and record comparison and classification', 'Develop, refine and oversee master data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functions', 'Responsible for owning data quality metrics and meeting defined data accuracy goals according to industry best practices', 'Improve data sharing, increase data repurposing and improve cost efficiency associated with data management efforts', 'Build best practices that help with chain of custody of data so it can be easily traced back to the source for accuracy and consistency', 'Work across functional teams to understand advanced statistical, machine learning, and text processing models. Incorporate them into Govini’s existing data engineering infrastructure', 'Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns', 'Work directly with users as well as SMEs to establish, create and populate optimal data architectures and structures, as well as articulate techniques and results using non-technical language', 'U.S. Citizenship is required', ""Bachelor's degree in Computer Science, Mathematics or related technical field"", 'Minimum of 3 years direct experience creating sustainable, automated processes for data discovery, curation and synthesis', '2-5 years experience with programmatically manipulating data', 'Experience with PostgreSQL or similar RDBMS', 'Advanced SQL programming skills', 'Experience utilizing open-source technologies such as Linux, PostgreSQL', 'Proficient usage of common data formats such as CSV, XML, and JSON', 'Requires strong analytical ability and attention to detail', 'Ability to work independently with little supervision', 'A burning desire to tackle hard problems and create sustainable solutions', 'Experience using Amazon Web Services', 'Experience in or exposure to the nuances of a startup or other entrepreneurial environment', 'Strong expertise with scripting languages such as Python, Ruby, Perl', '2+ years Master Data Management experience including data consolidation, linkage, federation and dissemination', 'Current possession of a U.S. security clearance or the ability to obtain one']",2020-09-24 13:44:12
Data Engineer (Python/Postgres),"Omicron Media, Inc.",N/A,Florida,"['We build cutting-edge technology that is literally changing how the world consumes online content.', 'We get to collaborate with really smart, interesting people every day.', 'Omicron rewards its team with really fun company events. Past events include food trucks on-site for lunch, private movie screenings, tickets to charity galas and more!', 'Develop queries to aggregate data considering performance and runtime.', 'Work with data sources that are supplied in batch or near real-time streams.', 'Troubleshoot and performance-tune large datasets.', 'Integrate with REST APIs in Python.', 'Owner-level experience with PostgreSQL – indexes, materialized views, parent/child tables.', 'Familiarity with Python & Pandas.', 'Experience in writing analytic queries in SQL.', 'Familiarity with some other relational database platforms such as MySQL or MS SQL Server.', 'Familiarity with automated workflows in Airflow, cron, or another tool.', 'Data analysis experience with SQL and other programming languages.', 'Basic quantitative skills that will allow the successful use of data in business processes.', 'Experience in basic Linux server administration: ssh, rsync, etc.', 'Other scripting experience: Go, PHP, Perl', 'Knowledge of common Linux tools for text processing: awk, sed, grep', ""Bachelor's degree in Computer Science, Information Technology, Math, or related quantitative experience."", 'As Data Engineer you will report to the Business Intelligence Team in our Winter Park, FL office. The position is open to local and remote candidates.']",2020-09-24 13:44:12
Data Engineer,ShopKeep,3.1 out of 5,"New York, NY 10016","['You are passionate about working with data to solve business problems and will build and maintain the infrastructure to answer questions with data.', ""We have a big data warehouse with data ranging from merchant transactions to Zuora billing to Product usage. You'll model new constructs and improve existing ones."", 'Help streamline our data science workflows, adding value to our product offering and building out our customer life cycle and retention models.', ""All of our teams are hungry for insights. You'll work with stakeholders across the company, fielding abstract requests. This may involve pointing someone to the answer, teaching them how to fish, or ticketing a large project for later."", 'SQL (3 or more years of experience)', 'Python (3 or more years of experience)', 'Data visualization / exploration tools (1 or more years of experience)', 'Communications skills, especially of technical concepts to non-technical business leaders', 'Familiarity with the AWS ecosystem specifically RedShift and RDS', 'Attention to detail', 'Looker experience', 'Building or maintaining ETL processes', 'Ability to juggle multiple projects', 'Experience with Git', 'Medical, Dental, and Vision Insurance', 'Flexible Paid Time Off (PTO)', 'Commuter Benefits', '401k Match', 'Lively and enriching Engineering culture', 'Regularly scheduled hackathons, meetups and Tech Talks', 'Opportunity to attend Engineering Conferences, thanks to our generous company conference budget', 'Newsletters produced by Engineering teams', 'Cross-office collaboration between our NYC and Belfast teams with the opportunity to travel to our different offices', 'Regular team events, including Happy Hours and Game Nights', 'Catered lunches', 'Break area to play and relax', 'Standing desks', 'Meditation Sessions', 'And more to come as we work on ideas to help us keep the community feel connected while working remote']",2020-09-24 13:44:12
Data Engineer - Monitoring Solutions,CDO Chief Digital Office,N/A,"Dallas, TX","['Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.', 'Have experience with ""full stack"" (ETL-> Production/iteration) and experience apply data insights in industry.', 'Working experience with Tableau, Kibana, Graphene, Matplotlib, Jupyter, or similar data visualization tools.', 'Understanding of dimensional modelling concepts and database design/architecture or experience with feature engineering both at model build and in production', 'Extensive experience using Python/Java including a strong grasp of object-oriented programming (OOP) fundamentals', 'Extensive experience analyzing data using SQL', '2+ years of Python or Java development experience', '2+ years of SQL experience (NoSQL experience is a plus)', '2+ years of experience with schema design and dimensional data modeling', 'Ability in managing and communicating data warehouse plans to internal clients', '3+ years of relevant experience such as implementing statistical analysis, developing cloudbased data-lake / data warehouses, managing data science projects, developing APIs, developing machine learning models, creating advanced data visualizations.', 'Good communication and writing skills to facilitate productive collaboration with other team members and business units;', 'Strong knowledge of project management principles and concepts;', 'Experience solving problems with an emphasis on product development', 'Experience with predictive modeling and dissemination of research results;']",2020-09-24 13:44:12
Software Engineer - Data Automation,Syndigo,3.6 out of 5,"Nashville, TN 37204","['Partner with Data Management and Product teams to automate common data processes', 'Provide technical expertise for diagnosing data issues, recognizing common patterns and tracing issues to root cause', 'Write scripts to create ad hoc extracts of content, and ad hoc reports', 'Perform data imports, and batch content updates', 'Estimate, track, and communicate status of assigned items to a diverse group of stakeholders', '3+ years experience in developing software using relevant technologies', 'C# and .NET core, JSON, XML', 'API development, integration and maintenance through C# and .NET core', 'Import and Export feeds development and maintenance through C# and .NET core', 'Data transmission through messages, FTP file transfer, Amazon S3', 'Experience with development in cloud computing environment – Microsoft Azure', 'Experience with blob storage, service bus, durable messaging etc.', 'Git and Gitlab', 'Excellent analytical and problem-solving skills', 'Ability to work collaboratively with cross functional stakeholders', 'Detail oriented and analytical mindset, ability to recognize issues in data']",2020-09-24 13:44:12
Sr. Data Engineer,Protocol Labs,N/A,Remote,"['Partner with project and enablement leaders to understand data needs and translate them into data models that are easy to understand and use.', 'Set up, maintain, and scale our data infrastructure, including a data warehouse, pipelines, and visualization tools.', 'Build, maintain, and scale our data ingestion engine, gathering data from our networks, products, communities, systems, and other sources.', 'Build and enforce a pattern language across our data stack, ensuring that our definitions, taxonomy and tables are consistent, accurate, and well-understood.', 'Develop and maintain documentation to enable Labbers to understand our data and conduct analysis that drives actionable insights. Support project and enablement teams with core analytics and dashboards that guide day-to-day operations, planning, and strategic decision making.', 'Champion Protocol Labs’ strategy for data governance, privacy, security, quality, and retention, ensuring compliance with legal and business requirements.', 'Build, lead, and elevate the data team.', 'Have 8+ years of software development experience with 4+ years of data engineering.', 'Have demonstrated experience with data warehousing, data modeling, and building ETL pipelines .', 'Are fluent in several programming languages such as Python, Scala, SQL, or HQL (Plus)', 'Have experience in data processing using traditional and distributed systems (e.g., Hadoop, Spark, Airflow) or have experience in data processing using AWS solutions (e.g., AWS Glue, AWS Lambda, etc)', 'Have strong interdisciplinary collaboration skills, with the ability to communicate effectively verbally and in writing.', 'Experience with and passion for open source software is a strong plus.', 'Can guide the team to adopt and deploy new technologies and best practice designs.']",2020-09-24 13:44:12
Lead Data Engineer (Remote),CarMax,3.7 out of 5,"Richmond, VA 23238",[],2020-09-24 13:44:12
General Engineer/Physical Scientist (Data Scientist),US Other Agencies and Independent Organizations,3.8 out of 5,"Washington, DC","['Support the National Fuels Program by identifying, researching, designing, and evaluating Information Technology (IT) solutions for air quality policy and regulatory problems and issues;', 'Develop software applications to measure, forecast, mine, model, and manage data related to regulatory and/or compliance programs;', 'Develop, enhance, maintain, and implement new and existing systems, databases, and user interfaces that could include, but are not limited to, software and major enhancements to existing systems and analytical applications that support the fuels compliance programs;', 'Propose and develop new policies and revise existing policies and guidelines for collecting, quality assuring, and accessing data needed by internal and external partners.', 'Job family (Series)1301 General Physical Science0801 General Engineering', ""RequirementsRequirementsConditions of EmploymentYou must be a U.S. citizen.If you are selected, a pre-employment background check is required.You must submit a resume and required documents-see How to Apply section.Position has education requirements-see Qualifications/Education section.EPA and non-EPA applicants must submit transcripts/course listings.You may be required to travel less than 25% of each month.This position is designated as Moderate Risk and requires a background investigation. Unless an appropriate background investigation is already on record with the Office of Personnel Management, you must undergo a background investigation. All conditions of the pre-employment security process must be met before an official letter of employment can be issued with a report for duty date.If you are selected, you may be required to complete a one-year probationary period.QualificationsIn addition to the educational requirements, we are looking for at least one year of specialized experience related to this position as described below:To qualify for the GS-12 level, you need to have at least one year of full-time experience equivalent to the GS-11 level defined as designing, implementing, and modifying enterprise data information systems/software; data mining of datasets.Your application package will be used to evaluate your competencies in the following areas: 1) Knowledge of data information systems/software; 2) Skill in software development; 3) Skill in data modeling/analytics; 4) Skill in building and maintaining professional relationships; 5) Skill in written communication.Experience refers to paid and unpaid experience, including volunteer work done through National Service programs (e.g., Peace Corps, AmeriCorps) and other organizations (e.g., professional, philanthropic, religious, spiritual, community, student, social). Volunteer work helps build critical competencies, knowledge, and skills and can provide valuable training and experience that translates directly to paid employment. You will receive credit for all qualifying experience, including volunteer experience.If you have part-time work experience, read this: EPA Announcement Policies and Procedures.EducationYou need a degree or combination of education and experience as described below to qualify for this position.Engineering: All applicants must meet one of the following requirements to qualify for consideration for an engineering position:Successful completion of a professional engineering degree at an accredited university or collegeORHave a combination of college level education or training AND technical experience that has furnished you with (1) a thorough knowledge of the physical and mathematical sciences underlying professional engineering, and (2) a good understanding, both theoretical and practical, of the engineering sciences and techniques and their applications to one of the branches of engineering. The adequacy of such background must be demonstrated by one of the following:Professional registration as an engineer.Evidence of passing the Engineer-in-Training written test.Successful documented completion of at least 60 semester hours of courses in the physical, mathematical, and engineering sciences as described by OPM.Successful completion of a curriculum leading to a bachelor's or higher degree from an accredited or pre-accredited college or university in engineering technology or in an appropriate professional field and at least 1 year of professional engineering experience acquired under professional engineering supervision and guidance.Please review the OPM page on specifics about required curriculum and for more information on qualifications, please visit GS-800: All Professional Engineering Positions qualifications.Physical Science: You must have a bachelor's or higher degree from an accredited or pre-accredited college or university in one of the following: physical science, engineering, or mathematics that included 24 semester hours in physical science and/or related engineering science such as mechanics, dynamics, properties of materials, and electronics; OR a combination of education and experience with education equivalent to one of the majors listed that included at least 24 semester hours in physical science and/or related engineering science, plus appropriate experience or additional education.For information about accreditation requirements, visit EPA Announcement Policies and Procedures.Additional informationExcept in special circumstances, those new to the federal government will be hired at the starting salary (step 1) of the applicable grade range listed above.EPA participates in E-Verify. E-Verify is an Internet based system operated by the Department of Homeland Security (DHS) in partnership with the Social Security Administration (SSA) that enables participating employers to electronically verify the employment eligibility of their newly hired employees. For additional information: EPA Announcement Policies and Procedures.Are you a Displaced Federal Employee? If so, please read the Required Documents section and visit the EPA website for additional information: EPA Announcement Policies and ProceduresPosition has portable work and selectee may be authorized to telework after meeting eligibility requirements if approved by the supervisor/manager.If you are selected, travel, transportation, and relocation expenses will not be paid by EPA. Any travel, transportation, and relocation expenses associated with reporting to work in this position will be your responsibility.This position is in the bargaining unit.How You Will Be EvaluatedYou will be evaluated for this job based on how well you meet the qualifications above.This position is being filled through the Office of Personnel Management’s government-wide direct-hire authority. Under the provisions of the direct-hire authority, category rating, veterans’ preference, and traditional rating and ranking of applicants do not apply. All eligible applicants will be forwarded to the selecting official for further consideration, and you may be subject to assessments during the selection process. If you are selected, we will review your resume and required documents to ensure you meet the qualification requirements.To preview questions please click here.Background checks and security clearanceSecurity clearanceNot RequiredDrug test requiredNo"", 'You must be a U.S. citizen.', 'If you are selected, a pre-employment background check is required.', 'You must submit a resume and required documents-see How to Apply section.', 'Position has education requirements-see Qualifications/Education section.', 'EPA and non-EPA applicants must submit transcripts/course listings.', 'You may be required to travel less than 25% of each month.', 'Successful completion of a professional engineering degree at an accredited university or college', 'Have a combination of college level education or training AND technical experience that has furnished you with (1) a thorough knowledge of the physical and mathematical sciences underlying professional engineering, and (2) a good understanding, both theoretical and practical, of the engineering sciences and techniques and their applications to one of the branches of engineering. The adequacy of such background must be demonstrated by one of the following:', 'Professional registration as an engineer.', 'Evidence of passing the Engineer-in-Training written test.', 'Successful documented completion of at least 60 semester hours of courses in the physical, mathematical, and engineering sciences as described by OPM.', ""Successful completion of a curriculum leading to a bachelor's or higher degree from an accredited or pre-accredited college or university in engineering technology or in an appropriate professional field and at least 1 year of professional engineering experience acquired under professional engineering supervision and guidance."", 'Required DocumentsRequired DocumentsDocuments to be submitted online:NOTE: You should ensure your social security number, date of birth, and any other personal information are redacted.-Resume clearly stating your experience related to this position as described in the Duties section and Qualifications section. In describing your experience, you need to be clear and specific. We may not make assumptions regarding your experience.-Responses to the online assessment questionnaire (you must complete this online - it is not a document you need to upload).-College transcripts - required to submit either unofficial transcripts or a list of courses that includes school(s) attended, school address, course title, grades earned, completion dates, department, and quarter or semester hours earned. NOTE: Official educational transcripts are not required at the time of application; however, if you are selected, you must provide official transcripts before you start work with EPA.-Displaced Federal employees under ICTAP/CTAP: copy of your most recent performance appraisal, proof of eligibility, and your most current SF-50 noting position, grade level, tenure, and duty station.To learn more about submitting documentation, visit Uploading Documents to USAJOBS.If you are relying on your education to meet qualification requirements:Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education.Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.', '-Resume clearly stating your experience related to this position as described in the Duties section and Qualifications section. In describing your experience, you need to be clear and specific. We may not make assumptions regarding your experience.', '-Displaced Federal employees under ICTAP/CTAP: copy of your most recent performance appraisal, proof of eligibility, and your most current SF-50 noting position, grade level, tenure, and duty station.', 'BenefitsBenefitsA career with the U.S. Government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Learn more about federal benefits.Join EPA in protecting human health and the environment and enjoy many work life quality options! Working for the EPA offers you a comprehensive benefits package that includes, in part, paid vacation, sick leave, holidays, life insurance, health benefits, and participation in the Federal Employees Retirement System. To learn more about us, visit Life and Careers at EPA.Review our benefitsEligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time, or intermittent. Contact the hiring agency for more information on the specific benefits offered.', 'The publicU.S. citizens, nationals or those who owe allegiance to the U.S.']",2020-09-24 13:44:12
Bioinformatics Engineer,Data Driven Bioscience,N/A,"Durham, NC","['Flexible schedule', 'Health insurance', 'Paid time off', 'Relocation assistance', 'Monday to Friday', 'Fully Remote', 'ddb.bio']",2020-09-24 13:44:12
Senior Data Engineer/Analyst,Inspur USA Inc.,N/A,"Bellevue, WA 98007","['We are looking for a Jr. Data Analyst/Engineer to support the Data Management Project.', 'Co-ordinate with Internal Stakeholders, FTEs and Inspur Team.', 'Ability to learn quickly and work independently while dealing with ambiguous data points and situations with a strong positive attitude.', 'Build and design PowerBI dashboards to enable ongoing monitoring of business health.', 'Acquire data from primary or secondary data sources and maintain databases/data systems', 'Work with data engineers to operationalize dashboards and ingest new data sources.', 'Maintain detailed reporting of all activities keeping stakeholders informed and prepare project metrics and reports.', ""Ensure compliance with the company's policies."", '1-2 years heads on data analytics experience', 'Develop and implement SQL databases, SSAS cubes and ETLs.', 'Coding skills in languages such as C#, Python, Java Script.', 'BS in Mathematics, Computer Science, Information Management or Statistics', 'Familiarity with Microsoft Azure ecosystem and Microsoft BI tools.', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'Java Script: 1 year (Preferred)', 'data analytics : 2 years (Preferred)', 'C#: 2 years (Preferred)', 'Python: 2 years (Preferred)', 'Microsoft Azure ecosystem and Microsoft BI tools: 2 years (Preferred)', ""Bachelor's (Preferred)"", 'Temporarily due to COVID-19']",2020-09-24 13:44:12
Data Analyst (Contract),Lumere,N/A,Remote,"['Connect and map key data sets utilized by Lumere’s solutions', 'Develop and monitor metrics related to data mapping and data quality', 'Collaborate with analyst and engineering teams to automate processes for consistent and efficient analysis', 'Maintain Standard 40 hour work week during regular business hours in a remote/ telecommute capacity', 'Professional experience analyzing and finding insights in large data sets', 'Proficient in SQL and MS Excel', 'Familiarity with healthcare data a plus', 'Detailed oriented with a demonstrated track record of accomplishing goals and meeting deadlines']",2020-09-24 13:44:12
Data Engineer,Freestar,4.3 out of 5,Arizona,"['Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.', 'Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.', 'Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.', 'Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.', 'Writes unit/integration tests, contributes to engineering wiki, and documents work.', 'Works closely with a team of frontend and backend engineers, product managers, and analysts.', 'Defines company data assets (data models), SQL, Airflow to populate data models.', 'Designs data integrations and data quality framework.', 'Build dashboards that concisely and succinctly convey business metrics.', 'Designs and evaluates open source and vendor tools for data lineage.', 'Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.', 'Knowledge of best practices and IT operations in an always-up, always-available service', 'Experience with or knowledge of Agile Software Development methodologies', 'Excellent problem solving and troubleshooting skills', 'Process oriented with great documentation skills', 'Excellent oral and written communication skills with a keen sense of customer service', 'Ample relevant knowledge and experience. You either have a BS or MS degree in Computer Science or a related technical field OR + 2 years of experience in a role as a data engineer', 'Proficiency in one Python and Java, Scala, or Go development experience', '4+ years of SQL experience (Strong SQL required)', 'Familiarity with BI reporting tools like Tableau, Looker.', '4+ years of experience with schema design and dimensional data modeling', 'Ability in managing and communicating data warehouse plans to internal clients', 'Experience designing, building, and maintaining data processing systems', 'Experience working with either a Map Reduce or an MPP system on any size/scale', 'Experience/knowledge of cloud computing platforms like AWS/GCP would be a plus', 'Excellent interpersonal and problem solving skills with the ability to communicate with team members to deliver actionable results', 'Comfortable interacting across multiple teams and management levels within the organization', 'Previous background in the ad tech or media landscape (linear, digital, or social) is a plus', 'Full-Time, Salaried Position', 'Medical, Dental, and Vision benefits', '401K with company match, vested immediately', 'The opportunity to be part of something BIG']",2020-09-24 13:44:12
Data Engineer/ETL Specialist,"Keypoint Intelligence, LLC",N/A,"Weymouth, MA 02189","['Data Intuition', 'Data Visualization & Communication', 'Data Wrangling', 'Data Warehousing', 'Statistics', 'Programming Skills - Low Code, Workflow, .NET', 'Knowledge in Machine Learning', 'DOMO (or other reporting platform, such as', 'KNIME (or other ETL/Worflow Automation platform)', 'SQL Server', 'VB or C#', 'Outsystems (or other low-code platform)']",2020-09-24 13:44:12
Data Engineer,Beshton Software,N/A,"San Francisco Bay Area, CA","['Develop mathematical analysis models to use in development of Beshton’s website applications for identifying product marketing influence and other software products to assist clients in improving their business operations;', 'Apply knowledge of statistics and mathematics to software data analysis and provide analytical support on big data projects;', 'Assemble data such as product news and process the data to use in analysis, utilize analytical methods including regression analysis and hypothesis testing;', 'Design and analyze statistical algorithms for use in software, collaborate with application developers to ensure the mathematical accuracy of the platform;', 'Perform complex analysis computations to validate software models and algorithms, identify discrepancies, and develop solutions;', 'Disseminate analysis results through presenting reports with data visualizations to explain analysis process and results to peers and management.']",2020-09-24 13:44:53
Senior Data Engineer,Tend,N/A,"Nashville, TN 37215","['Our comprehensive benefits & perks program will make you grin.', 'Employer-sponsored healthcare coverage, 401(k) with an employer match, generous paid time off, a pre-tax commuter benefit, and much more!', '$102,859.00 - $130,000.00 per year', 'Benefits:', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Design, implement and maintain reporting databases, data warehouse and OLAP data structures', 'Design, develop, test, deliver, and implement SQL solutions within ETL processes.', 'Manage day to day operations of multiple Microsoft SQL Server/Postgres databases.', 'Optimize databases for performance and scalability.', 'Develop, implement and optimize stored procedures and functions using T-SQL', 'Analyze, define, and document system requirements for data, workflow, logical processes, interfaces with other systems, internal and external checks and controls, and outputs.', 'Responsible for problem resolution, database configuration, capacity planning, performance tuning and optimizations.', 'Create and maintain database master plans, data dictionaries and disaster recovery documentation', 'Consults with internal and external clients to prototype, refine, test, and debug databases and obtain client approval.', 'Writes and maintains documentation to describe program development, logic, coding, testing, changes, and corrections.', 'Design, build, and deploy BI solutions (Looker)', 'Responsible for on-call emergency response during database failure.', 'Develops and maintains professional relationships', 'Promotes good working relationships among staff and between other disciplines and departments. Assumes individual accountability for own conduct and maintenance of professional attitude and appearance.', 'Approaches change in a positive manner, motivate staff to work as a team, accept constructive criticism and learn from it.', 'Must be able to apply principles of critical thinking to a variety of practical and emergent situations and accurately follow standardized procedures that may call for deviations.', 'Must be able to apply sound judgment beyond a specific set of instructions and apply knowledge to different factual situations.', 'Must be able to work under stress on a regular or continuous basis.', '5+ years of experience with MSSQL/TSQL/BI', '3+ years or more ETL concept exp', 'Bachelor’s degree.', 'Knowledge of dimensional and relational database models', 'Experience with web services (Both REST and SOAP).', 'Some programming experience.', 'Experience with MSSQL and/or Postgres', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Monday to Friday', 'Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', 'Temporarily due to COVID-19']",2020-09-24 13:44:53
Data Engineer,"Arctic Information Technology, Inc.",3.7 out of 5,Remote,"['Thorough understanding of legacy data models (through analysis and investigation) to complete data migration and integration', 'Design, create, and maintain the Dynamics 365 entity model to support extended functionality for Client needs', 'Creates data models utilizing best practices to ensure optimal and acceptable performance', 'Create and manage data flow diagrams and responsible for understanding the overall data ecosystem of large enterprise systems', 'Create data mappings and data migration plans', 'Designs and implements data integrations between disparate systems', 'Create and manage SQL database(s) used for data archiving and/or report servers, and other needs for Arctic IT Clients utilizing Microsoft Azure SQL and SQL Server', 'Work with project teams on reporting related questions, tasks, and implementation', 'In coordination with development and/or QA team members create and execute load testing plans to validate database performance', 'Coordinate with project Architects to ensure consistency in implementation tools and processes among the various systems.', 'Responsible for data privacy and security and ensuring compliance with federal, state, and other applicable laws', 'Functions as the liaison to work with Client IT or other team members as it relates to data to ensure the work is completed and transitioned', 'Functions as a data Subject Matter Expert and accountable to the Senior Program Manager regarding data (questions, challenges, risks, etc.)', 'Other duties as assigned', 'Excellent written and verbal communication', 'Proven problem-solving skills and very deadline-oriented', 'Able to rapidly build and sustain long-term relationships, based on trust and consistent delivery to expectations', 'Enhance own development by taking responsibility for staying informed and up to date with industry knowledge Ability and desire to grow and mentor solution consultants with data migration tasks and knowledge', 'Bachelor’s degree in Business, Computer Science, or equivalent education and experience', 'Minimum 5 years of experience working in Microsoft SQL data initiatives such as data integration, database administration, data migration, reporting, etc. with progressive responsibilities', 'Excellent Microsoft SQL Server skills: Certifications preferred but not required', 'Expertise in Extract-Transform-Load process definition and execution', 'Expertise with data migration tools such as, SSIS, Scribe, Kingsway Soft', 'Knowledge of the Microsoft Power Platform including LogicApps', 'Experience supporting performance and load testing, analysis, and evaluation of results, and providing recommendations', 'Skilled in understanding and maintaining data integrity, developing documentation, and ability to be accountable for overall data validation', 'Able to assimilate unstructured information and produce clear data plans for large enterprise-level IT projects', 'Must have valid state driver’s license, reliable personal transportation, and auto insurance', 'Applicants subject to government security investigations and must meet eligibility requirements related to the clearance process', 'Except as provided otherwise under applicable law, all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, or national origin. We are also an equal opportunity employer of individuals with disabilities and protected veterans.', 'Please view Equal Employment Opportunity Posters provided by OFCCP.']",2020-09-24 13:44:53
Jr. Mobile Engineer,Betterment LLC,N/A,United States,"['Mission: Partnering closely with product and design to build dynamic and engaging user experiences that empower our customers to live better lives', 'Tech: Building best-in-class financial products using state-of-the-art tech and design patterns. Utilizing RX and Flutter for reactive data flows and composable UIs', 'Quality: Releasing polished features and minimizing bugs via feature gating, CI/CD, automated testing, and observability', 'Iteration: Shipping early and often in a fast-paced, experiment driven product development process', 'Experience or interest in learning to build interactive iOS or Android applications using Objective-C, Swift, Java, or Kotlin.', 'Experience or interest in learning Dart and Flutter to help propel us as we continue to lean into this exciting and promising cross-platform stack.', 'Collaborativeness and excitement to partner with your teammates.', 'The ability to thrive in a startup environment', 'You’ll join a Community:', 'Betterment is a place to bring your best self. We welcome families (and pets) for all our activities such as lunches, company retreats, and celebrations.', 'Make meaningful connections with your peers through interest groups, sports clubs, social events, meetups, and regular knowledge sharing.', 'You’ll stay Happy and Healthy:', ""Regardless of where you are, we will ensure you're well set up and cared for, through gym reimbursements, a customizable workstation, enrollment in our 401(k) service, flexible parental leave, and a whole suite of thoughtful benefits."", 'You’ll have unlimited paid personal and vacation days, and a team that cares about your whole life, not just what you’re working on.', 'You’ll Learn & Grow:', 'Enhance your skills and abilities through Betterment University courses and additional spending for outside learning.', 'Contribute to our knowledge and transparent workspace through mentoring and career coaching programs, weekly company meetings, show & tells and BetterDev.']",2020-09-24 13:44:53
DevOps Engineer,super hero (supro LLC),N/A,"Baltimore, MD","['Pay:', '$50.00 - $70.00 per hour', 'Experience:DevOps, 5 years (Preferred)', ""Education:Bachelor's (Preferred)"", 'Work authorization:United States (Preferred)', '3+ years of experience with AWS Services (AWS Certified is preferred)', 'Strong full stack engineering experience', '3+ years of experience deploying production enterprise web applications in AWS', 'Experience in a large scale, high performance enterprise big data application deployment and solution architecture', 'BS or MS in Computer Science or related field', '8 hour shift', 'DevOps: 5 years (Preferred)', ""Bachelor's (Preferred)"", 'United States (Preferred)', 'Possible', 'No']",2020-09-24 13:44:53
Big Data Engineer,"ASAP Solutions Group, LLC",4 out of 5,"Saint Petersburg, FL 33701","['$110,000.00 - $150,000.00 per year', 'Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Retirement plan', 'Vision insurance', 'Experience:AWS, 3 years (Preferred)developing, deploying and supporting scalable data pipelines, 3 years (Required)Docker, 3 years (Preferred)Data Management, 5 years (Required)ETL Tools, 3 years (Required)Kafka, 3 years (Preferred)Graph, 3 years (Preferred) Python, 4 years (Required)Linux, 4 years (Required)', ""Education:Bachelor's (Required)"", 'Location:Saint Petersburg, FL 33701 (Preferred)', 'Design new or integrate existing tool(s) to automatically ingest, sort, tag, and organize various data sources and types according to a schema, methodology, or ontology. Prepare data for predictive and prescriptive modeling. Provide expertise / assistance in identifying and integrating applicable technologies and/or methodologies from government or commercially available sources to address needs. Translate intelligence production end state goals into machine ingestible code/tools.', 'Provide technical assistance in identifying and integrating appropriate technology solutions for data and knowledge management. Develop new or refine existing databases to ingest, sort, tag, and organize various data sources and types (structured and unstructured) according to an ontology to enable wider integration and analysis. Maintain working knowledge of AI and ML initiatives leveraging existing expertise to better meet customer needs.', 'Develop and build relationships with other data engineers developing similar tools and products. Brief leadership on new requirements to meet analytical needs and significant findings.', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Retirement plan', 'Vision insurance', 'Monday to Friday', 'AWS: 3 years (Preferred)', 'developing, deploying and supporting scalable data pipelines: 3 years (Required)', 'Docker: 3 years (Preferred)', 'Data Management: 5 years (Required)', 'ETL Tools: 3 years (Required)', 'Kafka: 3 years (Preferred)', 'Graph: 3 years (Preferred)', 'Python: 4 years (Required)', 'Linux: 4 years (Required)', ""Bachelor's (Required)"", 'Saint Petersburg, FL 33701 (Preferred)', 'Fully Remote']",2020-09-24 13:44:53
"Software Engineer, Recent Graduate",eBay Inc.,3.9 out of 5,"New York, NY 10012",[],2020-09-24 13:44:53
Expert Cloud Data Engineer,McKinsey & Company,4.3 out of 5,"Waltham, MA 02451","['Degree in computer science or engineering or related discipline; industry recognized cloud certifications, patents, open source contributions are preferred', '12+ years of experience in engineering – hands-on leader with deep engineering track record in modern tech stacks, frameworks, and programming languages', 'Extensive track record in engineering large-scale cloud, big data and analytics implementations in complex usage scenarios and migration paths', 'Expert hands-on knowledge in public cloud products, cloud-native architectures, serverless frameworks, Docker/Kubernetes, data security and integration services', 'Deep expertise in building big data ecosystems, analytics and AI/ML platforms and accelerators, data management systems using Hadoop/Spark, Tensorflow, Jupyter, HBase, BI tools, and public cloud ML tools and services', 'Experience building enterprise-grade data and analytics platforms that are highly scalable, compliant and secure with robust data quality, data governance, data discovery, catalog and visualization capabilities', 'Proficient in building large scale systems using Python, Java, or other high-performance languages, developer tools, CI/CD, DevOps, monitoring tools and engineering cloud migration solutions', 'Proven track record in enterprise wide API management, Microservices, event-driven architectures and complex integrations', 'Experience in building and leading highly effective and agile data and analytics engineering teams', 'Track record of collaboration; ability to build strong relations that enable robust debate and survive periodic disagreements regarding priorities', 'Influential without direct line management control across multiple cultural environments (Asia/India/Europe/America), other internal McKinsey units, and external third parties', 'Ability to communicate effectively with technical and non-technical audience']",2020-09-24 13:44:53
Big Data Hadoop Engineer,"Wisetek Providers, Inc.",5 out of 5,"Pleasanton, CA","['4+ years of hands-on Development, Deployment and production Support experience in Big Data environment.', '4-5 years of programming experience in Java, Scala, Python, Solr, Hbase', 'Proficient in SQL and relational database design and methods for data retrieval.', 'Hands-on experience in Cloudera Distribution 6.x', ""Must have experience with Spring framework, Web Services and REST API's."", 'Project Experience in Query Processing Language (QPL) – a search engine independent technology for Advance Query Processing is highly desirable.', 'Provide vision, gather requirements and translate client user requirements into technical architecture.', 'Design and implement an integrated Big Data platform and analytics solution', 'Design and implement data collectors to collect and transport data to the Big Data Platform.', 'Implement monitoring solution(s) for the Big Data platform to monitor health on the infrastructure', 'Project Experience in Query Processing Language (QPL) – a search engine independent technology for Advance Query Processing is highly desirable.', '4+ years of hands-on Development, Deployment and production Support experience in Big Data environment.', '4-5 years of programming experience in Java, Scala, Python.', 'Proficient in SQL and relational database design and methods for data retrieval.', 'Knowledge of NoSQL systems like HBase or Cassandra', 'Hands-on experience in Cloudera Distribution 6.x', 'Hands-on experience in creating, indexing Solr collections in Solr Cloud environment.', 'Hands-on experience building data pipelines using Hadoop components Sqoop, Hive, Solr, MR, Impala, Spark, Spark SQL.', 'Must have experience with developing Hive QL, UDF’s for analyzing semi structured/structured datasets.', ""Must have experience with Spring framework, Web Services and REST API's."", 'Hands-on experience ingesting and processing various file formats like Avro/Parquet/Sequence Files/Text Files etc.', 'Must have working experience in the data warehousing and Business Intelligence systems.', 'Expertise in Unix/Linux environment in writing scripts and schedule/execute jobs.', 'Successful track record of building automation scripts/code using Java, Bash, Python etc. and experience in production support issue resolution process.', 'Experience in building ML models using MLLib or any ML tools.', 'Hands-on experience working in Real-Time analytics like Spark/Kafka/Storm', 'Experience with Graph Databases like Neo4J, Tiger Graph, Orient DB', 'Agile development methodologies.', 'Health insurance', '8 hour shift', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-09-24 13:44:53
Systems Engineer-Data Thread,"Cyber Cloud Technologies, LLC",N/A,Colorado,"['We offer awesome benefits (Medical, Dental, Vision with 100% Company premiums, 401K Match 100% vested day 1, Competitive salaries and sign on bonuses, to name a few!)', 'Medical, Dental, Vision with 100% Company premiums, 401K Match 100% vested day 1, Competitive salaries and sign on bonuses, to name a few!)', 'Provide support and related services to the implementation of enterprise data representations in various mission domains. The successful individual will perform end-to-end systems engineering for data flows from the perspective of data format modeling, implementation, and support. This position requires strong systems engineering expertise from cradle to grave with limited, high-level direction, in the areas of:', 'Performing high-level requirements analysis to support application of data standards across the enterprise. Duties require a broad range of knowledge including information technology, requirements, technical architecture analysis (e.g., understanding data flow diagrams, system architecture diagrams, etc.), and an understanding of functional and system analysis.', 'Coordinating across teams that leverage multiple development methodologies (e.g., Waterfall, Agile (Scrum & Kanban), Spiral, etc.) simultaneously.', 'Possessing an instinctive aptitude to leverage information and knowledge sharing networks and navigate conflict in a way that fosters constructive outcomes.']",2020-09-24 13:44:53
"Associate, Data Engineer",CCC Information Services Inc.,3.7 out of 5,"Chicago, IL 60654","['Build end to end data pipelines from sources to fully curated and enhanced data sets. This can include the effort to locate and analyze source data, create data flows to extract, profile, and store ingested data, define and build data cleansing and imputation, map to a common data model, transform to satisfy business rules and statistical computations, and validate data content.', 'Produce data building blocks, data models, and data flows for varying client demands such as dimensional data, data feeds, dashboard reporting, and data science research & exploration', 'Produce automated tests of data flow components', 'Use knowledge of the business to automate business-specific tests for data content quality', 'Build automated orchestration and error handling for use by production operation teams', 'Provide technical expertise to diagnose errors from production support teams', 'Collaborate with team members in an Agile team (e.g., Scrum)', 'Participate as both leader and learner in team tasks for architecture, design and analysis', 'Coordinate within collocated on-site team members as well as remote team members', 'Bachelor’s Degree or Two-Year Technical Program with a Programming Specialization', '1+ years’ experience with complex data flows', 'Programming in a language such as Python (preferred), Scala, etc.', 'Open source big data tools such as Hive, Spark, Kafka', 'Advanced SQL for data profiling and data validation', 'Unix commands and scripting', 'Hadoop fundamentals and architecture: HDFS, map-reduce, job performance', 'Familiar with open source monitoring and orchestration tools such as Airflow, Oozie', 'Advanced transformations and statistical computations using Spark-SQL and Hive programming', 'Experience with development of metadata-driven and fully parameterized data processing applications']",2020-09-24 13:44:53
Azure Data Engineer (C2H),Primesoftinc,N/A,"Houston, TX","['Experience:Total IT, 10 years (Preferred)Data lake, 5 years (Preferred)', 'Location:Houston, TX (Preferred)', 'Total IT: 10 years (Preferred)', 'Data lake: 5 years (Preferred)', 'Houston, TX (Preferred)', 'Temporarily due to COVID-19']",2020-09-24 13:44:53
Data Warehouse Engineer,PTC,3.7 out of 5,United States,"['While your salary is the major component of your compensation, you also receive a competitive benefits package including: •', 'Retirement Savings Plan with Company Match • Employee Stock Purchase Plan (ESPP) • Healthcare and Dental insurance • Paid Time Off and Sick Time • Birthday Day-off • Tuition Reimbursement (Canada, India, Israel, US) • Holiday Pay • Employee Referral Program • Management and Employee Training Development • Other Regional-specific Benefits All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.', 'Region']",2020-09-24 13:44:53
Big Data Engineer,Avani Systems,N/A,"Seattle, WA","['Ensure high throughput of development teams by identifying potential issues, removing impediments or guiding the team to remove impediments by collaborating with the appropriate resource', 'Manage sprint planning and execution which includes the management of project progress and provide status and visibility', 'Facilitate release planning and scheduling by providing empirical Scrum team statistics, identifying project dependencies, and creating velocity forecasts', 'Assist with internal and external communications to improve transparency and radiate information ensuring the team’s progress and successes are highly visible to all stakeholders including the team itself (e.g. backlogs, burn down/up charts, etc.)', 'Develop pipelines using copy activity from different sources like FTP, Windows Blob Storage, SQL SERVER, COSMOS big data etc. and scheduling the pipelines as per requirement using azure data factory.', 'Required minimum Bachelor’s degree in Computer Science']",2020-09-24 13:44:53
Data Center Hardware Engineer,1974,N/A,"Princeton, NJ 08540","['Learn and understand the data center site in order to manage events that put our critical systems at risk', 'Organize people, communication and knowledge to support problem follow-up and data center activity', 'Perform activity impact and risk assessment along with service notification at the appropriate level of awareness', 'Maintain accuracy of documentation and recorded details of physical assets and connections', 'Detect, investigate, and drive operating system issues affecting production equipment availability', 'Perform hardware level activity including investigation, maintenance and repair of server, network components and data cabling', 'Develop familiarity with the critical systems at each data center in order to provide a high level response and escalation', 'Linux/unix knowledge sufficient to identify and interrogate system hardware, review system logs, report on file systems, and manipulate files', 'Ability to prioritize work including active data center service and projects in flight', 'Knowledge of Layer2 and 3 network concepts', 'Desire to learn and take ownership of personal development', 'Passion for educating others and improving our team capabilities', 'The ability to communicate timely and concise information to various teams throughout Engineering at the appropriate level of detail']",2020-09-24 13:44:53
Remote Lead Data Engineer (Azure),United Consulting LLC,N/A,"Las Vegas, NV","['Data Engineering/Data Warehousing development/operations experience of at least 10 years', 'Azure cloud experience of at least 3 years with ADF V2, ADF Data flows, Azure Databricks, SQLDB/Hyperscale, SQLDW, ADLS Gen 2, and other Azure services', 'Python & PySpark development', 'SQL development including PL/SQL, preferably SQL Server but another RDBMS may be fine', 'Managing an offshore team', 'Good communication (verbal & written) & documentation skills', 'Development using ETL tools like DataStage or Informatica', 'ADF source code version control using Azure DevOps or Git', 'Experience with Snowflake', 'Collaboration with business teams', 'Experience in fast-paced & complex environments, including large enterprise settings', 'Monday to Friday', 'Yes']",2020-09-24 13:45:34
Sr. Data Platform Engineer – remote 12 months contract – Houston,DataSys America,N/A,"Houston, TX 77061","['Monday to Friday', 'Temporarily due to COVID-19']",2020-09-24 13:45:34
Data Engineer,Federal Reserve Bank of Chicago,3.9 out of 5,"Chicago, IL 60604","['Build data architecture to support data strategy', 'Provide guidance and share best practices on data architecture and design', 'Help create the data management strategies to support business intelligence efforts for different partners', 'Lead the design of the logical data model and implement the physical database structure', 'Constructs and implements operational data stores and data marts', 'Provide support for deployed data applications and analytical models by being a trusted advisor to Data Scientists and', 'other data consumers by identifying data problems and guiding issue resolution', 'Develop real-time and batch ETL data processes aligned with our needs (on-premise and in the Cloud)', 'Manage and expand the data pipeline from raw OLTP databases to data solution structures', 'Document data flow diagrams, security access, data quality and data availability across all business systems', ""Bachelor's degree in Computer Science, related field or equivalent experience"", 'One or more years of relevant work experience', 'Knowledge of data design and architecture', 'Experience with data warehouse technical architectures and ETL/ELT processes', 'Knowledge of scripting languages, such as Python', 'Experience with data related tools and services in AWS Cloud such as DMS, RedShift, RDS, or Glue', 'Knowledge and understanding of big data tools and software', 'Experience with ETL tools (Informatica, nice to have)', 'Comprehensive benefits package include medical, dental, vision, prescription drug coverage, 401k savings plan, retirement plan, paid time off, transit benefit, onsite gym and subsidized cafeteria', 'A continuous learning environment with opportunities to gain new skills and grow your career', 'Applicants must be authorized to work in the United States without the need for visa sponsorship now or in the future.', 'As a condition of employment, Federal Reserve Bank of Chicago employees must comply with the Bank’s ethics rules, which generally prohibit employees, their spouses/domestic partners, and minor children from owning securities, such as stock, of banks or savings associations or their affiliates, such as bank holding companies and savings and loan holding companies. If you or your spouse/domestic partner or minor child own such securities, and would not be willing or able to divest them if you accepted an offer of Bank employment, you should raise this issue with the recruiter for this posting, who can provide you contact information for our ethics official if necessary.']",2020-09-24 13:45:34
Sr. Data Engineer,Staff Smart,N/A,"Irvine, CA","['Build, update and maintain stream processing pipelines that contains a massive, rich, and connected set of data that supports the company’s programming decisions', 'Build data expertise for the awesome pipelines you build', 'Build highly available and resilient processes', 'Build software and social glue between engineers, scientists, product managers, and other analytics teams', 'Give the company’s data the zoomies', 'Collaborate with product and engineering teams in multiple projects building forward thinking, innovative data solutions that up-level our features and get results in a data driven way.', 'Build highly scalable resilient data pipelines and models which produce high quality datasets.', 'Deliver visualizations that distill clear, actionable insights from large, complex datasets.', 'Improve our tooling by building generic data features such as data quality and anomaly detection and drive overall improvements in our data infrastructure.', 'Drive ideas and projects through deep understanding of our data and how it applies in the broader sense of the organization.', 'BS or equivalent experience in Computer Science', 'Minimum of 5 years of work experience', 'Great application development skills. The company’s programs are written in Python, Scala, and Java. Any 2 of these will do.', 'Data stream processing using Flink', 'Batch processing using Spark', 'AWS (S3, SQS, SNS, Lambda, EMR, VPCs)', 'On-prem, Kafka, HDFS, and MPP DBs', 'Knowledge of data warehouse techniques that will make the systems awesome', 'Know how to work with analytics, security, & data science people', 'Team-based software development tools and best practices', 'Experience with Vertica a plus', 'Strong SQL skills preferred', 'You have expertise in building and designing distributed systems.', 'Talent matters but so does curiosity, inventiveness, and passion for your craft.', 'You have strong and well-formed ideas that are weakly held; you can discuss, listen, and participate in a passionate debate that may make you reconsider.', 'You create code that is understandable, simple, clean, and want to frame it and hang it next to your desk with pride.', 'Given context, you are capable of self-direction.', 'You enjoy exploring new technologies and taking them for a spin.']",2020-09-24 13:45:34
Entry Level - Associate Business Transformation Consultant,IBM,3.9 out of 5,United States,[],2020-09-24 13:45:34
Voice-of-Customer Data Engineer,Lenovo,3.9 out of 5,"Morrisville, NC",[],2020-09-24 13:45:34
Administrative Specialist,"DeKalb County, GA",3.5 out of 5,"DeKalb County, GA",[],2020-09-24 13:45:34
Sr. Data Engineer,Innovien Solutions,N/A,"Atlanta, GA","['6+ years of experience hands on technical within Data Engineering (ETL, data modeling, data analysis, data governance)', 'Extensive experience building out data pipelines, data lakes, data warehouses/marts utilizing data analysis tools such as: Hadoop, Spark, SQL, NoSQL, Elastic Map Reduce (EMR), etc.', 'Enterprise level experience', 'Experience with Java, Scala, or Python programming languages', 'Exposure to Agile environment', 'Great communication, problem solving abilities, and collaboration skills to work across various cross-timezone teams']",2020-09-24 13:45:34
Data Analytics Engineer,ABC INFORMATION TECHNOLOGY GROUP,N/A,"Spring, TX","['Monday to Friday', 'Analytics Skills - Azurre, DEVOPS, Python: 5 years (Required)', ""Bachelor's (Required)"", 'United States (Required)', 'Temporarily due to COVID-19']",2020-09-24 13:45:34
Data Engineer - Remote,Workforce Logiq,3.1 out of 5,"Fort Lauderdale, FL 33309","['Performing data integration related work which includes Ad stack Tech integration, BI continuity and other data integration required for running our business""', 'Python', 'Cloud experience – preferably GCP (airflow experience)', 'Bachelor’s Degree in Computer Science or a related discipline', '5+ years of applicable engineering experience', 'Strong proficiency in Python with an emphasis in building data pipelines', 'Ability to write complex SQL to perform common types of analysis and aggregations', 'Experience with Apache Airflow or Google Composer', 'Detail-oriented and document all the work', 'Ability to work with others from diverse skill-sets and backgrounds', 'Experience with version control systems (Git and Bitbucket)', 'Experience with Atlassian products Jira and Confluence', 'Experience with Docker containerization', 'Knowledge of Application Programming Interfaces']",2020-09-24 13:45:34
Data Scientist / Engineer - Machine Learning (Entry-Level) -- EOSL,Georgia Tech Research Institute,4.2 out of 5,"Atlanta, GA 30318","['Develop innovative algorithms and apply machine learning/deep learning methods to EW applications', 'Run simulations and algorithm optimizations', 'Curate data and write automation scripts', 'Write and perform software tests supporting software verification and document outcomes', 'Perform other duties as assigned', ""A Bachelor's degree in Electrical engineering, computer engineering, computer science, or a related technical field."", 'A Master’s degree in Electrical engineering, computer engineering, computer science, or a related technical field and three (3) years of relevant full-time experience after completion of that degree,', 'A Master’s degree in Electrical engineering, computer engineering, computer science, or a related technical field and five (5) years of relevant full-time experience after completion of a Bachelor’s degree, or', 'A Doctoral degree in Electrical engineering, computer engineering, computer science, or a related technical field.', 'Experience with machine learning and/or genetic programming methods through full-time employment, coursework, internship, student employment, or freelance', 'Experience with Python (including numPy, sciPy, pandas, matplotlib) and C++', 'Experience with Linux and Git', 'Experience with Evolutionary Multi-objective Algorithm Design Engine (EMADE) tool set', 'Experience with Modeling and Simulation (M&S)', 'Experience with Matlab, Fortran, or Ada', ""A Master's degree in electrical engineering, computer engineering, computer science, or a related technical field""]",2020-09-24 13:45:34
Data Engineer,Saggezza,3.7 out of 5,"Chicago, IL 60606","['Working across multiple clients and industries to add value and strategic insights within data & analytics.', 'Cleaning and preparing data for analysis and processing', 'Providing proficiency in analyzing data and formulating insights/conclusions.', 'Building, developing and maintaining reporting systems that support key business decisions.', 'Helping clients reach solutions by utilizing data management & operations, data quality & governance, cloud transformation, self-service analytics & visualization, and data intelligence.', 'Working hands-on with SQL/SQL server & Python to deliver analytics to clients.', 'Examining and reporting results to stakeholders in leadership, technology, marketing, sales, and product teams.', 'Entrepreneurial spirit: We seek individuals who enjoy contributing to the growth of an organization and who show commitment to the success of their team.', 'Problem-solving skills: Individuals at our company have well-honed analytical skills coupled with business acumen to structure problems, deliver solutions, and communicate insights.', 'Drive: Our team sets ambitious goals and seeks energetic professionals, enjoy a fast pace environment, and thrive in taking on responsibility.', ""A Bachelor's in Computer Science, Information Technology, Mathematics, Engineering or an equivalent field."", '3+ years of practical hands-on experience working within data modeling, data extraction, data manipulation, and data warehousing concepts.', 'Minimum of 2+ years of practical hands-on experience working with SQL/SQL Server and Python for analytics and data science purposes.', 'Strong understanding of data modeling and entity-relationship diagrams', 'Demonstratable experience writing complex SQL queries, including but not limited to stored procedures, functions, views, and triggers.', 'Knowledge of Indexes and how they can be used to enhance query performance.', 'Proficiency in modern data tools and cloud technologies would be advantageous, including but not limited to Spark, Hadoop, Tableau, AWS, Azure, Kafka, GCP & IBM Cloud.', 'Analytical mindset and business acumen. Self-motivated, individual contributor.', 'Great communication and data-oriented personality with strong problem-solving skills.', 'Experience with analytic modeling in a scripting language (Python, R, etc.).', 'An understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.', 'Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc (Depending on specific project requirements).', 'Cloud certification, or any certification related to database or BI Tools.', 'Diverse culture, experiences, and skills.', 'Our nurturing and supportive environment fosters collaboration across the entire organization.', 'We are not hierarchical but operate as a flat surface where every opinion matters, ideas are cultivated and innovation is encouraged.', 'At Saggezza, we are fortunate to have a strong mentorship program that provides every one of our employees the ability to thrive professionally and personally.', 'We are only as good as our people. Saggezza, Italian for wisdom, is rooted from the perspective that knowledge is power. We create thought-leaders who are constantly exposed and trained in different technologies in the ever-evolving world of software development.', 'We welcome innovators with entrepreneurial spirits to grow with our team.', 'Consulting Magazine - Fastest Growing Firms 2019', 'Built-In Top Places to Work in Chicago 2020', 'Best and Brightest Companies in the Nation 2019 and 2020, Best and Brightest Companies in Milwaukee 2020 and Best and Brightest Companies in Chicago 2020', '2020 Inc. 5000 List - Honored as one of the fastest-growing private companies in America']",2020-09-24 13:45:34
Data Engineer I,Conde Nast,4 out of 5,"New York, NY 10007","['Build batch and streaming data pipelines using Spark, Airflow and AWS/GCP services', 'Build efficient code to transform raw data', 'Collaborate with other Data Engineers to implement a shared technical vision', 'Follow agile processes with a focus on delivering production-ready, testable deliverables, and automated code', 'Participate in the entire software development life cycle, from concept to release', 'Create new data models that are appropriately scalable, standardized, and reliable', 'BS, or equivalent industry experience in Computer Science, Software Engineering, or other related Science/Technology/Engineering/Math fields.', '1+ years experience working with data in a large enterprise', 'Experience in writing reusable/efficient code to automate analysis and data processes', 'Experience in processing structured and unstructured data into a form suitable for analysis and reporting with integration with a variety of data metric providers ranging from web analytics, consumer analytics, user behavior and advertising', 'Experience implementing scalable, distributed, and highly available systems using AWS services such Kinesis, DynamoDB, S3', 'Proficiency in Python/PySpark, Scala or Java', 'Proficiency in SQL', 'Experience with Spark, AWS ecosystem, Hadoop, Pig, Hive, Flink, or Beam.', 'Experience with orchestration tools such as Airflow', 'Experience with Git version control, and other software adjacent tools']",2020-09-24 13:45:34
"Data Analytics Developer, People Analytics",Apple,4.2 out of 5,"Seattle, WA","['Minimum 5 years of experience in an analytics and data engineering role', 'Mastery of relational databases including SQL', 'A proven foundation in data modeling, data analytics, including at least 3 years of relevant business or people analytics experience, and a commitment to data governance', 'Demonstrated ability to manage technical and non-technical partners and drive collaboration', 'Experience with Python or any scripting language', 'Experience in implementing data science pipelines, analyses, and applications in a programming language such as Python or R', 'Working knowledge of large-scale distributed systems such as Hadoop and Spark a plus', 'Experience with Tableau a plus', 'Ability to translate business processes and data into analytics solutions', 'Experience working with cross-functional teams to translate business needs into data requirements, develop data models, and deliver solutions for customers', 'Ability to pivot between widely divergent tasks and subject matter on short notice, and rapidly adapt to varied audiences', 'A record of adding value to work outcomes through innovation and an orientation toward continuous refinement and improvement', 'Highly thorough and attentive to detail', 'Creativity to engineer novel features and signals, and to push beyond current tools and approaches']",2020-09-24 13:45:34
"Data Scientist, Growth",Pinterest,4.2 out of 5,"San Francisco, CA 94103","['Perform deep dive analyses to understand and optimize the key levers of our growth ecosystems', 'Design core metrics that serve as the North Stars for team efforts and model tradeoffs across product areas', 'Apply statistics, modeling and ML to improve the efficiency of systems and relevance algorithms across Growth Initiatives', 'Work with product managers and engineers to design data products and debug A/B experiments', '4+ years of industry experience with proven ability to apply scientific methods to solve real-world problems on web scale data', 'Expert in at least one scripting language(Python/R)', 'Proficient in SQL/Hive', 'Proven ability to apply scientific methods to solve real-world problems', 'Knowledgeable about the machine learning trade-offs and model evaluation', 'Ability to lead initiatives across multiple product areas and communicate findings with leadership and product teams']",2020-09-24 13:45:34
Data Integration Engineer,Northwestern Mutual,3.8 out of 5,"Milwaukee, WI",[],2020-09-24 13:46:14
Data Engineer,Coalition,N/A,"San Francisco, CA","['Health, dental, and vision benefits for you and your family', 'Life insurance and disability benefits', 'Paid Parental Leave', '401(k) plan', 'Wellness and commuter benefits', 'Implement risk models for various insurance products', 'Evaluate, recommend, and implement data pipelines for a variety of data sources used at Coalition', 'Deliver production-quality software implementations for ETL and streaming pipelines', 'Explore new data sources and develop insights into existing data sources that improve business efficiency', '3+ years working with large disparate data sets', 'Deep understanding of ETL pipelines, statistical modeling, data analytics, and large scale data streaming', 'Expert-level knowledge of SQL, Python, R, or similar language used for data engineering', 'A proven track record of successfully automating business value from data insights', 'Experience with at least one big data search tool, such as Elastic', 'Excellent oral and written communications skills at all levels', 'Bachelor’s degree in Computer Science or a related field preferred', 'Prior experience with insurance or network security technologies', 'In-depth knowledge of AWS or other cloud-hosted platforms relevant to data engineering', 'Experience with data visualization technologies', 'Enjoy a highly fulfilling, mission-driven culture', 'Health, dental, and vision benefits for you and your family', 'Life insurance and disability benefits', 'Paid Parental Leave', '401(k) plan', 'Wellness and commuter benefits', 'Flexible working hours', 'Open vacation days', 'We embrace distributed work; some benefits will vary by location', 'You are an owner! We offer stock options to each of our employees', 'More details at https://www.coalitioninc.com/careers']",2020-09-24 13:46:14
SQL SERVER DATA ENGINEER,InspiHER Tech,N/A,"Chicago, IL","['$70/hr - $80/hr (W2 or C2C), Direct Hire:', '$110k to $135k', 'STATUS:', 'Contribute to design and development database solutions', 'Contribute to the technical design including high-level conceptual diagrams, updates to data dictionary, creation of standards', 'Capable of executing/running projects with least amount of guidance', 'Develop database structures that fit into the overall architecture of the systems under development', 'Effectively manage trade-offs among data volumes, number of users logical and physical distribution, response times, retention rules, security and domain controls', 'Code, install, optimize and debug database queries and stored procedures using appropriate tools or editors', 'Proactively monitor database trends and act to improve database systems and processes', 'Identify tactical risks and raise/resolve issues effectively and in a timely manner', '5+ years managing MS SQL database systems', '5+ years OO programming in .Net and deploying Restful API’s', '1+ years developing data driven Cloud and on Prem solutions and integrations preferring AWS', 'Must have Microsoft SQL Server and MS SQL Server Integration Services, T-SQL and Powershell Scripting', 'Must be adept at creating stored procedures, views, user-defined functions, and table functions', 'Proven record on performing near real time data integrations and processing vis: JSON/CSV/XML file/message types', 'Must have Performance tuning SQL queries and strong table design, DML (data manipulation language)', 'Master Degree in Computer Science or equivalent years of experience']",2020-09-24 13:46:14
"100% Remote Sr. Big Data Engineer (Spark, Scala)",Noblesoft Solutions Inc.,N/A,"Jacksonville, FL","['Experience and understanding with unit testing, release procedures, coding design and documentation protocol as well as change management procedures', 'Proficiency using versioning tools', 'Thorough knowledge of Information Technology fields and computer systems', 'Demonstrated organizational, analytical and interpersonal skills', 'Flexible team player', 'Ability to manage tasks independently and take ownership of responsibilities', 'Ability to learn from mistakes and apply constructive feedback to improve performance', 'Must demonstrate initiative and effective independent decision-making skills', 'Ability to communicate technical information clearly and articulately', 'Ability to adapt to a rapidly changing environment', 'In-depth understanding of the systems development life cycle', 'Proficiency programming in more than one object-oriented programming language', 'Proficiency using standard desktop applications such as MS Suite and flowcharting tools such as Visio', 'Proficiency using debugging tools', 'High critical thinking skills to evaluate alternatives and present solutions that are consistent with business objectives and strategy', 'Yes']",2020-09-24 13:46:14
Data Engineer Trainee,Cndro,N/A,"Houston, TX",[],2020-09-24 13:46:14
Big Data Engineer,HYR Global Source Inc,N/A,"Sunnyvale, CA","['GCP: 3 years (Preferred)', 'SQL: 5 years (Required)', 'Azure: 3 years (Preferred)', 'Python: 4 years (Required)']",2020-09-24 13:46:14
"Data Visualization Engineer, Data Labs",Indigo,4 out of 5,Massachusetts,"[""Understand data infrastructure and sources and be able to deploy applications within Indigo's production environment"", 'Collaborate across teams at Indigo and contribute to applications that have been deployed to internal stakeholders and external customers', ""Design and deploy rapid, web-based solutions to bring Indigo's data science assets to market"", 'Build out reusable templates to improve front end portals and API development for common prototyping use cases', 'Understand and anticipate user needs and be able to build applications in a collaborative and self-directed environment', ""Demonstrated history of building intuitive and interactive visualizations or the endpoints that drive them (if you have a portfolio to share, we'd love to see it)"", 'Passion for data visualization and discovering the best ways to communicate insights effectively', 'Able to create and execute tasks with minimal direction', 'Able to collaborate as a team member and work independently in a fast paced project-based environment', 'Write well-documented, maintainable code in a collaborative environment', 'Work cross-functionally with an enablement mindset to improve visualization capabilities across the team', 'Strong desire to learn and develop existing and new skill sets', 'Thrive in a fast-paced, growth environment with an insatiable hunger to learn', '3+ years of experience working professionally in data visualization, analytics, or web app development (full stack)', 'Fluent in Python, Java, or other back end development language', 'Familiar with JavaScript; practical experience with ReactJS or Vue preferred', 'Experience with SQL database schema design and developing RESTful APIs (Postgres, Flask)', 'Cloud architecture and continuous integration / deployment experience (AWS / GCP, CircleCI / Jenkins)', 'Experience developing unit and integration tests (PyTest, Mocha, Jasmine, etc.)', 'UX / UI experience is a plus', 'Familiarity with Git or similar version control']",2020-09-24 13:46:14
DATA ANALYST I,RI Department of Administration,4.1 out of 5,"Cranston, RI 02920",[],2020-09-24 13:46:14
BUSINESS INTELLIGENCE AND DATA SCIENCE ENGINEER,Continuus Technologies,N/A,"Milwaukee, WI 53202",[],2020-09-24 13:46:14
Manufacturing Engineer - Assembly,Tesla,3.5 out of 5,"Austin, TX","['Collaborating with product engineering on design for assembly of various components to allow for an efficient assembly process that builds quality into the product', 'Participating in periodic design and process reviews during product development and ensuring correct specifications are set and best practices adhered to', 'Designing assembly processes, tools, and equipment that are efficient to operate and easy to maintain', 'Assessing and reducing risk in the assembly process using PFMEA methodology', 'Collaborating with external vendors and internal stakeholders to conduct design reviews of the production equipment throughout the development process', 'Supporting all engineering builds and verifying scalability of assembly processes', '.)', 'Commissioning production processes and equipment through the use of factory and site acceptance testing', 'Defining a robust process control plan to enable high level of quality', 'Submitting, reviewing, and approving any process changes for continuous improvement of ongoing production', 'Supporting make/buy/ROI analyses as required; Validating external components suppliers using industry-standard PPAP methodology', 'Actively participating in cross-functional (Product Excellence) studies of field/warranty defects, and design of countermeasures to mitigate occurrences', 'Analyzing downtime data to identify processes causing downtime, or trends in overall performance', 'Planning sufficient capacity to meet business targets for production output', 'Bachelor’s degree in Mechanical Engineering or similar; MS preferred. Relevant hands-on experience and a proven record of delivering results will be considered in-lieu of specific formal educational criteria.', '5-7+ years of hands on working experience with defining assembly processes and relevant fixture and equipment design', 'Strong foundation of problem solving skills, statistical process control, design of experiments and simulation techniques', 'Understanding of Design for Assembly (DFM), lean manufacturing, and capacity planning techniques', 'Exceptional project management and leadership skills', 'Strong verbal and written communication skills', 'Willingness to travel domestically or internationally', 'Self-starter with a proactive approach to job responsibilities', 'Comfortable in leading diverse multi-functional team', 'Proficient in basic software (i.e. Excel, Word, PowerPoint, Minitab, JMP, etc.)']",2020-09-24 13:46:14
Senior Data Engineer,IMG Systems,N/A,"Scottsdale, AZ","['The Data Warehouse Engineer will design and develop interfaces between applications, data warehouses, and third-party systems in a combination of cloud and on-premise platforms.', 'They will participate in developing integration architecture and frameworks for the organization.', 'This role will have great communication skills working in close collaboration with IT and business stakeholders to provide integration solutions.', 'Design and Develop solutions utilizing Integration Best Practices.', 'Provide day to day support and technical expertise to other engineers and stakeholders', 'Provide design and automation options to increase efficiencies and simplify integration across multiple platforms.', 'Develop solutions on time with a high level of quality with zero defects and perform to user SLAs', 'Hands-on experience with Snowflake & DataStage', '3 or more years of related experience in software design and development', '3 or more years working with the integration of data across disparate platforms and applications.']",2020-09-24 13:46:14
"Data Scientist—Strategic Customer Experience Solutions (Round Rock TX, may consider Remote-USA)",Dell Technologies,4 out of 5,"Round Rock, TX","['Create and foster analytics and thought leadership around developing customer journey measurement system for Services across businesses and regions, while collaborating with business stakeholders, product managers, software engineers, data engineers, and data analysts to create data science products', 'Write SQL queries, python scripts to clean, wrangle data from multiple sources making them model ready; use techniques which include (but not limited to) Natural Language Processing, Machine Learning, Data Pipelining to build scalable models; build Data Pipelines & platform to operationalize the models at scale; create Data Dictionary for the reusable datasets and document as Knowledge Articles', 'Become a subject matter expert of the data to create and refine features for modeling; evaluate data science models in terms of outcomes and computational performance; able to troubleshoot software issues with 3rd party support', 'Effectively communicate, verbally, in writing and in presentations to scientists and non-scientists, and influence a broad spectrum of stakeholders toward achieving business goals', 'Own, and shepherd other teams in, achieving results in a very large and cross matrix organization', 'Requires 8+ years of related experience in a professional role with a Bachelor’s degree, or 6+ years with a Master’s, or 3+ years with a PhD, or equivalent experience; Experience to include:', 'Strong database experience with expertise in SQL, and programming skills to retrieve, analyze and process data, and build machine learning models from the ground up (Python/R)', 'Data Science Platforms (Domino Data Lab, Apache Airflow), AWS and Google Cloud (working environment to build and deploy models), and Machine Learning techniques (Ranking, Classification, Clustering, Regression and Topic Modeling); Deep knowledge of machine learning, information retrieval, data mining, statistics, NLP or related field', 'Experience in Agile practices', 'Experience successfully dealing with ambiguity, while at the same time clearly assessing priorities, making strategic decisions and then articulating the issues, solutions and ongoing performance to teams and executive audiences in ambiguous situations', 'Proven experience in presenting complex data, statistics and insights and adjusting presentation as needed for clarity of understanding to varying audiences, via effective written and verbal communications, including executive level presentations', 'If remote, potential travel as needed to Round Rock (pending pandemic resolution)']",2020-09-24 13:46:14
(Senior) Data Engineer,BridgeBio,N/A,Remote,"['Excellent compensation package (Base, Performance Bonus, Stock, RSU programs)', 'Excellent benefits package', 'Leverage an analytical, data-oriented approach to cultivate knowledge of the challenges and methods of human population genetics', 'Design, build and launch innovative, efficient, and reliable data pipelines and reports that enable analysts and other stakeholders across the organization', 'Drive the selection, acquisition, and administration of database solutions and external data sources, managing relationships with external vendors', 'Implement custom data solutions: downloading, cleaning, transforming, summarizing, serving, visualizing', 'BA degree', 'At least intermediate-level Python', 'Version control with git', 'Familiarity with S3', 'Knowledge of relational databases', 'Experience with Apache Spark, Databricks and/or Delta Lake, Human genetic variant data, Hail tables, R, Regular expressions, or CI/CD considered a plus', 'Ability to work in a small company with a largely virtual environment', 'Ability to manage complexity and uncertainty', 'Strong team interaction and communication skills', 'Embraces the BridgeBio core values: 1. put patients first; 2. think independently, 3. be radically transparent; 4. every minute counts; and 5. let science speak', 'Patient Days, where we are fortunate enough to learn more about the lives we are looking to impact and a real exchange of ideas as to how we can improve our efforts', 'A culture inspired by our values: put patients first; think independently, be radically transparent; every minute counts, and let the science speak', 'Learning and development training to help employees be the best version of themselves', 'Collaborative business environment', 'Excellent compensation package (Base, Performance Bonus, Stock, RSU programs)', 'Excellent benefits package', 'Flexible PTO', 'With office locations in San Francisco, Boston, New York, and Raleigh, there are ample cross-collaboration opportunities with other BridgeBio Pharma programs', 'A fast-paced, data-driven, work environment with world-class R&D minds and capabilities', 'Work with the most productive groups of R&D operators in the industry', 'Partnerships with leading institutions', 'A platform for meaningful scientific contributions to shine', 'Commitment to Diversity & Inclusion – with initiatives like Women at Bridge, we are committed to fostering an inclusive environment where every person feels respected for who they are, empowered to contribute, inspired to lead, and supported in their efforts to do so']",2020-09-24 13:46:14
Data Science Engineer,Ampersand,N/A,"New York, NY 10036","['$100,000.00 - $200,000.00 per year', 'Benefits:', '401(k)', '401(k) Matching', 'Dental Insurance', 'Flexible Schedule', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Parental Leave', 'Tuition Reimbursement', 'Vision Insurance', 'Define + Find a strategic audience or select from traditional Nielsen demos', 'Plan + Execute against an optimized schedule across multi-screen TV', 'Measure + Report both reach and frequency and business outcomes', 'Create and improve various forecasting models (audience, reach & frequency, inventory, demand, etc.)', 'Create and improve various optimization schemes (proposals, cross screen planning, etc.)', 'Collaborate with teams throughout Ampersand to help rationalize and optimize the business and identify opportunities for further growth', 'Evaluate internal and external data sets for model and process improvement', 'Design experiments to test hypotheses, measure the results, and find ways to improve outcomes', 'Ability to communicate and collaborate with stakeholders across Ampersand and to present clear oral and written arguments', 'Degree in quantitative field like math, statistics, operations research, economics, or physics', 'Advanced degree or equivalent experience preferred', '4+ years of experience as a data scientist', 'Advanced knowledge of one or more of these:', 'Modern statistical methods', 'Machine learning', 'Bayesian methods (preferable)', 'Fluency in Python or R', 'Solid SQL abilities', 'Experience using version control (git), interactive computing, data visualization libraries, e.g. Jupyter, matplotlib, ggplot2, bokeh', 'Spark experience nice-to-have but not required', '401(k)', '401(k) Matching', 'Dental Insurance', 'Flexible Schedule', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Parental Leave', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'Machine Learning: 4 years (Required)', 'Data Scientist: 4 years (Required)', 'Big Data: 4 years (Required)', 'One location', 'https://ampersand.tv/', 'Temporarily due to COVID-19']",2020-09-24 13:46:14
Remote Jr. Data Engineer,C&G Consulting Services,N/A,"Hoboken, NJ 07030","['Building the data pipelines that fuel the personalization and relevance platform.', 'Able to write efficient and performant code.', 'Developing a platform that applies continuous delivery principles to the deployment of these pipelines.', 'Using data and metrics to inform your decision making.', 'Using infrastructure as code wherever vital.', 'Using Workflow management tools.', 'Building proof-of-concept applications or conducting exploratory experiments for the platform.', 'Collaborating with your quality assurance and technical operations peers as one team.', 'Resisting the accrual of “technical debt” in our systems.', 'Mentoring more junior members of the technical staff, performing code reviews, and owning the team to be effective and agile.', 'Working in a self-driven environment where engineers own their products end to end.', 'Staying educated on technical developments and tools vital for the design and maintenance of complex, distributed platforms.', 'BS in Computer Science, Computer Engineering or related technical field. Advanced degree preferred.', 'Generally, requires 5-7 years related experience', 'Proficient with one or more general purpose programming languages –', 'Hands-on experience with distributed processing technologies', 'Experience developing service-oriented architectures and an understanding of design for scalability, performance and reliability', 'Experience with continuous integration (Concourse & Jenkins), test-driven-development, automated unit and integration testing', 'Experience with infrastructure as code technologies like Terraform, Ansible and Docker.', 'Solid intermediate knowledge of SQL (e.g. grouping clause and distinguish the difference between a having clause and a where clause).', 'Ability to analyze a query execution plan and identify performance bottlenecks that should be addressed.', 'Ability to parse JSON and XML into relational form and transform a relational structure into JSON or XML.', 'Bachelor’s degree in Computer Science, Mathematics, Statistics, or similar quantitative field.', 'Experience with industry standard version control system tools like Git, Bitbucket.', 'Experience with a cloud provider such as AWS or Azure.', 'Experience with or an interest in alternative implementations of data storage such as MongoDB, Elasticsearch, Cassandra, and Hadoop.', 'Monday to Friday', 'Fully Remote', 'Yes']",2020-09-24 13:46:14
BUSINESS INTELLIGENCE AND DATA SCIENCE ENGINEER,Continuus Technologies,N/A,"Milwaukee, WI 53202",[],2020-09-24 13:46:55
Manufacturing Engineer - Assembly,Tesla,3.5 out of 5,"Austin, TX","['Collaborating with product engineering on design for assembly of various components to allow for an efficient assembly process that builds quality into the product', 'Participating in periodic design and process reviews during product development and ensuring correct specifications are set and best practices adhered to', 'Designing assembly processes, tools, and equipment that are efficient to operate and easy to maintain', 'Assessing and reducing risk in the assembly process using PFMEA methodology', 'Collaborating with external vendors and internal stakeholders to conduct design reviews of the production equipment throughout the development process', 'Supporting all engineering builds and verifying scalability of assembly processes', '.)', 'Commissioning production processes and equipment through the use of factory and site acceptance testing', 'Defining a robust process control plan to enable high level of quality', 'Submitting, reviewing, and approving any process changes for continuous improvement of ongoing production', 'Supporting make/buy/ROI analyses as required; Validating external components suppliers using industry-standard PPAP methodology', 'Actively participating in cross-functional (Product Excellence) studies of field/warranty defects, and design of countermeasures to mitigate occurrences', 'Analyzing downtime data to identify processes causing downtime, or trends in overall performance', 'Planning sufficient capacity to meet business targets for production output', 'Bachelor’s degree in Mechanical Engineering or similar; MS preferred. Relevant hands-on experience and a proven record of delivering results will be considered in-lieu of specific formal educational criteria.', '5-7+ years of hands on working experience with defining assembly processes and relevant fixture and equipment design', 'Strong foundation of problem solving skills, statistical process control, design of experiments and simulation techniques', 'Understanding of Design for Assembly (DFM), lean manufacturing, and capacity planning techniques', 'Exceptional project management and leadership skills', 'Strong verbal and written communication skills', 'Willingness to travel domestically or internationally', 'Self-starter with a proactive approach to job responsibilities', 'Comfortable in leading diverse multi-functional team', 'Proficient in basic software (i.e. Excel, Word, PowerPoint, Minitab, JMP, etc.)']",2020-09-24 13:46:55
Senior Data Engineer,IMG Systems,N/A,"Scottsdale, AZ","['The Data Warehouse Engineer will design and develop interfaces between applications, data warehouses, and third-party systems in a combination of cloud and on-premise platforms.', 'They will participate in developing integration architecture and frameworks for the organization.', 'This role will have great communication skills working in close collaboration with IT and business stakeholders to provide integration solutions.', 'Design and Develop solutions utilizing Integration Best Practices.', 'Provide day to day support and technical expertise to other engineers and stakeholders', 'Provide design and automation options to increase efficiencies and simplify integration across multiple platforms.', 'Develop solutions on time with a high level of quality with zero defects and perform to user SLAs', 'Hands-on experience with Snowflake & DataStage', '3 or more years of related experience in software design and development', '3 or more years working with the integration of data across disparate platforms and applications.']",2020-09-24 13:46:55
"Data Scientist—Strategic Customer Experience Solutions (Round Rock TX, may consider Remote-USA)",Dell Technologies,4 out of 5,"Round Rock, TX","['Create and foster analytics and thought leadership around developing customer journey measurement system for Services across businesses and regions, while collaborating with business stakeholders, product managers, software engineers, data engineers, and data analysts to create data science products', 'Write SQL queries, python scripts to clean, wrangle data from multiple sources making them model ready; use techniques which include (but not limited to) Natural Language Processing, Machine Learning, Data Pipelining to build scalable models; build Data Pipelines & platform to operationalize the models at scale; create Data Dictionary for the reusable datasets and document as Knowledge Articles', 'Become a subject matter expert of the data to create and refine features for modeling; evaluate data science models in terms of outcomes and computational performance; able to troubleshoot software issues with 3rd party support', 'Effectively communicate, verbally, in writing and in presentations to scientists and non-scientists, and influence a broad spectrum of stakeholders toward achieving business goals', 'Own, and shepherd other teams in, achieving results in a very large and cross matrix organization', 'Requires 8+ years of related experience in a professional role with a Bachelor’s degree, or 6+ years with a Master’s, or 3+ years with a PhD, or equivalent experience; Experience to include:', 'Strong database experience with expertise in SQL, and programming skills to retrieve, analyze and process data, and build machine learning models from the ground up (Python/R)', 'Data Science Platforms (Domino Data Lab, Apache Airflow), AWS and Google Cloud (working environment to build and deploy models), and Machine Learning techniques (Ranking, Classification, Clustering, Regression and Topic Modeling); Deep knowledge of machine learning, information retrieval, data mining, statistics, NLP or related field', 'Experience in Agile practices', 'Experience successfully dealing with ambiguity, while at the same time clearly assessing priorities, making strategic decisions and then articulating the issues, solutions and ongoing performance to teams and executive audiences in ambiguous situations', 'Proven experience in presenting complex data, statistics and insights and adjusting presentation as needed for clarity of understanding to varying audiences, via effective written and verbal communications, including executive level presentations', 'If remote, potential travel as needed to Round Rock (pending pandemic resolution)']",2020-09-24 13:46:55
(Senior) Data Engineer,BridgeBio,N/A,Remote,"['Excellent compensation package (Base, Performance Bonus, Stock, RSU programs)', 'Excellent benefits package', 'Leverage an analytical, data-oriented approach to cultivate knowledge of the challenges and methods of human population genetics', 'Design, build and launch innovative, efficient, and reliable data pipelines and reports that enable analysts and other stakeholders across the organization', 'Drive the selection, acquisition, and administration of database solutions and external data sources, managing relationships with external vendors', 'Implement custom data solutions: downloading, cleaning, transforming, summarizing, serving, visualizing', 'BA degree', 'At least intermediate-level Python', 'Version control with git', 'Familiarity with S3', 'Knowledge of relational databases', 'Experience with Apache Spark, Databricks and/or Delta Lake, Human genetic variant data, Hail tables, R, Regular expressions, or CI/CD considered a plus', 'Ability to work in a small company with a largely virtual environment', 'Ability to manage complexity and uncertainty', 'Strong team interaction and communication skills', 'Embraces the BridgeBio core values: 1. put patients first; 2. think independently, 3. be radically transparent; 4. every minute counts; and 5. let science speak', 'Patient Days, where we are fortunate enough to learn more about the lives we are looking to impact and a real exchange of ideas as to how we can improve our efforts', 'A culture inspired by our values: put patients first; think independently, be radically transparent; every minute counts, and let the science speak', 'Learning and development training to help employees be the best version of themselves', 'Collaborative business environment', 'Excellent compensation package (Base, Performance Bonus, Stock, RSU programs)', 'Excellent benefits package', 'Flexible PTO', 'With office locations in San Francisco, Boston, New York, and Raleigh, there are ample cross-collaboration opportunities with other BridgeBio Pharma programs', 'A fast-paced, data-driven, work environment with world-class R&D minds and capabilities', 'Work with the most productive groups of R&D operators in the industry', 'Partnerships with leading institutions', 'A platform for meaningful scientific contributions to shine', 'Commitment to Diversity & Inclusion – with initiatives like Women at Bridge, we are committed to fostering an inclusive environment where every person feels respected for who they are, empowered to contribute, inspired to lead, and supported in their efforts to do so']",2020-09-24 13:46:55
Data Science Engineer,Ampersand,N/A,"New York, NY 10036","['$100,000.00 - $200,000.00 per year', 'Benefits:', '401(k)', '401(k) Matching', 'Dental Insurance', 'Flexible Schedule', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Parental Leave', 'Tuition Reimbursement', 'Vision Insurance', 'Experience:Machine Learning, 4 years (Required)Data Scientist, 4 years (Required)Big Data, 4 years (Required)', 'Define + Find a strategic audience or select from traditional Nielsen demos', 'Plan + Execute against an optimized schedule across multi-screen TV', 'Measure + Report both reach and frequency and business outcomes', 'Create and improve various forecasting models (audience, reach & frequency, inventory, demand, etc.)', 'Create and improve various optimization schemes (proposals, cross screen planning, etc.)', 'Collaborate with teams throughout Ampersand to help rationalize and optimize the business and identify opportunities for further growth', 'Evaluate internal and external data sets for model and process improvement', 'Design experiments to test hypotheses, measure the results, and find ways to improve outcomes', 'Ability to communicate and collaborate with stakeholders across Ampersand and to present clear oral and written arguments', 'Degree in quantitative field like math, statistics, operations research, economics, or physics', 'Advanced degree or equivalent experience preferred', '4+ years of experience as a data scientist', 'Advanced knowledge of one or more of these:', 'Modern statistical methods', 'Machine learning', 'Bayesian methods (preferable)', 'Fluency in Python or R', 'Solid SQL abilities', 'Experience using version control (git), interactive computing, data visualization libraries, e.g. Jupyter, matplotlib, ggplot2, bokeh', 'Spark experience nice-to-have but not required', '401(k)', '401(k) Matching', 'Dental Insurance', 'Flexible Schedule', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Parental Leave', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'Machine Learning: 4 years (Required)', 'Data Scientist: 4 years (Required)', 'Big Data: 4 years (Required)', 'One location', 'https://ampersand.tv/', 'Temporarily due to COVID-19']",2020-09-24 13:46:55
Remote Jr. Data Engineer,C&G Consulting Services,N/A,"Hoboken, NJ 07030","['Building the data pipelines that fuel the personalization and relevance platform.', 'Able to write efficient and performant code.', 'Developing a platform that applies continuous delivery principles to the deployment of these pipelines.', 'Using data and metrics to inform your decision making.', 'Using infrastructure as code wherever vital.', 'Using Workflow management tools.', 'Building proof-of-concept applications or conducting exploratory experiments for the platform.', 'Collaborating with your quality assurance and technical operations peers as one team.', 'Resisting the accrual of “technical debt” in our systems.', 'Mentoring more junior members of the technical staff, performing code reviews, and owning the team to be effective and agile.', 'Working in a self-driven environment where engineers own their products end to end.', 'Staying educated on technical developments and tools vital for the design and maintenance of complex, distributed platforms.', 'BS in Computer Science, Computer Engineering or related technical field. Advanced degree preferred.', 'Generally, requires 5-7 years related experience', 'Proficient with one or more general purpose programming languages –', 'Hands-on experience with distributed processing technologies', 'Experience developing service-oriented architectures and an understanding of design for scalability, performance and reliability', 'Experience with continuous integration (Concourse & Jenkins), test-driven-development, automated unit and integration testing', 'Experience with infrastructure as code technologies like Terraform, Ansible and Docker.', 'Solid intermediate knowledge of SQL (e.g. grouping clause and distinguish the difference between a having clause and a where clause).', 'Ability to analyze a query execution plan and identify performance bottlenecks that should be addressed.', 'Ability to parse JSON and XML into relational form and transform a relational structure into JSON or XML.', 'Bachelor’s degree in Computer Science, Mathematics, Statistics, or similar quantitative field.', 'Experience with industry standard version control system tools like Git, Bitbucket.', 'Experience with a cloud provider such as AWS or Azure.', 'Experience with or an interest in alternative implementations of data storage such as MongoDB, Elasticsearch, Cassandra, and Hadoop.', 'Monday to Friday', 'Fully Remote', 'Yes']",2020-09-24 13:46:55
Data Engineer,"Amazon Dev Center U.S., Inc.",3.6 out of 5,"Boston, MA","['Job', 'Company', '1+ years of experience as a Data Engineer or in a similar role', 'Experience with data modeling, data warehousing, and building ETL pipelines', 'Experience in SQL', '1+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets', 'Demonstrated strength in data modeling, ETL development, and data warehousing', 'Experience using big data technologies (Hadoop, Hive, Hbase, Spark etc.)', 'Knowledge of data management fundamentals and data storage principles', 'B.S. degree in mathematics, statistics, computer science or a similar quantitative field.', 'Work closely with product management, sales, and business stakeholders to analyze data from a multitude of sources.', 'Design, implement, and maintain a data pipeline and analytical environment using third-party and in-house reporting tools, modeling metadata, and building reports and dashboards.', 'Use creative problem-solving to automate the collection and analysis from available data sources in order to deliver actionable output.', 'Iteratively improve analysis and identify new metrics to improve analytics.', 'Experience in writing complex, optimized SQL queries across large datasets.', 'Experience with data analysis tools like Jupyter and Pandas.', 'Experience working with a diverse set of business and engineering stakeholders at all levels', 'Experience with AWS technologies including Redshift, SageMaker, EMR, RDS, S3, and Kinesis', 'Demonstrated ability to coordinate projects across functional teams, including engineering, sales, product management, finance, and operations', 'Proven track record of successful communication of analytical outcomes through written communication, including an ability to effectively communicate with both business and technical teams']",2020-09-24 13:46:55
"Associate Data Engineer (Full Time Starting Summer 2021 - Richmond, VA)",EAB,N/A,"Richmond, VA 23219","['Medical, dental, and vision insurance; dependents and domestic partners eligible', '401(k) retirement plan with company match', '20+ days of PTO annually, in addition to paid firm holidays', 'Daytime leave policy for community service or fitness activities (up to 10 hours a month each)', 'Paid parental leave for birthing or non-birthing parents', 'Phase Back to Work program for employees returning from parental leave', 'Infertility treatment coverage and adoption or surrogacy assistance', 'Wellness programs including gym discounts and incentives to promote healthy living', 'Responsible for data modeling and schema design that will range across multiple business domains within higher education', 'Partner with multiple stakeholders including clients, new product development, BI engineers to develop scalable standard schemas', 'Work with clients to research and conduct business information flow studies', 'Codify high-performing SQL for efficient data transformation', 'Coordinate work with external teams to ensure a smooth development process', 'Support operations by identifying, researching and resolving performance and production issues', 'Experience working with relational or multi-dimensional databases', 'Experience developing logical data models within a data warehouse', 'Experience developing ETL processes', 'Demonstrated mastery in one or more SQL variants: PostgreSQL, MySQL, Oracle, SQL Server, or DB2', 'Demonstrated mastery in database concepts and large-scale database implementations and design patterns', 'Proven ability to work with users to define requirements and business issues', 'Excellent analytic and troubleshooting skills', 'Strong written and oral communication skills', 'Bachelor’s or Master’s degree in Computer Science or Computer Engineering', 'Experience working in an AGILE environment', 'Experience developing commercial software products', 'Experience with AWS data warehouse infrastructure (redshift, EMR/spark)', 'GIT expertise', 'Medical, dental, and vision insurance; dependents and domestic partners eligible', '401(k) retirement plan with company match', '20+ days of PTO annually, in addition to paid firm holidays', 'Daytime leave policy for community service or fitness activities (up to 10 hours a month each)', 'Paid parental leave for birthing or non-birthing parents', 'Phase Back to Work program for employees returning from parental leave', 'Infertility treatment coverage and adoption or surrogacy assistance', 'Wellness programs including gym discounts and incentives to promote healthy living', 'Dynamic growth opportunities with merit-based promotion philosophy', 'Benefits kick in day one, see the full details here.']",2020-09-24 13:46:55
Data Engineer,General Motors,4.1 out of 5,"Roswell, GA 30076","['Paid time off including vacation days, holidays, and parental leave for mothers, fathers and adoptive parents;', 'Healthcare (including a triple tax advantaged health savings account and wellness incentive), dental, vision and life insurance plans to cover you and your family;', 'Company and matching contributions to 401K savings plan to help you save for retirement;', 'Global recognition program for peers and leaders to recognize and be recognized for results and behaviors that reflect our company values;', 'Tuition assistance and student loan refinancing;', 'Work cross functionally with business and IT partners to define KPIs, discover data and determine transformation needs', 'Quickly design, develop, and deliver new code', 'Create data insights using industry standard tools and techniques', 'Estimate and design work that is just-in-time and sized in small increments', 'Perform root cause analysis, do technology evaluations, and develop quick prototypes', 'Commit to completing well-defined, secure, and elegant work and deliver on their commitments', 'Report status of assigned development and/or maintenance tasks', 'Consistently follow the specified software development methodology', 'Promote improvements in programming practices such as acceptance test driven development, continuous integration, and continuous delivery', 'Experience with Agile teams that have regularly delivered software while practicing code review', 'Over 6 years of data development experience in Python, Spark and similar technologies', 'Expertise in SQL (relational databases), key-value datastores, and document stores', 'Expertise in end-to-end applications hosted on Kubernetes with a focus on scalability, high availability, and fault tolerance', 'Creating self-contained, reusable, and testable modules and components in frontend and backend work', 'Proven experience diagnosing issues throughout the data migration landscape', 'Ability to elicit and communicate requirements with business users on KPIs, Analytical models, and data visualization', 'Excellent verbal and written communication skills and ability to effectively communicate and translate feedback, needs and solutions', 'Creative problem-solving skills that deliver elegant solutions to complex issues', 'Strong teamwork focus (live by the team, die by the team) and the ability to foster collaboration within and across teams', 'Bachelor degree in Computer Science or related field, or, equivalent combination of education and recent, relevant work experience', '10+ years of Data Analysis', 'Ability to design data layouts accounting for load and extraction performance to meet operational goals and efficiency', '5+ years utilizing data visualization tools such as powerBI, Cognos, Tableau', 'Experience using Git source control doing rebases, merges, and handling merge conflicts', 'Paid time off including vacation days, holidays, and parental leave for mothers, fathers and adoptive parents;', 'Healthcare (including a triple tax advantaged health savings account and wellness incentive), dental, vision and life insurance plans to cover you and your family;', 'Company and matching contributions to 401K savings plan to help you save for retirement;', 'Global recognition program for peers and leaders to recognize and be recognized for results and behaviors that reflect our company values;', 'Tuition assistance and student loan refinancing;', 'Discount on GM vehicles for you, your family and friends.']",2020-09-24 13:46:55
"MACHINE LEARNING ENGINEER - PYTHON, TENSORFLOW",InspiHER Tech,N/A,United States,"['$90k - $140k', 'STATUS:']",2020-09-24 13:46:55
Data Scientist,JJR Solutions,4.9 out of 5,"Dayton, OH 45402","['JJR has had a “Highly Engaged” workforce for the past 3 years (independent third-party assessment)', '“JJR is one of the best companies I have worked with (for) in the past 20+ years.” – Anonymous employee feedback from internal engagement surveys', '“I feel JJR does a very good job of hiring people who will work well in the group dynamic - people who share the same work ethic and values, which makes for working together to be much easier and more enjoyable.” – Anonymous employee feedback from internal engagement surveys', 'Perform all required responsibilities and duties in accordance with JJR’s Handbook and job description', 'Actively engage in your role, make informed decisions, be accountable for all outcomes, and be a positive influence for JJR', 'Deliver exceptional service to internal and external clients, partners, teammates', 'Contribute to the programs and initiatives designed to advance company strategic priorities', 'Support the build out plan to develop & implement methodology for systematic, risk-based facility investment decision making through USAF/USSF software', 'Lead the design of requirements for the web-based technology solution, specifically for business intelligence and visualization', 'Work with stakeholders to understand needs and requirements, participate in workshops, investigate AI/ML opportunities, and provide input to the design specification', 'Build out prototypes to validate the plan approach for critical pieces of functionality', 'Research and analyze various data sources', 'Develop capability to generate and visualize data insights', 'Conduct statistical modeling and experiment design, and test and validate predictive models', 'Develop customized algorithms to solve analytical problems with incomplete data sets and implement automated processes for efficiently producing scale models', 'Collaborate with database engineers and other scientists to develop, refine, and scale data management and analytics procedures, systems, workflows, best practices, and other issues', 'Work within an Agile-based software development life cycle', 'Implement new or enhanced software designed to access and handle data more efficiently', 'Write and implement quality procedures.', 'Additional duties as assigned', ""Bachelor's Degree in Data Science, Statistics, Computer Science, Engineering, or related field"", '7+ years Analytical Programming and/or Data-Driven Analysis', 'Exceptional written skills for data, processes, and architecture documentation', 'JJR may choose to substitute education with relevant experience', 'Experience with Air Force Civil Engineering', 'Master’s degree in Computer Science, Engineering, or related field', 'Data Science skills:Data pre-processing: Data cleansing, data manipulation, feature engineeringStatistics: Regression, Confidence intervals, Bayesian methods, InferenceMachine Learning: Predictive analytics (Classification and Regression), ClusteringVisualization: Microsoft Power BI, Tableau, R ShinyProgramming: SQL, Python', 'Prescriptive Analytics: Optimization and Simulation', 'Experience implementing a strategic data solution within an existing legacy system landscape', 'Ability to translate enterprise needs and convey them for implementation', 'Excellent client relationship management skills', 'Results oriented with the demonstrated ability to apply strategic and decisive problem-solving skills in ambiguous situations', 'Working understanding of industry best practices & technologies that effectively govern and manage data from various perspectives. (Data governance, curation, preparation, stewardship, analysis &/or reporting)', 'Agile Software Development experience']",2020-09-24 13:46:55
Mechanical Design Engineer - Motors,Tesla,3.5 out of 5,"Austin, TX","['3D CAD and 2D drawings for stators, rotors and assemblies', 'Driving choices and development in:winding technologymagnet technologysteel stamping and lamination joiningelectrical insulation systemsinterconnectionsthermal sensing', 'Identifying and qualifying suppliers of raw materials, components, and assemblies', 'Design validation and durability testing profile development and data analysis', 'Carry designs through to high-volume production; DFM, cost reductions, and second sourcing', 'Mentoring junior engineers and interns', 'Evidence of exceptional ability', 'Taken motor designs from clean sheet to volume production', 'Experience with multiple coil winding and termination technologies', 'Experience with multiple magnet technologies', 'Worked with an international supply chain', 'Automotive design and validation experience', 'Asked “why” throughout his or her career']",2020-09-24 13:46:55
Business Intelligence Engineer,Electronic Arts,3.8 out of 5,"Austin, TX",[],2020-09-24 13:46:55
Machine Learning Engineer,"IndustrialML, Inc.",N/A,"Boston, MA","[""null (Required)Bachelor's (Preferred)Machine Learning: 1 year (Preferred)Manufacturing: 1 year (Preferred)"", 'Flexible schedule', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Machine Learning: 1 year (Preferred)', 'Manufacturing: 1 year (Preferred)', 'Yes', 'Fully Remote', '10-19', 'A job for which all ages, including older job seekers, are encouraged to apply', 'A job for which people with disabilities are encouraged to apply', 'industrialml.com']",2020-09-24 13:46:55
Data Science Engineer (Data Scientist),Plume,N/A,"Palo Alto, CA","['Utilize data science and machine learning techniques to developPredictive models of network parameters such as load and interferenceModels of user behavior such as churn, satisfaction, and support requirementsAnomaly detection of device and network behaviorDevice identification and classification', 'Derive estimates of load, capacity, link rates, etc. from noisy raw measurements', 'Develop data analysis and dashboards to represent the network statistics and behaviors we are observing', 'Apply innovative quantitative research tools and models to answer difficult but critical business questions', 'Create unusual data based stories and visualizations for marketing and publicity', 'Specify tools and data pipelines to enable real time processing and offline processing', 'Strong ability in Python and SQL', 'Expertise in data ""wrangling"": data cleaning, augmentation, validation, the creation of ETL pipelines', 'Data base creation and organization including schema design, selection of keys, partitioning, indexing, etc.', 'Ability to perform sophisticated statistical analysis', 'Experience working with large databases, high volume of data', 'Experience and fundamental understanding of machine learning techniques', ""Bachelor's degree or higher in Electrical Engineering, Computer Science, or Statistics"", 'Some experience or background with networking is desired - in particular experience applying big data/machine learning to networking', 'Experience with specific machine learning techniques: linear regression, random forest, clustering, unsupervised learning techniques, NLP, neural networks', 'Data visualization, and experience with data visualization tools', 'Experience with Spark and the Databricks platform']",2020-09-24 13:47:37
Data Engineer,Technodeed Inc,N/A,"Minneapolis, NC",[],2020-09-24 13:47:37
Staff Data Engineer,Lytx,3.6 out of 5,"San Diego, CA 92121","['Provide technical thought leadership for the design and development of mission critical data applications', 'Prepare detailed architecutural, data model, and data flow diagrams', 'Design infrastructure and solutions for monitoring and managing streaming data pipelines at scale', 'Determine and implement strategies for persistent data storage (data lakes)', 'Plan and manage data governance, security, cataloging, and retention', 'Participate in the research, design, and testing of next generation data engine platforms', 'Develop and guide long-term strategy for data pipelines and persistent data storage', 'Evaluate and recommend database infrastructure and tools including cloud technologies', 'Communicate architecture design and decisions to business stakeholders', 'Mentor and coach junior engineers ,software developers, and data analysts', 'Perform other related duties as assigned', 'Minimum 10 years of experience in Data Engineering and/or Software Development', 'Minimum 3 years of experience working with the Apache Hadoop Ecosystem', 'Minimum 3 years of experience with MS SQL Server or other RDBMS', 'Significant experience with streaming data platforms and tools', 'Versed in cloud data offerings (AWS, GCP, Azure, Snowflake)', 'Excellent interpersonal and communication skills', 'Ability to influence at all levels while building strong cross-functional relationships', 'Advanced T-SQL, Streaming, and ETL programming', 'Extensive knowledge of common data warehousing technologies and techniques', 'Excellent conceptual, analytical, and problem-solving skills', 'Experience in a high growth, fast paced environment', 'Demonstrated record of delivering quality technology outcomes', 'Strong organizational skills and a keen attention to detail', 'Self-motivated, engaged, and accountable', 'Bachelor’s degree in Information Technology or similar discipline', 'Project management skills', 'Team leadership experience']",2020-09-24 13:47:37
Data Engineer - WWOps Connections,Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['5+ years of experience as a Data Engineer or in a similar role', 'Experience with data modeling, data warehousing, and building ETL pipelines', 'Experience in SQL', ""Bachelor's degree in a quantitative/technical discipline such as Computer Science, Engineering, Statistics"", '6+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics', 'Demonstrable skills and experience writing complex, highly-optimized SQL queries across large data sets', 'Experience in scripting languages such as Python', 'Experience with AWS technologies such as Redshift, EMR, S3', 'Experience in building reporting solutions using BI tools', 'Experience with tools including, Excel, PowerBI, Tableau, Quicksight, etc.', 'Experience building metrics for Senior leadership reviews', 'Familiarity with statistical modeling and machine learning techniques', 'Strong verbal and written communication skills and ability to build rapport with cross-functional partners']",2020-09-24 13:47:37
"Data Engineer II, Amazon Fuse",Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['3+ years of experience as a Data Engineer or in a similar role', 'Experience with data modeling, data warehousing, and building ETL pipelines', 'Experience in SQL', ""Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Economics, Finance, Mathematics, Statistics, Engineering)."", '5+ years of relevant experience one of the following areas: data science, data engineering, business intelligence or business analytics.', 'Strong analytical and problem-solving skills.', 'Expertise in the design, creation and management of large datasets/data models.', 'Expert-level proficiency in writing complex, highly-optimized SQL queries across large datasets.', 'Ability to work with business owners to define key business requirements and convert to technical specifications.', 'Ability to manage competing priorities simultaneously and drive projects to completion.', 'Develop and maintain data sets to measure the performance of the program. This will include building metrics for High Value Actions, engagement, acquisition and landscape.', 'Build, maintain and optimize scalable self-service solutions that empower stakeholders to address their data needs.', 'Liaising with technology teams across Amazon to influence data model designs and data sharing. This may include writing papers to influence executive decisions.', 'Assist business stakeholders in creating and implementing business requirement documents to drive projects, working backward from customer needs.', 'Implement standardized, automated operational and quality control processes for difficult datasets to deliver accurate and timely data and reporting to meet or exceed SLAs', 'Communicate timely information to all stakeholders on current and future initiatives, prioritizing based on the organization’s needs', '7+ years of experience as a data engineer, BI Engineer, Business/Financial Analyst or Systems Analyst in an internet-based company with large, complex data sources.', 'Experience with AWS services including S3, Redshift, EMR and RDS.', 'Knowledge with statistical and/or econometric modeling.', 'Experience in BI/DW as a change leader providing strategic research, recommendations, and implementations.']",2020-09-24 13:47:37
"Sr. Data Engineer, Exempt",Adventist Health System/West,3.8 out of 5,"Roseville, CA","['Functions as a technical Informatica Administrator to maintain and develop ETL specifications for healthcare business and clinical users. Designs, builds and tests deliverables for complex ETL process and interfaces spanning multiple applications.', 'Moderates discussions between technical and non-technical end users, taking non-technical requirements and converting them into technical requirements.', 'Develops ETL source and target mapping design/specifications based on the business requirements and ETL standards and architecture.', 'Assesses organizations, processes, channels, applications and data to identify practical solutions. Assumes responsibility for problem assessment and resolution in compliance with SLA requirements for ETL support.', 'Participates in the on-call rotation schedule as needed.', 'Performs other job-related duties as assigned.', ""Bachelor's Degree in computer science, management information systems, applied mathematics or equivalent combination of education/related experience: Required"", 'Five years ETL development or equivalent work experience using Informatica: Preferred', 'Healthcare experience: Preferred']",2020-09-24 13:47:37
Data Engineer - Snowflake,"Daman, Inc.",N/A,"San Antonio, TX","['$100,000.00 - $130,000.00 per year', 'Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Deploy and customize Daman Standard Architecture components', 'Mentor client personnel. Train clients on the Daman Integration Methodology and related supplemental solutions', 'Provide feedback and enhance Daman intellectual property related to data management technology deployments', 'Assist in development of task plans including schedule and effort estimation', 'Experience with streaming related technologies ex Spark streaming or other message brokers like Kafka is a plus', 'Experience in the financial services, banking and/ or Insurance industries is a nice to have', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-09-24 13:47:37
"Data Analyst, Product Analytics",Employment Opportunities at BuzzFeed,N/A,New York State,"['Help internal teams understand how BuzzFeed users interact with our range of products - through detailed analysis, dashboard creation, and regular reporting tasks.', 'Work closely with product teams to develop and test strategies for activating users and creating habitual product usage.', 'Deploy funnel analysis to understand user drop-off and conversion.', 'Administer A/B tests to evaluate feature impact and inform product strategy.', 'Conduct retention analyses that help identify investment opportunities.', 'Develop key performance metrics that align with company user retention and acquisition goals.', '2+ years of experience doing quantitative analysis.', '1+ years experience with product optimization work focused on user retention (e.g. funnel optimization) and/or user acquisition (e.g.outbound communication channels such as email or push notifications).', 'Experience with product optimization or growth best practices.', 'Very comfortable using SQL to explore large datasets.', 'Experience with Looker (or another BI tool) is a plus.', 'Excellent communication capabilities, with a focus on clearly articulating recommendations to a range of stakeholders.', 'Practiced at taking a structured approach to problem solving.', 'A supportive, inclusive atmosphere on a team that values your contributions', 'Opportunities for personal and professional growth via work experience, offerings from our in-house Learning @ BuzzFeed team, our Employee Resource Groups, and more', 'An attractive and equitable compensation package, including salary and stock options', 'A generous and well-rounded benefits program featuring PTO, unlimited sick time, comprehensive medical benefits, a family leave policy, access to mental health platforms, retirement plans, gym and wellness discounts, and much more', 'Plenty of snacks (healthy and indulgent), catered lunches, beverages, etc..']",2020-09-24 13:47:37
"Data Engineer, Cell Engineering",Tesla,3.5 out of 5,"Palo Alto, CA","['Design and implement backend services and tools that handle fleet data collection and batch processing', 'Help construct machine learning infrastructure to help increase our learnings and experimental throughput', 'Build systems to monitor and validate our battery reliability and performance tests to make sure that we are making decisions on quality experiment data', 'Improve the robustness of our experimental pipeline from the time we receive cells, to test, to results', 'Build tables with the optimum indices for fast querying. These tables will also be constrained to reduce the chance of bad data leaking into our system', 'BS/MS in Computer Science or related area, with strong software engineering experience.', 'Experience in building and maintaining databases', 'Experience with Python', 'Experience working in a Linux command line environment.', ""Experience with JavaScript and building UI's is a plus"", 'Experience with and MATLAB is a plus']",2020-09-24 13:47:37
AWS Cloud Data Engineer,"Webtellect, LLC",N/A,"Seattle, WA 98104","['Experience setting up AWS Data Platform – AWS CloudFormation, DevelopmentEndPoints, AWS Glue, EMR and Jupyter/Sagemaker Notebooks, Redshift, S3, and EC2 instances.', 'Track record of successfully building scalable Data Lake solutions that connects to distributed data storage using multiple data connectors.', 'Must have a background in data engineering – Data Warehouse Development experience would be perfect', 'Must have strong skills in SQL, Python, PySpark, and AWS', 'Experience in designing, developing, optimizing and troubleshooting complex Data Pipelines using Spark cluster', 'Ability to lead proofs-of-concepts and then effectively transition and scale those concepts into production at scale through, engineering, deployment and commercialization.', 'Serve as an expert; envision and integrate emerging data technologies, anticipate new trends to solve complex business and technical problems.', '6 month contract.', '** No 3rd parties. **', '** No Visas allowed **']",2020-09-24 13:47:37
Data Modelling Engineer - USC and GC only,Youth Power Technosoft LLC,N/A,"Upper Providence, PA","['Pay:', '$55.00 - $60.00 per hour']",2020-09-24 13:47:37
Data Analytics Engineer,"Modernizing Medicine, Inc.",3.6 out of 5,"Boca Raton, FL 33431","['Your compensation is a combination of base salary and bonus potential.', 'Health Insurance, 401(k), Vacation, Employee Assistance Program, Flexible Spending Accounts.', 'Weekly catered breakfast and lunch, treadmill workstations, quarterly onsite massages, onsite dry cleaning, onsite car wash and many more!', 'Inc. Magazine Best Workplaces of 2020', 'Inc. 5000 Fastest-Growing Private Companies in America - 2015 - 2019', 'Best Use of Technology in Customer Service (Gold) - Customer Sales and Service World Awards® - 2019', 'Customer Service Department of the Year (Gold) - Customer Sales and Service World Awards - 2018', 'South Florida Business Journal Fastest Growing Technology Company - 2016 - 2018', ""Customer Success Team of the Year by SIIA's Company CODiE - 2017"", ""People's Choice UX Award for modmed® Kiosk - 2017"", 'Gather, analyze, refine, validate, report, and publish data.', 'Deliver complete, concise, and accurate business intelligence reports/visuals.', 'Follow best practice guidelines for business intelligence at Modernizing Medicine.', 'Work with multifunctional teams to determine and articulate report requirements.', 'Analyze complex data to provide operational intelligence.', 'Monitor and manage data life cycle process.', 'Development of data quality metrics and controls.', 'Descriptive and summary statistics.', 'Data visualization supporting insights.', 'Compile, review, and analyze data through database and statistical programming.', 'Share insights across the enterprise.', ""Bachelor's degree in one of the following: engineering, computer science, or other relevant degree preferred."", 'Knowledge of data modeling, query languages (SQL, etc.), and key trends in reporting, business intelligence, and analytical processes.', 'Experience working in a data analyst role actively engaged with data and business intelligence.', 'Knowledge and understanding of relational database.', 'Ability to learn new database concepts, processes, tools, and best practices.', 'Strong verbal and written communication skills.', 'Strong analytical and problem solving skills.', 'Strong commitment to quality, architecture, and documentation.', 'Experience with python, R or other programming languages.', 'Experience with big data tools (Hadoop, Hive, Impala, etc.).', 'Your compensation is a combination of base salary and bonus potential.', 'Health Insurance, 401(k), Vacation, Employee Assistance Program, Flexible Spending Accounts.', 'Weekly catered breakfast and lunch, treadmill workstations, quarterly onsite massages, onsite dry cleaning, onsite car wash and many more!']",2020-09-24 13:47:37
Validation Engineer,HCL America Inc,2.3 out of 5,"Draper, UT 84020","['401(k) matching', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Experience:Shelf life testing, 1 year (Preferred)Stability Testing, 1 year (Preferred)Biocompatibility, 1 year (Preferred)Design Verification, 1 year (Preferred)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Shelf life testing: 1 year (Preferred)', 'Stability Testing: 1 year (Preferred)', 'Biocompatibility: 1 year (Preferred)', 'Design Verification: 1 year (Preferred)']",2020-09-24 13:47:37
Product Data Scientist,KPA,3.7 out of 5,"Lafayette, CO","['Medical (both PPO and HSA plans available)', 'Dental', 'Vision', 'Paid Time Off', 'Parental Leave', 'Holidays', '401(k) match with immediate vesting', 'Life Insurance', 'Short and long term disability insurance', 'FSA', 'HSA matching', 'Drive the discovery, collection, and preparation of new data and the refinement of existing data sources.', 'Develop a test data-driven hypotheses in order to find patterns and useful trends to help our customers.', 'Work closely with customers from product discovery through solution implementation to improve products and business methods.', 'Work with the Product and UX team to develop best practices for instrumentation and visualization of data.', 'Develop stories from data and visuals that make sense and are actionable for our customers to help them provide appropriate training,', 'Collaborate with engineers to implement machine learning techniques into our production environment.', 'Experience with R or Python.', 'Experience with predictive modeling.', 'Familiarity with data visualization in Python, R, or D3.js.', 'Experience with BI tools (i.e. Tableau, PowerBI, Sisense, etc.)', 'Understanding of relational data structures and SQL.', 'Ability to multi-task several priorities simultaneously and manage multiple projects.', 'Excellent written and verbal communication skills - being able to bring others along and speak in “common terms” for team and', 'Ability to take initiative, think on your feet, and problem solve.', 'B.A. or M.S. in Computer Science, Statistics, Applied Mathematics, or another relevant technical field.', 'Onboard to the team.', 'Become familiar with current data sets.', 'Assess the landscape of data analytics tools and technologies at KPA and establish areas of improvement.', 'Start running experiments with our data.', 'Participate in the agile development process.', 'Get to know the Product, UX Design, and Technology team.', 'Be key in the next release of our Reporting Dashboard enhancements.', 'Start to demonstrate productivity and ownership on par with the other product team members.', 'Show strong leadership and direction on our data analysis and structure.', 'Have participated in various customer discovery calls with UX and Product.', 'Have strong hypotheses towards potential data product enhancements that meet customer needs and goals.', 'Be working closely and collaboratively with our Product Managers, Designers, and Engineers.', 'Extend and optimize our Reporting Dashboard platform.', 'Be designing experiments for benchmarks, recommendation pipelines, and machine learning models.', 'Ensure the best development practices are being used and translated to execute on your data product visualizations in production.', 'Have a solid understanding of our customer base and their practical data needs.', 'Continue experimenting with the Product and UX Design team on new ways to communicate insights and provide data products to our', 'Be an expert in KPA’s products.', 'Have full ownership and direction of the machine learning models.', 'Contribute to the data science vision and processes.', 'Be a mentor and help introduce and level-up our Product Managers, UX Designers, and Engineers in data science methods and best', 'Continuously offer process improvements to our team, the business, and for our customers.', 'This position reports to the User Experience Director, Product and is a full-time exempt position.', 'The location will be at KPA’s corporate headquarters in Lafayette, CO.', 'Medical (both PPO and HSA plans available)', 'Dental', 'Vision', 'Paid Time Off', 'Parental Leave', 'Holidays', '401(k) match with immediate vesting', 'Life Insurance', 'Short and long term disability insurance', 'FSA', 'HSA matching']",2020-09-24 13:47:37
Data Engineer,Getty Images,3.9 out of 5,"New York, NY","['You have prior experience working as a Data Engineer, preferably in a product or customer-focused organization.', 'You are extremely comfortable working with Python and have a working knowledge of Cloud services and Tools, as well as standard engineering tools such as Git, Linux and SQL.', 'You have experience building streaming and batch data pipelines and are comfortable working within a large-scale distributed environment with open source tools such as Hadoop, Hive, Airflow and Spark.', 'You can independently execute on a project, from ideation to delivery to stakeholders, and can pro-actively interact with other engineers at Getty Images to access necessary resources or data.', 'You understand, or have interest learning about, the real-world advantages and drawbacks of various Machine Learning techniques, and have applied those to a variety of datasets.', 'A M.S. or PhD. in computer science, statistics, economics/econometrics, natural science or any other equivalent quantitative project is preferred. If you are self-taught and believe you are a good fit for this role, or have significant work experience, we would love to hear from you as well.', 'Previous experience in an analytical role, and experience working with teams of Data Scientists and Data Analysts.', 'Experience having managed or contributed to the use of Business Intelligence platforms such as Looker and Snowflake.', 'Experience with Marketing platforms such as Google Analytics and SA 360.', 'Frequent communication with others to exchange information.', 'Occasionally moving objects up to 20 lbs and frequently moving objects up to 10 lbs.', 'Frequent sedentary work that primarily involves sitting/standing; Time of each will vary.', 'Constant operation of computer and frequent usage of other office machinery, including (but not limited to) calculator, copy machine, computer printer, etc.', 'Constant assessment of accuracy and thoroughness of the work assignment.']",2020-09-24 13:47:37
"Sr. Data Engineer, Exempt",Adventist Health System/West,3.8 out of 5,"Roseville, CA","['Functions as a technical Informatica Administrator to maintain and develop ETL specifications for healthcare business and clinical users. Designs, builds and tests deliverables for complex ETL process and interfaces spanning multiple applications.', 'Moderates discussions between technical and non-technical end users, taking non-technical requirements and converting them into technical requirements.', 'Develops ETL source and target mapping design/specifications based on the business requirements and ETL standards and architecture.', 'Assesses organizations, processes, channels, applications and data to identify practical solutions. Assumes responsibility for problem assessment and resolution in compliance with SLA requirements for ETL support.', 'Participates in the on-call rotation schedule as needed.', 'Performs other job-related duties as assigned.', ""Bachelor's Degree in computer science, management information systems, applied mathematics or equivalent combination of education/related experience: Required"", 'Five years ETL development or equivalent work experience using Informatica: Preferred', 'Healthcare experience: Preferred']",2020-09-24 13:48:17
"Data Analyst, Product Analytics",Employment Opportunities at BuzzFeed,N/A,New York State,"['Help internal teams understand how BuzzFeed users interact with our range of products - through detailed analysis, dashboard creation, and regular reporting tasks.', 'Work closely with product teams to develop and test strategies for activating users and creating habitual product usage.', 'Deploy funnel analysis to understand user drop-off and conversion.', 'Administer A/B tests to evaluate feature impact and inform product strategy.', 'Conduct retention analyses that help identify investment opportunities.', 'Develop key performance metrics that align with company user retention and acquisition goals.', '2+ years of experience doing quantitative analysis.', '1+ years experience with product optimization work focused on user retention (e.g. funnel optimization) and/or user acquisition (e.g.outbound communication channels such as email or push notifications).', 'Experience with product optimization or growth best practices.', 'Very comfortable using SQL to explore large datasets.', 'Experience with Looker (or another BI tool) is a plus.', 'Excellent communication capabilities, with a focus on clearly articulating recommendations to a range of stakeholders.', 'Practiced at taking a structured approach to problem solving.', 'A supportive, inclusive atmosphere on a team that values your contributions', 'Opportunities for personal and professional growth via work experience, offerings from our in-house Learning @ BuzzFeed team, our Employee Resource Groups, and more', 'An attractive and equitable compensation package, including salary and stock options', 'A generous and well-rounded benefits program featuring PTO, unlimited sick time, comprehensive medical benefits, a family leave policy, access to mental health platforms, retirement plans, gym and wellness discounts, and much more', 'Plenty of snacks (healthy and indulgent), catered lunches, beverages, etc..']",2020-09-24 13:48:17
"Data Engineer, Cell Engineering",Tesla,3.5 out of 5,"Palo Alto, CA","['Design and implement backend services and tools that handle fleet data collection and batch processing', 'Help construct machine learning infrastructure to help increase our learnings and experimental throughput', 'Build systems to monitor and validate our battery reliability and performance tests to make sure that we are making decisions on quality experiment data', 'Improve the robustness of our experimental pipeline from the time we receive cells, to test, to results', 'Build tables with the optimum indices for fast querying. These tables will also be constrained to reduce the chance of bad data leaking into our system', 'BS/MS in Computer Science or related area, with strong software engineering experience.', 'Experience in building and maintaining databases', 'Experience with Python', 'Experience working in a Linux command line environment.', ""Experience with JavaScript and building UI's is a plus"", 'Experience with and MATLAB is a plus']",2020-09-24 13:48:17
AWS Cloud Data Engineer,"Webtellect, LLC",N/A,"Seattle, WA 98104","['Experience setting up AWS Data Platform – AWS CloudFormation, DevelopmentEndPoints, AWS Glue, EMR and Jupyter/Sagemaker Notebooks, Redshift, S3, and EC2 instances.', 'Track record of successfully building scalable Data Lake solutions that connects to distributed data storage using multiple data connectors.', 'Must have a background in data engineering – Data Warehouse Development experience would be perfect', 'Must have strong skills in SQL, Python, PySpark, and AWS', 'Experience in designing, developing, optimizing and troubleshooting complex Data Pipelines using Spark cluster', 'Ability to lead proofs-of-concepts and then effectively transition and scale those concepts into production at scale through, engineering, deployment and commercialization.', 'Serve as an expert; envision and integrate emerging data technologies, anticipate new trends to solve complex business and technical problems.', '6 month contract.', '** No 3rd parties. **', '** No Visas allowed **']",2020-09-24 13:48:17
Data Modelling Engineer - USC and GC only,Youth Power Technosoft LLC,N/A,"Upper Providence, PA","['Pay:', '$55.00 - $60.00 per hour']",2020-09-24 13:48:17
Data Analytics Engineer,"Modernizing Medicine, Inc.",3.6 out of 5,"Boca Raton, FL 33431","['Your compensation is a combination of base salary and bonus potential.', 'Health Insurance, 401(k), Vacation, Employee Assistance Program, Flexible Spending Accounts.', 'Weekly catered breakfast and lunch, treadmill workstations, quarterly onsite massages, onsite dry cleaning, onsite car wash and many more!', 'Inc. Magazine Best Workplaces of 2020', 'Inc. 5000 Fastest-Growing Private Companies in America - 2015 - 2019', 'Best Use of Technology in Customer Service (Gold) - Customer Sales and Service World Awards® - 2019', 'Customer Service Department of the Year (Gold) - Customer Sales and Service World Awards - 2018', 'South Florida Business Journal Fastest Growing Technology Company - 2016 - 2018', ""Customer Success Team of the Year by SIIA's Company CODiE - 2017"", ""People's Choice UX Award for modmed® Kiosk - 2017"", 'Gather, analyze, refine, validate, report, and publish data.', 'Deliver complete, concise, and accurate business intelligence reports/visuals.', 'Follow best practice guidelines for business intelligence at Modernizing Medicine.', 'Work with multifunctional teams to determine and articulate report requirements.', 'Analyze complex data to provide operational intelligence.', 'Monitor and manage data life cycle process.', 'Development of data quality metrics and controls.', 'Descriptive and summary statistics.', 'Data visualization supporting insights.', 'Compile, review, and analyze data through database and statistical programming.', 'Share insights across the enterprise.', ""Bachelor's degree in one of the following: engineering, computer science, or other relevant degree preferred."", 'Knowledge of data modeling, query languages (SQL, etc.), and key trends in reporting, business intelligence, and analytical processes.', 'Experience working in a data analyst role actively engaged with data and business intelligence.', 'Knowledge and understanding of relational database.', 'Ability to learn new database concepts, processes, tools, and best practices.', 'Strong verbal and written communication skills.', 'Strong analytical and problem solving skills.', 'Strong commitment to quality, architecture, and documentation.', 'Experience with python, R or other programming languages.', 'Experience with big data tools (Hadoop, Hive, Impala, etc.).', 'Your compensation is a combination of base salary and bonus potential.', 'Health Insurance, 401(k), Vacation, Employee Assistance Program, Flexible Spending Accounts.', 'Weekly catered breakfast and lunch, treadmill workstations, quarterly onsite massages, onsite dry cleaning, onsite car wash and many more!']",2020-09-24 13:48:17
Validation Engineer,HCL America Inc,2.3 out of 5,"Draper, UT 84020","['401(k) matching', 'Dental insurance', 'Health insurance', 'Vision insurance', '401(k) matching', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Shelf life testing: 1 year (Preferred)', 'Stability Testing: 1 year (Preferred)', 'Biocompatibility: 1 year (Preferred)', 'Design Verification: 1 year (Preferred)']",2020-09-24 13:48:17
Product Data Scientist,KPA,3.7 out of 5,"Lafayette, CO","['Medical (both PPO and HSA plans available)', 'Dental', 'Vision', 'Paid Time Off', 'Parental Leave', 'Holidays', '401(k) match with immediate vesting', 'Life Insurance', 'Short and long term disability insurance', 'FSA', 'HSA matching', 'Drive the discovery, collection, and preparation of new data and the refinement of existing data sources.', 'Develop a test data-driven hypotheses in order to find patterns and useful trends to help our customers.', 'Work closely with customers from product discovery through solution implementation to improve products and business methods.', 'Work with the Product and UX team to develop best practices for instrumentation and visualization of data.', 'Develop stories from data and visuals that make sense and are actionable for our customers to help them provide appropriate training,', 'Collaborate with engineers to implement machine learning techniques into our production environment.', 'Experience with R or Python.', 'Experience with predictive modeling.', 'Familiarity with data visualization in Python, R, or D3.js.', 'Experience with BI tools (i.e. Tableau, PowerBI, Sisense, etc.)', 'Understanding of relational data structures and SQL.', 'Ability to multi-task several priorities simultaneously and manage multiple projects.', 'Excellent written and verbal communication skills - being able to bring others along and speak in “common terms” for team and', 'Ability to take initiative, think on your feet, and problem solve.', 'B.A. or M.S. in Computer Science, Statistics, Applied Mathematics, or another relevant technical field.', 'Onboard to the team.', 'Become familiar with current data sets.', 'Assess the landscape of data analytics tools and technologies at KPA and establish areas of improvement.', 'Start running experiments with our data.', 'Participate in the agile development process.', 'Get to know the Product, UX Design, and Technology team.', 'Be key in the next release of our Reporting Dashboard enhancements.', 'Start to demonstrate productivity and ownership on par with the other product team members.', 'Show strong leadership and direction on our data analysis and structure.', 'Have participated in various customer discovery calls with UX and Product.', 'Have strong hypotheses towards potential data product enhancements that meet customer needs and goals.', 'Be working closely and collaboratively with our Product Managers, Designers, and Engineers.', 'Extend and optimize our Reporting Dashboard platform.', 'Be designing experiments for benchmarks, recommendation pipelines, and machine learning models.', 'Ensure the best development practices are being used and translated to execute on your data product visualizations in production.', 'Have a solid understanding of our customer base and their practical data needs.', 'Continue experimenting with the Product and UX Design team on new ways to communicate insights and provide data products to our', 'Be an expert in KPA’s products.', 'Have full ownership and direction of the machine learning models.', 'Contribute to the data science vision and processes.', 'Be a mentor and help introduce and level-up our Product Managers, UX Designers, and Engineers in data science methods and best', 'Continuously offer process improvements to our team, the business, and for our customers.', 'This position reports to the User Experience Director, Product and is a full-time exempt position.', 'The location will be at KPA’s corporate headquarters in Lafayette, CO.', 'Medical (both PPO and HSA plans available)', 'Dental', 'Vision', 'Paid Time Off', 'Parental Leave', 'Holidays', '401(k) match with immediate vesting', 'Life Insurance', 'Short and long term disability insurance', 'FSA', 'HSA matching']",2020-09-24 13:48:17
Data Engineer,Getty Images,3.9 out of 5,"New York, NY","['You have prior experience working as a Data Engineer, preferably in a product or customer-focused organization.', 'You are extremely comfortable working with Python and have a working knowledge of Cloud services and Tools, as well as standard engineering tools such as Git, Linux and SQL.', 'You have experience building streaming and batch data pipelines and are comfortable working within a large-scale distributed environment with open source tools such as Hadoop, Hive, Airflow and Spark.', 'You can independently execute on a project, from ideation to delivery to stakeholders, and can pro-actively interact with other engineers at Getty Images to access necessary resources or data.', 'You understand, or have interest learning about, the real-world advantages and drawbacks of various Machine Learning techniques, and have applied those to a variety of datasets.', 'A M.S. or PhD. in computer science, statistics, economics/econometrics, natural science or any other equivalent quantitative project is preferred. If you are self-taught and believe you are a good fit for this role, or have significant work experience, we would love to hear from you as well.', 'Previous experience in an analytical role, and experience working with teams of Data Scientists and Data Analysts.', 'Experience having managed or contributed to the use of Business Intelligence platforms such as Looker and Snowflake.', 'Experience with Marketing platforms such as Google Analytics and SA 360.', 'Frequent communication with others to exchange information.', 'Occasionally moving objects up to 20 lbs and frequently moving objects up to 10 lbs.', 'Frequent sedentary work that primarily involves sitting/standing; Time of each will vary.', 'Constant operation of computer and frequent usage of other office machinery, including (but not limited to) calculator, copy machine, computer printer, etc.', 'Constant assessment of accuracy and thoroughness of the work assignment.']",2020-09-24 13:48:17
Minerals Processing Engineer - (Mining/Chemical),"Disa, LLC",N/A,"Casper, WY 82604","['Work hand-in-hand with management on business development', 'Lead and strategize R&D for advancing the technology and taking it to market', 'Collaborate with consultants for technology R&D', 'Interface with clients on project design', 'Focus on process flow diagrams and detailed engineering', 'Structure experimental designs on a variety of materials; generate data sets and written reports', 'BS in Mining, Chemical or Minerals Processing Engineering (Masters or PhD a plus)', 'Strong Math and Science background (especially Chemistry and Physics)', '2-5 years of experience in mining, minerals processing and/or reclamation preferred', 'Experience using Auto CAD or solid works', 'Must be able to travel', 'Be able to learn about new techniques and technologies and maintain awareness on industry advancements', 'Possess an aptitude for design and computing', 'Flexible schedule', 'Monday to Friday', 'Mining/Minerals Processing: 2 years (Preferred)', ""Bachelor's (Required)"", '25% (Required)', 'Yes']",2020-09-24 13:48:17
Data Engineer,B12,N/A,New York State,"['We build our product on Python/Django and JavaScript/React.', ""We store blobs in Amazon's S3, munch on them in Amazon's EC2, develop in Docker, and deploy containers to Amazon's Elastic Beanstalk."", 'We believe Postgres should be the first system you consider when you think about persisting structured data.', ""We religiously clean and centralize data in Amazon's Redshift, and are able to answer most any question in SQL. We recently wrote our 1000th query in Metabase!"", 'Before building complex statistical machine learning models, we build simple ones we can understand. Rarely, we build complex models.', 'We have near-full test coverage on the backend, and are making progress on our frontend and integration tests.', ""We set up continuous integration and deployment because, while this model comes with its own pains, we've disliked being on fixed release schedules on previous projects."", 'We like to move fast and support point-in-time recovery :).', 'Collaborate with operational teams including sales, marketing, and customer success.', ""Contribute to infrastructure that enables and informs B12's analytical efforts."", 'Write SQL queries and reusable views that enable various analyses including funnel, retention, and performance reporting.', 'Use Python to clean data, send it to various systems including our data warehouse and operational services, and perform feature engineering to power the creation of predictive models.', 'Build rules-based models and statistical machine learning models in Python using packages like scikit-learn.', 'You are fluent in SQL and Python.', 'You have experience building and using data infrastructure, including systems like Postgres and Redshift.', ""You've used reporting tools like Metabase, Tableau, or Looker in the past."", 'You know that no dataset is ever pristine, but love to interrogate, structure, and clean data.', ""You've contributed to extract-transform-load pipelines to collect data from disparate sources and centralize them in a data warehouse."", 'You feel comfortable managing your time and deciding amongst competing priorities.', 'You have worked with non-engineering teams and are comfortable explaining technical solutions to them.', 'You are passionate about the future of work.', 'You enjoy learning and teaching.', 'You have strong written and verbal communication skills in English.', 'You care about and want to contribute to our mission of helping people do meaningful work.', ""We don't have a minimum number of years of experience for this role. We highly favor talent and interest."", ""Some candidates may see this list and feel discouraged because they don't match all the items. Please apply anyway: there's a good chance you're more wonderful than you think you are."", 'B12 is a safe place for human beings. We are dedicated to building a diverse and inclusive team with a wide range of backgrounds and experiences, each helping us understand our customers better, and strengthen our team. We particularly encourage you to apply if you identify as a woman, are a person of color or other underrepresented minority, or are a member of the LGBTQIA community.', 'A pointer to your CV, resume, LinkedIn profile, or any other summary of your career so far.', 'Some informal text introducing yourself and what you are excited about.', ""If you have a profile on websites like GitHub or other repositories of open source software, you can provide that as well. If you don't have one, it's still very possible for us to get along just fine!""]",2020-09-24 13:48:17
Data Privacy Engineer,Trimble,3.7 out of 5,"Westminster, CO","['Build and maintain Data Protection and privacy service offerings that can be used by all Trimble divisions, including:', ""Tools and processes to ensure we're using personal data correctl"", 'Collaboration with Information Systems and Product Development teams to implement technical and process best practices in data protection across the organization', 'Internal consultation, training and assessments', 'Be an evangelist for data protection throughout the enterprise', 'Think broadly in your approach as new privacy regulations develop', 'BS or MS in computer science, information systems or related experience', 'At least 5 years of experience, including 3 years of software engineering experience on public clouds such as AWS or Azure', 'Must have experience and working knowledge of GDPR and CCPA', 'Experience consulting or technical pre-sales, or other customer-facing role is also desired', 'Understanding of the IT and/or software engineering process and tools', 'Understanding of best practices in data lifecycle management, security and data protection and privacy', 'Analytical, but pragmatic mindset and ability to simplify complex concepts', 'Ability and willingness to learn more about data protection and deepen knowledge e.g. by taking certification exams and be the technical expert. CIPP or CIPT certification is a plus.', 'Excellent (internal) customer service and communication skills, both written and verbal (to the right audience), with a strong attention to detail', 'Able to work with little day-to-day direction, working across multiple organizations / roles, on multiple simultaneous projects', 'Quickly establish competence and trust with your (internal) customers', 'Flexibility with working hours as your colleagues are located across the globe']",2020-09-24 13:48:17
Azure Data Engineer,Publicis Sapient,3.9 out of 5,"Houston, TX","['Work across a cross-functional team to develop and deliver cloud, data, and analytics solution for enterprise clients', 'Develop and deliver large-scale Azure cloud application development and transformation engagements, helping enterprise customers understand cloud considerations, develop cloud application strategies and helping refactor existing applications for Azure, as well as develop new Azure-based cloud-native applications on Azure PaaS.', 'Implement data solutions in Azure including Azure SQL, Azure Synapse, Cosmos DB, Databricks', 'Build data models and reports for business users', 'Experience in implementing data solutions in Azure including Azure SQL, Azure Synapse, Cosmos DB, Databricks', 'Hands on experience configuring Delta Lake on Azure Databricks', 'Experience in designing data solutions in Azure including data distributions and partitions, scalability, disaster recovery and high availability', 'Hands on experience with C#, ASP.NET, MVC, .NET Core, .Net Framework (4.6) JSON, and API development.', 'Hands on development or architecture of Azure SQL or SQL DWH (synapse)', 'Proficiency with DevOps and CI/CD methodologies and tools for automated infrastructure code test, integration, deployment, and assurance', 'Azure Synapse Analytics', 'Data Migration from on Prem to Azure', 'API Management', 'Azure Logic Apps', 'Azure Function Apps', 'Power BI & Tibco Spotfire']",2020-09-24 13:48:17
Data Engineer/System Analyst,State Street,3.5 out of 5,"Quincy, MA 02169","['Analyze and organize data into meaningful business concepts', 'Design efficient data models that support common model strategy', 'Map raw information from different sources/applications into common terms and structures', 'Evaluate business needs and objectives to design solutions that meet client deliverables', 'Collaborate with developers to design, build and test life cycle for data ingestion', 'Coordinate Design Review Sessions', 'Collaborate with Data Governance in incorporating common model into IGC', 'Utilize tools for mapping (DEH/IDW) , modeling, and creation of AVRO schemas', 'Strong technical, strategic and business analysis skills with the ability to solve complex problems', 'The ability to manage resources and project to meet deadlines.', 'Written and verbal communication skills', 'Strong experience in designing data models that are efficient, agnostic to source, scalable and performs as required', 'BS degree in Computer science or related degree', '10+ years demonstrated experience in related field', 'Experience with SQL', 'Experience with Data Modeling tools: Visio, Erwin and Toad Data Modeler', 'Knowledge and experience working within financial services and related data domains']",2020-09-24 13:48:17
Sr. Data Engineer,Blueprint Technologies,3.3 out of 5,Washington State,"['At least 10-years of experience as a data engineer', 'At least 5-years of experience with SQL Development (ETL, transformations, stored procedure)', 'Proven ability in building high-performance and scalable data solutions using Azure, or similar cloud platforms', 'Excellent collaboration skills to work on a team as well as independently (be self-reliant and resourceful)', 'Excellent organization skills and able to multi-task and detailed oriented', 'Excellent verbal and written communication skills (must be able to write clear and concise emails for any audience, etc.', 'Experience building out large-scale integration landscapes for an Enterprise. Including strategy and execution on Enterprise level APIs for near real-time communication between software systems', 'Ability to look at solutions in unconventional ways and see opportunities to innovate', 'Proven experience in accessing, communicating and implementing enterprise strategy', 'Ability to architect and build out integration pipelines', 'Experience with Python/Pyspark (Databricks or Spark)', 'Excellent design, coding, testing, problem solving, and debugging skills', 'Well versed with software development and deployment best practices', 'Ability to quickly learn new technologies, application domains, implementing new knowledge and adapt to changes', 'Excellent critical thinking and problem-solving skills.', 'Ability to develop simple, elegant solutions to complex problems', 'Excellent verbal and written communication skills, team player', 'Expert with AWS cloud environment', 'Experience working with Databricks and Spark', 'Experience with team building and mentoring', 'A people person, being both highly motivated and motivating', ""Bachelor's or Master's degree in Computer Science, Computer Engineering or related technical discipline is favored.""]",2020-09-24 13:48:17
Junior Systems Engineer,ManTech International Corporation,4 out of 5,"Stafford, VA 22554","['Job', 'Company', 'Develop Department of Defense Architecture Framework (DoDAF) 2.02 and Marine Corps compliant solution architectures.', 'Participate in the collaborative process of identifying and capturing architecture data with engineers, technical subject matter experts and information technology standards personnel.', 'Identify common data shared across Marine Corps Solution Architecture and participate in efforts to reuse common data.', 'Research and analyze new and existing technologies and tools to provide more efficient architecture development techniques and processes.', 'Promote and educate stakeholders on the use and value of architecture.', 'Coordinate, and participate in architectural meetings and events', 'Familiar with DoDAF 2.02 and solution architecture development.', 'Ability to think critically and problem-solve.', 'Certified Enterprise Architect (CEA)', 'Basic familiarity with one of the following: System Architect, MagicDraw, Innoslate, Vitech Core or Genesys', 'Basic familiarity with one of the following: UML, SysML, UAF, UPDM, BPMN, IDEF Written and oral communication skills', 'Bachelor of Science Degree in Computer Science, System Engineering, Model Based Systems Engineering or Enterprise Architecture']",2020-09-24 13:49:00
2021 - Undergraduate Leap Technology Program,Fidelity Investments,4.1 out of 5,"Westlake, TX 76262","['A robust 2-week onboarding aimed at cultural immersion, development of vital teamwork and virtual collaboration capabilities, and meaningful, cross-company connections.', 'Extensive technical skill development delivered through a combination of digital and instructor-led training and numerous internal learning opportunities.', 'Team-based hands-on project work that integrates fully with your technical skill development to provide real-world application of skills.', 'Direct technical coaching throughout the learning journey to support broader or deeper skill development as needed for your personal learning outcomes.']",2020-09-24 13:49:00
Principal/Senior Software Engineer,Liberty Mutual Insurance,3.6 out of 5,"Dover, NH","['Job', 'Company', 'Develop effective, defect free source code that meets business requirements and team standards.', 'Participate in unit test case development', 'Develop complex test scripts.', 'Conduct impact analysis.', 'Develop component design', 'Provide system/application architecture', 'Contribute technical alternatives', 'Develop production support documentation.', 'Interact with customers and development team to gather and define requirements', 'Work within project team on iterative development that delivers a high-quality product.', 'Execute all levels of testing (System, Integration, and Regression)', 'Analyze user stories for validity and feasibility', 'Provide functional/system integration testing support.', 'Perform Quality Assurance coding and design review; defects or discrepancies in requirements identified and resolved with appropriate partners and stakeholders.', 'Plan work out appropriately, proactively escalates issues that may impact scope, schedule, budget.', 'Participate in the development of Build and Deployment guide and script.', 'Mentor new developers and junior developers.', 'Strong enterprise-level software development experience in an object-oriented language, preferably Java/J2EE', 'Solid programming discipline: unit testing, fault tolerance, data structures, complexity analysis, object-oriented principles, design patterns, etc.', 'Oracle, SQL Server, DB2', 'Familiarity with CI/CD and DevOps tools such as BitBucket/Git or Gradle/Jenkins', 'Experience driving platform modernization initiatives including micro services, cloud deployment and technologies such as: AWS, Docker, Java, NodeJS, Spring Boot', 'Experience working in an agile environment (Scrum, Kanban, XP, etc.) is preferred', 'An evident appreciation of current and emerging technology trends', 'Desired Qualifications:', 'Bachelors or master’s degree in technical or business discipline or equivalent experience.', 'Generally, 8+ years of professional experience.', 'Strong oral and written communication skills; presentation skills.', 'Proficient in negotiation, facilitation and consensus building skills.', 'Proficient in new and emerging technologies (microservices, AWS, & Docker a plus).', 'Thorough knowledge of the following: IT concepts, strategies and methodologies. Business function(s) and of business operations.', 'Proficiency in multiple programming languages and tools (Java, Spring, experience).', 'Understanding of agile software development concepts and processes', 'Thorough understanding of backlog tracking, burndown metrics, and incremental delivery.', 'Collaboration, prioritization, and adaptability skills required.']",2020-09-24 13:49:00
Software Engineer (Fullstack),6 River Systems,N/A,"Waltham, MA","['Develop new features across multiple domains (browser, cloud, and bots) as we build:', 'Performant, resilient, horizontally scalable back-end web servers', 'Real-time views of orders, inventory, and overall efficiency', 'Efficient workflows for collaborative robots driven by behavior trees', 'Create scripts and data migration plans to integrate with existing frameworks and databases', 'Work with a squad of 4-6 awesome Software Engineers, embedded QA, and a Product Manager to build end-to-end solutions', 'Scrappy, yet thoughtful approach to problem solving', 'Practical experience designing and developing scalable software', 'Interest in working with a variety of technologies, including:', 'TypeScript or JavaScript', 'NodeJS', 'PostgreSQL Databases', 'Object Oriented Programming (SOLID)', 'Knowledge of:', 'Relational databases and data modeling', 'Networking (HTTP)', 'Microservices Architecture', 'Docker, Kubernetes, GCloud', 'Interest in behavior trees and real-world applications for robots', 'Commitment to rigorous testing and validation (we write lots of unit tests)', 'Entrepreneurial spirit of a start-up combined with the stability of a global commerce company', 'Competitive compensation packages and Shopify RSUs', 'Company-paid health, dental, and vision coverage for all employees', 'Paid holidays, vacation/sick time, and parental leave', 'Annual 401k contribution from the company', 'Lifestyle spending account', '401(k)', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Employee discount', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Parental leave', 'Professional development assistance', 'Referral program', 'Vision insurance', 'Monday to Friday', 'Fully Remote', 'Dependable -- more reliable than spontaneous', 'People-oriented -- enjoys interacting with people and working on group projects', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Achievement-oriented -- enjoys taking on challenges, even if they might fail', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'A job for which military experienced candidates are encouraged to apply', 'A job for which all ages, including older job seekers, are encouraged to apply', 'Open to applicants who do not have a college diploma', 'https://6river.com', 'Only full-time employees eligible']",2020-09-24 13:49:00
Data Engineer,X-Mode Social,5 out of 5,Virginia,"['Write Spark, Python/Scala, and SQL to perform ETL on billions of location records per day', 'Implement ETL pipelines in AWS (EMR/Glue) to support feature stores for analysis and machine learning use cases.', 'Write complex SQL, including geospatial, to fulfill customer requests for analysis', 'Build dashboards to surface data-driven insights', '3-5 years of data engineering or relevant industry experience', '1+ years experience and working proficiency with Spark', ""Bachelor's Degree in Computer Science or related technical areas like Math, Statistics, and/or other Engineering degrees"", 'Strong proficiency with Python', 'Advanced proficiency with SQL, comfortable with complex joins', 'Familiarity with Scala preferred', 'Knowledge of AWS data engineering products (S3, RDS, EMR, Glue, Athena...) is a plus', 'Experience with spatial data, joins and operations is a plus', 'Self-initiative and an entrepreneurial mindset', 'Strong communication skills', 'Passion for data', 'Cool people, solving cool problems.', 'Competitive Salary', 'Medical, Dental and Vision', '15 Days of PTO (Paid Time Off)', 'We value your input. This is a chance to get in on the ""ground floor"" of a growing company']",2020-09-24 13:49:00
Data Engineer,Caserta,N/A,United States,[],2020-09-24 13:49:00
Data Engineer,Claremont Mckenna College,4 out of 5,"Claremont, CA 91711","['Organize reliable and efficient operations of campus data integrations and tools used to implement the integrations', 'Lead configuration, management, and access control for SaaS deployments.', 'Conduct design architect reviews, gap analysis and assessment when required.', 'Develop Interfaces using middleware technologies.', 'Develop a comprehensive understanding of internal customer business needs, system functionality and business processes.', 'Plan, implement, and maintain tools for exchanging data and reporting.', 'Design configurations for management and access control for student data and other campus information systems.', 'Independently and proactively monitor critical services and take appropriate action to resolve issues.', 'Produce dashboards and reports that support operations across the College.', 'Create and maintain needed documentation.', 'Create and maintain optimal data pipeline architecture.', 'Assemble data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes and optimizing data delivery, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using query languages and cloud technologies.', 'Build analytics tools that utilize the data pipeline to provide actionable insights into the colleges operations.', 'Take and follow directions.', 'Work cooperatively with others.', 'Receive and respond appropriately to constructive criticism.', 'Display a positive attitude.', 'Balance multiple tasks and priorities.', 'Performs other essential duties and tasks specific to the position.', 'Experience working with relational databases, query authoring as well as working familiarity with a variety of databases.', 'Experience building and optimizing data pipelines, architectures and/or data sets.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Experience building processes supporting data transformation, data structures, and metadata.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Technical understanding and experience with single sign-on and multi-factor authentication.', 'Background knowledge of TCP/IP, DNS, HTTP, SQL, Active Directory, Linux, Bash.', 'Dell Boomi Developer or Administrator Certifications', 'Workday Developer or Report Writing Certifications', 'Advanced working knowledge of a query language (SQL).', 'Strong problem-solving and critical thinking skills to develop and test hypotheses.', 'Desire and willingness to keep up with constantly changing cloud offerings by reading widely, attending conferences and networking with other IT professionals.', 'Ability to communicate technical concepts in simple terms.', 'Demonstrate effective, accurate and clear communication with excellent/strong verbal, written, interpersonal, reading, phone, and customer service skills. Follow all written and verbal instructions, asking questions as needed for clarification of projects/tasks/duties/assignments.', 'Prioritize and perform multiple projects/tasks, meet deadlines/timelines, respond to others in a timely manner, and work both independently and as a collaborative member of the College with a high standard of integrity and ethics, in support of the College’s strategic vision and the division’s/department’s annual goals.']",2020-09-24 13:49:00
Workday Data Modeler,Milan Solution,N/A,"McLean, VA","['PRISM data modeling: 5 years (Required)', 'ER Studio or Erwin: 3 years (Required)', 'Big Data: 3 years (Required)', 'Data Modeling: 5 years (Required)', 'Workday Echo system: 5 years (Required)', ""Master's (Required)""]",2020-09-24 13:49:00
Petroleum Engineer / Production Engineer,Countrymark Refining and Logistics,N/A,"Evansville, IN 47715","['Identify, generate and implement production enhancement opportunities, both completion and drilling, as part of a multi-discipline area team.', 'Monitor performance of existing production and provide recommendations for improvement and best optimization methods.', 'Identify, plan, and implement expense and capital production enhancement projects (workovers, stimulations, waterfloods, new drills, etc.).', 'Develop workover and waterflood drilling projects and Authorization for Expenditure (AFE).', 'Perform artificial lift optimization and selection of artificial lift type.', 'Design and/or size facilities and equipment.', 'Work with integrative team members to prepare risked reserve estimates and economics for drilling prospects, workovers, well service jobs and new facility or expansion projects.', 'Foster operation reviews involving production, completion and expense optimization of individual well or field performance.', 'Utilize ARIES program to provide economic evaluations for projects and acquisitions including calculation of estimated reserves, costs and cash flow.', 'Forecast production data for yearly budget process, Long Range Plan, and other presentations/forecasts, including end of month reports and Balance Score Card.', 'Run project economics.', 'Analyze potential acquisition opportunities and prepare presentations.', 'Solve technical problems for the field operations.', 'Put together data for and manage the process to have annual reserve report prepared.', 'Provide technical and operational support for company-operated completions and remedial workovers in oil and gas wells', 'Participate in multi-discipline well planning team', 'Interface with Operations & Technical Team Leaders (Engineers, Geologists, Techs, etc.) to execute projects effectively.', 'Perform field studies and build economic models to determine value for acquisitions or divestitures.', ""Carry out budget preparation and monitoring; prepare cost analysis, estimates, and AFE's for routine workovers and completion/recompletion of wells."", 'Liaise with production managers to champion capital project activities and regular well reviews.', 'As needed, supervise field activities such as drilling, frac jobs, acid jobs, and other work that may arise.', 'Develop goals and performance metrics. Track and measure metrics, implementing improvements as necessary.', 'Identify and incorporate best practices from past operations to ensure continuous improvement.', 'Proficiency in ARIES or other economic-related analysis programs.', 'Knowledge of well design and completion operations, with capability to ensure safe, consistent and high performance operations.', 'Strong analytical and problem solving skills.', 'Knowledge of government regulations and permitting requirements.', 'Strong communication skills, teamwork behaviors, ability to work in cross-functional teams and influence partners.', 'Ability to communicate throughout the organization including making presentations and communicating with executive management.', 'Work effectively, relate well with others, and exhibit a professional manner in dealing with others, working to maintain constructive working relationships.', 'Demonstrate the ability to organize and manage multiple priorities.', 'Knowledge of operations; production, injection, gathering systems and surface facilities equipment.', 'Capable of measuring performance to company goals and standards.', 'Serve as a resource (experience, knowledge, process) to team and teammates.', 'Able to function well on high performance teams and be a strong team player.', 'Proficient in Microsoft Office Suite.', 'Experience with Avocet and Oil Field Manager (OFM) preferred.', 'Advocate for the use of industry standard production equipment and practices.', 'Strong decision-making skills.', 'Adapts to change and ambiguity.', 'Perform in field and on-site observations.', 'Demonstrates CountryMark’s core values of Excellence, Improvement, Innovation, Integrity, and Reliability.', 'Must be able to accommodate travel (5%) and extended hours as needed.']",2020-09-24 13:49:00
Data Engineer/ ETL Developer,SDH Systems,N/A,"Chicago, IL 60604","['Create and enhance datasolutions enabling seamless delivery of data and is responsible for collecting, parsing, managing and analyzing large sets of data across different domains for analysis.Works with various departments in collecting requirements and creates tables to load data based on business requirements. Manages data in Development, QA and PRODUCTION environments ensuring seamless delivery to the customers.', 'Use different Data warehousing concepts to build a Data warehouse for internal departments of the organization.Applies Data warehousing concepts such as star and snowflake schema approach while creating tables and maintaining data to ensure data integrity.', 'Designs and develops data pipelines, data ingestion and ETL processes that are scalable, repeatable and secure for stakeholder needs.Designs ETL Processes using Informatica tool to extract data from heterogeneous sources and transforms data using complex logic as per business needs and ingests it into our warehouse.', 'Build Data architecture to support data management strategies to support business intelligence efforts for various stakeholders.Ensures data stored in the warehouse can be used to create dynamic Business Intelligence reports for complex analysis helping in making business driven decisions.', 'Leads the design of the logical datamodel and implements the physical database structure and constructs and implements operational data stores and dataManages access to confidential data by creating database views and data marts for customers and ensures confidential data is shared using company policies.', 'Support deployed dataapplications and analytical models by being a trusted advisor to Data Scientists and other data consumers by identifying data problems and guiding issue resolution Data Pipeline Management.Works with other team members in analyzing the data and advises on how to improve data quality and provide cleaner solutions to business stakeholders.', 'Develops real-time and batch ETL dataprocesses aligned with business needs, manages and augments data pipeline from raw OLTP databases to data solution structures.Builds complex ETL process using Informatica to transform the data as per business needs and automated the process capturing real time data and maintaining history for complex analysis.', 'Documents data flow diagrams, security access, data quality and data availability across all business systems.Documents all processes of every project using JIRA for reference by any other member on the team and ensures it is always secure.']",2020-09-24 13:49:00
Technical Engineer,"Inovalon, Inc.",3.1 out of 5,Remote,"['Convey technical jargon in a wide array of syntax from beginner level users to advanced users in our tickets as well as knowledge base articles;', 'Uses a strong sense of urgency in issue resolution;', 'Advocate to empower end-users to support themselves using our knowledge base;', 'Evaluate, troubleshoot, and follow-up on customer issues as well as replicate and document for further escalation;', 'Innovation - look for creative ways to solve incidents; collaborate with Senior Technical Engineers and Technical Architects for faster resolution;', 'Participate in technical swarms during escalated engagements;', 'Author knowledge base articles;', 'Mentor and support other team members, provide technical guidance across multiple products;', 'Prioritize and manage assigned support tickets while adhering to department service level standards;', 'Maintain positive attitude and advocate for the customer through product issue resolution;', 'Follow department processes for issue resolution, escalation and triage;', 'Available to work rotating late shift schedule as assigned, as well as provide scheduled support during evening and weekend hours;', 'Maintain compliance with Inovalon’s policies, procedures and mission statement;', 'Adhere to all confidentiality and HIPAA requirements as outlined within Inovalon’s Operating Policies and Procedures in all ways and at all times with respect to any aspect of the data handled or services rendered in the undertaking of the position;', 'Fulfill those responsibilities and/or duties that may be reasonably provided by Inovalon for the purpose of achieving operational and financial success of the Company; and', 'Uphold responsibilities relative to the separation of duties for applicable processes and procedures within your job function.', 'Minimum 2 years’ experience in a software and technical engineering or implementation;', 'Understanding of basic SQL and database concepts;', 'Familiarity with authentication technology (SAML, JWT);', 'Desire to learn, master and teach;', 'Strong teamwork skills for cross group cooperation;', 'Strong written and verbal communication skills;', 'Motivated, thorough, articulate, detail-oriented, creative, personable, organized and a team-player;', 'Proficiency with Microsoft Office 365, PowerPoint, Word and Excel required;', 'Experience with Tableau dashboards and basic administration is a plus; and', 'Experience in other cloud and data technologies such as AWS, Looker and Snowflake are also a plus.', 'High School Diploma or equivalent is required; and', 'Associates degree in computer sciences, software design, information systems or equivalent experience.', 'Sedentary work (i.e. sitting for long periods of time);', 'Exerting up to 10 pounds of force occasionally and/or negligible amount of force;', 'Frequently or constantly to lift, carry push, pull or otherwise move objects and repetitive motions;', 'Subject to inside environmental conditions; and', 'Travel for this position will include less than 5%.']",2020-09-24 13:49:00
Data Engineer,Helen of Troy,3.4 out of 5,"El Paso, TX 79912","['Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing data infrastructure for greater scalability', 'Ensure the effective collection, organization and distribution of data from a variety of data sources', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management', 'Translate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies', 'Create and maintain excellent data documentation that allows the data to be understood (Metadata) and leveraged for additional use', 'Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions', 'Analyze data to find actionable insights and “tell the story” of our business as well as help deliver solutions to any business needs', 'Use machine learning, text-mining/NLP to extract insights from structured and unstructured data to assist in new product development, improving the quality of the products and customer service experience', 'Explore/analyze company’s operational data and find correlation between different business process to improve and/or recommend changes to business processes', 'Develop programs to assist business in improving marketing strategy, product pricing and customer retention', 'Build strong relationships with the different departments, teams, and support functions to understand the business needs', 'Collaborate and knowledge share with internal stakeholders to ensure single source of truth for all data', 'Conduct written and verbal presentations to share insights and recommendations to audiences of varying levels of technical sophistication', 'Determine business information needs, identify system requirements, KPIs, and methods for the data warehouse to assist with operational and strategic planning', 'Develop and implement effective/strategic business solutions through research and analysis of data and business processes', 'Troubleshoot data quality issues - identifying root cause/system & documentation/communication of resolution', 'Deliver value-add solutions at the speed of business', ""Bachelor's degree from an accredited four-year college or university in related field"", 'Experience articulating business questions and using quantitative techniques and driving insights for business', 'Solution-oriented with an ability to identify and assess risk and prioritize competing demands', 'Strong communication skills with the ability to explain technical data analysis results to business users and explain challenges and issues to a technical audience', 'Ability to devise and deliver persuasive presentations, based on data-driven insights and facts, to gain support for business strategies and/or initiatives', 'Experience in predictive/perspective models design', 'Experience in developing data pipelines and infrastructure to scale and automate extraction of data from multiple internal and external sources', 'Curious, independent mindset and attitude – you explore new technological & methodical options independently', 'Knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations', 'Strong programming skills in R and Python for exploratory and predictive analytics', 'Proficiency in data transformations, handling missing data, feature engineering, regression, classification and clustering analysis', 'Deep technical understanding of machine learning (linear models, decision trees, boosting, random forest, k-means, ensemble models etc.)', 'Experience in relational databases such as Oracle and proficiency with SQL', 'Experience working with structured, semi structured (JSON, XML) & unstructured data types (text, files etc)', 'Familiarity with Git, NoSql databases, Spark, TensorFlow', 'Applicants must be authorized to work in the United States on a full-time basis']",2020-09-24 13:49:00
Data Scientist,Vic.ai,N/A,New York State,"['Python', 'Pandas', 'AWS (EC2, RDS, KMS, SNS, etc)', 'Docker + Kubernetes + Rancher', 'Git', 'Django', 'Celery', 'Elixir + Phoenix', 'Angular.io / TypeScript', 'Tesseract + Textract', 'TravisCi', 'You will own the data pipelines that feed and interact with our AI models! You will build them, monitor them, scale them.', 'Our AI eats large amounts of data. You will work closely with our AI team to set up scalable data storage solutions, for managing our datasets.', 'As part of continuous improvement take ownership of relevant system components to improve functionality, stability and/or capability', 'Experience (3+ years) with Python, including extensive experience with Pandas.', 'Experience operating, scaling, and optimizing databases and storage systems on the cloud. Strong AWS experience preferred', 'You know that deploying software is as much about the environment as it is about the code: experience with docker, unit testing, Ci systems (TravisCi or CircleCi preferred), performance monitoring, log monitoring, and security', 'An exciting work environment operating at the forefront of AI technology development', 'A company full of talented, curious, and friendly people', 'A competitive compensation package', 'Company-paid benefits for employees such as medical, dental, vision, disability, and life insurance', 'The opportunity to work fully remotely', 'Flexible time schedules', 'A workstation and tools of your choice']",2020-09-24 13:49:00
Senior Video Operations Engineer,Ziply Fiber,N/A,"Everett, WA 98203","['Maintain the Video Hub Office through surveillance of equipment alarms and QOS tools to ensure the stability and quality of video to Frontier customers.', 'Perform proactive health checks for all primary services (linear video) and secondary services (VOD, IMG, PPV, Ad Insertion)', 'Manage and maintain surveillance system database', 'Troubleshoot and restore video service failures involving MPEG Transport streams, encoders, transcoders, Media Converters, Encryption, QOS issues pertaining to video quality, EAS, Closed Captioning, Primary and Secondary audio, Descriptive Audio', 'Perform Root Cause Analysis (RCA) for video outages including what was done to resolve the issue, what can be done to reduce impact and what could be done to prevent future occurrences', '7+ years related cable, satellite, and telephony industries knowledge', '7+ years of experience working with digital video in a multi-channel system', 'Cisco certification preferred', 'Demonstrated ability to troubleshoot and restore video service failures involving MPEG Transport streams, encoders, transcoders, Media Converters, Encryption, and resolve IP network troubles in the physical, data link, and network layers.', 'Extensive knowledge of Arris, and Synamedia technologies involved in video multichannel systems as well as layered connections and usage of LAN and WAN technologies.', 'Understanding of and ability to troubleshoot server hardware components and subsystems.', 'Demonstrated knowledge of RF, IPTV multicast and ABR delivery technologies.', 'Operations, Digital media and content management systems and applications.', 'Proven ability to create momentum and foster organizational change.', 'Proficient with MS-Project, MS-Visio, MS-Office, MS-Teams & Smartsheet', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'Everett, WA 98203 (Required)', 'United States (Required)', 'https://get.ziplyfiber.com/', 'No']",2020-09-24 13:49:00
"Software Engineer, Recent Graduate",eBay Inc.,3.9 out of 5,"New York, NY 10012",[],2020-09-24 13:49:00
Data Engineer - Junior Level,USAA,3.9 out of 5,"Plano, TX 75023",[],2020-09-24 13:49:00
Campground Data Engineer,The Dyrt,N/A,Oregon,"['Are great communicators — Effective communication is key to how we work. We value patience and empathy in our product planning, support, and day-to-day relations.', 'Work well both collaboratively and independently — We come together to pair on tricky problems and architecture, then dive deep on individual tasks.', 'Are ready to learn and share knowledge — Everyone comes to our company with their own set of skills and experiences. Cross-training, code review, mentorship, and curiosity all help us build better products.', 'Evolve and maintain campground data processing pipelines, combining public, private, and user-contributed data', 'Use natural language processing to extract relevant highlights and amenity information from campground review text', 'Coordinate manual data review and improvement projects using internal staff, community crowdsourcing, or mechanical turk', 'Make use of photo geotags and computer vision (via Amazon Rekognition / GCP Vision AI) to infer information about campground amenities.', 'Improve techniques for matching and deduplication between multiple data sources', 'Import public data on national and state parks, forests, and recreation areas to provide a better search experience', '4+ years of professional experience in data engineering, data science, software development, or related field', 'Strong backend programming skills in one or more languages', 'Experience creating and maintaining data ETL pipelines or other complex data import systems', 'Fluency with SQL and relational schema design', 'A friendly working relationship with CSVs', 'Advanced degree in math, statistics, computer science, information science, or related field', 'Experience working with geospatial datasets and GIS analysis', 'Experience applying machine learning techniques to real world problems', 'Familiarity with Elasticsearch']",2020-09-24 13:49:00
20GA590 Life Science Automation Engineers (Validation and Commissioning),Mason-Grey Corporation,N/A,"Vacaville, CA","['Generate and execute Validation life cycle documentation such as Systems Commissioning, Installation Qualification (IQ), Operational Qualification (OQ), Validation Summary Reports, and Deviations reports for Manufacturing and process Equipment & Utilities as per client GES guidelines.', 'Have expertise working with the Emerson DeltaV Process Control System and Emerson Syncade Manufacturing Execution System. Configuration within DeltaV or Syncade is not part of this requirement.', 'Perform Commissioning of Process Equipment, Utilities, HVAC Systems and Control Temperature Units in process rooms areas as per GMP requirements of the Client’s operations.', 'Analyze and interpret validation test data to determine whether systems or processes have met validation criteria or to identify root causes of deviations.', 'Generate Deviation Reports, perform root cause investigation and document Corrective And Preventive Actions (CAPA).', 'Dental insurance', 'Health insurance', 'Vision insurance', '8 hour shift', 'pharmaceutical / biotech validation: 5 years (Required)', ""Bachelor's (Required)"", 'Multiple locations']",2020-09-24 13:49:00
Senior Data Visualization Engineer,Mathematica Policy Research,3.8 out of 5,"Washington, DC 20024","['Lead design and develop web and application-based data visualization products', 'Mentor junior staff in their development of design skills', 'Provide expertise in a consulting capacity on projects throughout the company', 'Help develop data visualization sections of proposals for new projects', 'Work independently and as part of a team', 'Be self-motivated to learn, introduce new ideas, and teach others', 'Demonstrated expertise in data visualization design', 'Strong design skills and attention to detail', 'Experience creating interactive web-based data visualizations using D3', 'Experience working with web technologies (D3, React/Angular, TypeScript, HTML, SCSS)', 'Experience working with design tools such as Adobe XD or Figma as well as Adobe Creative Cloud', 'Excellent listening and communication skills, including an ability to translate research findings for a policy audience.', 'Experience cleaning, managing, and analyzing large datasets.', 'Experience managing data using Python (pandas), Node, or R', 'Experience with a version control tool(git)', 'Demonstrated knowledge of User Experience design a plus', 'Experience with BI tools (Tableau, Looker, QuickSight, Power BI) a plus', 'Bachelor’s degree in relevant field; Master’s degree preferred', '7+ years of experience designing, developing, and implementing solutions in fields that include business intelligence, visual information design, and/or interactive data visualization development', 'Must be a self-starter, capable of independent learning, and inclusive.', 'Must have the ability to juggle multiple projects and be responsible for competing deadlines', 'Must have an entrepreneurial spirit to bring technical solutions to an audience that is not technically savvy', 'Have a strong desire to improve society through evidence-based research', 'Ability to work well in teams', 'Strong writing skills']",2020-09-24 13:49:00
Process Engineer,Tesla,3.5 out of 5,"Sparks, NV 89434","['Develop expertise in manufacturing processes. Understand process capabilities through critical data analysis and in depth understanding of the product. Develop and modify line layouts, including material flow, waste reduction, and ergonomics, utilizing Lean Manufacturing best practices. Participate in the transition of a product from concept to pilot line production and into mass manufacturing.', 'Analyze and optimize production processes to ensure safety while maximizing Overall Equipment Effectiveness (OEE) in cost effective means while driving to achieve world-class quality levels. Champion continuous improvement projects (CIP) to maximize yield, capacity, and capability.', 'Responsible for diagnosing issues found during the part manufacturing process and drive corrective action back to source, resulting in root cause identification and elimination. Utilize structured problem solving techniques such as DMAIC, Ishikawa, Five Why (5W) and Eight Disciplines (8D).', 'Analyze data from various sources to identify trends in build quality and efficiency. Develop robust and clear data collection, visualization, and analysis tools. Enable data driven operational and financial decisions through predictive insights into tool and process performance, including integration of factory data systems and use of software such as MySQL, Python, R, JMP, Minitab, Tableau and Ignition.', 'Perform supporting activities for engineering and manufacturing including 5S and Lean manufacturing activities, material handling improvements, production line configuration, and safety procedures.', 'Monitor and reduce process variation using techniques such as Statistical Process Control (SPC) and Measurement Systems Analysis (MSA). Monitor and audit manufacturing processes to ensure product specifications and standards are achieved. Participate in the development and maintenance of FMEAs and Control Plans. Analyze, develop, process, and implement Engineering Change Orders.', 'Create and maintain Manufacturing Instructions, routings, and associated processes. Develop and train sustaining technicians, assist in the training of operators as needed. Manage activities for process sustaining technicians to support day to day coverage of production line, including developing and documenting appropriate rework procedures.', 'Support 24 by 7 production operations', 'Compulsory:', 'Preferred:', 'Exceptional capacity for managing simultaneous activities, competing priorities and challenges.', 'Strong ability to work and communicate effectively with team and peers within a manufacturing and engineering organization. This includes excellent communication skills: written and verbal.', 'Creative capacity for developing new ways to do things better, cheaper, faster in alignment with the Tesla approach to revolutionary product development.', 'Passion for making fantastic new products and using testing as a means to enable an engineering organization to achieve outstanding quality, reliability and excellence.']",2020-09-24 13:49:48
Senior Data Engineer,Publicis Sapient,3.9 out of 5,"Arlington, VA","['Lead, design, develop and deliver large-scale data systems, data processing and data transformation projects.', 'Combine your technical expertise and problem-solving passion to work closely with clients, turning complex ideas into end-to-end solutions that transform our clients’ business', 'Deploy, manage and audit best practices for clients’ products.', 'Actively participate in overall engagement from strategy, assessment, migration and implementation.', 'Execute technical feasibility assessments and project estimates for moving databases and data processing.', 'Mentor, help and grow junior team members.', 'Demonstrated experience designing, implementing and supporting enterprise-grade technical solutions for meeting complex data requirements.', 'Ability to handle multiple responsibilities simultaneously in leadership and contributing to tasks “hands on.”', 'Strong and innovative approach to problem-solving and creating solutions.', 'Advanced experience with data modeling, table design and mapping business needs to data structures.', 'Experience designing and building data marts, warehouses and customer profiles databases.', 'Knowledge of cloud-based big data architectures.', 'Experience with Data Lake, SQL data warehouse and Cosmos DB.', 'Experience using Data Management Gateway and storage options.', 'Willingness to travel.', 'Flexible vacation policy; time is not limited, allocated, or accrued', '15 paid holidays throughout the year', 'Generous parental leave and new parent transition program', 'Tuition reimbursement', 'Corporate gift matching program']",2020-09-24 13:49:48
Big Data Engineer,Rocket Homes,N/A,"Detroit, MI 48226","['Bachelor’s degree in computer science or equivalent experience', '2 years of experience with big data tools: Hadoop, Spark, Kafka, NiFi, Hive and/or Sqoop', '2 years of experience with AWS cloud services: EC2, S3, EMR, RDS, Redshift, Athena and/or Glue', '2 years of experience with stream-processing systems: Spark-Streaming, Kafka Streams and/or Flink', '3 years of experience with object-oriented/object function scripting languages: Java (preferred), Python and/or Scala', '2 years of experience with relational SQL and NoSQL databases like MySQL, Postgres, Cassandra and Elasticsearch', '2 years of experience working in a Linux environment', 'Expertise in designing/developing platform components like caching, messaging, event processing, automation, transformation and tooling frameworks', 'Demonstrated ability to performance-tune MapReduce jobs', 'Strong analytical and research skills', 'Demonstrated ability to work independently as well as with a team', 'Ability to troubleshoot problems and quickly resolve issues', 'Strong communication skills', 'Experience with managing real estate data', 'Experience leading a team of engineers on a large enterprise data platform build', 'Focus on scalability, performance, service robustness and cost trade-offs', 'Design and implement high-volume data ingestion and streaming pipelines using Apache Kafka and Apache Spark', 'Create prototypes and proofs of concept for iterative development', 'Learn new technologies and apply the knowledge in production systems', 'Develop ETL processes to populate a data lake with large data sets from a variety of sources', 'Create MapReduce programs in Java and leverage tools like AWS Athena, AWS Glue and Hive to transform and query large data sets', 'Monitor and troubleshoot performance issues on the enterprise data pipelines and the data lake', 'Follow the design principles and best practices defined by the team for data platform techniques and architecture']",2020-09-24 13:49:48
Data Engineer,Navigator CRE,N/A,"Seattle, WA","['Acquire data from primary or secondary sources and maintain databases/data systems', 'Identify, analyze, and interpret trends or patterns in complex data sets', 'Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems', 'Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality', 'Work on scripts to automate the data cleaning process (Python)', 'Write SQL queries to analyze data, generate insights & produce descriptive statistics and reports', 'Work with spreadsheets to analyze, cross-reference & validate data', 'Work with data analytics team to prioritize business and information needs', 'Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc.)', 'Experience with programming/scripting languages, specifically Python and Pandas', 'Proficiency in combining multiple sources, data manipulation & reporting in Microsoft Excel / Python', 'Basic familiarity with Azure (preferred – not required)', 'Technical expertise regarding data models, database design development, data mining and segmentation techniques', 'Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy', 'BS in Mathematics, Economics, Computer Science, Information Management or Statistics', 'Experience using DBMS such as MySQL, PostgreSQL, Oracle or MSSQL', 'Ability to manage workload and self-prioritize effectively', 'Ability to work independently or in collaborative environment', 'Can clearly communicate cross-functionally among both technical and non-technical roles']",2020-09-24 13:49:48
Senior Data Engineer,Erstom,N/A,"Minneapolis, MN","['Design, develop, and automate scalable data engineering solutions by leveraging cloud infrastructure. Extend or migrate existing data pipelines to new cloud environment.', 'Lead technical projects involving design and development of data pipelines for complex datasets. Document project plans, outline tasks and milestones, provide estimation of effort.', 'Work closely with business partners to devise and manage data pipelines, load frequency, data delivery mechanisms, and performance tuning.', 'Identify and implement best practices for data engineering and software development to ensure quality delivery of enterprise solutions.', 'Help enable team alignment by participating in code reviews, change management and team meetings.', 'Develop and maintain detailed technical documentation of data engineering solutions.', 'Collaborate with key stakeholders, both internal and external, including enterprise data architect, data modelers, and subject matter experts (SMEs).', 'Five or more years of professional experience as data engineer. Bachelor’s degree in Computer Science or equivalent experience.', 'Demonstrated experience in data warehousing and ETL development.', 'Experience building complex data pipelines using large, disparate data sources.', 'Demonstrated expert knowledge in SQL.', 'Demonstrated experience working with relational databases such as Oracle, Postgres and other modern database technologies.', 'Proficiency in modern programming languages such as Python, R, Java.', 'Thorough understanding of data movement and transformation tools, such as Informatica, Datastage or equivalent.', 'Demonstrated experience in selecting tools, methods, techniques, and evaluation criteria for designing optimal data engineering solutions.', 'Demonstrated experience in leading complex technical projects, including assigning tasks and selecting team members.', 'Ability to make technical presentations to teams, focus groups, management, and governance committees.', 'Excellent customer service, communication and collaboration skills.', 'Five years or more experience as data engineer designing and implementing complex data pipelines.', 'Master’s degree in Computer Science, Information Technology or related field.', 'Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.).', 'Experience with AWS technologies.']",2020-09-24 13:49:48
Lead Backup/Data Protection Engineer,CDK Global,3.2 out of 5,"Hoffman Estates, IL 60169","['Be the design authority and company SME for the global backup and recovery environments.', 'Be project orientated in your approach, whilst keeping a keen eye on standards, next generation architecture, solution improvements and cost analysis.', 'Advise on technology trends and standards.', 'Guide technical staff on assignments to achieve appropriate outcome and deliverables.', 'Drive projects and initiatives for the backup engineers to deliver against.', 'Provide support and analysis of complex problems. Provide 3rd level support as required. Provide mentorship to engineers and support staff.', 'Vendor and product analysis/selection. Possess good commercial awareness, with the ability to understand supplier proposals and promote cost effective solutions.', 'Ensure operating standards and procedures are defined and adhered to by others.', 'Identify opportunities for infrastructure and process improvements.', 'Deliver technology evaluations, Proof of concepts, and solution proposals.', 'Define and deliver on capacity planning analysis and monthly reporting.', 'As the service/technology owner, work with the Service Transitional and Service Operations teams to deliver well defined and adhered to solutions and process.', 'Function as a liaison between infrastructure teams and other teams within the company, which may include direct or indirect contact with our customers.', 'Any and all additional job duties as defined by hosting management.', 'Has 7+ years’ experience, having held a senior technical level position for at least 2 of those.', 'Not only should the candidate have extensive experience of backup technologies, they should also be able to demonstrate & articulate the needs to the business of rigorous backup and recovery processes and Disaster Recovery principals.', 'Given the importance of the backup, recovery and availability needs of customer data, the candidate should be aware of the processes and rigor required to ensure data availability during normal operations, High Availability failovers and Disaster Recovery events.', 'With a significant on-prem and cloud environments, candidates should have an in-depth understanding of commercial backup offerings of the major vendors. For example Rubrik or Veritas Netbackup', 'Have experience of providing data protection for databases such as SQL Server, Oracle and PostgreSQL.', 'Be able to demonstrate architectural and leadership qualities.', 'Demonstrates strong written and verbal communication skills, being able to articulate their ideas and thoughts to senior management. Demonstrate interpersonal and negotiating skills, being able to influence internal & external stakeholders to achieve results.', 'Has experience in creating processes and procedural documentation.', 'Demonstrates exceptional problem solving skills.', 'Providing in-depth investigations and root cause analysis of incidents and outages', 'Provide strategic direction and ensure the delivery of technical based projects', 'As experience of deploying new platforms and improvements to existing ones', 'Designing complex solutions and providing architectural recommendations', 'Have a flexible approach to your working hours whilst part of a global organisation. Work effectively with all levels of company staff; must be a self-starter, and work well in a team environment.', 'Keen to learn and develop new skills as part of continual self-development.', 'Knowledge of hosting/SaaS/ASP environments. Experience of large scale multi location data centre environments.', 'Have a working knowledge of data protection practices such as GDPR & CCPA', 'Understand the tiers of long term archive storage solutions available, both within the Data Centre and the major cloud providers.', 'The role is aligned to ITIL Service Design, so experience of being responsible of these deliverables in a design, build, run organisational structure would be advantageous.', 'Develop and maintain solution roadmaps.', 'Has experience of solution cost management.', 'Having experience of hybrid compute environments is highly beneficial, together with an understanding of AWS offerings.', 'Have been involved in defining backup/recovery processes, as well as generating supporting collateral against audit requirements.']",2020-09-24 13:49:48
"Data Engineer, Analytics (Instagram Ecosystems)",Facebook,4.2 out of 5,"New York, NY","['Craft and own the optimal data processing architecture and systems for new data and ETL pipelines', 'Build canonical datasets as well as scalable and fault-tolerant pipelines', 'Build data anomaly detection, data quality checks, and optimize pipelines for ideal compute and storage', 'Define and own the data engineering roadmap for Ecosystems', 'Collaborate with Software Engineers and Data Scientists to design technical specification for logging and add logging to production code to generate metrics both online as well as offline', 'Work with different cross functional partners - Data Scientists, Infra Engineering, Logging Framework Infra Teams, Product Managers', 'Build visualizations to provide insights into the data & metrics generated', 'Work with data infrastructure teams to suggest improvements and influence their roadmap', 'Immerse yourself in all aspects of the product, understand the problems, and tie them back to data engineering solutions', 'Recommend improvements and modifications to existing data and ETL pipelines', 'Communicate and influence strategies and processes around data modeling and architecture to multi-functional groups and leadership', 'Drive internal process improvements and automating manual processes for data quality and SLA management', 'Provide ongoing proactive communication and collaboration throughout the organization', ""4+ years' experience in the data warehouse space"", ""4+ years' experience working with either a MapReduce or an MPP system"", ""7+ years' experience in writing complex SQL and ETL processes"", ""4+ years' experience with object-oriented programming languages"", ""7+ years' experience with schema design and dimensional data modeling""]",2020-09-24 13:49:48
Data Engineer 2,Choctaw Nation,3.9 out of 5,"Durant, OK","['Works on problems of moderate scope where analysis of situations or data requires a review of a variety of factors.', 'Exercises judgment within defined procedures and practices to determine appropriate action and escalates to manager as needed', 'Builds productive internal/external working relationships.', 'Participates, and in some cases takes the lead on, formulating and monitoring data architecture policies, procedures and standards.', 'Builds moderate level complexity data interfaces, both internal and external sources', 'Participates in design of data architecture standards.', 'Designs and implements database logical and physical models', 'Provide development and production support to troubleshoot all data interfaces and data model related issues', 'Performs other duties as may be assigned.', 'Bachelors degree in computer science, computer information systems, electronic engineering or related field, and 3-4 years of equivalent experience', 'Professional Database or ETL framework focused Certifications Preferred (MS SQL Server, Oracle, SSIS, SAP DS, Informatica, etc)', '3-4 years exposure to database conceptual design, logical data modeling and capacity planning.', 'Moderate level of hands-on experience developing internal and external data interfaces and data loading plans.', 'Some experience with defining and managing data security policies', '3-4 years of converting business requirements into data, database specifications and loading plans.', 'Moderate level of hands on experience hands-on with data modeling tools (SSIS, Erwin, etc)', 'Some experience working with development teams on data used in user based interfaces and backend data requirements.', 'Bachelor’s degree in a computer information systems degree', 'Professional ETL or data modeling focused Certifications', '4 years experience with data modeling tools', 'Working knowledge of Data Governance concepts', '3-4 years exposure to database conceptual design, logical data modeling and capacity planning.', 'Experience with managing multiple Service Requests and competing priorities4-7 years of data migration experience Moderate level of hands on experience hands-on with data modeling tools (SSIS, Erwin, etc)', 'Some experience working with development teams on data used in user based interfaces and backend data requirements.', '4 years experience with data modeling tools', '5-7 years of converting business requirements into data, database specifications and loading plans']",2020-09-24 13:49:48
Jr. Backend Engineer (New Graduates-2021),Deliverr Inc,N/A,California,"['Reinvent fulfillment by designing, developing, testing, deploying, maintaining and improving pragmatic software .', 'Manage individual project priorities, deadlines and deliverables.', 'Be a full business owner: shape the foundation of the product and business that you work on.', 'Actively learn new language, techniques, and methodologies.', 'Contribute actively to code reviews and design reviews.', 'BS degree in Computer Science, similar technical field of study or equivalent practical experience.', 'Insatiable Curiosity, Undying Passion and Ownership to take on hard real world problems.', 'Extensive Typescript, Javascript, Java, or Python experience.', 'Someone who follows TDD or in general likes to write tests.', 'Experience shipping production code with full instrumentation: deployment, logging, and monitoring, and documentation.', 'Experience processing large amount of data.', 'Experience with building and evolving REST APIs.', 'Experience with distributed systems.', 'Excellent communication skills in verbal and written English.', 'Must be based in North America.', ""Master's, PhD degree, further education or experience in engineering, computer science or other technical related field."", 'Prior experience in Supply Chain, Fulfillment, Logistics, Shipping and Warehouse technologies.', 'Machine learning, operations research and optimization, developing large software systems, logistics & fulfillment industry, pricing algorithms, shipping technology.', 'Rich github or hackathon accolades or other ways you can show that you love to code.', 'React and Redux for UI.', 'Independent Service Oriented Architectures with services composed of:Java, Spring and MySQL RDS.Node, Typescript, MySQL RDS.', 'DynamoDB for integration services', 'SQS for queuing.', 'We run on AWS.']",2020-09-24 13:49:48
Data Analyst (Remote),Suplari Inc,N/A,"Seattle, WA 98101","['While you don’t need to have experience in every technology we use, as a startup, we do expect you to be comfortable contributing anywhere throughout the stack. Here are some of the heavy-hitters that we rely on daily: Python, Javascript, Excel, RESTful web services, OData, PostgreSQL, Go', 'You will work with customers to gather data requirements and implement data transformation, normalization and categorization processes.', 'You will work with data scientists, product management, and customer success teams to understand data requirements.', 'You will work with other cloud service engineers as well as web application developers to build the Suplari platform and application suite.', 'Experience in scripting languages, such as Python', 'Proficient written and spoken English language skills', 'Experience with data curation and analysis leveraging Python modules including: Pyspark/pandas/dask/odo/statsmodels/scikit-learn.', 'Experience with creating & maintaining training datasets for ML algorithms.', 'Passion for tackling big data challenges.', 'Experience working with large, semi-structured datasets like legal documents, application logs, and product invoices.', 'Rigor in automated testing, continuous integration, DevOps and other engineering best practices.', 'Experience in text processing toolkits, such as NLTK or Stanford-NLP.', 'Experience in data querying languages, such as SQL or ElasticSearch.', 'BS or MS in computer science', '5 or more years of experience as a data engineer, database administrator or similar role required.', 'You love being part of a small, dynamic, and agile organization that encourages you to learn and grow', 'You love finding solutions to interesting problems', 'You welcome having autonomy with complex tasks', 'You are passionate about using your experience and expertise to inspire the team', 'Competitive compensation package', 'Ownership through equity and options', 'Company-paid health and dental benefits', 'Early-stage company experience']",2020-09-24 13:49:48
Implementation Analyst,Revint Solutions,N/A,Remote,"['Experience:Analytical , 1 year (Preferred)Client Facing , 1 year (Preferred)', 'Work authorization:United States (Required)', '0-2 years experience working with data projects', '0-2 years directly responsible for individual projects', 'Full client implementations a strong plus (bringing a client from 0 to 1)', 'Validating data for accuracy, writing data validation checks/scripts', '1+ years in a customer-facing role', 'Servicing requests and communicating directly with clients/customers', 'Both internal and external roles are acceptable (e.g. serving “internal” customers such as other departments in your company)', '1+ years experience querying data', 'Experience with one or more of the following: SQL, MySQL, Postgres, Couchbase, Mongo, DynamoDB, DocumentDB', 'Experience importing/exporting data from the systems above (e.g. SSIS, Native import tools, Custom Import tools', 'Analyzing data', 'Moderate data analysis using the systems noted above', 'Moderate report building & analysis with tools like Excel, PowerBI, Tableau, etc', 'Experience with healthcare data', 'Working with data extracts from Healthcare Information Systems', 'Experience with Epic, Cerner, or Meditech is a strong plus', 'Experience with scripting languages', 'One or more of the following: PowerShell, Bash, Perl, Python', 'Comfortable reading/modifying/testing existing scripts', 'Document Database Experience (Couchbase, Mongo, DocumentDB/Cosmos DB)', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Parental leave', 'Referral program', 'Vision insurance', 'Monday to Friday', 'Bonus pay', 'Analytical : 1 year (Preferred)', 'Client Facing : 1 year (Preferred)', 'United States (Required)', 'Fully Remote', 'https://revintsolutions.com/']",2020-09-24 13:49:48
Staff Data Engineer,Sumo Logic,3.8 out of 5,Texas,"['Building, improving, maintaining, and scaling stream processing services.', 'Writing code. Reviewing code. Revising code.', 'Giving feedback on our standards. Holding your team mates to them.', 'Collaborating with teammates on major feature designs. Sometimes, you will own features, sometimes others will.', 'Helping our team grow organically. We value referrals. We value your feedback on candidates.', 'You are a software engineer. (We treat our data systems as software systems, and engineer them accordingly.)', 'You love working with data. (Small data. Big data. All the data.)', 'You are excited to optimize for events per second (not requests per second).', 'You have deep experience working with the technologies we use: Kafka, RocksDB, ElasticSearch, JanusGraph, Postgres, Spark, HBase.', 'You know (or want to write software in) Scala.', 'You love collecting data about your software as much as writing software that collects data. We measure everything. We make data-driven decisions.', 'You are collaborative. Nothing this hard can be accomplished by working alone. We work as a team.', 'Minimum Bachelors in Computer Science or similar technical education. Masters or PhD preferred!']",2020-09-24 13:49:48
Validation Engineer,"Agilent Technologies, Inc.",4.1 out of 5,"Frederick, CO 80504","['Generates, revises, and executes documentation for validation studies ensuring compliance with QA and cGMP systems. Responsible for generating and executing validation protocols for equipment, instruments, utilities, and control systems through commissioning, URS, Software Acceptance Testing (SAT) IQ, OQ, and PQ phases.', 'Responsible for temperature mapping of facility Controlled Temperature Units, Stability Chambers, Warehouse Space, Autoclave, Incubators, Humidity Controlled Rooms/Glove boxes and Cold Rooms. Involves the startup of new Controlled Temperature Units.', 'Assist with contractor audits, supplier audits, pre-delivery inspections and on-site factory acceptance tests when related to validation. This may involve short periods of travel.', 'Responsible for the calibration of equipment supporting validation protocols and ensuring the calibration specifications for the equipment are appropriate.', 'Responsible to participate in both factory and site acceptance testing for new manufacturing and engineering equipment.', 'Required to support the validation schedule within the scope of ongoing projects.', 'Generate and oversee facility qualification of classified environments.', 'Support manufacturing, engineering, quality assurance, and quality control for validation related activities.', 'Provide the generation and execution of cleaning validation support activities, such as: spray ball coverage testing, equipment characterization reports, protocol generation and review, and equipment sampling SOPs.', 'Assist with validation planning and risk assessments associated with validation activities.', ""Resolve CAPA's, nonconformances, protocol incidents, and change controls related to validation protocols."", 'Execute lyophilizer, HVAC, and autoclave annual requalification and final package integrity testing.', 'Generate data and reports for the validation system evaluation program.']",2020-09-24 13:49:48
Data Engineer,Gradient AI,N/A,"Boston, MA 02210","['Design, build, and implement the data systems that fuel our ML and AL models', 'Develop tools to extract and process client data from different sources, and tools to profile and validate data', 'Work cross functionally with data scientists to transform large amounts of data and store it in a format to facilitate modeling', 'Contribute to production operations, data pipelines, workflow management, reliability engineering, and much more', 'BS in Computer Science (or in another quantitative discipline); 5+ years of working experience', 'Fluency in SQL, and experience with non-relational/alternative databases', 'Experience working in Python in a professional environment', 'Desire to learn new skills and tools (e.g. Redshift, Tableau, AWS Lambda, etc.)', 'Exposure working with a cloud-computing environment (e.g. AWS EC2)', 'Comfortable with Linux, including developing shell scripts', 'Experience working with Machine Learning and/or Artificial Intelligence is a bonus']",2020-09-24 13:49:48
Big Data Analytics Engineer,"FYI-For Your Information, Inc.",N/A,"Rockville, MD 20850","['Opportunity to work remotely (per contract requirements).', 'A knowledgeable, high-achieving, experienced and fun team.', 'A diverse work atmosphere.', 'The chance to be part of a rapidly growing company and the next success story.', 'Team building and innovation.', 'A competitive base salary with a loaded benefits package plus 401K.', 'Personal computer device allowance.', 'Pet Insurance.', 'Required: 5+ years IT experience', 'Required: Bachelors of Science. Graduate level degrees in Mathematics/ Statistics highly preferred', 'Required: Programming - Java / C++ / Scala/ Python', 'Required: Experience with Hadoop / Map-Reduce and/or HIVE', 'Required: SQL Development', 'Required: Unix / Shell scripting', 'Required: Designing distributed solutions for parallel processing of large data', 'Required: Full SDLC Experience (requirements analysis, design, development, unit testing, deployment, support)', 'Required: Good communication skills', 'Preferred: Big-Data technologies, Cloud Computing', 'Preferred: Test driven development', 'Preferred: Understanding NASDAQ/ Capital Markets/ Market Structures']",2020-09-24 13:49:48
ETL Data Engineer,Urbane Systems LLC,N/A,"Reston, VA","['Pay:', '$60.00 per hour', 'Day shift', 'software development: 8 years (Preferred)', ""Bachelor's (Preferred)"", 'United States (Required)', '5 - 6 months', 'Likely', 'Yes', 'Fully Remote', 'Dependable -- more reliable than spontaneous', 'People-oriented -- enjoys interacting with people and working on group projects', 'Autonomous/Independent -- enjoys working with little direction', 'www.urbanesystems.com']",2020-09-24 13:50:29
NextGen Data Engineer,BICP,N/A,"Portland, OR",[],2020-09-24 13:50:29
Data Quality Engineer,"Technalink, Inc.",N/A,"McLean, VA 22102","['$95,000.00 - $125,000.00 per year', 'Benefits:', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Referral program', 'Vision insurance', '3+ years of IT experience', '3+ years of experience with coding in at least one scripting language, including Python', 'Experience with developing, manipulating, and analyzing large data sets', 'Experience with conducting root cause analysis of data discrepancies across disparate architectural layers of complex IT solutions and developing action plans to resolve issues', 'Knowledge of implementing statistical models to assess technological solutions', 'Knowledge of Security Information and Event Monitoring (SIEM) technologies and network devices, including routers, switches, and similar technologies', 'Ability to articulate complicated technical topics to non-technical audiences through briefings and technical documentation', 'Ability to obtain a security clearance', 'Possession of excellent interpersonal skills to effectively work across multiple teams of varying levels of technical competence', 'Secret clearance', 'BA or BS degree', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Referral program', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'IT : 3 years (Required)', 'Coding in at least one scripting language : 3 years (Required)', ""Bachelor's (Required)"", 'More than 1 year', 'No', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'Team-oriented -- cooperative and collaborative', 'www.technalink.net', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-09-24 13:50:29
Data Engineer - Big Data,Lighthouse,3.7 out of 5,"Phoenix, AZ 85009","['Responsible for designing, building & managing the advanced analytics platform preprocessing, validation and configuration to support data science teams', 'Collaborate with senior management, product management, and other engineers in the development of optimal data products', 'Build and operate stable, scalable and highly performant data pipelines that cleanse, structure and integrate disparate datasets into a readable and accessible format for end user analyses and targeting.', 'Develop tools to monitor, debug, and analyze data pipelines', 'Design and implement data schemas and models to scale and portable.', 'Provide technical recommendations regarding buy vs. build decisions for different components of the data analytics infrastructure', 'Degree in computer science, computer engineering with 5+ years of experience in data related field', 'Experience with implementing big data workflows in cloud native technologies (Azure is preferred)', 'Expertise working with both structured and unstructured data in a Big Data platform setting with standard toolsets', 'Experience with data streaming such as Apache Kafka, AWS kinesis, Spark Streaming, or similar tools.', 'ETL processing experience using modern processes.', 'Knowledge of various data science techniques and experience implementing models developed with these techniques into production environment', 'Knowledge and experience working with, and relational databases like MS SQL or Hyperscale SQL', 'ETL processing experience using Python, C#, or Java', 'Prior experience building scalable cloud environments handling petabyte data and operationalizing clusters with hundreds of compute nodes.', 'Prior experience in building real-time data collection infrastructure including client SDKs will be a huge plus.', 'Experience in operationalizing Machine Learning workflows to business requirements.', 'Experience with open source such as Hadoop, Spark, Kafka, and Yarn', 'Experience with containers such as Kubernetes.', 'Experience in working with Data Scientists to operationalize machine learning models.', 'Proficiency with agile development methodologies shipping features every two weeks.', 'Azure or AWS big data or architecture certification preferred']",2020-09-24 13:50:29
Workday / Prism Data Modeler,Perito Systems Inc,N/A,"Washington, DC 20032","['Capability to lead data design effort associated with a new build in Workday / PRISM space to support reporting capabilities.', 'Ability to analyze current state sourcing and design model, reporting & business requirements, and translate into future state data model.', 'Implements and enforces data definitions, standards and procedures relating to logical design.', 'Leads data design efforts and assists software engineers in data source discovery, data modeling, metadata capture and normalization techniques.', 'Incrementally develop conceptual, logical and physical data models for new database objects', 'Define data requirements and business rules, perform logical and physical data modeling, implement and test database design.', 'Coordinate data models, dictionaries and other documentation across multiple applications.', 'Lead database design sessions and capture data requirements for software engineering or re-engineering projects', 'Monday to Friday', 'Workday: 9 years (Preferred)', 'Prism: 7 years (Preferred)', 'SQL: 10 years (Preferred)', '1 year', 'Yes']",2020-09-24 13:50:29
Federal - EDW Data Engineer,Accenture,4 out of 5,"Gaithersburg, MD","['Participate in critical conversations with the client to understand DOC’s existing system landscape and data assets.', 'Support the effort to design, develop, and implement the data warehouse / data lake solution, in an agile development environment.', 'Own development and test of significant pieces of functionality / modules, following secure coding standards.', 'Support deployment, production validations, issue resolution and iterative agile releases to incorporate enhancements and fixes.', 'Minimum of 1-2 years development experience with Informatica Power Center', 'Experience with Oracle BI Application (OBIA) Financial Analytics', 'Experience with AWS Applications', 'Experience with AWS Data & Database Solutions', 'Data Architecture Principles', 'Data Conversion & Migration', 'Data Management and Integration', 'Data Archiving Patterns & Techniques', 'Strong written and oral communication skills; ability to engage with the client in discussions to clarify requirements or guidance provided', 'Strong organizational skills', 'Attention to detail', 'US Citizenship or Green Card Holder Required']",2020-09-24 13:50:29
"Data Engineer (Python, Spark, AWS)",Komodo Health,4 out of 5,"San Francisco, CA","['Owned ingestion of several complex data sources and / or enhanced existing data sources.', 'Participated in design and implemented distributed data systems using Spark or similar technologies.', 'Collaborated with product managers and data scientists to implement validation and/or data quality enhancements.', 'Optimized the pipelines for performance and cost.', 'Helped ensure smooth operations of the ingestion pipelines.', 'Helped ensure patient privacy by implementing business rules.', 'Building new architecture focused on improving consistency between different pipelines, improving ability to backfill, and increasing data quality.', 'Ingesting new complex data sources. Many of our data sources consist of a large historical load, followed by regular incremental deliveries.', 'Enabling data ingestion as a service - to enable other teams to self-serve their ingestion needs when they are less sophisticated', 'Expertise with industry standard distributed systems (ie. Spark), data pipeline tools (ie. Airflow).', 'Capable of quickly building expertise on an as-need basis on new tech stack.', 'Demonstrable experience with Python.', 'Understand and design for non-functional concerns such as performance, cost optimization, maintainability and developer experience.', 'Strong communication with engineers, product managers.', 'Ability to work as part of an agile collaborative team in a fast-paced environment.', 'Experience with systems support, debugging and operations.', 'Cholangiocarcinoma Foundation & Komodo Health partner to fight cancer', ""Komodo Health's 'Meet a Dragon' series"", ""Komodo Health's $50M Series C funding led by Andreessen Horowitz, Joined by Oak HC/FT"", ""Komodo's Values that Drive our Culture"", ""In Conversation with Dr. Arif Nathoo, Komodo Health's CEO""]",2020-09-24 13:50:29
Machine Learning Engineer,AMP Robotics,N/A,"Louisville, CO","['Experiment with modern neural network architectures or techniques driven by research publications', 'Design and implement deep learned, computer vision solutions in new domains', 'Help us improve our ML infrastructure', 'Support our existing ML infrastructure', ""Master's degree in Computer Science/Machine Learning or similar, or equivalent combination of technical education and work experience."", '3-5 years experience writing production-level code in python.', 'Proficiency working with SQL databases and data pipelines.', 'Proficiency with professional software engineering practices; including coding standards, code reviews, source control management, build processes, testing, and operations.', 'Ability to work on a small team and self-manage.', 'Familiarity with Tensorflow.', 'Familiarity with machine learning/computer vision techniques.', 'Familiarity and interest in research-level mathematics.', 'Startup ready mentality', 'Passion for recycling, robotics and changing the world', 'While performing the duties of this job, the employee is frequently required to stand, walk, use hands and fingers, handle or feel, reach with hands and arms, climb or balance, stoop, kneel, crouch, or crawl and talk and hear. The employee must occasionally lift and/or move up to 45 pounds. Specific vision abilities required by this job include close vision, peripheral vision, depth perception and ability to adjust focus, and ability to accurately see and label color.']",2020-09-24 13:50:29
Customer Facing Data Scientist,Comet.ml,N/A,"New York, NY","['Partner with sales during the sales cycle and enable prospects to understand the benefits of leveraging the platform', 'Lead technical demonstrations onsite or via video conference', 'Work with the sales and customer success team to identify and qualify business opportunities and identify key customer technical objections. Develop the strategy to resolve technical impediments', 'Gather technical requirements from prospective clients and mapping the platform to the prospective clients’ unique requirements', '(Potentially) travel on-site and aid customers in setting up the Comet platform', 'Create technical benchmarks', 'Partner with Marketing and Evangelism in the creation of blogs and technical content', 'Engage with the community on forums/groups', '1-8 years of experience as a sales engineer supporting a complex, technical product', 'Quick learner, self-starter and comfortable working with ambiguity', 'Deep and demonstrable knowledge of Python and ML frameworks such as Keras, PyTorch, Tensorflow', 'Good understanding of Linux', 'Previous experience with software development in Python', 'Background / Orientation with Machine Learning – a big plus', 'Bachelor’s degree in Mathematics, Engineering, Computer Science is helpful', 'Ability to understand the workflow and tools used by data scientists', 'Excellent communicator and presenter; able to win the confidence of a technical audience and simplify messaging', 'A deep understanding of data scientists’ needs and pain points is a big plus']",2020-09-24 13:50:29
Data Engineer,INTL FCStone,3.4 out of 5,"Seattle, WA 98101","['To lead in creating the data architecture and design for the firm’s Commodity Trading, Transaction and Reporting Systems.', 'Lead the implementation of that design as well as the ongoing maintenance of the data infrastructure for the broader commodity trading platform.', 'Understands system protocols, how systems operate and data flows.', 'Monitors and evaluates overall strategic data infrastructure; tracks system efficiency and reliability; identifies and recommends efficiency improvements and mitigates operational vulnerabilities', 'Organize and store the data for efficient reporting and data transformation', 'Beyond the primary responsibility of owning the firm’s data design and data infrastructure, we are a small firm growing quickly that participates in a LOT of transactions! With that, the candidate will be expected to be a key solution provider for the broader firm, including:', 'Maintaining a strong focus on innovation, and continuously working to improve existing processes, systems, and technology', 'Working with management team and front office users to review existing designs and processes to highlight more efficient ways to complete existing workload', 'Bachelor’s Degree in Computer Science or related engineering discipline.', '4+ years of experience developing software in a professional environment.', '3+ years of hands on Data Driven Enterprise Application development.', 'Strong understanding of Enterprise architecture patterns, Object Oriented & Service Oriented principles, design patterns, industry best practices.', 'Foundational knowledge of data structures, algorithms, and designing for performance.', 'Proficiency in programming in C#, .NET or Python and willingness to learn and adopt new languages as necessary.', 'In-depth expertise in database design and technology.', 'Climate controlled office environment', 'Minimal physical requirements other than occasional light lifting of boxed materials', 'Dynamic, time-sensitive environment']",2020-09-24 13:50:29
Data Engineer,Excella,4.4 out of 5,"Arlington, VA 22201","['Developing and managing data processes to ensure that data is available and usable', 'Creation and automation of data pipelines and platforms', 'Managing and monitoring data quality via automated testing frameworks (Data Driven Testing, TDD, etc.)', 'Working closely with Architects, Data Scientists, and DevOps to design, build, test, deliver, and maintain sustainable and highly scalable data solutions', 'Researching data acquisition and evaluating suitability', 'Integration of data management solutions into client environment', 'Actively managing risks to data and ensuring there is a data recovery plan', 'Building data repositories such as: data warehouses, data lakes, and operational data stores, etc.', '3+ years relevant professional work experience.', 'Experience and expertise in the following:', 'Project experience using the Scrum or Kanban framework.', 'Professionalism; to include written and oral communication – the ability to communicate collaboratively in front of a whiteboard. An ability to understand your audience and adjust your communication style to fit', 'Aptitude and desire for learning new technologies.', 'Technically savvy, entrepreneurial spirit who thrives in environments that reward self-initiative and resourcefulness.', ""You'll work with great people who love what they do: our team includes published authors, certified trainers, and internationally renowned speakers."", 'We have a ""bring your own device"" workplace and will share the cost of a new computer of your choice - Mac or PC. It\'s up to you.', ""We'll invest in your career by providing 3 days of paid professional development every year, including travel and registration fees to attend classes and conferences, in addition to tuition assistance for degrees and certifications."", 'Starting day one, every employee is bonus eligible and receives 17 days of paid vacation.', 'You can bike, drive, or metro to work - our commute reimbursement plan has you covered.', ""You'll have fun! We hold monthly social events all year long, including a summer event for you and your family.""]",2020-09-24 13:50:29
"Data Engineer, Healthcare Map",Komodo Health,4 out of 5,"New York, NY 10003","['Owned ingestion of several complex data sources and / or enhanced existing data sources.', 'Participated in design and implemented distributed data systems using Spark or similar technologies.', 'Collaborated with product managers and data scientists to implement validation and/or data quality enhancements.', 'Optimized the pipelines for performance and cost.', 'Helped ensure smooth operations of the ingestion pipelines.', 'Helped ensure patient privacy by implementing business rules.', 'Building new architecture focused on improving consistency between different pipelines, improving ability to backfill, and increasing data quality.', 'Ingesting new complex data sources. Many of our data sources consist of a large historical load, followed by regular incremental deliveries.', 'Enabling data ingestion as a service - to enable other teams to self-serve their ingestion needs when they are less sophisticated', 'Expertise with industry standard distributed systems (ie. Spark), data pipeline tools (ie. Airflow).', 'Capable of quickly building expertise on an as-need basis on new tech stack.', 'Demonstrable experience with Python.', 'Understand and design for non-functional concerns such as performance, cost optimization, maintainability and developer experience.', 'Strong communication with engineers, product managers.', 'Ability to work as part of an agile collaborative team in a fast-paced environment.', 'Experience with systems support, debugging and operations.', 'Cholangiocarcinoma Foundation & Komodo Health partner to fight cancer', ""Komodo Health's 'Meet a Dragon' series"", ""Komodo Health's $50M Series C funding led by Andreessen Horowitz, Joined by Oak HC/FT"", ""Komodo's Values that Drive our Culture"", ""In Conversation with Dr. Arif Nathoo, Komodo Health's CEO""]",2020-09-24 13:50:29
Senior Data Engineer (Remote US Only),ArcheMedX,N/A,Remote,"['Employee stock options', 'Retirement plan', 'Paid time off', 'Generous employee health, dental, and vision benefits', 'New Apple equipment', 'Problem solver: With existing infrastructure and live customers, we have a data solution that is solving our problems today, but we need to be forward thinking and continue to evolve. We are looking for someone with hands on experience developing, maintaining, and improving production data solutions.', 'Strong communicator: This role will be working closely with other members of the product & engineering teams to provide expertise to help shape new features and improve existing ones.', 'Experienced:Relational and non-relational databasesWriting tests for relational databasesSource control (Git)Cloud services (Bonus: AWS Experience)', 'Passionate:Desire to work with ""serverless"" technologies.A desire to learn and use the latest and greatest technologies (we use tools such as Kinesis Firehose, DynamoDB, Redshift, and Lambda)A desire to improve and iterate on an an existing data warehouse.', 'DBT experience', 'Experience working with ""serverless"" technologies (such as Lambda and DynamoDB).', 'BI Tooling experience (Bonus: Looker)', ""Experience with Kimball's dimensional modeling techniques."", 'Experience with Star Schema.', 'CloudFormation / CDK (TypeScript) experience', 'Node.js experience', 'Experience with Redshift', 'Passion for functional languages (like Clojure) or have a strong desire to learn!', 'A small group of dedicated craftspeople can change the world.', 'Software development is a creative problem solving process.', 'We are all on the product team.', 'We all thrive to create a working environment where we constantly reassess priorities and deliver product value without chaos and interruption.', 'We believe in creating a tight build/measure/learn development cycle.', 'Everyone should wear a lot of hats.', 'Everyone can have good ideas.', 'The time and tools you need, and the freedom to advance in your craft.', 'A collaborative, whiteboards-everywhere, fun workplace.', 'A team of smart, like-minded, creative professionals who will constantly support and challenge you to build better solutions every day.', 'A safe environment where every idea is heard, where mistakes are the way we learn, and where experimentation is the rhythm of our day.', 'Trust that you know best how, when, and where you should work to achieve great results.', 'The opportunity to see your work impact end users every day.', 'Employee stock options', 'Retirement plan', 'Paid time off', 'Generous employee health, dental, and vision benefits', 'New Apple equipment', 'Continuous opportunities for professional development (Conferences / Learning Stipends)', 'Bi-annual company wide outings']",2020-09-24 13:50:29
Azure Data Engineer,Lenora Systems Inc,N/A,"Philadelphia, PA","['Pay:', 'Up to $50.00 per hour']",2020-09-24 13:50:29
Data Engineer - Software Engineer,Wells Fargo,3.7 out of 5,"Charlotte, NC 28202","['Job', 'Company', 'Work with Data Modeler to understand and define Source to Target mapping, ensuring changes/impacts to existing designs don’t change the fundamental metrics', 'Provide Data Profiling and Data analysis support for Data Modeler and Report Developers', 'Help load or create mockup data as needed to ensure development team can continue building when lack of data is present', 'Ensure Data Quality standards are met, and suggest Data Quality checks for ETL', 'Assist Technical Analyst in defining data needs and identifying data gaps, as well as, breaking down complex data issues to help resolve them', 'Work with technical teams to deliver on commitments within time and scope', 'Collaborate with source system and Authorized provisioning point (APP) teams, Data Analysts and Modelers to build scalable data solutions.', 'Understand business requirements with respects to data and reporting needs', 'Work closely with QA testers to review and assist in testing script creation, as well as, the execution of testing scripts in relation to data validation', 'Performance tuning and designing high performance applications involving huge data processing. The successful candidate will need to have advanced information delivery and development skills in order to create effective data solutions that can be easily maintained and extended to meet the growing demands.', 'Lead your team with integrity and create an environment where your team members feel included, valued, and supported to do work that energizes them.', 'Accomplish management responsibilities which include sourcing and hiring talented team members, providing ongoing coaching and feedback, recognizing and developing team members, identifying and managing risks, and completing daily management tasks.', '5+ years of software engineering experience', '7+ years of SQL experience', '7+ years of business intelligence experience', '5+ years of MS SQL server experience', '5+ years of experience writing Microsoft SQL Server relational database queries, stored procedures, query optimization and performance tuning', '4+ years of ETL (Extract, Transform, Load) Programming experience', '4+ years of data modeling experience', '4+ years of experience with data analysis and documentation', '2+ years experience designing and optimizing complex SQL queries involving table joins and correlated sub-queries on large scale data tables', 'An industry-standard technology certification', 'Strong verbal, written, and interpersonal communication skills', '6+ years of experience with end-to-end design and delivery of data warehouse applications', '4+ years of experience in Hadoop ecosystem tools for real-time batch data ingestion, processing and provisioning such as Apache Flume, Apache Kafka, Apache Sqoop, Apache Flink, Apache Spark or Apache Storm', '5+ years of RESTful or SOAP web services', 'Ability to prioritize work, meet deadlines, achieve goals, and work under pressure in a dynamic and complex environment', 'Experience applying new technologies to business needs in a technologically innovative , change-driven organization', 'Advanced Microsoft Office (Word, Excel, Outlook and PowerPoint) skills', 'Ability to articulate complex concepts in a clear manner', 'Strong analytical skills with high attention to detail and accuracy', 'Outstanding problem solving skills', 'Strong organizational, multi-tasking, and prioritizing skills', 'A BS/BA degree or higher', 'Experience introducing improvements in his or her workplace through effective analysis, critical thinking, and innovation, including demonstrated ability to present complex concepts, options and recommendations in a manner that supports quality decision making.']",2020-09-24 13:50:29
Data Engineer - Software Engineer,Wells Fargo,3.7 out of 5,"Charlotte, NC 28202","['Job', 'Company', 'Work with Data Modeler to understand and define Source to Target mapping, ensuring changes/impacts to existing designs don’t change the fundamental metrics', 'Provide Data Profiling and Data analysis support for Data Modeler and Report Developers', 'Help load or create mockup data as needed to ensure development team can continue building when lack of data is present', 'Ensure Data Quality standards are met, and suggest Data Quality checks for ETL', 'Assist Technical Analyst in defining data needs and identifying data gaps, as well as, breaking down complex data issues to help resolve them', 'Work with technical teams to deliver on commitments within time and scope', 'Collaborate with source system and Authorized provisioning point (APP) teams, Data Analysts and Modelers to build scalable data solutions.', 'Understand business requirements with respects to data and reporting needs', 'Work closely with QA testers to review and assist in testing script creation, as well as, the execution of testing scripts in relation to data validation', 'Performance tuning and designing high performance applications involving huge data processing. The successful candidate will need to have advanced information delivery and development skills in order to create effective data solutions that can be easily maintained and extended to meet the growing demands.', 'Lead your team with integrity and create an environment where your team members feel included, valued, and supported to do work that energizes them.', 'Accomplish management responsibilities which include sourcing and hiring talented team members, providing ongoing coaching and feedback, recognizing and developing team members, identifying and managing risks, and completing daily management tasks.', '5+ years of software engineering experience', '7+ years of SQL experience', '7+ years of business intelligence experience', '5+ years of MS SQL server experience', '5+ years of experience writing Microsoft SQL Server relational database queries, stored procedures, query optimization and performance tuning', '4+ years of ETL (Extract, Transform, Load) Programming experience', '4+ years of data modeling experience', '4+ years of experience with data analysis and documentation', '2+ years experience designing and optimizing complex SQL queries involving table joins and correlated sub-queries on large scale data tables', 'An industry-standard technology certification', 'Strong verbal, written, and interpersonal communication skills', '6+ years of experience with end-to-end design and delivery of data warehouse applications', '4+ years of experience in Hadoop ecosystem tools for real-time batch data ingestion, processing and provisioning such as Apache Flume, Apache Kafka, Apache Sqoop, Apache Flink, Apache Spark or Apache Storm', '5+ years of RESTful or SOAP web services', 'Ability to prioritize work, meet deadlines, achieve goals, and work under pressure in a dynamic and complex environment', 'Experience applying new technologies to business needs in a technologically innovative , change-driven organization', 'Advanced Microsoft Office (Word, Excel, Outlook and PowerPoint) skills', 'Ability to articulate complex concepts in a clear manner', 'Strong analytical skills with high attention to detail and accuracy', 'Outstanding problem solving skills', 'Strong organizational, multi-tasking, and prioritizing skills', 'A BS/BA degree or higher', 'Experience introducing improvements in his or her workplace through effective analysis, critical thinking, and innovation, including demonstrated ability to present complex concepts, options and recommendations in a manner that supports quality decision making.']",2020-09-24 13:51:10
Data Engineer - Outcomes Research,Houston Methodist,4.2 out of 5,"Houston, TX","['Provide personalized care and service by consistently demonstrating our I CARE values:INTEGRITY: We are honest and ethical in all we say and do.', 'COMPASSION: We embrace the whole person including emotional, ethical, physical, and spiritual needs.ACCOUNTABILITY: We hold ourselves accountable for all our actions.RESPECT: We treat every individual as a person of worth, dignity, and value.EXCELLENCE: We strive to be the best at what we do and a model for others to emulate.', 'Focuses on patient/customer safety', 'Delivers personalized service using HM Service Standards', 'Provides for exceptional patient/customer experiences by following our Standards of Practice of always using Positive Language (AIDET, Managing Up, Key Words)', 'Intentionally rounds with patients/customers to ensure their needs are being met', 'Involves patients (customers) in shift/handoff reports by enabling their participation in their plan of care as applicable to the given job', 'Accurately prepares written business correspondence that is coherent, grammatically correct, effective and professional. (EF)', 'Establishes and maintains effective working relationship with clients. Shares acquired skills with team members through documentation and training. (EF)', 'Assists, trains and supports customers with the operation and administration of systems. (EF)', 'Debugs, programs and tests systems and applications. Proposes solutions to problems and considers timeliness, effectiveness, and practicality in addressing client needs. (EF)', 'Utilizes working knowledge of assigned applications to effectively complete assigned tasks. Applies workflow to and from clinical and business applications. (EF)', 'Effectively leads and facilitates meetings. Develops meeting objectives, agendas and action items.', 'Supports and installs software applications, including on call support. (EF)', 'Provides high quality technical support for assigned application(s). Creates custom solutions or configuration options to solve operational or workflow issues. (EF)', 'Leads medium to large scale projects utilizing Houston Methodist project guidelines including budget adherence. (EF)', 'Establishes responsible deadlines and personal work plans and manages time effectively. Accurately completes and submits assigned work and status reports according to project timelines and expectations. (EF)', 'Prioritizes issue resolution, work requests and tasks effectively. (EF)', 'Anticipates client needs and communicates to department leadership for solution development. (EF)', 'Resolves problems of moderate to advanced complexity using strong analytical and logic skills. Generates innovative solutions in partnership with customers, vendors cross and functional IT teams(EF)', 'Seeks out opportunities to cross train and become proficient in multiple applications (EF)', 'Participates in professional development. Completes Individual Development Plan. (IDP) (EF)', 'Bachelor’s Degree in Information Technology, Business Administration or related field or experience working as a licensed clinical or certified IT professional. An additional four years experience in addition to the experience listed below in lieu of Bachelors or licensed clinical or certified IT professional experience', 'Three years experience in IT or clinical or business workflow required', 'Experience supporting clinical, ancillary or business environments', 'Certification within six months of hire if appropriate to assigned application. (i. e. Epic) Epic Certification must be maintained.', 'Demonstrates the skills and competencies necessary to safely perform the assigned job, determined through on-going skills, competency assessments, and performance evaluations', 'Sufficient proficiency in speaking, reading, and writing the English language necessary to perform the essential functions of this job, especially with regard to activities impacting patient or employee safety or security', 'Ability to effectively communicate with patients, physicians, family members and co-workers in a manner consistent with a customer service focus and application of positive language principles', 'Understanding of business processes and requirements as related to the assigned (clinical or business) environment.', 'Ability to support large scale clinical and ancillary systems', 'Familiar with current database and operating systems as required for assigned applications', 'Technical skills to support multiple applications', 'Intermediate level competency in multiple applications or areas of clinical workflow.', 'Demonstrated project management skills.', 'Ability to problem solve and generate innovative solutions in conjunction with customers, vendors, and Information Technology', 'Note that employees may be required to be on-call during emergencies (ie. Disaster, Severe Weather Event, etc) regardless of selection above.']",2020-09-24 13:51:10
Integration engineer,Peopleforce INC,N/A,"Chicago, IL","[""Integration engineer to support the existing client's integration team"", 'Integration engineer will help the client with data transformation, validation and compliance. Data transformation will be from HL7 V2, V3 to FHIR.', 'Integration engineer will understand current architecture and processes, user accounts and access, identify roadblocks and define backlog', ""Integration engineer will follow all the processes, methodology defined by the client's team"", 'HL7 v3: 3 years (Required)', 'HL7 v2: 4 years (Required)', 'FHIR: 3 years (Required)', 'data transformation: 3 years (Required)', 'Yes']",2020-09-24 13:51:10
District Engineer,"Helmerich & Payne, Inc.",4.1 out of 5,"Odessa, TX","['Assist in implementing performance improvement initiatives based on customer requests and data analytics (including support of FlexApps and HSE initiatives as necessary)', 'Manage projects to meet the needs of the district (rig upgrades, rig retrofits, FlexApp roll outs, etc.)', 'Liaison between the district and engineering as necessary for retrofits, rig equipment issues, etc.', 'Demonstrate the H&P Company values: Actively C.A.R.E., Service Attitude, Innovative Spirit, Teamwork and Do the Right Thing', 'Bachelor’s degree in Mechanical or Petroleum Engineering and 1-3 years industry experience preferred', 'Knowledge of Oil and Gas, field activity preferred', 'Proficient knowledge of rig activities required', 'Performance Engineer experience preferred', 'Self-starter, motivated and takes the initiative to find and complete projects', 'Proficient in the use of PC application skills, including visualization, spreadsheet, and database products', 'Ability to complete data analysis and provide solutions and recommendations based on insight', 'Works well in a collaborative and team-based environment', 'Excellent problem-solving, presentation, and communication / interpersonal skills', 'Willingness and ability to travel 25-50% of the time', 'Assist in implementing performance improvement initiatives based on customer requests and data analytics (including support of FlexApps and HSE initiatives as necessary)', 'Manage projects to meet the needs of the district (rig upgrades, rig retrofits, FlexApp roll outs, etc.)', 'Liaison between the district and engineering as necessary for retrofits, rig equipment issues, etc.']",2020-09-24 13:51:10
Junior Data Engineer - Irving TX - (ONLY UC/GC ),Pricesenz,N/A,"Irving, TX","['Maintain high levels of integrity and dependability', 'Maintain a focus on results & quality.', 'Works well in a team environment and effectively manage work activities', 'Project a professional demeanor and appearance', 'Be extremely flexible and adaptable', 'Demonstrates the ability to function and stay focused on constant pressure, fast-growing and ever-changing organization', 'Monday to Friday', 'Healthcare and Claims Data: 1 year (Preferred)', 'Teradata, PostgreSQL, Tableau, ETL, SQL, & AWS: 2 years (Preferred)', 'Data Engineer: 2 years (Preferred)', 'Irving, TX (Preferred)', '3 - 4 months', 'Possible', 'No']",2020-09-24 13:51:10
Associate Data Warehouse Engineer,TriMedx,2.9 out of 5,"Indianapolis, IN","['Everyone is focused on serving the customer and we do that by collaborating and supporting each other', 'Associates look forward to coming to work each day', 'Every associate matters and makes a difference', 'Data Warehouse & ETL Maintenance', 'ETL Testing', 'Data Warehouse Implementation Methodology', 'ETL Development', 'Systems Development Lifecycle Cycle', 'Analytical Thinking', 'Attention to Detail', 'Basic knowledge in Problem solving, database, application design and testing', 'Bachelor’s degree or equivalent in MIS, Computer Science or related field', 'Data analysis or modeling experience', 'Software development experience', 'Develops with guidance, data warehouse objects and the underlying framework metadata', 'Assists to design and develop new functionality and enhancements across multiple data domains', 'Assists in the implementation, testing and delivery of new features for multiple data domains', 'May assist in framework design', 'Understands best practices for TriMedx data management. (ex. Security Policy)', 'Understands and adheres to data architecture policies, standards and procedures.', 'Works to gain data SME knowledge of TriMedx data assets.', 'Resolves issues based on defined standard practices and procedures', 'Uses analytical thinking to solves problems', 'Selects from a limited range of options to solve problems', 'With direction, follows best practices and clearly defined procedures to complete assignments', 'Issues not defined by best practices are escalated to Manager', 'Not yet self-sufficient; still requires daily and weekly work guidance', 'Communicates with project team on information requiring some explanation', 'Interacts with peers to gain broader business or technical exposure']",2020-09-24 13:51:10
Data Scientist,Huntington Ingalls Industries Inc.,3.8 out of 5,"North Charleston, SC 29405","['Mine and analyze data sets to extract meaningful trends', 'Produce meaningful and actionable reports', 'Write documentation and procedural materials for multiple audiences', 'Develop and maintain appropriate reference materials, including research, usability tests, and design specifications as they relate the big data efforts', 'Use statistical programming languages, machine learning and other toolkits and techniques for analyzing large, complex datasets', 'Demonstrate technical proficiency with transforming structured and unstructured data sets', 'Mentor and support multiple business/technical areas', 'Develops theories for understanding, characterizing and organizing natural phenomena into a systematic and meaningful pattern for research into potential new products or inventions.', 'Participates in intellectual property evaluations and development of patent applications.', 'Coordinates interdepartmental activities and research efforts.', ""3 years experience and Bachelor's degree in Information Systems, business administration."", '3 years as a data scientist/data analyst', '2+ years mining and analyzing data sets', 'Superior written and verbal communication skills, with a keen eye for detail', 'Must be able to obtain and maintain a Secret level clearance', 'MBA preferred', 'Background as a data analyst, DBA and/or data scientist is a plus', 'Experience in big data migration strategies and best practices is a plus', 'Expertise in Talend platform for MDM practices is plus', 'Expertise in working in a cloud based environment and tools is a plus']",2020-09-24 13:51:10
Data Engineer,Nexstar Broadcasting,2.9 out of 5,"Los Angeles, CA","['Data collection', 'Data transformation and cleanup', 'Data importation into analysis and reporting databases', 'Daily monitoring of data systems', 'Analysis of data to find new insights', 'Python', 'SQL', 'BASH Scripting', 'AWS knowledge', 'AWS Redshift knowledge', 'Javascripting skills', 'Knowledge about Docker containers', 'Knowledge about NoSQL Systems', 'Bachelor’s degree in computing related field preferred', 'Will consider work or internship experience that involves daily usage of Python and SQL', 'Takes initiative to solve problems', 'Able to multi-task and manage multiple projects', 'Seeks feedback', 'Excellent interpersonal, written, and verbal communication skills', 'Able to self-manage', 'Quality oriented']",2020-09-24 13:51:10
Quality Engineer,Topre America Corporation,N/A,"Cullman, AL 35057","['Communicate Internally and with Customers on Quality Issues', 'Protect line from non-conforming product', 'PPAP of New Product or Design changes', 'Continual Improvement of internal parts', 'Track Cost of Quality', 'Generate and Track Quality Alerts', 'Ensure a safe work place for TAC employees and Customers inside facility', ""Responsible for making regular visits to customer's facilities."", 'Develops a thorough understanding of customers QA system, organization chart, procedures, and line processes. Develops plans, following and prepares for customers PPAP requirements.', 'Calculates and evaluates Cp and Cpk values.', 'Analyzes plant and customers problems. Develops countermeasure for same. Gives feedback to suppliers on quality problems.', 'Develops and initiates standards and methods for inspection, testing, and evaluation. Develops inspection standard, check sheets and process control standards.', 'Gives detailed line audits on critical lines.', 'Develops any receiving / inspection plans for purchased parts.', 'Sets up R&R studies for any new gauges if required.', 'Devises sampling procedures and designs and develops form and instructions for recording, evaluating, and reporting quality and reliability data.', 'Review blueprint drawing and / or read standards to determine part disposition.', 'Knows critical points for each part, based on part function; distribute information to others.', 'Establishes programs to evaluate precisions and accuracy of production equipment and testing, measurement, and analytical equipment and facilities.', 'Develops and implements methods and procedures for disposition of discrepant material and devises methods to assess cost and responsibility.', 'Performs supplier audits.', 'Directs workers engaged in measuring and testing product and tabulating data concerning materials, product, or process quality reliability.', 'Assists other TAC departments (MFG, ENG, etc.) in determining part disposition, root causes of problem, or appropriate countermeasure.', 'Determines responsibility and disposition of materials written up on Quality Alert and assures prompt return.', 'Follows up on Quality Alerts to ensure good countermeasure.', 'Complies and writes training material and conducts training session on quality control activities.', 'Support departmental A3 goals.', 'Analytical - Synthesizes complex or diverse information; Collects and researches data; Uses intuition and experience to complement data.', 'Design - Generates creative solutions; Translates concepts and information into images; Uses feedback to modify designs; Applies design principles; Demonstrates attention to detail.', 'Problem Solving - Identifies and resolves problems in a timely manner; Gathers and analyzes information skillfully; Develops alternative solutions; Works well in-group problem solving situations; Uses reason even when dealing with emotional topics.', 'Project Management - Coordinates projects; Communicates changes and progress; Completes projects on time and budget.', 'Technical Skills - Strives to continuously build knowledge and skills; Shares expertise with others.', 'Customer Service - Manages difficult or emotional customer situations; Responds promptly to customer needs; Solicits customer feedback to improve service; Responds to requests for service and assistance; Meets commitments.', ""Interpersonal Skills - Focuses on solving conflict, not blaming; Maintains confidentiality; Listens to others without interrupting; Keeps emotions under control; Remains open to others' ideas and tries new things."", 'Oral Communication - Speaks clearly and persuasively in positive or negative situations; Listens and gets clarification; Responds well to questions; Demonstrates group presentation skills; Participates in meetings.', 'Written Communication - Writes clearly and informatively; Edits work for spelling and grammar; Varies writing style to meet needs; Presents numerical data effectively; Able to read and interpret written information.', ""Teamwork - Balances team and individual responsibilities; Exhibits objectivity and openness to others' views; Gives and welcomes feedback; Contributes to building a positive team spirit; Puts success of team above own interests; Supports everyone's efforts to succeed."", 'Visionary Leadership - Displays passion and optimism; Inspires respect and trust.', 'Change Management - Develops workable implementation plans; Communicates changes effectively; Builds commitment and overcomes resistance; Prepares and supports those affected by change; Monitors transition and evaluates results.', 'Leadership - Exhibits confidence in self and others; Accepts feedback from others.', 'Quality Management - Looks for ways to improve and promote quality; Demonstrates accuracy and thoroughness.', 'Cost Consciousness - Works within approved budget; Develops and implements cost saving measures; Contributes to profits and revenue; Conserves organizational resources.', 'Ethics - Treats people with respect; Keeps commitments; Inspires the trust of others; Works with integrity and ethically; Upholds organizational values.', ""Organizational Support - Follows policies and procedures; Completes administrative tasks correctly and on time; Supports organization's goals and values."", 'Judgement - Displays willingness to make decisions; Exhibits sound and accurate judgment; Supports and explains reasoning for decisions; Includes appropriate people in decision-making process; Makes timely decisions.', 'Motivation - Demonstrates persistence and overcomes obstacles.', 'Planning/Organizing - Prioritizes and plans work activities; Uses time efficiently; Plans for additional resources; Sets goals and objectives; Organizes or schedules other people and their tasks; Develops realistic action plans.', 'Professionalism - Approaches others in a tactful manner; Reacts well under pressure; Treats others with respect and consideration regardless of their status or position; Accepts responsibility for own actions; Follows through on commitments.', 'Quality - Demonstrates accuracy and thoroughness; Looks for ways to improve and promote quality; Applies feedback to improve performance; Monitors own work to ensure quality.', 'Quantity - Completes work in timely manner; Works quickly.', 'Safety and Security - Observes safety and security procedures; Determines appropriate action beyond guidelines; Reports potentially unsafe conditions; Uses equipment and materials properly.', 'Adaptability - Adapts to changes in the work environment; Manages competing demands; Changes approach or method to best fit the situation; Able to deal with frequent change, delays, or unexpected events.', 'Attendance/Punctuality - Is consistently at work and on time; Ensures work responsibilities are covered when absent; Arrives at meetings and appointments on time.', 'Dependability - Follows instructions, responds to management direction; Takes responsibility for own actions; Keeps commitments; Commits to long hours of work when necessary to reach goals. Completes tasks on time or notifies appropriate person with an alternate plan.', 'Initiative - Seeks increased responsibilities; Takes independent actions and calculated risks; Looks for and takes advantage of opportunities; Asks for and offers help when needed.', ""Innovation - Displays original thinking and creativity; Meets challenges with resourcefulness; Generates suggestions for improving work; Develops innovative approaches and ideas; Presents ideas and information in a manner that gets others' attention."", '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Retirement plan', 'Vision insurance', 'Day shift', 'Monday to Friday', 'On call', 'Overtime', 'Weekends', 'Bonus pay', 'Microsoft Office: 3 years (Preferred)', 'Customer Service: 3 years (Preferred)', 'Microsoft Word: 3 years (Preferred)', 'Communication Skills: 3 years (Preferred)', 'Data Collection: 3 years (Preferred)', 'One location', 'Only full-time employees eligible', 'No']",2020-09-24 13:51:10
Data Engineer,Frontend Arts,N/A,"Seattle, WA","['Good experience in data engineering skills – SQL, data warehousing, ETL and data modeling.', 'Good coding skills (python preferred)', 'Proficient over data structures and algorithms.', 'Strong communication skills to engage people together.', 'Fully proficient in pipeline building and job automation.']",2020-09-24 13:51:10
Senior Data Engineer,The Hartford,3.7 out of 5,"Hartford, CT","['Job', 'Company', 'Identify and validate internal and external data sources for availability and quality. Work with SME’s to describe and understand data lineage and suitability for a use case.', 'Create data assets and build data pipelines that align to modern software development principles for further analytical consumption. Perform data analysis to ensure quality of data assets.', 'Create summary statistics/reports from data warehouses, marts, and operational data stores.', 'Extract data from source systems, and data warehouses, and deliver in a pre-defined format using standard database query and parsing tools.', 'Understand ways to link or compare information already in our systems with new information.', 'Perform preliminary exploratory analysis to evaluate nulls, duplicates and other issues with data sources.', 'Work with data scientists to understand the requirements and propose and identify data sources and alternatives.', 'Produce code artifacts and documentation using Github for reproducible results and hand-off to other data science teams.', 'Propose ways to improve and standardize processes to enable new data and capability assessment and to enable pivoting to new projects.', 'Understand data classification, and adhere to the information protection and privacy restrictions on data.', 'Collaborate closely with data scientists, business partners, data suppliers, and IT resources.', 'Bachelor degree or equivalent experience in a related quantitative field', 'Experience accessing and retrieving data from disparate large data sources, by creating and tuning SQL queries. Understanding of data modeling concepts, data warehousing tools and databases (e.g. Oracle, AWS, Spark/PySpark, ETL, Big Data, and Hive)', 'Demonstrated ability to create and deliver high quality Python code using software engineering best practices. Experience with object oriented programming and software development a plus. Proficiency with Github and Linux highly desired.', 'Ability to analyze data sources and provide technical solutions. Strong exploratory and problem solving skills to check for data quality issues.', 'Determine business recommendations and translate into actionable steps', 'Self-starter with curiosity and a willingness to become a data expert', 'Demonstrate a passion to both learn new skills and lead discovery of the data research', 'Results oriented with the ability to multi-task and adjust priorities when necessary', 'Ability to work both independently and in a team environment with internal customers', 'Ability to articulate and train technical concepts regarding data to both data scientists and partners']",2020-09-24 13:51:10
Contract Data Engineer,Deloitte,4 out of 5,"Sunnyvale, CA","['Understand and anticipate the infrastructure needs of the ML service development.', 'Automate, deploy and maintain ML services using existing cloud resources.', 'Automate end-to-end ETL/ML pipelines with structural understanding of data products.', 'Work with team members to assist with data-related technical issues and support their data product needs.', 'A background in computer science, engineering, mathematics, or similar quantitative field with a minimum of 2 years professional experiences.', 'Experience in cloud application development and testing', 'Strong programming skills and experience in implementing data pipelines using python', 'Experience with workflow scheduling / orchestration such as Kubernetes or Airflow', 'Experience with NoSQL and SQL databases (e.g. Cassandra, Postgres)', 'Experience with microservices architecture', 'Experience with Unix-based command line interface and Bash scripts', 'Data visualization or web development skills a plus', 'Monday to Friday', 'Possible', 'Temporarily due to COVID-19']",2020-09-24 13:51:10
Data Engineer,Infogroup,3.3 out of 5,"Washington, DC 20006","['Must have applied experience with developing, implementing and using data models, including integration of massive amounts of data across multiple databases in a data warehousing, ETL or analytic environment.', 'Must possess expertise with multiple program languages across language types.', 'Must have strong communications and facilitation skills, with ability to work with analysts and end users to clearly capture requirements.', 'Must have experience in preparing and/or reviewing technical model requirements documentation to ensure accuracy and to ensure that impacts are identified, understood and communicated.', 'Must possess knowledge and experience in data extract, transform and load (ETL) processes, Talend experience preferred.', 'Responsible for technical leadership, setting standards and procedures and following up to mentor and train technical staff.', 'Meet and/or exceed data delivery time service standards. This role must support time critical corporate reporting requirements. Meeting these needs can entail intense periods of work to meet timeliness standards.', 'Work with appropriate customers to create and manage project schedules for reporting solutions.', 'Actively participate in the overall Data Warehouse/Business Intelligence strategy.', 'Document and conduct unit and system testing as it pertains to new Business Information/Data Warehouse development and maintenance.', 'Working closely with development team to clearly understand the business applications and databases supporting the applications.', 'Maintenance of database dictionaries, and integration of systems through database design.', 'Logical and Physical design of the warehouse BI and OLTP systems.', 'Working with the DBA group helping develop best practices, policies, and design of logical and physical tables within the databases.', 'Support in all aspects of data analysis and data movement among different systems - source systems and data warehouses.', 'Essential functions are the basic job duties that an employee must be able to perform, with or without reasonable accommodation. The function is considered essential if the reason the position exists is to perform that function.', 'Perform other miscellaneous duties as assigned by management.', 'These tasks do not meet the Americans with Disabilities Act definition of essential job functions and usually equal 5% or less of time spent. However, these tasks still constitute important performance aspects of the job.']",2020-09-24 13:51:10
Software Engineer,"Alliance Consulting Partners, Inc.",N/A,"Austin, TX","['Responsible for design thru implementation of enterprise software', 'Develops and implements new features that meet One Networks standards in performance, reliability, and maintainability.', 'Write code, unit tests, and build/deployment scripts', 'Participates in development efforts in an Agile development environment, daily stand-ups, sprint planning, backlog grooming, retrospectives, and sprint demos.', 'Be a part of a ground floor opportunity building enterprise applications', 'Participates in analysis and design tasks with the Agile team using software development life-cycle concepts', 'Contribute to design documents and participate in design reviews', 'Troubleshoot and support production systems when required', 'Works within a collaborative environment and contributes to team goals by offering open and honest communication and helping to meet deadlines.', '2+ years of experience in software development', 'Strong Object-Oriented Programming skills. Working knowledge of design patterns, data structures and algorithms.', 'Needs to have solid JAVA knowledge', 'Strong analytical problem-solving skills', 'Extensive knowledge of the Java programming language', 'Familiarity with J2EE technologies', 'Unix or Linux experience a big plus', 'Must know Java Script and one of the Java Script frameworks: JQUERY, EXTJS, Backbone', 'Experience with relational databases (preferably Oracle)', 'Excellent communication (verbal and written) and interpersonal skills', 'Systems implementation skills: requirements/process analysis, conceptual and detailed design, configuration, testing, training, change management, support', 'Prior experience in development or consulting with an enterprise software vendor is a plus.', 'Functional knowledge of supply chains, logistics, order management, etc. is a plus', 'Experience with processing large volumes of data is a plus', '401(k)', 'Disability insurance', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Referral program', 'Vision insurance', '8 hour shift', 'Bonus pay', 'Java: 2 years (Required)', ""Bachelor's (Preferred)"", 'United States (Required)', 'Multiple locations', 'Fully Remote', 'Dependable -- more reliable than spontaneous', 'People-oriented -- enjoys interacting with people and working on group projects', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Achievement-oriented -- enjoys taking on challenges, even if they might fail', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'Innovative -- innovative and risk-taking', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'A job for which military experienced candidates are encouraged to apply', 'Only full-time employees eligible']",2020-09-24 13:51:10
Data Center Engineer,"Zenlayer, Inc",N/A,"Los Angeles, CA 90012","['Perform server hardware requests such as adding additional hard drives, memory, installing operating system', 'Perform basic server cabling such as power and network cables according to standards', 'Maintain inventory, asset management and compliance with audit, daily log tracking, thorough documentation, and retention practices.', 'Provide smart-hands assistance at various sites within specified SLA response time.', 'Provide status reporting regarding data center service availability, performance, and capacity utilization.', 'Strong working knowledge with server and network hardware/components, copper and fiber infrastructure installation and testing, data center productivity and support tools, applications and software (Windows, Linux, SSH, RDP, Putty, etc.), and data center infrastructure management (DCIM) related tools.', 'Coordinate equipment/material receiving, shipping and RMA processing support as/when required.', 'Provide general cleaning on raised floor, cabinet/rack exterior surfaces, work benches and other areas as needed on a regular basis', 'High School Diploma or equivalent and minimum of 1 year of IT support experience', 'Must be self-motivated, detail oriented, positive in approach, professional and help create, develop and implement project process improvement(s).', 'Excellent communication skills.', 'Basic server application, hardware and OS knowledge.', 'Ability to use hand tools.', 'Ability to lift heavy loads, up to 50 lbs.', 'Must be able to work at heights, off of a ladder and in confined space.', 'Ability to rotate shift including holiday, off hours (i.e., graveyard shift), weekend and vacation.', 'Any server, OS, Network or data center certifications.', 'Fluent in Mandarin Chinese (listen, speak, read, and write)', 'Schedule: Full-time', 'Job Type: Regular', 'Work Location: Downtown Los Angeles, CA', 'Benefit Eligibility: Yes', 'Salary: Compensation package will be commensurate with experience.', 'Zenlayer offers a competitive compensation package, including health, dental and vision insurance, paid holidays, vacation, personal and sick days, 401(k) plan, wellness benefits, etc.']",2020-09-24 13:51:10
Data Engineer,AmSurg,2.7 out of 5,"Nashville, TN 37215","['Design, construct, install, test and maintain highly scalable data management systems', 'Ensure systems meet business requirements and industry practices', 'Build high-performance algorithms, prototypes, predictive models and proof of concepts', 'Research opportunities for data acquisition and new uses for existing data', 'Develop data set processes for data modeling, mining and production', 'Integrate new data management technologies and software engineering tools into existing structures', 'Employ a variety of techniques and tools to marry systems together', 'Recommend ways to improve data reliability, efficiency and quality', 'Collaborate with data architects, modelers and IT team members on project goals', 'Intermediate to Advanced level user of Microsoft Office products. Advanced/power user of Excel', 'Knowledge of relational database principles including SQL and MS-Office products', 'Excellent quantitative and analytical skills as well as the ability to translate findings into meaningful information appropriate to the audience/stakeholder', 'High level of comfort with many types of data including financial, quality, clinic and security', 'Ability to work independently and prioritize work appropriately', 'Ability to work under tight deadlines and switch quickly and comfortably between projects as business needs dictate', 'Displays a positive morale and a sense of teamwork', 'Excellent organizational skills and strong oral and written communication skills a must', 'Regular and reliable attendance required.']",2020-09-24 13:51:52
Quality Data Analyst,Lincotek Surface Solutions,N/A,"Hickory, NC","['Gather and enter data from production and laboratory processes', 'Maintain clean and organized work area', 'Analyze documents for accuracy', 'Interpret technical drawings and documents', 'Maintain the integrity of work orders and double checking the accuracy of quality control measure and documents', 'Performing a variety of clerical duties for technical quality control support staff like collecting and compiling data from various processes', 'Preparing quality data packages for the customer', 'Operate calibration software', 'Multitasking while performing prep-work and analysis efficiently', 'Assist in managing the document control system', 'Work with Engineers and other Managers on assuring complete process and project data collection', 'Working within the Company’s Quality and Safety System context, in accordance with its procedures and requirements', 'Analyze and discuss lab results and reports', 'Organizes filing of controlled documents', 'Manage consumable supplies', 'Performs other duties as assigned']",2020-09-24 13:51:52
Data Engineer,Invitae,3.6 out of 5,"Seattle, WA","['Understand our complex data ecosystem and build ETL solutions', 'Develop a real-time streaming infrastructure that supports critical business functions', 'Design and develop tools to enable teams to consume and understand data faster', 'Collaborate with multiple teams and own solutions from end-to-end', 'Are self-starters and can work towards a larger goal with minimal guidance', 'Prior experience utilizing data warehousing or building out data warehouses', 'Have at least 3 years of hands-on experience working with large datasets, pipelines, and warehouses', 'Have a focus on high-quality code, including automated testing and coding best practices', 'Have experience with messaging/queuing systems or stream processing systems', 'Have architected distributed systems with infrastructure automation, monitoring and alerting']",2020-09-24 13:51:52
Data Engineer,"Rooftop Digital, LLC",N/A,"Agoura Hills, CA 91301","['Develop data pipelines and build out integrations to support continuing increases in data volume and complexity.', 'Assist in the design, construction, testing and maintenance of data management systems.', 'Build high-performance algorithms, predictive models, and prototypes.', 'Evaluate and integrate data management and software engineering technologies into existing data structures.', 'Develop set processes for data mining, data modeling, and data production.', 'Research new uses for existing data.', 'Utilize appropriate languages and tools to connect systems together.', 'Collaborate across functional teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.', 'Implement processes and systems to monitor data quality, data accuracy and data availability.', 'Initiate and validate disaster recovery procedures.', 'Ensure that all systems meet the business/company standards as well as industry practices and compliance requirements.', 'Perform data analysis as required to troubleshoot data related issues and assist in the resolution of data issues.', 'Recommend different ways to constantly improve data reliability and quality.', 'Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics statistics.', '4+ years of SQL experience (No-SQL experience is a plus)', 'Practical experience or knowledge of Python or R is a plus', 'Experience in a marketing or related field using large data sets', 'Experience with or knowledge of Agile Software Development methodologies', 'Excellent problem solving and troubleshooting skills', 'Process oriented with great documentation skills']",2020-09-24 13:51:52
"ID&C Engineer: Instrumentation, Data System, and Controls Engineer","Integration Innovation, Inc.",4.6 out of 5,"Tullahoma, TN","['Evaluate current methods and procedures used at AEDC and recommend solutions for Phoenix.', 'Provide instrumentation selections based off of requirements for all J5 Phoenix systems.', 'Provide equipment recommendations and standard configurations for all J5 Phoenix systems and work with each system engineer.', 'Provide problem solving support to field measurement techniques.', 'Support installation and checkout integrations with other systems within the Phoenix Project.', 'Develop best practice documentation of field configurations to supply to technicians when installing and checking out system components.', 'Work closely with functional, technical, and vendor teams to create and implement industry leading solutions.', 'Coordinate and participate in CONOPS development.', 'Maintain technical expertise in all data and controls system computer hardware, software, interconnection, and interfacing.', 'Evaluate, report, and make recommendations on new data system and control system technologies to enhance the capabilities of i3 and its partners.', 'Must be willing to participate in continuing education in the form of training, courses, PDUs, and certifications.', 'Bachelor’s degree in either electrical or computer engineering.', '5+ years total of relevant experience required.', 'Strong analytical and technical skills, understanding of system integration concepts.', 'Demonstrated ability to take ownership and responsibility for systems.', '3+ years of Instrumentation and Data Acquisition system design and maintenance experience.', '2+ years of knowledge and experience with controls system development.', 'Experience with working government contracts.', 'Knowledge of LabVIEW and Microsoft SQL Server', 'GE CIMPLICITY or other HMI/SCADA solution']",2020-09-24 13:51:52
"Data Engineer, Growth",Pinterest,4.2 out of 5,"San Francisco, CA 94103","['Develop scalable and reliable workflows that efficiently process big data', 'Build marketing automation that manages media spend across dozens of advertising strategies', 'Partner with data scientists on machine learning and statistical models to predict user revenue and retention', '3+ years of data engineering experience, preferably in Growth teams', 'Strong experience in writing reliable, low-maintenance, and powerful code that may be used by many other engineers', 'Desire to understand the marketing/advertising space and learn metrics-driven approach to software development', 'Interest in working closely with marketers, designers, product managers, data scientists, and other partners to bring business vision & growth alive']",2020-09-24 13:51:52
Senior Data Engineer,Moda Health,3.1 out of 5,"Portland, OR 97204",[],2020-09-24 13:51:52
Cloud Data Engineer - DevOps,Ahana,N/A,Remote,"['Take on lead role in building out AWS infrastructure and microservices to automate deployment pipeline for a SaaS application', 'Build, automate and facilitate upgrades and patches to live customer deployments', 'Act as a player and coach, who can handle deep technical needs of customers, manage and grow other team members', 'Deliver best practices, guidance, documentation and support for architecting and building robust customer solutions', 'Deliver proactive suggestions for improving performance and efficiency of the overall application / service', 'Drive cloud-related product enhancement and feature requests working with product management and engineering', 'Be a true proponent of customer advocacy', 'Minimum 5 years experience architecting, designing, building, testing, and maintaining managed services or SaaS software applications', 'Deep understanding of AWS and services particularly the following:', 'Deep experience with orchestration technologies - including Terraform, Dockers, Kubernetes', 'First-hand experience architecting, developing, deploying, and operating large scale distributed systems from scratch.', 'Deep Linux and systems understanding.', 'Excellent Python programming experience especially related to web development.', 'Additional Java / Go experience a strong plus', 'Ability to work in a fast-paced startup environment', 'Experience in a SaaS cloud environments i.e. AWS, Azure, Google cloud platform', ""Bachelor's degree in computer science required""]",2020-09-24 13:51:52
"Data Scientist, Threat Detection",Reddit,N/A,"San Francisco, CA","['Work as part of a cross functional team of data scientists, operational specialists, and engineers to keep Reddit safe', 'Develop algorithms to help surface abusive content and to potentially remove content with very strong signals', 'Develop algorithms that uncover patterns of coordination and spam on the platform', 'Develop ML models for understanding text, image, and video content from an abuse perspective', '2+ years of experience in quantitative analytical roles (or and advanced degrees in quantitative fields such as physics, economics, statistics, etc)', 'Proficiency with relational database (e.g., SQL)', 'Familiarity with statistical analysis and programming languages (e.g., Python)', 'Motivated and self-directed, demonstrated ability to innovate and bias toward action in fast-paced environments.', 'Ability to communicate and discuss complex topics with technical and non-technical audiences.', 'Willingness to make mistakes, learn from them, and grow']",2020-09-24 13:51:52
Data Engineer,Eleks,N/A,"Chicago, IL","['At least 5+ years of experience in Data Engineering', 'Solid Experience with MySQL, Gemfire, IBM DB2, CosmosDB,', 'Good to know CI/CD, Jenkins, Concourse, Java', 'Experience in building ETLs', 'Understanding of TDD and extreme programming', 'Knowledge of cloud-based technologies', 'Pivotal tech stack knowledge', 'Develop solutions and algorithms according to technical specifications or other requirements documentation; use standard algorithms in the applicable cases', 'Write program code according to the defined application architecture', 'Structure and format the source code, comment and mark up the code, as well as name variables, functions, classes, data structures, and files according to the company conventions and industry best practices', 'Modify existing code and verify its functioning. Analyze code compliance with readability and performance standards', 'Use version control systems to track code optimization progress and to merge or split program code entities. Commit changes according to version control rules', 'Perform analysis, verification, and debugging of the software code at the level of application units', 'Detect defects, apply debugging methods and techniques, correctly interpret bug reports, as well as apply modern compilers, debuggers, and program code optimizers', 'Able to develop procedures for testing code availability, collecting diagnostic data, generating test data sets with necessary characteristics, identifying required software characteristics etc.', 'Reproduce defects logged in an issue tracking system, identify defect causes, and then modify code to eliminate defects', 'Able to develop and document program interfaces, software module and component assembling procedures, software deployment and update procedures as well as data migration and transformation (conversion) procedures', 'Estimate and set up task completion terms independently', 'Evaluate and coordinate task deadlines with Technical Leader or Project Manager', 'May have valid competence-related certifications', 'Participate, both as a trainer or a trainee, in various learning programs outside the major project', 'Close cooperation with a customer', 'Challenging tasks', 'Competence development', 'Ability to influence project technologies', 'Team of professionals', 'Dynamic environment with low level of bureaucracy']",2020-09-24 13:51:52
Principle Data Engineer,Diligente Technologies,N/A,"Austin, TX","['Play a key role in defining and driving the data strategy, target platform and governance principles', 'Create a fluid, end-to-end vision for data flowing through our ecosystem to enable seamless, near real-time workflow integration with both relational and non-relational data stores.', 'Define strategy for data acquisition from legacy systems', 'Own end-to-end architecture vision & roadmap for the data platform to support the data strategy', 'Design infrastructure & technology for data platform, including owning technology selection', 'Understand and be accountable for the financial implications of the design', 'Plan data and database architectural progression for year 1, year 2 etc. and define achievable transitions', 'Be hands-on, especially with the initial implementation work', 'Research, understand, recommend, and plan for the integration of new technologies', 'Ensure all non-functional aspects of the platform are addressed; including scalability, security, maintainability and supportability', 'Continually monitor current state, business direction & technology trends to ensure the platform direction is sustainable', 'Identify opportunities for technical innovation that add value to the platform', 'Assist in establishing and embedding data management and governance processes', 'Excellent interpersonal and presentation skills, equally comfortable engaging with and presenting to senior stakeholders, as well as writing code alongside software engineers', 'Work closely with architects from across the organization to ensure alignment with the broader technical strategy', 'Work closely with other platform teams/project management/release management that may be dependent on/impacted by changes in the platform scope or technical implementation', 'Ability to evangelize new technologies and their impact on the company.', 'Bachelor’s degree with 8+ years of relevant experience', '8+ years of experience in defining and implementing data strategies', '5+ years of experience integrating data in batch and near real-time', '5+ years of experience with large data sets and deep understanding of associated technologies such as OLTP relational databases, OLAP & Dimensional Environments, Cloud technologies, Search tools and algorithms, ETL tool and techniques, document or other NoSQL databases, and process tools.', 'Experience delivering flexible, reliable, supportable conceptual, logical, and physical data models across a broad ecosystem.', 'A good understanding of best practice techniques to build and maintain data models, along with advantages and disadvantages of enterprise data models', 'Capable of working with complex data structures and data models to provide recommendations on business focused data architecture', 'Able to work in a faced paced, dynamic environment', 'Experienced in Agile Software Development Environment', 'Experience with at least 1 of the following:', 'Data Mining,', 'Machine Learning', 'Predictive Analytics', 'Experienced Data Architect or Solution Architect with considerable exposure to data led driven environments', 'Specific experience defining Data Architecture, including future/target architectures', 'Knowledge of Data Analytics offerings from AWS, GCP or Azure', 'Establishing and embedding data management and governance processes', 'Experience working within agile led environments', 'Experience with event design, event streaming & event driven architectures', 'Experience in a Microservices Based Environment', 'Degree in Mathematics, Computer Science or Electrical Engineering', 'Temporarily due to COVID-19']",2020-09-24 13:51:52
Software Engineer Intern - Data Science & Sol,Oklahoma City Thunder,4.4 out of 5,"Edmond, OK 73013","['Manage, implement, and maintain data systems and applications related to team and player performance, medical and physical performance, player identification and evaluation, and planning strategies', 'Develop impactful tools, systems, and ongoing results', 'Collaborate with teammates on new research initiatives across various functions', 'Carry out other administrative tasks consistent with the policies and procedures of the NBA and OKC Thunder', 'Maintain good attendance and punctuality', 'Other duties as assigned', 'Currently enrolled in an accredited college or university pursuing a degree in computer science or related field', 'Outstanding analytical and quantitative problem-solving skills', 'Some experience in areas such as front-end and back-end development, database administration, and cloud services', 'Some experience with development tools such as Python, Django, SQL, etc.', 'Experience working with and protecting confidential information', 'Good communication and interpersonal skills with the ability to deliver clear and effective messages to a variety of partners']",2020-09-24 13:51:52
Database / Data Engineer,"Webtellect, LLC",N/A,"Seattle, WA 98104","['Development of Tools, Reporting & Analysis:Design, develop and maintain scalable, automated, user-friendly systems, reports, dashboards, etc. that will support our analytical and business needsWrite robust SQL code to retrieve and analyze data from database tables (ex. MySQL, Redshift, Athena)Analyze projects for data quality issues and supporting the use of data in an enterprise settingDevelop analysis and visualizations for ad-hoc requests and one-off projectsUse analytical and statistical rigor to solve complex problems and drive business decisions', 'Contribute to current data infrastructure:Understand corporate data structure to be able to draw data from transactional data tables existing in the companySupport the acquisition of external data sets, interpreting data layouts, structures, fields and values to incorporate new data into the core analytics data base', 'Communication:Interface with business customers to gather data and metrics requirements, then driving analytic projects which will help solve complex challengesDraw insights from data and clearly communicate complex findings to stakeholders and external customersWork closely with the Modeling and Data Science teams to determine where gaps and opportunities lie', 'Experience working with MySQL, PostgreSQL, AWS Redshift/S3', 'Experience with Excel (including VBA) and Tableau', 'Experience with Python, PySpark, and DataRobot', 'Analytical Curiosity: Motivated individual with strong analytic, problem solving, and troubleshooting skills.', 'Teamwork and Adaptability: Ability to be flexible and work as part of a team in ever-changing start-up environment.', ""Educational Credentials: Bachelor's degree in Computer Science or a quantitative field such as Mathematics, Statistics, Economics, Finance, Physics, or Engineering"", 'Relevant experience: A minimum of 2 to 3 years of experience (3 to 5 years preferred) of SQL experience', 'Technical Knowledge: Intermediate to expert level programming experience in SQL along with a solid understanding of data warehousing concepts and ability to build and work with data from different sources efficiently.', '6 month contract.', '** No 3rd parties. **', '** No Visas allowed **']",2020-09-24 13:51:52
Scrum Master- Data Analytics & Engineer,Liberty Mutual Insurance,3.6 out of 5,"Portsmouth, NH 03801","['Job', 'Company', 'Work with a team committed to excellence!', 'Help bring Information Management operations into the future!', 'Facilitate squads developing state of the art technology!', 'Model and promote a “Data First” attitude', 'Implements consistent process and tools and identify emerging best practices and issues to help continuously advance agile methods and practices.', 'Work closely with executives, business unit leaders, product owners, and squads as an expert on agile methods and to educate organizations to use a variety of approaches to deliver customer value in both business and IT teams.', 'Ensures successful delivery of large impact and/or cross-functional product initiative by assisting in the identification and solution of organizational impediments which limit team’s customer centricity, productivity, and/or quality.', 'Provide scaling expertise to align multiple agile teams, collaborate and facilitate quarterly planning with large groups, manage portfolio backlog of epics and features, and facilitate decision making with Product Management, Senior Leaders and Architects.', 'Coaches, mentors and provides guidance to Scrum Masters, Technologists, Architects and other members of the squad.', 'Provide feedback to management at all levels regarding the progress of agile transformations within their teams.', 'Requires ability to manage projects from conception to successful implementation.', 'Requires solid project management skills, ability to multitask and manage multiple projects in a cross-functional environment.', 'Requires excellent communication, interpersonal, organizational and team building skills, business judgment, and proven expertise in directing the efforts of a technical staff.', 'In-depth knowledge of business functions and extensive understanding of business operations, strategies and objectives.', 'In-depth knowledge of SAFe (Scaled Agile Framework) with three plus years’ experience as a Scrum Master, Product Owner or Agile Coach.', 'Strong communication, facilitation, presentation and consensus building skills.']",2020-09-24 13:51:52
Data Engineer,adidas,4 out of 5,"Portland, OR",[],2020-09-24 13:51:52
Data Engineer,Invitae,3.6 out of 5,"Seattle, WA","['Understand our complex data ecosystem and build ETL solutions', 'Develop a real-time streaming infrastructure that supports critical business functions', 'Design and develop tools to enable teams to consume and understand data faster', 'Collaborate with multiple teams and own solutions from end-to-end', 'Are self-starters and can work towards a larger goal with minimal guidance', 'Prior experience utilizing data warehousing or building out data warehouses', 'Have at least 3 years of hands-on experience working with large datasets, pipelines, and warehouses', 'Have a focus on high-quality code, including automated testing and coding best practices', 'Have experience with messaging/queuing systems or stream processing systems', 'Have architected distributed systems with infrastructure automation, monitoring and alerting']",2020-09-24 13:52:32
Data Engineer,"Rooftop Digital, LLC",N/A,"Agoura Hills, CA 91301","['Develop data pipelines and build out integrations to support continuing increases in data volume and complexity.', 'Assist in the design, construction, testing and maintenance of data management systems.', 'Build high-performance algorithms, predictive models, and prototypes.', 'Evaluate and integrate data management and software engineering technologies into existing data structures.', 'Develop set processes for data mining, data modeling, and data production.', 'Research new uses for existing data.', 'Utilize appropriate languages and tools to connect systems together.', 'Collaborate across functional teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.', 'Implement processes and systems to monitor data quality, data accuracy and data availability.', 'Initiate and validate disaster recovery procedures.', 'Ensure that all systems meet the business/company standards as well as industry practices and compliance requirements.', 'Perform data analysis as required to troubleshoot data related issues and assist in the resolution of data issues.', 'Recommend different ways to constantly improve data reliability and quality.', 'Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics statistics.', '4+ years of SQL experience (No-SQL experience is a plus)', 'Practical experience or knowledge of Python or R is a plus', 'Experience in a marketing or related field using large data sets', 'Experience with or knowledge of Agile Software Development methodologies', 'Excellent problem solving and troubleshooting skills', 'Process oriented with great documentation skills']",2020-09-24 13:52:32
"ID&C Engineer: Instrumentation, Data System, and Controls Engineer","Integration Innovation, Inc.",4.6 out of 5,"Tullahoma, TN","['Evaluate current methods and procedures used at AEDC and recommend solutions for Phoenix.', 'Provide instrumentation selections based off of requirements for all J5 Phoenix systems.', 'Provide equipment recommendations and standard configurations for all J5 Phoenix systems and work with each system engineer.', 'Provide problem solving support to field measurement techniques.', 'Support installation and checkout integrations with other systems within the Phoenix Project.', 'Develop best practice documentation of field configurations to supply to technicians when installing and checking out system components.', 'Work closely with functional, technical, and vendor teams to create and implement industry leading solutions.', 'Coordinate and participate in CONOPS development.', 'Maintain technical expertise in all data and controls system computer hardware, software, interconnection, and interfacing.', 'Evaluate, report, and make recommendations on new data system and control system technologies to enhance the capabilities of i3 and its partners.', 'Must be willing to participate in continuing education in the form of training, courses, PDUs, and certifications.', 'Bachelor’s degree in either electrical or computer engineering.', '5+ years total of relevant experience required.', 'Strong analytical and technical skills, understanding of system integration concepts.', 'Demonstrated ability to take ownership and responsibility for systems.', '3+ years of Instrumentation and Data Acquisition system design and maintenance experience.', '2+ years of knowledge and experience with controls system development.', 'Experience with working government contracts.', 'Knowledge of LabVIEW and Microsoft SQL Server', 'GE CIMPLICITY or other HMI/SCADA solution']",2020-09-24 13:52:32
"Data Engineer, Growth",Pinterest,4.2 out of 5,"San Francisco, CA 94103","['Develop scalable and reliable workflows that efficiently process big data', 'Build marketing automation that manages media spend across dozens of advertising strategies', 'Partner with data scientists on machine learning and statistical models to predict user revenue and retention', '3+ years of data engineering experience, preferably in Growth teams', 'Strong experience in writing reliable, low-maintenance, and powerful code that may be used by many other engineers', 'Desire to understand the marketing/advertising space and learn metrics-driven approach to software development', 'Interest in working closely with marketers, designers, product managers, data scientists, and other partners to bring business vision & growth alive']",2020-09-24 13:52:32
Senior Data Engineer,Moda Health,3.1 out of 5,"Portland, OR 97204",[],2020-09-24 13:52:32
Cloud Data Engineer - DevOps,Ahana,N/A,Remote,"['Take on lead role in building out AWS infrastructure and microservices to automate deployment pipeline for a SaaS application', 'Build, automate and facilitate upgrades and patches to live customer deployments', 'Act as a player and coach, who can handle deep technical needs of customers, manage and grow other team members', 'Deliver best practices, guidance, documentation and support for architecting and building robust customer solutions', 'Deliver proactive suggestions for improving performance and efficiency of the overall application / service', 'Drive cloud-related product enhancement and feature requests working with product management and engineering', 'Be a true proponent of customer advocacy', 'Minimum 5 years experience architecting, designing, building, testing, and maintaining managed services or SaaS software applications', 'Deep understanding of AWS and services particularly the following:', 'Deep experience with orchestration technologies - including Terraform, Dockers, Kubernetes', 'First-hand experience architecting, developing, deploying, and operating large scale distributed systems from scratch.', 'Deep Linux and systems understanding.', 'Excellent Python programming experience especially related to web development.', 'Additional Java / Go experience a strong plus', 'Ability to work in a fast-paced startup environment', 'Experience in a SaaS cloud environments i.e. AWS, Azure, Google cloud platform', ""Bachelor's degree in computer science required""]",2020-09-24 13:52:32
"Data Scientist, Threat Detection",Reddit,N/A,"San Francisco, CA","['Work as part of a cross functional team of data scientists, operational specialists, and engineers to keep Reddit safe', 'Develop algorithms to help surface abusive content and to potentially remove content with very strong signals', 'Develop algorithms that uncover patterns of coordination and spam on the platform', 'Develop ML models for understanding text, image, and video content from an abuse perspective', '2+ years of experience in quantitative analytical roles (or and advanced degrees in quantitative fields such as physics, economics, statistics, etc)', 'Proficiency with relational database (e.g., SQL)', 'Familiarity with statistical analysis and programming languages (e.g., Python)', 'Motivated and self-directed, demonstrated ability to innovate and bias toward action in fast-paced environments.', 'Ability to communicate and discuss complex topics with technical and non-technical audiences.', 'Willingness to make mistakes, learn from them, and grow']",2020-09-24 13:52:32
Data Engineer,Eleks,N/A,"Chicago, IL","['At least 5+ years of experience in Data Engineering', 'Solid Experience with MySQL, Gemfire, IBM DB2, CosmosDB,', 'Good to know CI/CD, Jenkins, Concourse, Java', 'Experience in building ETLs', 'Understanding of TDD and extreme programming', 'Knowledge of cloud-based technologies', 'Pivotal tech stack knowledge', 'Develop solutions and algorithms according to technical specifications or other requirements documentation; use standard algorithms in the applicable cases', 'Write program code according to the defined application architecture', 'Structure and format the source code, comment and mark up the code, as well as name variables, functions, classes, data structures, and files according to the company conventions and industry best practices', 'Modify existing code and verify its functioning. Analyze code compliance with readability and performance standards', 'Use version control systems to track code optimization progress and to merge or split program code entities. Commit changes according to version control rules', 'Perform analysis, verification, and debugging of the software code at the level of application units', 'Detect defects, apply debugging methods and techniques, correctly interpret bug reports, as well as apply modern compilers, debuggers, and program code optimizers', 'Able to develop procedures for testing code availability, collecting diagnostic data, generating test data sets with necessary characteristics, identifying required software characteristics etc.', 'Reproduce defects logged in an issue tracking system, identify defect causes, and then modify code to eliminate defects', 'Able to develop and document program interfaces, software module and component assembling procedures, software deployment and update procedures as well as data migration and transformation (conversion) procedures', 'Estimate and set up task completion terms independently', 'Evaluate and coordinate task deadlines with Technical Leader or Project Manager', 'May have valid competence-related certifications', 'Participate, both as a trainer or a trainee, in various learning programs outside the major project', 'Close cooperation with a customer', 'Challenging tasks', 'Competence development', 'Ability to influence project technologies', 'Team of professionals', 'Dynamic environment with low level of bureaucracy']",2020-09-24 13:52:32
Principle Data Engineer,Diligente Technologies,N/A,"Austin, TX","['Play a key role in defining and driving the data strategy, target platform and governance principles', 'Create a fluid, end-to-end vision for data flowing through our ecosystem to enable seamless, near real-time workflow integration with both relational and non-relational data stores.', 'Define strategy for data acquisition from legacy systems', 'Own end-to-end architecture vision & roadmap for the data platform to support the data strategy', 'Design infrastructure & technology for data platform, including owning technology selection', 'Understand and be accountable for the financial implications of the design', 'Plan data and database architectural progression for year 1, year 2 etc. and define achievable transitions', 'Be hands-on, especially with the initial implementation work', 'Research, understand, recommend, and plan for the integration of new technologies', 'Ensure all non-functional aspects of the platform are addressed; including scalability, security, maintainability and supportability', 'Continually monitor current state, business direction & technology trends to ensure the platform direction is sustainable', 'Identify opportunities for technical innovation that add value to the platform', 'Assist in establishing and embedding data management and governance processes', 'Excellent interpersonal and presentation skills, equally comfortable engaging with and presenting to senior stakeholders, as well as writing code alongside software engineers', 'Work closely with architects from across the organization to ensure alignment with the broader technical strategy', 'Work closely with other platform teams/project management/release management that may be dependent on/impacted by changes in the platform scope or technical implementation', 'Ability to evangelize new technologies and their impact on the company.', 'Bachelor’s degree with 8+ years of relevant experience', '8+ years of experience in defining and implementing data strategies', '5+ years of experience integrating data in batch and near real-time', '5+ years of experience with large data sets and deep understanding of associated technologies such as OLTP relational databases, OLAP & Dimensional Environments, Cloud technologies, Search tools and algorithms, ETL tool and techniques, document or other NoSQL databases, and process tools.', 'Experience delivering flexible, reliable, supportable conceptual, logical, and physical data models across a broad ecosystem.', 'A good understanding of best practice techniques to build and maintain data models, along with advantages and disadvantages of enterprise data models', 'Capable of working with complex data structures and data models to provide recommendations on business focused data architecture', 'Able to work in a faced paced, dynamic environment', 'Experienced in Agile Software Development Environment', 'Experience with at least 1 of the following:', 'Data Mining,', 'Machine Learning', 'Predictive Analytics', 'Experienced Data Architect or Solution Architect with considerable exposure to data led driven environments', 'Specific experience defining Data Architecture, including future/target architectures', 'Knowledge of Data Analytics offerings from AWS, GCP or Azure', 'Establishing and embedding data management and governance processes', 'Experience working within agile led environments', 'Experience with event design, event streaming & event driven architectures', 'Experience in a Microservices Based Environment', 'Degree in Mathematics, Computer Science or Electrical Engineering', 'Temporarily due to COVID-19']",2020-09-24 13:52:32
Software Engineer Intern - Data Science & Sol,Oklahoma City Thunder,4.4 out of 5,"Edmond, OK 73013","['Manage, implement, and maintain data systems and applications related to team and player performance, medical and physical performance, player identification and evaluation, and planning strategies', 'Develop impactful tools, systems, and ongoing results', 'Collaborate with teammates on new research initiatives across various functions', 'Carry out other administrative tasks consistent with the policies and procedures of the NBA and OKC Thunder', 'Maintain good attendance and punctuality', 'Other duties as assigned', 'Currently enrolled in an accredited college or university pursuing a degree in computer science or related field', 'Outstanding analytical and quantitative problem-solving skills', 'Some experience in areas such as front-end and back-end development, database administration, and cloud services', 'Some experience with development tools such as Python, Django, SQL, etc.', 'Experience working with and protecting confidential information', 'Good communication and interpersonal skills with the ability to deliver clear and effective messages to a variety of partners']",2020-09-24 13:52:32
Database / Data Engineer,"Webtellect, LLC",N/A,"Seattle, WA 98104","['Development of Tools, Reporting & Analysis:Design, develop and maintain scalable, automated, user-friendly systems, reports, dashboards, etc. that will support our analytical and business needsWrite robust SQL code to retrieve and analyze data from database tables (ex. MySQL, Redshift, Athena)Analyze projects for data quality issues and supporting the use of data in an enterprise settingDevelop analysis and visualizations for ad-hoc requests and one-off projectsUse analytical and statistical rigor to solve complex problems and drive business decisions', 'Contribute to current data infrastructure:Understand corporate data structure to be able to draw data from transactional data tables existing in the companySupport the acquisition of external data sets, interpreting data layouts, structures, fields and values to incorporate new data into the core analytics data base', 'Communication:Interface with business customers to gather data and metrics requirements, then driving analytic projects which will help solve complex challengesDraw insights from data and clearly communicate complex findings to stakeholders and external customersWork closely with the Modeling and Data Science teams to determine where gaps and opportunities lie', 'Experience working with MySQL, PostgreSQL, AWS Redshift/S3', 'Experience with Excel (including VBA) and Tableau', 'Experience with Python, PySpark, and DataRobot', 'Analytical Curiosity: Motivated individual with strong analytic, problem solving, and troubleshooting skills.', 'Teamwork and Adaptability: Ability to be flexible and work as part of a team in ever-changing start-up environment.', ""Educational Credentials: Bachelor's degree in Computer Science or a quantitative field such as Mathematics, Statistics, Economics, Finance, Physics, or Engineering"", 'Relevant experience: A minimum of 2 to 3 years of experience (3 to 5 years preferred) of SQL experience', 'Technical Knowledge: Intermediate to expert level programming experience in SQL along with a solid understanding of data warehousing concepts and ability to build and work with data from different sources efficiently.', '6 month contract.', '** No 3rd parties. **', '** No Visas allowed **']",2020-09-24 13:52:32
Data Engineer,adidas,4 out of 5,"Portland, OR",[],2020-09-24 13:52:32
Senior Data Engineer,The Predictive Index,2.8 out of 5,Massachusetts,"['Streamline the current data landscape and create a visible and reusable architecture to increase transparency and standardization of definitions.', 'Partner with stakeholders and BI Analysts to define and build a centralized data repository purpose-built for reporting.', 'Create and maintain a single source of truth data dictionary.', ""Streamline ETL's into coherent views to support effective and consistent reporting to the business."", ""Work closely with vendors from PI's tech stack to evaluate all API integration options with DOMO."", 'Build historical datasets to eventually leverage them into data science investigations.', 'Work closely with the systems team to understand and develop expertise in a growing range of PI data sources and their applications across the business. Staying up to date on the data lineage is critical.', 'Constitute rules of engagement and governance processes regarding the analytics data landscape.', 'Support and train team members on data architecture and similar concepts.', 'Experience building schema to scale and automate workflows.', 'Experience and knowledge of modern data stores, pipeline and reporting/analytic techniques and tools.', 'Experience building data models and data warehouses is highly desired.', 'Expertise in SQL, MYSQL, Python, and/or R is preferred.', 'Strong analytical skills: Ability to collect, organize, and analyze data; summarize findings and develop conclusions and recommendations.', 'Self-starter who takes initiative and is proactive and able to prioritize multiple projects involving various stakeholders by meeting deadlines and proactively communicating status updates.', 'Ability to communicate at all levels of the organization, from end-users to Senior Management.', ""Bachelor's degree in engineering, mathematics, computer science, or equivalent data engineering work experience, preferred""]",2020-09-24 13:52:32
Senior Data Engineer,Swiftly Systems,N/A,"Seattle, WA 98104","['Comprehensive HealthcareWe help you stay healthy with medical, dental, and vision insurance', 'Powered by JazzHR', '49vG4zL1rX', 'Demonstrated ability to work collaboratively in an ambiguous, fast-paced environment', '10+ years of industry experience architecting, coding, verifying and operating large-scale data pipelines and architectures', 'Mastery of SQL, NoSQL, Document DB, Key-Value, Columnar and blob data storage patterns', 'Operational experience with multiple vendor solutions for repository patterns and the ability to quickly identify the right solution for a given data architecture and workload', 'Proven ability to collaborate with client and service engineering teams to ensure the best possible data architecture', 'Operational experience architecting, building and operating large scale data warehouses and/or data lakes', 'Understanding of data science and have experience building data pipelines to support data scientists', 'B.S. in Mathematics, Statistics, Computer Science, Computer Engineering, or a related field', 'Authorization to work in the United States', 'Ideal candidates have a mix of startup and large software company experience', 'Is a seasoned senior or principal engineer with many years of industry experience working on big, complex projects', 'Has demonstrated the ability to work collaboratively in an ambiguous, fast-paced environment', ""Considers software development a craft that they're on a lifetime journey to master"", 'Will not settle for anything less than clean, SOLID, testable code', 'Takes ownership of their domain from the ground up, from architectural decisions to coding to testing to operations', 'Takes pride in keeping a tidy house with minimal technical debt', 'Leaves their ego at the door and ensures the best idea leaves the room', 'Is always experimenting with new technologies and learning new skillsets']",2020-09-24 13:52:32
Analytics Data Engineer,Progressive Leasing,3.6 out of 5,"Draper, UT 84020","['Competitive Compensation', 'Full Health Benefits; Medical/Dental/Vision/Life Insurance + Paid Parental Leave', 'Company Matched 401k', 'Paid Time Off + Paid Holidays + Paid Volunteer Hours', 'Diversity Alliance Resource Groups', 'Employee Stock Purchase Program', 'Tuition Reimbursement', 'Charitable Gift Matching', 'Work in a self-directed but not isolated manner. Take ownership of the technical work you and your team create.', 'Enable our data analysts and scientists to perform data exploration activities with as much autonomy as possible', 'Collaborate with business data partners to rapidly iterate on new metrics / datasets and promote the results into a governed Enterprise Data Warehouse', 'During the normal course of work, contribute tests that improve data quality in our Enterprise Data Warehouse', 'Proactively identify areas for operational improvement in the data delivery space and collaborate with the rest of the data engineering team to achieve those goals', 'Help team operate current data platform (on-prem SQL Server) while migrating to new data platform (Snowflake) using a new data transformation architecture', 'Leverage platform in order to turn data into usable assets', 'Bachelor’s degree in a technical field (Engineering, Computer Science, Information Systems, etc.)', '2+ years professional experience in data & analytics/software engineering or 1+ year professional experience and a graduate degree in relevant field', '1+ year experience moving data between systems, ideally into an analytical system', 'Understands and can explain different data storage technologies at a high level, with in depth knowledge and experience in at least one technology (such as Hadoop, SQL Server, Cassandra, Snowflake, Azure Data Lake Gen2)', 'Solid knowledge of data modeling, SQL, and optimization techniques', 'Experience modeling data to be consumed in a BI technology (such as Power BI, Tableau, Excel, Looker, ThoughtSpot, SAP Business Objects)', 'Deployed production code in at least 1 programming or scripting language (such as Python, R, Java, C#, PowerShell, bash)', 'Understand modern data warehouse practices', 'Understanding of modern software development and engineering practices', 'Understands different levels of technical ability in business users (data analysts, data scientists, management) and can speak at those levels', 'Competitive Compensation', 'Full Health Benefits; Medical/Dental/Vision/Life Insurance + Paid Parental Leave', 'Company Matched 401k', 'Paid Time Off + Paid Holidays + Paid Volunteer Hours', 'Diversity Alliance Resource Groups', 'Employee Stock Purchase Program', 'Tuition Reimbursement', 'Charitable Gift Matching', 'Job required equipment and services']",2020-09-24 13:52:32
Principle Data Engineer,Diligente Technologies,N/A,"Austin, TX","['Play a key role in defining and driving the data strategy, target platform and governance principles', 'Create a fluid, end-to-end vision for data flowing through our ecosystem to enable seamless, near real-time workflow integration with both relational and non-relational data stores.', 'Define strategy for data acquisition from legacy systems', 'Own end-to-end architecture vision & roadmap for the data platform to support the data strategy', 'Design infrastructure & technology for data platform, including owning technology selection', 'Understand and be accountable for the financial implications of the design', 'Plan data and database architectural progression for year 1, year 2 etc. and define achievable transitions', 'Be hands-on, especially with the initial implementation work', 'Research, understand, recommend, and plan for the integration of new technologies', 'Ensure all non-functional aspects of the platform are addressed; including scalability, security, maintainability and supportability', 'Continually monitor current state, business direction & technology trends to ensure the platform direction is sustainable', 'Identify opportunities for technical innovation that add value to the platform', 'Assist in establishing and embedding data management and governance processes', 'Excellent interpersonal and presentation skills, equally comfortable engaging with and presenting to senior stakeholders, as well as writing code alongside software engineers', 'Work closely with architects from across the organization to ensure alignment with the broader technical strategy', 'Work closely with other platform teams/project management/release management that may be dependent on/impacted by changes in the platform scope or technical implementation', 'Ability to evangelize new technologies and their impact on the company.', 'Bachelor’s degree with 8+ years of relevant experience', '8+ years of experience in defining and implementing data strategies', '5+ years of experience integrating data in batch and near real-time', '5+ years of experience with large data sets and deep understanding of associated technologies such as OLTP relational databases, OLAP & Dimensional Environments, Cloud technologies, Search tools and algorithms, ETL tool and techniques, document or other NoSQL databases, and process tools.', 'Experience delivering flexible, reliable, supportable conceptual, logical, and physical data models across a broad ecosystem.', 'A good understanding of best practice techniques to build and maintain data models, along with advantages and disadvantages of enterprise data models', 'Capable of working with complex data structures and data models to provide recommendations on business focused data architecture', 'Able to work in a faced paced, dynamic environment', 'Experienced in Agile Software Development Environment', 'Experience with at least 1 of the following:', 'Data Mining,', 'Machine Learning', 'Predictive Analytics', 'Experienced Data Architect or Solution Architect with considerable exposure to data led driven environments', 'Specific experience defining Data Architecture, including future/target architectures', 'Knowledge of Data Analytics offerings from AWS, GCP or Azure', 'Establishing and embedding data management and governance processes', 'Experience working within agile led environments', 'Experience with event design, event streaming & event driven architectures', 'Experience in a Microservices Based Environment', 'Degree in Mathematics, Computer Science or Electrical Engineering', 'Temporarily due to COVID-19']",2020-09-24 13:53:16
Data Center Design Developer,Oracle,3.8 out of 5,United States,[],2020-09-24 13:53:16
Associate Quality Engineer,Boehringer Ingelheim,4.1 out of 5,"Fremont, CA 94555","['Participate in small size validation (Equipment) projects:Participate with risk assessments for new systems and changes to existing systemsWrite simple validation plans, protocols and reports', 'Owning Quality Systems Records:Create, own, and manage life cycle of minor deviations, corrective actions and change controls for GMP equipment, facilities and automation systemsOperate within the relevant quality computer systems (ex. SAP, TrackWise) ensuring implementation in line with quality and timeliness objectivesWorking closely with Engineering, Quality, Process Development, Validation, and Manufacturing to investigate and resolve deviations including leading investigation teams in order to determine root cause, product impact, and appropriates corrective and preventive actions', 'Preparing material for internal and external regulatory and customer auditors', 'Participate in generating quality system metrics for the E&T department', 'Bachelors Degree from an accredited institution in Engineering with one (1) year of relevant cGMP biopharmaceutical manufacturing environment experience, or Masters Degree from an accredited institution in Engineering', 'Working knowledge of GMP guidelines, ICH Q7, Q8, Q9, Q10 and other international regulatory requirements', 'Excellent technical writing and verbal communication skills', 'Ability to work as part of a high performing team and collaborate effectively with staff at all levels.', 'Must have well-developed interpersonal skills with the ability to establish highly functional relationships with diverse personalities both within and outside the company.', 'Demonstrated ability to manage multiple activities while maintaining a high level of organization', 'Preferred experienced in Microsoft Office Suite', 'Knowledge of Microsoft Excel', 'Good knowledge and skills in biopharmaceutical and process engineering', 'Participation on technical projects with an interdisciplinary project team from planning to realization and start up', 'Understanding of validation concepts for biopharmaceutical manufacturing process, instrumentation and utility equipment.', 'Must be legally authorized to work in the United States without restriction.', 'Must be willing to take a drug test and post-offer physical (if required)', 'Must be 18 years of age or older']",2020-09-24 13:53:16
"Data Engineer, Healthcare Map",Komodo Health,4 out of 5,"New York, NY 10003","['Owned ingestion of several complex data sources and / or enhanced existing data sources.', 'Participated in design and implemented distributed data systems using Spark or similar technologies.', 'Collaborated with product managers and data scientists to implement validation and/or data quality enhancements.', 'Optimized the pipelines for performance and cost.', 'Helped ensure smooth operations of the ingestion pipelines.', 'Helped ensure patient privacy by implementing business rules.', 'Building new architecture focused on improving consistency between different pipelines, improving ability to backfill, and increasing data quality.', 'Ingesting new complex data sources. Many of our data sources consist of a large historical load, followed by regular incremental deliveries.', 'Enabling data ingestion as a service - to enable other teams to self-serve their ingestion needs when they are less sophisticated', 'Expertise with industry standard distributed systems (ie. Spark), data pipeline tools (ie. Airflow).', 'Capable of quickly building expertise on an as-need basis on new tech stack.', 'Demonstrable experience with Python.', 'Understand and design for non-functional concerns such as performance, cost optimization, maintainability and developer experience.', 'Strong communication with engineers, product managers.', 'Ability to work as part of an agile collaborative team in a fast-paced environment.', 'Experience with systems support, debugging and operations.', 'Cholangiocarcinoma Foundation & Komodo Health partner to fight cancer', ""Komodo Health's 'Meet a Dragon' series"", ""Komodo Health's $50M Series C funding led by Andreessen Horowitz, Joined by Oak HC/FT"", ""Komodo's Values that Drive our Culture"", ""In Conversation with Dr. Arif Nathoo, Komodo Health's CEO""]",2020-09-24 13:53:16
Senior Data Engineer,Pinwheel,4.5 out of 5,"New York, NY","['Work with business leaders and engineering leads to define KPIs and success metrics.', 'Model our data in LookerML and create analytics dashboards.', 'Work with the engineering team to define a data dictionary for analytics tracking calls from our different micro-services.', 'Architect and implement data pipelines for ETL processes into our AWS Redshift warehouse.', 'Leverage a variety of cloud technologies such as S3, SQS, and Lambda to efficiently and reliably deliver data from a variety of sources to our customers.', 'Write complex SQL queries to analyze data.', 'Perform more in depth exploratory data analysis using Jupyter notebooks and python libraries as pandas, numpy, matplotplib, seaborn, and scikit-learn.']",2020-09-24 13:53:16
Data Engineer,REX,4.5 out of 5,"Redwood City, CA 94065","['Significant experience with multiple data platforms, including SQL and NoSQL systems.', 'Experience with ETL pipelines', 'Comfortable coding in backend languages such as Java, Python, and Go', 'AWS experience', 'Experience with distributed batch data-processing techniques and tools', 'Experience with web-scale architectures', 'Java proficiency', 'Python proficiency']",2020-09-24 13:53:16
Senior Data Engineer,Humana,3.7 out of 5,"Louisville, KY","['Acquire/possess in depth understanding of the Azure ML DevOps to deploy/automate/monitor machine learning and forecasting models in production', 'Possess in depth understanding of building ingestion & data processing pipelines, from batch to streaming', 'Possess in depth understanding of computer science parallelism concepts and efficient data processing techniques suitable for machine learning applications', 'Architect and implement ETL / machine learning product solutions using best practices in the Azure cloud environment', 'Understand available data, including both structured and unstructured formats, and recommend effective ways for storage and analytical processing in the cloud', 'Comfortable working in a fast paced agile environment, closely interacting with business and some of industry’s best data scientists and engineers', ""Bachelor's degree in Computer Science, Technology, Analytics or related field"", '5+ years of technical experience', '1-2 years of working in a Cloud environment', 'Experience taking complex data and making it more accessible, understandable and usable for leaders to derive insights', 'Proven experience taking advanced data science concepts to production', 'Experience with data extraction and analysis technologies such as SAS, SPSS, QlickView, Hadoop, ETL, SQL or similar tools', 'Flexible, dynamic personality who is able to work independently in a start-up environment', ""Master's degree in Computer Science, Technology, Analytics or related field"", 'Healthcare or managed care experience', 'Azure experience']",2020-09-24 13:53:16
Chief Data Officer,Akuna Capital,3.2 out of 5,"Chicago, IL 60605","['Focus on delivering solutions to improve decision-making, optimize our trading and research processes, increase operational efficiency, and ultimately, transform data into actionable insights.', 'Lead the ongoing growth, design, and expansion of a high-quality data platform from across a wide variety of data sources, and supporting an array of streaming, operational and research workflows.', 'Champion the effort to democratize data access at Akuna, powering analyses and strategies with easy access to high quality data.', 'Develop data ingestion strategies to easily on-board new data assets.', 'Work closely with trading, quant and technology stakeholders across the firm to identify and optimize how data is produced and consumed.', 'Provide excellent management and technical oversight to the global Data Infrastructure team. Ensure the team is delivering using Agile methodologies and modern software best practices.', 'Promote and standardize our data management governance and best practices across the firm.', 'BS/MS/PhD in technical field – Computer Science, Engineering, Physics, Math, or equivalent.', '7+ years of experience in engineering data pipelines, analytics infrastructure, visualizations, and data platforms.', 'Results-oriented leader with a proven track record of leading a data transformation initiative.', 'Strong communication and interpersonal skills needed to collaborate, negotiate and influence effectively with all stakeholders at the firm.', 'Advanced knowledge and experience with best in class data strategy design.', 'Prior experience with big data platforms and technologies such as Kafka, Presto, Delta Lake, Spark, Snowflake and Beam is ideal.', 'Extensive experience with AWS or other public cloud providers such as GCP and Azure is strongly preferred.', 'Experience in building and growing teams and providing mentorship to junior team members.', 'Deep experience with financial trading data is strongly preferred, but not required.', 'Ability to operate in a fast-moving environment and deal with the complexity of multiple priorities and stakeholders.']",2020-09-24 13:53:16
NextGen Data Engineer,BICP,N/A,"Portland, OR",[],2020-09-24 13:53:16
Data Engineer - eCommerce (Remote),CrowdStrike,2.8 out of 5,United States,"['Design, develop, and maintain a data platform that serves as the foundation of the eCommerce business unit, automating and aggregating data from internal systems as well as external vendors and agencies', 'Design, develop, build and maintain data models to deliver insightful analytics while ensuring the highest standard in data integrity', 'Interface with engineers from other systems and applications to ensure proper data collection', 'Ensure data quality by implementing data detection mechanisms', 'Maintain and onboard new systems/vendors to enable data collection and analytics for the eCommerce business unit', 'Participate in reviewing the data models created by the team and change the existing data models in Production as necessary', 'Build data pipelines and reports that enable analysts and other stakeholders across the business unit', 'Educate your partners: Use your data and analytics experience to ‘see what’s missing’, identifying and addressing gaps in their existing processes', 'Support existing processes running in production and optimize when possible', 'Proven experience as a Data Engineer, including designing, building, and maintaining data processing systems', '6+ years of experience with schema design and dimensional data modeling', '6+ years of SQL, Python, and Java experience preferred', 'Experience with Salesforce, Marketo required', 'Experience with Snowflake, Domo, Tableau preferred', 'Experience with eCommerce, Paid Media a plus', 'BS/MS in Computer Science, Data Science, Applied Mathematics, Statistics, or related field', 'Effective communication, at scale, through multiple media: presentations, dashboards, company-wide datasets, bots and more', 'Demonstrated understanding of development processes and agile methodologies', 'Intellectually curious and willing to learn', 'Market leader in compensation and equity awards', 'Competitive vacation policy', 'Comprehensive health benefits + 401k plan', 'Paid parental leave, including adoption', 'Flexible work environment', 'Wellness programs', 'Stocked fridges, coffee, soda, and lots of treats']",2020-09-24 13:53:16
Federal - EDW Data Engineer,Accenture,4 out of 5,"Gaithersburg, MD","['Participate in critical conversations with the client to understand DOC’s existing system landscape and data assets.', 'Support the effort to design, develop, and implement the data warehouse / data lake solution, in an agile development environment.', 'Own development and test of significant pieces of functionality / modules, following secure coding standards.', 'Support deployment, production validations, issue resolution and iterative agile releases to incorporate enhancements and fixes.', 'Minimum of 1-2 years development experience with Informatica Power Center', 'Experience with Oracle BI Application (OBIA) Financial Analytics', 'Experience with AWS Applications', 'Experience with AWS Data & Database Solutions', 'Data Architecture Principles', 'Data Conversion & Migration', 'Data Management and Integration', 'Data Archiving Patterns & Techniques', 'Strong written and oral communication skills; ability to engage with the client in discussions to clarify requirements or guidance provided', 'Strong organizational skills', 'Attention to detail', 'US Citizenship or Green Card Holder Required']",2020-09-24 13:53:16
Data Engineer,TeePublic,4.4 out of 5,"New York, NY","['Design, build and launch new data extraction, transformation and loading processes.', 'Support our Marketplace and Search engineering teams in solving challenging big data problems', 'Create and maintain star-schema data model, transforming application and third party data data model into a structure for our data warehouse.', 'Assist analysts across finance, operations, customer service and marketing in understanding their data set and using our BI platform.', 'Build integrations within infrastructure and to 3rd party systems (e.x. Salesforce, Marketo, AWS, Facebook, Google)', 'Identify valuable data within 3rd party systems with stakeholders, planning and developing integration to leverage for insights and actions.', 'Optimize large complex queries to reduce run time and improve efficiency.', '4+ years working in an office environment', 'Experience building data infrastructure on top of public cloud providers (AWS, Azure, GCP)', 'Previous work within a data warehouse (Snowflake, Redshift, BigQuery)', 'Highly skilled in SQL, templating languages (such as Jinja), ETL across various formats (csv, sql, json).', 'Experience supporting cloud based BI Tools (Mode, Looker, Tableau)', 'Experience with data orchestration technologies (Airflow, Luigi, Prefect, etc)', 'Understanding economics and the data landscape of marketplaces and e-commerce.', 'Experience with our specific platform (Heroku) and specific production databases (Postgres, Elasticsearch, Neo4)', 'An undying love of t-shirts, pop culture, and big data.']",2020-09-24 13:53:16
"Junior Software Engineer, Full-Stack",CharterUP,N/A,"New York, NY","['$70,000 base salary', 'Material equity award with standard vesting', 'Efficiently roll out technical features from concept to product', 'Collaborate with a team to develop our next generation travel platform', 'Develop tooling and processes to benefit and grow our team', ""Bachelor's degree in Computer Science, Computer Engineering, or similar STEM degree from a top-ranked institution"", 'Back-end expertise in Java Spring Boot or Hibernate', 'Front-end expertise in Vue, React, or Angular', 'Potential to quickly develop expertise in any part of our tech stack where you have limited experience', 'Candidate submits CharterUP online applicationResumes encouraged to be at most one page in length', 'Initial evaluationCandidate may be asked to submit a sample of their work or complete a quick hack', 'InterviewsCandidate to meet with various members of the dev team, including CTO, product leads, and senior engineersCandidate to meet with founder, head of recruiting, or other members of the executive team', 'TestingCoding exerciseGeneral aptitude assessment', 'OfferBackground and reference checks prior to formal offer', 'Customer FirstWe always think about how our decisions will impact our clients; earning and keeping customer trust is our top priorityWe are not afraid of short-term pain for long-term customer benefit', 'Create an Environment for Exceptional PeopleWe foster intellectual curiosityWe identify top performers, mentor them, and empower them to achieveEvery hire and promotion will have a higher standard', 'Everyone is an Entrepreneur / OwnerNo team member is defined by their function or job title; no job is beneath anyoneWe do more with less; we are scrappy and inventiveWe think long-term', 'Relentlessly High StandardsWe don’t accept “that’s how it’s always been done”; we constantly innovate and question established routines to improve processesWe actively push to be proved wrong and welcome different ideas; the best idea winsWe don’t compromise on quality', 'Clarity & SpeedWhen in doubt, we act; we can always change courseWe focus on the key drivers of a process that will deliver the most results', 'Mandate to Dissent & CommitWe are confident in expressing our opinions; it is our obligation to express our disagreementOnce we decide, we enthusiastically move together in the agreed upon direction']",2020-09-24 13:53:16
Data Scientist,Jerneltechcorp,N/A,"Boston, MA 02199","['Highly qualified trainers, Hands-on professional training.', 'Online Interactive session.', 'On Job Support with dedicated support team.', 'Special Technical mock with our technical experts before every interview with specific to the Job Description.', 'Monday to Friday', 'bachelors: 1 year (Preferred)', 'Temporarily due to COVID-19']",2020-09-24 13:53:16
Data Engineer II,Blue Nile,3.1 out of 5,"Seattle, WA 98109","['Experienced with working in a hybrid environment utilizing both on-premises and cloud-based data stores and tools', 'Create and maintain optimal data pipeline architecture.', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Design efficient data structures and database schemas', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and GCP ‘big data’ technologies.', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Keep our data separated and secure across national boundaries through multiple data centers and GCP regions.', 'Create data tools for analytics and data scientist team members that assist them in building/providing actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Bachelor’s Degree in Information Technology or Computer Science or equivalent', '5-8 years experience working in a data engineer role', 'Advanced working SQL knowledge and experience working with relational databases and data warehouses, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Experience with Python scripting', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.', 'Understanding of data warehouse concepts, best practices and tools', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Medical, Dental, and Vision Healthcare Coverage', '401(k) with Company Match', 'Paid Vacation', 'Competitive Salaries', 'Transportation Allowance', 'Employee Discount', 'Employee Referral Bonus', 'Fitness Center Discount']",2020-09-24 13:53:16
Data Engineer II,Blue Nile,N/A,"Seattle, WA 98109","['Interviews on the spot', 'Wednesday, September 30, 20202:00 PM - 4:00 PM US/Pacific', ""Interviewing via webYou'll receive an email on how to connect."", '128 slots left', '', 'Bioinformatics EngineerFull-time', 'Tampa, Tampa, FL 33601 US', 'St. Petersburg, St. Petersburg, FL 33701 US', 'Clearwater, Clearwater, FL 33755 US', 'Interviews on the spot', 'Wednesday, September 30, 20202:00 PM - 4:00 PM US/Pacific', ""Interviewing via webYou'll receive an email on how to connect."", '128 slots left', 'United States+1', 'United Kingdom+44', '', 'Afghanistan (\u202bافغانستان\u202c\u200e)+93', 'Albania (Shqipëri)+355', 'Algeria (\u202bالجزائر\u202c\u200e)+213', 'American Samoa+1684', 'Andorra+376', 'Angola+244', 'Anguilla+1264', 'Antigua and Barbuda+1268', 'Argentina+54', 'Armenia (Հայաստան)+374', 'Aruba+297', 'Australia+61', 'Austria (Österreich)+43', 'Azerbaijan (Azərbaycan)+994', 'Bahamas+1242', 'Bahrain (\u202bالبحرين\u202c\u200e)+973', 'Bangladesh (বাংলাদেশ)+880', 'Barbados+1246', 'Belarus (Беларусь)+375', 'Belgium (België)+32', 'Belize+501', 'Benin (Bénin)+229', 'Bermuda+1441', 'Bhutan (འབྲུག)+975', 'Bolivia+591', 'Bosnia and Herzegovina (Босна и Херцеговина)+387', 'Botswana+267', 'Brazil (Brasil)+55', 'British Indian Ocean Territory+246', 'British Virgin Islands+1284', 'Brunei+673', 'Bulgaria (България)+359', 'Burkina Faso+226', 'Burundi (Uburundi)+257', 'Cambodia (កម្ពុជា)+855', 'Cameroon (Cameroun)+237', 'Canada+1', 'Cape Verde (Kabu Verdi)+238', 'Caribbean Netherlands+599', 'Cayman Islands+1345', 'Central African Republic (République centrafricaine)+236', 'Chad (Tchad)+235', 'Chile+56', 'China (中国)+86', 'Christmas Island+61', 'Cocos (Keeling) Islands+61', 'Colombia+57', 'Comoros (\u202bجزر القمر\u202c\u200e)+269', 'Congo (DRC) (Jamhuri ya Kidemokrasia ya Kongo)+243', 'Congo (Republic) (Congo-Brazzaville)+242', 'Cook Islands+682', 'Costa Rica+506', 'Côte d’Ivoire+225', 'Croatia (Hrvatska)+385', 'Cuba+53', 'Curaçao+599', 'Cyprus (Κύπρος)+357', 'Czech Republic (Česká republika)+420', 'Denmark (Danmark)+45', 'Djibouti+253', 'Dominica+1767', 'Dominican Republic (República Dominicana)+1', 'Ecuador+593', 'Egypt (\u202bمصر\u202c\u200e)+20', 'El Salvador+503', 'Equatorial Guinea (Guinea Ecuatorial)+240', 'Eritrea+291', 'Estonia (Eesti)+372', 'Ethiopia+251', 'Falkland Islands (Islas Malvinas)+500', 'Faroe Islands (Føroyar)+298', 'Fiji+679', 'Finland (Suomi)+358', 'France+33', 'French Guiana (Guyane française)+594', 'French Polynesia (Polynésie française)+689', 'Gabon+241', 'Gambia+220', 'Georgia (საქართველო)+995', 'Germany (Deutschland)+49', 'Ghana (Gaana)+233', 'Gibraltar+350', 'Greece (Ελλάδα)+30', 'Greenland (Kalaallit Nunaat)+299', 'Grenada+1473', 'Guadeloupe+590', 'Guam+1671', 'Guatemala+502', 'Guernsey+44', 'Guinea (Guinée)+224', 'Guinea-Bissau (Guiné Bissau)+245', 'Guyana+592', 'Haiti+509', 'Honduras+504', 'Hong Kong (香港)+852', 'Hungary (Magyarország)+36', 'Iceland (Ísland)+354', 'India (भारत)+91', 'Indonesia+62', 'Iran (\u202bایران\u202c\u200e)+98', 'Iraq (\u202bالعراق\u202c\u200e)+964', 'Ireland+353', 'Isle of Man+44', 'Israel (\u202bישראל\u202c\u200e)+972', 'Italy (Italia)+39', 'Jamaica+1', 'Japan (日本)+81', 'Jersey+44', 'Jordan (\u202bالأردن\u202c\u200e)+962', 'Kazakhstan (Казахстан)+7', 'Kenya+254', 'Kiribati+686', 'Kosovo+383', 'Kuwait (\u202bالكويت\u202c\u200e)+965', 'Kyrgyzstan (Кыргызстан)+996', 'Laos (ລາວ)+856', 'Latvia (Latvija)+371', 'Lebanon (\u202bلبنان\u202c\u200e)+961', 'Lesotho+266', 'Liberia+231', 'Libya (\u202bليبيا\u202c\u200e)+218', 'Liechtenstein+423', 'Lithuania (Lietuva)+370', 'Luxembourg+352', 'Macau (澳門)+853', 'Macedonia (FYROM) (Македонија)+389', 'Madagascar (Madagasikara)+261', 'Malawi+265', 'Malaysia+60', 'Maldives+960', 'Mali+223', 'Malta+356', 'Marshall Islands+692', 'Martinique+596', 'Mauritania (\u202bموريتانيا\u202c\u200e)+222', 'Mauritius (Moris)+230', 'Mayotte+262', 'Mexico (México)+52', 'Micronesia+691', 'Moldova (Republica Moldova)+373', 'Monaco+377', 'Mongolia (Монгол)+976', 'Montenegro (Crna Gora)+382', 'Montserrat+1664', 'Morocco (\u202bالمغرب\u202c\u200e)+212', 'Mozambique (Moçambique)+258', 'Myanmar (Burma) (မြန်မာ)+95', 'Namibia (Namibië)+264', 'Nauru+674', 'Nepal (नेपाल)+977', 'Netherlands (Nederland)+31', 'New Caledonia (Nouvelle-Calédonie)+687', 'New Zealand+64', 'Nicaragua+505', 'Niger (Nijar)+227', 'Nigeria+234', 'Niue+683', 'Norfolk Island+672', 'North Korea (조선 민주주의 인민 공화국)+850', 'Northern Mariana Islands+1670', 'Norway (Norge)+47', 'Oman (\u202bعُمان\u202c\u200e)+968', 'Pakistan (\u202bپاکستان\u202c\u200e)+92', 'Palau+680', 'Palestine (\u202bفلسطين\u202c\u200e)+970', 'Panama (Panamá)+507', 'Papua New Guinea+675', 'Paraguay+595', 'Peru (Perú)+51', 'Philippines+63', 'Poland (Polska)+48', 'Portugal+351', 'Puerto Rico+1', 'Qatar (\u202bقطر\u202c\u200e)+974', 'Réunion (La Réunion)+262', 'Romania (România)+40', 'Russia (Россия)+7', 'Rwanda+250', 'Saint Barthélemy+590', 'Saint Helena+290', 'Saint Kitts and Nevis+1869', 'Saint Lucia+1758', 'Saint Martin (Saint-Martin (partie française))+590', 'Saint Pierre and Miquelon (Saint-Pierre-et-Miquelon)+508', 'Saint Vincent and the Grenadines+1784', 'Samoa+685', 'San Marino+378', 'São Tomé and Príncipe (São Tomé e Príncipe)+239', 'Saudi Arabia (\u202bالمملكة العربية السعودية\u202c\u200e)+966', 'Senegal (Sénégal)+221', 'Serbia (Србија)+381', 'Seychelles+248', 'Sierra Leone+232', 'Singapore+65', 'Sint Maarten+1721', 'Slovakia (Slovensko)+421', 'Slovenia (Slovenija)+386', 'Solomon Islands+677', 'Somalia (Soomaaliya)+252', 'South Africa+27', 'South Korea (대한민국)+82', 'South Sudan (\u202bجنوب السودان\u202c\u200e)+211', 'Spain (España)+34', 'Sri Lanka (ශ්\u200dරී ලංකාව)+94', 'Sudan (\u202bالسودان\u202c\u200e)+249', 'Suriname+597', 'Svalbard and Jan Mayen+47', 'Swaziland+268', 'Sweden (Sverige)+46', 'Switzerland (Schweiz)+41', 'Syria (\u202bسوريا\u202c\u200e)+963', 'Taiwan (台灣)+886', 'Tajikistan+992', 'Tanzania+255', 'Thailand (ไทย)+66', 'Timor-Leste+670', 'Togo+228', 'Tokelau+690', 'Tonga+676', 'Trinidad and Tobago+1868', 'Tunisia (\u202bتونس\u202c\u200e)+216', 'Turkey (Türkiye)+90', 'Turkmenistan+993', 'Turks and Caicos Islands+1649', 'Tuvalu+688', 'U.S. Virgin Islands+1340', 'Uganda+256', 'Ukraine (Україна)+380', 'United Arab Emirates (\u202bالإمارات العربية المتحدة\u202c\u200e)+971', 'United Kingdom+44', 'United States+1', 'Uruguay+598', 'Uzbekistan (Oʻzbekiston)+998', 'Vanuatu+678', 'Vatican City (Città del Vaticano)+39', 'Venezuela+58', 'Vietnam (Việt Nam)+84', 'Wallis and Futuna (Wallis-et-Futuna)+681', 'Western Sahara (\u202bالصحراء الغربية\u202c\u200e)+212', 'Yemen (\u202bاليمن\u202c\u200e)+967', 'Zambia+260', 'Zimbabwe+263', 'Åland Islands+358']",2020-09-24 13:54:00
Data Engineer - Junior Level,USAA,3.9 out of 5,"Euless, TX 76039",[],2020-09-24 13:54:00
BI Developer - Jaspersoft,Options Clearing Corporation,3.6 out of 5,"Chicago, IL","['Job', 'Company', 'BS degree in Computer Science, similar technical field or equivalent experience', '5+ years of data-centric design, development and architecture experience with primary focus on BI, reporting and analytics solution development', '3+ years of experience architecting, designing, and developing enterprise wide dashboards and reporting solutions with TIBCO Jaspersoft', 'Experience in performance tuning of complex reports and large datasets for optimal performance and maintainability', 'Expertise in iReport Designer, creating Ad Hoc reports, Views and Domains', 'Experience with common Java application development related technologies – Servlets, XML, JSP, HTML, XHTML, DHTML, CSS, Java script a plus', 'Understand data models and their relationship to reporting', 'Snowflake, Redshift, Postgres MySQL or similar data handling experience', 'Experience with rolling out BI platform as a self-service tool for users', 'Automation of BI reports distribution in different formats (Excel, PDF)', 'Knowledge of best practices in data visualization design and development', 'Understand statistical constructs and how to use them in a program', 'Strong knowledge of SQL, data warehousing concepts, various data management systems', 'Ability to design, construct foundation and implement a long-term strategy for Enterprise Reporting platform', 'Ability to interact with business users to identify reporting and data analysis needs', 'Experience with Linux/ OSX command line and git', 'Scripting knowledge using Shell scripting, Python, or equivalent', 'Experience working with Cloud ecosystems (AWS, Azure, GCP)', 'Understanding of the software development life cycle (SDLC) in Waterfall, Lean, and Agile work environments', 'Ability to develop and follow defined processes in structured environment', 'Ability to interact with business users to identify reporting and data analysis needs', 'Master’s degree or equivalent experience', 'Hands-on experience with more than one reporting tools like Tableau, Power BI, Looker or something similar.TIBCO Jaspersoft', 'Experience with data wrangling, data virtualization, data curation tools a plus', 'Experience with DevOps process (exposure to GitHub, Jenkins or other CI/CD tools)', 'Knowledge and experience with Terraform and Ansible', 'Financial markets work experience, knowledge of trade and settlement lifecycle', 'BI tool certification as a plus', 'AWS certification as a plus']",2020-09-24 13:54:00
Database Engineer (Data Warehouse),American Advisors Group,3.6 out of 5,"Irvine, CA 92612","['Consolidate and optimize available data warehouse infrastructure utilizing SSIS/SSAS/Snowflake', 'Create stored procedures, SSIS packages, and using other methods to import/translate/manipulate data', 'Analyze potential data quality issues to determine the root cause, and creating effective solutions', 'Conceive analytics and business intelligence platform architecture for clients, including internal and third-party clients', 'Design and implement, monitoring, and tuning ETL Processes', 'Collaborate with business and technology stakeholders in ensuring data warehouse architecture development and utilization', 'Perform the design and extension of data marts, meta data, and data models', 'Ensure all data warehouse architecture codes are maintained in a version control system.', 'Design and implement ETL procedures for intake of data from both internal and outside sources; as well as ensure data is verified and quality is checked', 'Perform the design and extension of data marts, meta data, and data models', 'Develop, monitor and maintain data marts across the enterprise, while ensuring high levels of data availability.', 'Develops, maintains and optimizes all efforts related to Data Warehouse (SSIS, Stored Procedures, Views etc.)', 'Identifies and implements optimizations to both performance and accuracy of databases, as required and appropriate.', 'Develops and adheres to standards, processes and procedures to create, deploy and maintain databases.', 'Design, implement, and maintain new and existing database objects including tables, indexes, constraints, stored procedures, and user-defined functions in support of data conversion projects.', 'Data Warehousing and related tools: SSAS, SSIS, Snowflake, SQL Server and Informatica Cloud Integration Services', 'Azure and Cloud Certification is a plus', 'Database Modeling, Tuning, Security, Administration and Management', 'Structured thinker and effective communicator, comfortable interacting with constituents', 'EDUCATION / WORK EXPERIENCE', 'Possess Bachelor’s degree in information technology, Computer science, and engineering discipline', '10+ years or more experience performing data warehouse architecture development and management', 'Remarkable experience with technologies such as SQL Server, Snowflake as well as SSIS and stored procedures', 'Strong Experience with Informatica', 'Exceptional experience developing codes, testing for quality assurance, administering RDBMS, and monitoring of database', 'Strong working knowledge of application and T-SQL code and ability to demonstrate the ability to write functional requirements.', 'High proficiency in dimensional modeling techniques and their applications', 'Extensive hands on experience in data warehousing design, tuning and ETL/ELT process development Solid communication skills – both written and verbal', 'Ability to meet deadlines', 'Excellent communication skills (written and verbal)', 'Client-facing presence and excellent business acumen.', 'Attention to detail and solid organization skills']",2020-09-24 13:54:00
Application Engineer,"CaptiveAire, Inc.",3.3 out of 5,"Saint George, UT","['Job', 'Company', 'Medical, dental and vision insurance', 'Disability & life insurance based upon election of medical insurance', 'Paid holidays, vacation, and sick days based upon tenure', '401k with employer match', 'Flexible spending account (FSA)', 'Salary:', 'Competitive base salary with monthly bonus based on productivity and profits.', 'Supplemental Pay:', 'Experience:HVAC, 1 year (Required)engineering, 2 years (Preferred)', ""Education:Bachelor's (Required)"", 'Responsible for working with internal sales staff along with internal Engineering team to help design sustainable mechanical ventilation and control strategies for a wide variety of commercial applications.', 'Must have strong communication skills, with the ability to discuss complex mechanical equipment and controls with a wide range of audiences, ranging from highly technical engineers down to non-technical owners.', 'Must be able to review and analyze remote monitoring data.', 'Must be a self-starter, able to handle long term tasks with little guidance.', 'Must be able to train in Raleigh, NC.', 'BS in Engineering- mechanical or electrical preferred', '2-3 yrs experience preferably with an MEP firm', 'Knowledge of HVAC/Ventilation systems preferred, DOAS a plus', 'Strong understanding of electrical schematics, psychrometrics experience preferred', 'Must be able to manipulate data to derive trends and useful facts using Excel or similar software.', 'Medical, dental and vision insurance', 'Disability & life insurance based upon election of medical insurance', 'Paid holidays, vacation, and sick days based upon tenure', '401k with employer match', 'Flexible spending account (FSA)', 'Monday to Friday', 'Bonus pay', 'HVAC: 1 year (Required)', 'engineering: 2 years (Preferred)', ""Bachelor's (Required)"", 'One location', 'No: Not providing sponsorship for this job', 'www.captiveaire.com', 'No']",2020-09-24 13:54:00
Senior Data Engineer,Lendeavor,N/A,"Columbus, OH 43215","['Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Employee assistance program', 'Health insurance', 'Paid time off', 'Vision insurance', 'Experience:data engineering, 3 years (Required)', 'Write complex SQL queries against a variety of data sources and data lakes', 'Build ETL pipeline in AWS infrastructure using Python/Scala, AWS DMS, AWS Glue, and Redshift', 'Build data visualizations using Tableau to enable business to more easily explore data', 'Work cross-functionally with multiple departments to provide required analytics and insights needed to support the business needs', 'Become an expert on our data, and work closely with engineering to improve the data model to serve the needs of data analytics and data science', 'Develop models that explore our data using Python or R that yield additional insights into the business', 'Must love data!', 'Undergraduate degree in computer science, mathematics, economics, or other quantitative discipline', '3+ years of experience in a data engineering role', 'Expert-level SQL proficiencyExpert-level Tableau proficiency', 'Prior ETL experienceWorking knowledge of Python or Scala or R or similar and willingness to learn', 'Strong written and verbal communication skills', 'A team player who works well with others', 'Prior experience with Salesforce', 'Prior experience with Redshift', 'Experience at a fintech or technology-enabled lender', '401(k)', '401(k) matching', 'Dental insurance', 'Employee assistance program', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'data engineering: 3 years (Required)', 'www.lendeavor.com', 'Temporarily due to COVID-19']",2020-09-24 13:54:00
Data Engineer III,SurveyMonkey,4.1 out of 5,"Portland, OR 97209","['Design, architect and build data pipes to support existing data models', 'Data quality: build quality checks in the end to end data pipelines', 'Build new Data models (fact vs dimension). Write performant/idempotent transformations in Snowflake sql.', 'Build data pipeline using Python scripting (in a modular/loop context) Write well-tested, production ready code in Python and/or Snowflake SQL', 'Hands-on experience implementing ETL (or ELT) best practices', 'Translate business requirements, to technical specifications, form project scope, and deliver deployable code.', 'Write complex data engineering Snowflake - SQL jobs that perform sophisticated queries on the entirety of our datasets', '5+ years experience in data engineering in Snowflake or SQL server', 'Experience in scheduling, automating and deploying production data pipelines using Airflow/Luigi, etc', 'Experience with tools such as dbt, matallion or other similar technologies', 'Experience with transforming, developing data structures, metadata, dependency and data workflows to support an Analytics function', 'In depth knowledge of Datalakes, EDW concepts, data modeling (star, snowflake and galaxy schemas)', '3+ years writing code in any OOP capable language, ideally Python', 'Job scheduling and workload management tools (Airflow etc)', 'Experience with ETL tools (Talend, Informatica, Matillion, Fivetran, DBT etc.)']",2020-09-24 13:54:00
Data Engineer,COTA,3.9 out of 5,"Boston, MA","['Develop and maintain various data ETL processes and the data warehouse', 'Implement quality monitoring to report on the accuracy and relevancy of processed data', 'Perform specialized data investigations to support analytics and custom reporting scenarios', 'Understand the available architectures and technologies, assess available options for new features', 'As part of a team, own data-centric processes, develop alerts for errors and service issues, and respond to alerts', 'Participate in code reviews with a goal of understanding the overall data pipeline and ensuring data quality', ""Holds a Bachelor's degree in Computer Science, Information Systems, or related major, or equivalent work experience"", 'Able to write well-documented, reusable, and testable code', 'Ability to write complex SQL queries for ETL or reporting', 'Strong working knowledge of Postgres or other relational databases', 'Proficiency in distributed version control systems such as git', 'Proficiency working as part of an Agile development team', 'Ability to interact and communicate effectively with colleagues on requirements and set expectations accordingly', 'Ability to work independently as well as with a team']",2020-09-24 13:54:00
Big Data Engineer,Data Sys It inc,N/A,"Richmond, VA","['Pay:', '$60.00 - $70.00 per hour', 'Temporarily due to COVID-19']",2020-09-24 13:54:00
Data Engineer - PrecisionLender,Q2ebanking,2.8 out of 5,"Cary, NC","['2 + years of experience working in backend development', '2 + years proficiency in Python, C#, Golang, or Java', 'Strong communication and reasoning skills', 'Bachelor’s Degree, preferably in a technical field', 'Experience using source control, unit testing frameworks, agile/scrum product development', 'Experience taking responsibility for small features, from design to delivery', 'Empathy for the end user and a desire to measure your work by both customer value and technical quality', 'A bias for action tempered with thinking about the implications of the work you are doing', 'Enthusiasm for the field and professional development/improvement outside the day to day job', 'Microsoft Azure', 'Azure Batch, Databricks', 'Kubernetes', 'Apache Airflow, Data Factory', 'SQL Server, PostgreSQL', 'Django, PySpark, Pandas', 'Python, Golang', 'Bash, Powershell', 'CI/CD: Git, Azure DevOps, Docker']",2020-09-24 13:54:00
BUSINESS INTELLIGENCE AND DATA SCIENCE ENGINEER,Continuus Technologies,N/A,"Milwaukee, WI 53202",[],2020-09-24 13:54:00
Campground Data Engineer,The Dyrt,N/A,Oregon,"['Are great communicators — Effective communication is key to how we work. We value patience and empathy in our product planning, support, and day-to-day relations.', 'Work well both collaboratively and independently — We come together to pair on tricky problems and architecture, then dive deep on individual tasks.', 'Are ready to learn and share knowledge — Everyone comes to our company with their own set of skills and experiences. Cross-training, code review, mentorship, and curiosity all help us build better products.', 'Evolve and maintain campground data processing pipelines, combining public, private, and user-contributed data', 'Use natural language processing to extract relevant highlights and amenity information from campground review text', 'Coordinate manual data review and improvement projects using internal staff, community crowdsourcing, or mechanical turk', 'Make use of photo geotags and computer vision (via Amazon Rekognition / GCP Vision AI) to infer information about campground amenities.', 'Improve techniques for matching and deduplication between multiple data sources', 'Import public data on national and state parks, forests, and recreation areas to provide a better search experience', '4+ years of professional experience in data engineering, data science, software development, or related field', 'Strong backend programming skills in one or more languages', 'Experience creating and maintaining data ETL pipelines or other complex data import systems', 'Fluency with SQL and relational schema design', 'A friendly working relationship with CSVs', 'Advanced degree in math, statistics, computer science, information science, or related field', 'Experience working with geospatial datasets and GIS analysis', 'Experience applying machine learning techniques to real world problems', 'Familiarity with Elasticsearch']",2020-09-24 13:54:00
Senior Data Engineer,Beacon Biosignals,N/A,Massachusetts,"[""You've encountered the myriad idiosyncrasies inherent to storing, streaming, and analyzing large volumes of dense signal data (e.g. audio, video, domain-specific sensor data, etc.)."", '3NF is generally table stakes for any relational schema you design.', 'Migrations fill you with a sense of excitement rather than dread, because your data layer just leveled up. Besides, you automated away most minor migration-related pain points a long time ago anyway.', ""You don't have any particular need to work with a pure monolithic architecture or a pure microservices architecture. For you, characterizing service boundaries is an architectural design decision driven by resource profile, operational cost/benefit, and product need."", 'You have a tried-and-true workflow for debugging cross-service performance issues and selecting the layer of the stack that actually merits optimization.', ""You've witnessed some truly weird (un)structures in clinical data, but at the same time, you know from experience that designing The One True EMR is actually just falling down The One True Rabbit Hole."", 'You are as comfortable optimizing bare-metal custom GPU kernels as you are orchestrating robust networks of source-specific ingest pipelines.', 'You know from experience that a well-designed K8s cluster can provide an essential, unified ontology for resource/workflow orchestration, while a poorly designed K8s cluster can make developers reconsider getting into software development in the first place.', ""You're a reproducibility/containers nerd who turns data scientists into reproducibility/containers nerds."", 'You\'ve tried just about every ""git but for dense models/data"" solution out there.', ""You prefer open-source dependencies to closed-source dependencies because you have a compulsion to read the code that you're running."", 'You think Hasura is cool.']",2020-09-24 13:54:00
Data Migrations Engineer (Enterprise),Filevine,3 out of 5,Utah,"['Creating, maintaining, optimizing stored procedures, database and ETL processes', 'Working with all levels of development from analysis through implementation and support', 'Resolving any database issues regarding database restores, SSIS flat file processing, query tuning', 'Executing Dynamic SQL, table driven processing, and performance tuning of current and future database objects', 'Carrying out current DB and ETL activities', 'Coordinating with Customer Success and Filevine clients during the migration process', 'Updating JIRA cards, Filevine Projects, and all follow internal processes for client migrations', '3-4 years in general database development using SQL up through SQL 2014', 'Intermediate level of writing dynamic stored procedures, reading query plans, tuning indexes and troubleshooting performance bottlenecks', 'Previous BSA or similar experience helpful', 'Problem solving, analytical and communication abilities', 'Ability to multitask', 'Superb communication and organizational skills', 'Attention to detail', 'Ability to follow-up proactively and reliably', 'Experience working with remote clients and teams helpful']",2020-09-24 13:54:00
Data Analyst (Contract),Lumere,N/A,Remote,"['Connect and map key data sets utilized by Lumere’s solutions', 'Develop and monitor metrics related to data mapping and data quality', 'Collaborate with analyst and engineering teams to automate processes for consistent and efficient analysis', 'Maintain Standard 40 hour work week during regular business hours in a remote/ telecommute capacity', 'Professional experience analyzing and finding insights in large data sets', 'Proficient in SQL and MS Excel', 'Familiarity with healthcare data a plus', 'Detailed oriented with a demonstrated track record of accomplishing goals and meeting deadlines']",2020-09-24 13:54:00
Data Engineer,Claremont Mckenna College,4 out of 5,"Claremont, CA 91711","['Organize reliable and efficient operations of campus data integrations and tools used to implement the integrations', 'Lead configuration, management, and access control for SaaS deployments.', 'Conduct design architect reviews, gap analysis and assessment when required.', 'Develop Interfaces using middleware technologies.', 'Develop a comprehensive understanding of internal customer business needs, system functionality and business processes.', 'Plan, implement, and maintain tools for exchanging data and reporting.', 'Design configurations for management and access control for student data and other campus information systems.', 'Independently and proactively monitor critical services and take appropriate action to resolve issues.', 'Produce dashboards and reports that support operations across the College.', 'Create and maintain needed documentation.', 'Create and maintain optimal data pipeline architecture.', 'Assemble data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes and optimizing data delivery, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using query languages and cloud technologies.', 'Build analytics tools that utilize the data pipeline to provide actionable insights into the colleges operations.', 'Take and follow directions.', 'Work cooperatively with others.', 'Receive and respond appropriately to constructive criticism.', 'Display a positive attitude.', 'Balance multiple tasks and priorities.', 'Performs other essential duties and tasks specific to the position.', 'Experience working with relational databases, query authoring as well as working familiarity with a variety of databases.', 'Experience building and optimizing data pipelines, architectures and/or data sets.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Experience building processes supporting data transformation, data structures, and metadata.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Technical understanding and experience with single sign-on and multi-factor authentication.', 'Background knowledge of TCP/IP, DNS, HTTP, SQL, Active Directory, Linux, Bash.', 'Dell Boomi Developer or Administrator Certifications', 'Workday Developer or Report Writing Certifications', 'Advanced working knowledge of a query language (SQL).', 'Strong problem-solving and critical thinking skills to develop and test hypotheses.', 'Desire and willingness to keep up with constantly changing cloud offerings by reading widely, attending conferences and networking with other IT professionals.', 'Ability to communicate technical concepts in simple terms.', 'Demonstrate effective, accurate and clear communication with excellent/strong verbal, written, interpersonal, reading, phone, and customer service skills. Follow all written and verbal instructions, asking questions as needed for clarification of projects/tasks/duties/assignments.', 'Prioritize and perform multiple projects/tasks, meet deadlines/timelines, respond to others in a timely manner, and work both independently and as a collaborative member of the College with a high standard of integrity and ethics, in support of the College’s strategic vision and the division’s/department’s annual goals.']",2020-09-24 13:54:00
"Field Engineer, Global Data Center Connectivity",Facebook,4.2 out of 5,"Gallatin, TN","['Service Delivery - Assure delivery and maintenance of all structured cabling and connectivity, on time, within budget, and to industry leading standards of quality and reliability.', 'Vendor Field Management – Develop and scale our partners responsible for all run ops, construction, and data center improvement activities on site. Work with key partner leaders to monitor the progress, and the quality of installation within our data centers.', 'Quality Assurance - Perform ongoing quality audits to assure vendor work meets DCC quality standards prior to turn-over and throughout the lifecycle of the data center. Review, comprehend, and implement work as shown in the contract documents. Able to review drawings and report back discrepancies (Proactive Quality Control).', 'Technical Subject Matter Expert (SME) – Serve as technical lead for industry and Facebook structured cabling standards, product selection, design, and installation methods in the field. Partner with global design and engineer team to support design reviews, BOM reviews, and as-built drawing validations.', 'Logistics – Coordinate with design teams as a material SME for all materials questions and estimates.', 'Documentation - Assure site as-built design documentation is complete and up-to-date.', 'Operations - Oversight of the Run Operations team for detailed turn-up schedule, moves, adds and changes and setting project priorities. Assure rapid responses to high priority builds and break-fixes.', 'Strategic Planning – Participate in project pipeline planning and discussions related to the data center.', 'Process - Support development of best practices and initiatives, coordinating SOPs/SIPs with vendors, and participating in global and regional standards. Assist in developing or identifying network cable/rack/cabinet installation processes and standards.', 'Communications - Assure crisp oversight and clear communications across an array of platforms with cross functional partners and vendors. Proactively communicate progress and project risks and initiatives to key stakeholders.', 'Safety – Ensure vendor is following site, OSHA and EHS safety standards.', '6+ years direct experience in fiber optic and structured cabling installation.', 'Experience overseeing vendors work and suppliers towards the same project goals.', 'Experience analyzing, understanding, and interpreting data.', 'Interpersonal experience, and experience connecting with and influencing stakeholders with different objectives.', 'Experience in a mission critical environment requiring coordination across multi-disciplines for delivering a goal.', 'Experience with inside plant cabling (ISP).']",2020-09-24 13:54:43
Data Engineer,Kognetics,N/A,"Gahanna, OH","['Pythondevelopers who can confidently work unassisted and deliver high qualitysolutions:', 'Strongprogramming experience in- Python', 'Strongbackground in data structures, algorithm complexities and object-orientedprogramming in- Python, with knowledge of at least one- Python- web framework(Django).', 'Stronghands-on experience as an individual contributor in Conceptualize.', 'Designand Develop new features in the product Experience with NoSQL technologies.', 'Handson experience with Cassandra and Redis is good to have.', 'Passion,commitment, resourcefulness, and a drive to continue learning are essentialprerequisites. For this role, we’re also looking for someone who meets thefollowing criteria:', ""B. Tech/PhD/ Master's Degree inStatistics, Mathematics, Computer Science, or equivalent; 5+ years of datascience mining experience;""]",2020-09-24 13:54:43
"Software Engineer, Data Infrastructure",Asana,3.6 out of 5,"San Francisco, CA 94103","['Design, build, and operate streaming and batch services used by all of Asana', 'Collaborate on scaling the core data pipeline and scaling up data processing to meet the rapid data growth at Asana', 'Design and implement tooling and automation for clustering, scaling, monitoring and alerting', 'Participate in the on-call rotation, investigate and resolve production problems', 'Like to leave code better than you found it', 'Are looking for an environment where you and your teammates empower one another to become the best versions of yourselves', 'A strong interest in building scalable and performant distributed systems with a focus on eliminating risks', 'Experience working in large, high-quality codebases', 'Experience in developing ETL jobs using a distributed processing framework', 'Experience with our tech stack - Scala, Python, Spark, Airflow, Kubernetes, AWS-based infrastructure', 'Rethinking the org chart: Areas of Responsibility (AoRs)', ""Distributed responsibility: An engineering manager's perspective"", 'The Pyramid of Clarity']",2020-09-24 13:54:43
"Software Engineer, Customer Data Portal Frontend",Disney Streaming Services,3.3 out of 5,"New York, NY","['Developer on frontend web applications', 'Coached by other developers on best practices & quality thru code review & instruction']",2020-09-24 13:54:43
Data Link Engineer,COLSA,3.9 out of 5,"Shalimar, FL 32579","['Perform as a member of the Air Force’s premiere tactical data link developmental test team', 'Plan and conduct initial and regression developmental testing on various platforms integrating equipment and applications processing Link 16, SADL, VMF, Harris SA, CoT, MADL and IFDL data', 'Author, review and edit program documentation, including test plans, concepts of operations, test cards, data-analysis plans and formal reports', 'Design test architectures for systems undergoing testing, to include test assets, support assets, lab requirements and data storage/retrieval schemes', 'Apply engineering principles to all aspects of support to systems undergoing testing and the analysis of data collected during test events', 'Develop and present briefings to test community personnel and program office leadership on developmental testing/reporting activities associated with systems under test', 'Meet stringent guidelines as defined by program-office leadership when producing test-related artifacts', 'Identify areas for improvement and recommend technical solutions required to meet assigned tasks', 'Conduct technical research, testing and reporting of emerging technological systems affecting the performance of all data link test programs', 'Travel to temporary duty locations to perform or conduct test procedures, data management, data reduction, data analysis, configuration management, hardware setup and formal reporting; also may be required to attend program-level meetings to ensure requirements and documentation are coordinated according to system deployment guidelines', 'Relevant engineering and/or technical experience in areas related to tactical data links, data link radios, radio frequency waves and propagation, and computer networking concepts', 'Current and Active Secret Security clearance', ""Capable of traveling to contractors' facilities, test sites, and other locations, both CONUS and OCONUS"", 'Analytical skills and basic problem solving skills in the area of Engineering', 'Good organization, decision making, and verbal and written communication skills', 'Excellent self-initiative and self-motivation', 'Proficiency in MS Office products to include Word, Excel and PowerPoint', 'Relevant technical experience in the areas of software system and hardware integration testing', 'An understanding of developmental test and evaluation processes, specifically - acquisition program development and detailed knowledge of Air Force Command and Control (C2) test methodologies including AFI 99-103']",2020-09-24 13:54:43
Supplier Development Engineer I,Caterpillar,3.9 out of 5,"Mossville, IL 61552","['Job', 'Company', 'Work with suppliers to assure proper process control standards are in place and continuously monitor key manufacturing processes for improvement opportunities', 'Ensure suppliers have adequate people, training, tooling, fixturing, and equipment', 'Monitor suppliers’ adherence to Process Change Notification on a timely and cost-effective basis as well as to develop the supply base to fulfill the total requirements from Caterpillar System implementation', 'Support Product Sourcing Strategy and provide technical leadership in new supplier selection', 'Evaluate and develop new supplier’s technological capability to meet requirements for Caterpillar Inc. Supplier Quality Excellence Program', 'Develop and maintain thorough knowledge of technological developments and trends for guidance of commodity teams in advancements of design, quality, and manufacturing', 'Provide resolution and ensure implementation of robust solutions for quality problems associated with the purchased materials, logistics, and engineering issues', 'Support and participate in 6 Sigma initiatives with facilities, category teams, and suppliers', 'Bachelor’s degree preferably in engineering, manufacturing, or quality', 'Minimum of 2 years of experience in manufacturing, quality, or working with suppliers', 'An engineering or manufacturing background plus familiarity with manufacturing processes used to produce components and assemblies for Caterpillar Products', 'Solid ability to use and demonstrate statistical and problem-solving tools', 'High proficiency and familiarity with Excel, reviewing large amounts of data and reporting metrics to leaders', 'Knowledge of the tools and techniques of 6 Sigma methodology', 'Good human relation/communication skills as well as possess the potential for leadership is required to develop a cooperative working relationship with others inside and outside of Caterpillar', 'Quality engineering certification']",2020-09-24 13:54:43
Data Engineer,Modcloth,3.1 out of 5,"Los Angeles, CA 90021","['Collaborating across an agile team to continuously design, iterate, and develop a data lake', 'Extracting, transforming, and loading data into internal databases', 'Optimizing our new and existing data pipelines for speed and reliability', 'Utilizing customer transaction + behavior data to build out data warehouse / reports for marketing / planning purposes', 'Deploying ETL pipelines for new products and product improvements', 'Documenting and managing multiple repositories of code', '3-5 years of experience using Microsoft SSIS server', 'Hands-on experience in data pipelining, ETLs, Stored Procedures, Views, Windowing Functions and Tableau Dashboards', 'Extensive experience with PL-SQL and optimizing queries (indexes/statistics) for databases like Microsoft SQL Server, Azure Synapse (SQL DW), PostgreSQL, etc.', '3-5 years of software engineering experience, preferably working with multiple data sets using APIs, JSON, CSVs', 'Working proficiency with C-Sharp and .Net Framework', 'Understanding of best practices and common coding patterns', 'Experience shipping features and fixing bugs in an agile environment', 'Experience with unit testing, and test/behavior-driven development', 'Understanding of Git and collaboration software', 'Prior experience with Python, Jenkins, Google BigQuery, GCP a plus', 'Proactive leader, problem solver — you are constantly looking for ways to work smarter, delivering new efficiencies anywhere an improvement can be made', 'Perpetual learner — you know what you don’t know and aren’t afraid to ask questions to fill in the gaps', 'Self-starter — you thrive working in small, collaborative teams with the opportunity to continue building your skillet', 'Strategic adapter — you’re able to pivot quickly when priorities change and still hit the ground running']",2020-09-24 13:54:43
Big Data/Hadoop Developer,ConglomerateIT,N/A,"McLean, VA","['Monday to Friday', 'Temporarily due to COVID-19']",2020-09-24 13:54:43
Senior Data Engineer (ETL & Azure cloud migration),360 Technology LLC,N/A,"Los Angeles, CA 90012","['Experience taking a lead role in architecting, designing, and setting standards for data-models', 'Experience gathering business requirements and understanding and translating business needs into data models, creating logical and physical data models using best practices to ensure high data quality and reduced redundancy of Product Information.', 'Cosmos DB', 'Postgres SQL', 'Cloud', '8 hour shift', 'Monday to Friday', 'ETL & Postgres SQL: 5 years (Preferred)', 'Azure cloud: 3 years (Preferred)', 'Temporarily due to COVID-19']",2020-09-24 13:54:43
Data Conversion Engineer,CentralSquare Technologies,2.8 out of 5,"Sioux Falls, SD 57108","['Work collaboratively with customer agencies undergoing CentralSquare software implementation to obtain data from their legacy system, understand what it means and how it is used, and determine how best to translate it into their CentralSquare system', 'Analyze legacy data to estimate / benchmark project scope and length', 'Develop scripts to load legacy data into conversion tools and convert data into CentralSquare software', 'Develop and maintain an understanding of CentralSquare software including functionality and database schema; use this knowledge to make informed decisions regarding data mapping and to review data within target system', 'Communicate with customer agencies throughout implementation projects to clarify questions that arise regarding data mapping, demonstrate converted data in target system, understand any modifications needed, and verify results of modifications', 'Manipulate and load data such as code tables from secondary additional sources to assist in configuration of agencies’ CentralSquare systems', 'Assist in running final data conversion at time of system go-live', 'Communicate proactively with supervisor and project manager regarding project progress and any project risks or issues that arise', 'Create and maintain documentation for data conversion processes; seek out process improvements', 'Experience with SQL and at least one RDBMS', 'Knowledge of ETL (Extract, Transform, and Load) processes', 'Ability to learn new applications and processes quickly', 'Passion for technology; eager to learn new tools and technologies', 'Strong customer-facing skills and personal interaction/interpersonal skills', 'Ability to adapt quickly to changing business and customer needs, maintaining a high degree of flexibility', 'Self-motivated; able to work independently']",2020-09-24 13:54:43
Data Engineer II (L5) - Business Data Technologies,Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['Job', 'Company', 'A desire to work in a collaborative, intellectually curious environment.', 'Degree in Computer Science, Engineering, Mathematics, or a related field and 4-5+ years industry experience', 'Must have one year of experience in the following skill(s):', 'Developing and operating large-scale data structures for business intelligence analytics using: ETL/ELT processes; OLAP technologies; data modeling; SQL;', 'Experience with at least one relational database technology such as Redshift, Oracle, MySQL or MS SQL', 'Experience with at least one massively parallel processing data technology such as Redshift, Teradata, Netezza, Spark or Hadoop based big data solution', 'Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.', 'Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)', 'Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets', 'Experience building data products incrementally and integrating and managing datasets from multiple sources', 'Query performance tuning skills using Unix profiling tools and SQL', 'Experience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies', 'Experience providing technical leadership and mentor other engineers for the best practices on the data engineering space', 'Linux/UNIX including to process large data sets.', 'Experience with AWS']",2020-09-24 13:54:43
Data Engineer,Alder Holdings LLC,N/A,"Orem, UT 84057","['Processing and cleansing data from a variety of sources to transform collected data into an accessible and curated state for Analysts and Data Scientists', 'Migrating self-serve data pipeline to centrally managed ETL pipelines', 'Advanced SQL development and performance tuning', 'Some exposure to Domo helpful', 'Work with business data stewards & analytics team to research and identify data quality issues to be resolved in the curation process', 'Design and build master dimensions to support analytic data requirements', 'Replacing legacy data structures with new datasets sourced from streaming data feeds from the core product and other operational systems', 'Design, build and support pipelines to deliver business critical datasets', 'Resolve complex data design issues & provide optimal solutions that meet business requirements and benefit system performance', 'Management of job scheduling', 'Dependency management mapping and support', 'Documentation of issue resolution procedures', 'Design and management of data access controls mapped to curated datasets', 'Normalization', 'Master data management patterns', 'Modeling trade-offs impacting data management & processing/query performance', 'Knowledge of distributed systems as it pertains to data storage, data processing and querying', 'Extensive experience in ETL and DB performance tuning', 'Hands on experience with a scripting language (Python, bash, etc.)', 'Metadata management: Data Governance, Data Quality, MDM, Lineage, Data Catalog etc.', 'Data management, data processing and curation: Postgres, Hadoop, Hive, Impala, Presto, Spark, Glue, etc.', 'Some exposure to Hadoop, Spark, Kafka, Impala, or other big data technologies helpful', '5+ years of progressive experience data engineering and data warehousing', 'Experience with a variety of data management platforms', 'Experience with high-performance query engines', 'Strong capability to manipulate and analyze complex, high-volume data from a variety of sources', 'Effective communication skills with technical team members as well as business partners. Able to distill complex ideas into straightforward language', 'Ability to problem-solve independently and prioritize work based on the anticipated business value']",2020-09-24 13:54:43
Data Engineer,Hinge,4.8 out of 5,"New York, NY","['Work with our Engineering teams to ensure data is flowing accurately through data creation to our presentation layers.', 'Write new and innovative ETL processes.', 'Improve our Data Engineering stack through containerization, data modeling, developing our ETL pipelines, and more.', 'Work with stakeholders and translate their needs and expectations into action items and deliverables.', 'Continue to learn more about the Data Engineering discipline, utilize that knowledge in your deliverables, and identify opportunities to enhance our pipelines.', 'Contribute meaningful insights and feedback to our team processes.', 'Proficient in Python, SQL, shell scripting, and databases.', '+3 years of professional/industry experience.', 'Experience delivering data products from conception to delivery and with the infrastructure that supports their underlying processes.', 'Good communication skills (written/verbal).', 'Experience modeling data sets for different types of sources and business processes.', 'Passionate about designing elegant ETL processes.', 'Authenticity: Share your genuine thoughts and opinions directly.', 'Courage: Invite and deeply consider challenges and criticism.', 'Empathy: Be empathetic, communitarian and trustworthy.']",2020-09-24 13:54:43
Data Presentation Engineer,Spreetail,2.7 out of 5,"Lincoln, NE","['Actively give and receive feedback to drive team success.', 'Maintain a positive attitude, so your teammates and business stakeholders look forward to working with you.', 'Have a high attention to detail and focus on the quality of the data and your applications.', 'Seek feedback on current tools and assist in building the data product road map.', '2+ years of experience building business dashboards and reports.', 'Experienced building Mobile Reports.', 'Experienced building Power BI Apps.', '2+ years of experience with data presentation tools (Power BI, Tableau, QlikView, etc.)', 'Knowledgeable about SQL.', 'Quick to learn and adapt to new technologies.', 'Able to analyze and tell a story with data.', 'Experienced with data modeling and data warehousing.', 'Unit Appreciation Rights: Up to 5% of yearly salary; based upon company and team', 'Company Bonus: Up to 5% of yearly salary; based upon company and team performance', 'Health Insurance: Spreetail will pay for your full premium and half for spouse/family', 'Dental Insurance: Spreetail will pay half of the dental coverage for you/spouse/family', '401k: Spreetail partners with ForUsAll to provide the opportunity to invest in your future with pre-tax and post-tax plan options', 'Paid Time Off: untracked time off', 'Wedding Week: Enjoy an additional 5 paid days off before or after your wedding', 'Gym Membership: Spreetail will pay for half of your membership to a specified gym', 'Creating a Home: After 2 years of employment, Spreetail will give you $5,000 when you', 'Year 3 Vacation: After 3 years of employment, you will be eligible for an all-inclusive', 'Year 5 Sabbatical: After 5 years of employment, you will be eligible for a 2-week paid', 'Donation Matching: Spreetail will match your donation dollar for dollar, up to $250 a', 'Community Involvement: Spreetail encourages employees to take time off for volunteer', 'Product Discount: Enjoy a 20% discount on the products we sell']",2020-09-24 13:54:43
Data Scientist - Fraud Analytics,DiDi Labs,N/A,"Mountain View, CA 94043","['Acute business sense, deeply understand the business model, transaction flow, and payment system. Discovery the potential risk point, work closely with product manager, engineer, and operations to design data pipeline and risk strategy framework.', 'Lay the groundwork – hypothesize as an individual researcher and in collaboration with other team members on how to solve fraud problems. Perform data preparation activities, such as collecting, cleaning, and organizing.', 'Produce clear, understandable visualizations, dashboard and reports to share with Senior Management and business partners, provide the insightful story from the data perspective to risk policy owners.', 'Establish a holistic risk modeling framework for addressing the risk of fraud and financial abuse across riders, drivers, merchants, and affiliates.', 'Deep dive into data through systematic and ad hoc analyses and build machine learning models to score the identity, behavior, reputation and other risk characteristics of the customers.', 'Communicate Results on a regular basis to stakeholders around the world, including executive leadership.', 'Master degree (Ph.D. is a plus) in Statistics, Mathematics, Computer Science, Engineering or a similar Quantitative field, or equivalent practical experience.', '3+ years of related industry experience.', 'Strong modeling skillset, hands on mastery of data manipulation and experience with data analytics tools (SQL, R, Python, Hive, Spark, and other data analysis packages).', 'Experience working in payments fraud or credit risk modeling is desired but not mandatory.', 'Knowledge of the latest ML techniques like decision tree, random forest is a plus, but not a requirement.', 'Creative problem solving and critical thinking skills.']",2020-09-24 13:54:43
Data Engineer,Trimble,3.7 out of 5,"Mayfield Heights, OH","['Translate business requirements into the design of the overall enterprise data architecture, data governance strategies and data quality standards', 'In-depth knowledge of relational database concepts – including design, implementation, programming, day-to-day administration, and support best practices', 'Designs and implements an enterprise data warehouse infrastructure including data marts, data models/dimensions and metadata repository', 'Promotes the functionality, scalability, performance, security, and integration requirements necessary to an enterprise business intelligence platform', 'Develops documents and maintains a formal description of the data and data structures.', 'Develops entity and attribute descriptions and definitions for the models and ensures that conflicts in descriptions and definitions are resolved', 'Support implemented BI solutions by: monitoring and tuning queries and data loads, addressing user questions concerning data integrity, monitoring performance and communicating functional and technical issues', 'Using strong analytical skills to solve and model complex business requirements', 'Hands on relational and multi-dimensional data modeling, including multiple source systems from databases and flat files, metadata repository development and the use of standard data modeling tools', 'Supporting data warehouse documentation, installation, implementation, training and support activities', 'Displaying a sound understanding of BI Best Practices/Methodologies, relational structures, dimensional data modeling, structured query language (SQL) skills, data warehouse and reporting techniques, including data visualization concepts', 'Collaborating on a team with infrastructure, BI report development and business analyst resources, and clearly communicate solutions to both technical and non-technical team members', 'Hands-on experience of ETL development for an Enterprise Data Warehouse (EDW) via SQL Server Integration Services (SSIS) or a similar Data Integration toolset', 'Hands-on experience of BI dashboard/report development, using an enterprise BI tool (Cognos, Tableau, or similar)', 'Experience with Snowflake database systems', ""Bachelor's degree in Engineering, MIS, Computer Science, Mathematics, Statistics or related field OR an equivalent combination of education, experience, knowledge, skills, abilities"", 'Proficient with Kimball multi-dimensional modeling techniques, designing and developing complex information architectures and assessing and evaluating alternative solutions', 'Experience in planning, developing, and supporting ETL systems to achieve data transformation goals including the design and architecture of operational data stores to support enterprise data integration goals', 'Experience with Business Intelligence tools and needs', 'Experience as a data architect involved in implementing company wide data policies, governance procedures, creating metadata repositories and working with data stewards to improve data quality', 'Strong SQL Server experience required, including SQL Server management; T-SQL and performance tuning techniques', 'Experience with the Microsoft BI Stack (SSMS, SSIS, SSAS and SSRS) helpful. Some experience in .NET (or equivalent) programming, C# preferred.', 'Proficient with Microsoft Office Suite', 'Ability to communicate effectively, orally and in writing', 'Ability to use sound judgment', 'Ability to manage time and workload effectively which includes planning, organizing, and prioritizing with attention to details', 'Excellent organizational and analytical skills']",2020-09-24 13:55:23
Sr. Data Engineer,GoodRx,5 out of 5,"Santa Monica, CA 90401","['Manage data warehouse plans for product and marketing teams', 'Work closely with product managers to understand the data needs of product and marketing', 'Act as internal expert in each of the data sources so that you can own overall data quality', 'Design, build and deploy new data models and ETL pipelines into production', 'Experience contributing to full lifecycle deployments with a focus on testing and quality', 'Define and manage overall schedule and availability for all data sets', 'Work closely with other engineers to enhance infrastructure, improve reliability and efficiency', 'Make smart engineering and product decisions based on data analysis and collaboration', 'Act as in house data expert and make recommendations regarding standards for code quality and timeliness', 'Architectural understanding of Hadoop (HDFS/MapReduce) distributed computing system.', 'Good knowledge of Apache Hive, Pig, and Spark etc.', 'Experience in architecting cloud-based data infrastructure solutions.', 'Degree in Computer Science or a related field or a minimum of 3 year’s working as a Data Engineer', '2+ years professional experience in the data warehouse space', 'Expert Proficiency with Python and AWS Services (e.g. Redshift, S3)', '2+ years’ experience in custom ETL design, implementation and maintenance', 'In depth knowledge of how to write and optimize SQL statements.', 'Deep familiarity with distributed processing (Map Reduce, MPP, etc.)', '2+ years’ experience with schema design (logical and physical)', 'Ability to quickly learn complex domains', 'Innately curious and organized with the drive to analyze data to identify deliverables, anomalies and gaps and propose solutions to address these findings', 'Ability to manage and communicate data warehouse plans', 'Thrives in fast-paced startup environment']",2020-09-24 13:55:23
New Grads 2020,Fortinet,3.8 out of 5,"Sunnyvale, CA 94086","['Software Development Engineers', 'Embedded Software Engineers', 'Web Developers', 'Software Dev QA Engineers', 'DevOps Engineers', 'Hardware Engineers', '...and more']",2020-09-24 13:55:23
Data Engineer,Eleks,N/A,"Chicago, IL","['At least 5+ years of experience in Data Engineering', 'Solid Experience with MySQL, Gemfire, IBM DB2, CosmosDB,', 'Good to know CI/CD, Jenkins, Concourse, Java', 'Experience in building ETLs', 'Understanding of TDD and extreme programming', 'Knowledge of cloud-based technologies', 'Pivotal tech stack knowledge', 'Develop solutions and algorithms according to technical specifications or other requirements documentation; use standard algorithms in the applicable cases', 'Write program code according to the defined application architecture', 'Structure and format the source code, comment and mark up the code, as well as name variables, functions, classes, data structures, and files according to the company conventions and industry best practices', 'Modify existing code and verify its functioning. Analyze code compliance with readability and performance standards', 'Use version control systems to track code optimization progress and to merge or split program code entities. Commit changes according to version control rules', 'Perform analysis, verification, and debugging of the software code at the level of application units', 'Detect defects, apply debugging methods and techniques, correctly interpret bug reports, as well as apply modern compilers, debuggers, and program code optimizers', 'Able to develop procedures for testing code availability, collecting diagnostic data, generating test data sets with necessary characteristics, identifying required software characteristics etc.', 'Reproduce defects logged in an issue tracking system, identify defect causes, and then modify code to eliminate defects', 'Able to develop and document program interfaces, software module and component assembling procedures, software deployment and update procedures as well as data migration and transformation (conversion) procedures', 'Estimate and set up task completion terms independently', 'Evaluate and coordinate task deadlines with Technical Leader or Project Manager', 'May have valid competence-related certifications', 'Participate, both as a trainer or a trainee, in various learning programs outside the major project', 'Close cooperation with a customer', 'Challenging tasks', 'Competence development', 'Ability to influence project technologies', 'Team of professionals', 'Dynamic environment with low level of bureaucracy']",2020-09-24 13:55:23
Data Analytics Engineer - TechOps (Remote),CrowdStrike,2.8 out of 5,United States,"['Data analysis and basic statistics using one or more of the following – Excel, Python, R, SQL.', 'Implement and apply methods and processes to help report, analyze, and manage costs associated with multi-cloud infrastructures.', 'Monitor and generate reports associated with changes in data center and public cloud resource use.', 'Assist in growth forecasting and capacity planning', 'Bachelor’s degree in Computer Science, Management Information Systems, or work-related discipline/field from an accredited college or university. Equivalent field experience considered.', 'Proficiency in Linux, SQL queries, APIs, and at least one scripting language (Python, R, Php, JavaScript).', 'Knowledge of Amazon Web Services (AWS) cloud computing infrastructure', 'Strong ability for communicating technical detail into succinct and fact-based business terminology, both verbally and in writing.', 'Strong ability for using independent judgment to make sound, justifiable decisions and take action to solve problems.', 'Strong leadership skills with demonstrated ability to prioritize and execute in a methodical and disciplined manner.', 'Strong ability to plan, organize and prioritize work independently and meet deadlines.', 'Strong ability to work in a collaborative, team environment', 'Familiarity with how Data Center hardware is priced, how OpEx is priced, and especially how Cloud Service Providers price and report their charges', 'Knowledge of Google Cloud Platform(GCP), and Microsoft', 'Knowledge of Tableau and other big data analysis and visualization tools', 'Market leader in compensation and equity awards', 'Competitive vacation policy', 'Comprehensive health benefits + 401k plan', 'Paid parental leave, including adoption', 'Flexible work environment', 'Wellness programs', 'Stocked fridges, coffee, soda, and lots of treats']",2020-09-24 13:55:23
Data Engineer,Tesla,3.5 out of 5,"Fremont, CA",[],2020-09-24 13:55:23
"Data Engineer, Growth",Pinterest,4.2 out of 5,"San Francisco, CA 94103","['Develop scalable and reliable workflows that efficiently process big data', 'Build marketing automation that manages media spend across dozens of advertising strategies', 'Partner with data scientists on machine learning and statistical models to predict user revenue and retention', '3+ years of data engineering experience, preferably in Growth teams', 'Strong experience in writing reliable, low-maintenance, and powerful code that may be used by many other engineers', 'Desire to understand the marketing/advertising space and learn metrics-driven approach to software development', 'Interest in working closely with marketers, designers, product managers, data scientists, and other partners to bring business vision & growth alive']",2020-09-24 13:55:23
Data Scientist,Oracle,3.8 out of 5,United States,"['As a specialist, provide technical proof points or drive proof of value to the customer with Oracle Cloud Solutions.', 'Maintain mastery of the Oracle portfolio and intimate knowledge of industry trends, multidiscipline design patterns, development/deployment methodologies, and competitive cloud offerings while evangelizing solutions.', 'Be a trusted advisor to the customers. Develop and present business cases, industry trends, competitive differentiators, in alignment with the go-to-market product and solution strategy.', 'Achieve desired results through planning, risk management, stakeholder management, conflict resolution, governance, team management, and ownership of the cloud adoption lifecycle', 'Be agile and maintain a relentless sense of urgency and a realistic view of time (urgent patience) throughout an extended customer engagement.', 'Inspire confidence and quickly establish connection, credibility, trust, and influence with customer executives to developer', 'Exercise creativity, independent judgment, and business acumen in selecting methods and techniques to design non-routine and elegant business solutions utilizing Oracle products and technology to meet customer needs', 'Influence customer strategy, architecture, roadmap, and migration planning workshops spanning business, applications, information, and technology domains', 'Maintain relevant expert-level competency across the data ecosystem – Big Data, Data Lakes, Advanced Analytics, and Data Science.', '10+ years of total experience in Consulting or Sales/Solution Engineering or with product development.', '3-5 years of proven domain knowledge of Data Science and big data ecosystems. Domain knowledge includes Python, R, Scala, Spark, Kafka, Hadoop, AI/ML, NoSQL, Cloud data architecture, etc.', 'Demonstrated ability to own the customer relationship and drive their success in focus areas such as Data Science, Data Lakes & Data Warehouses enablement.', 'Experience enhancing data collection procedures to include information that is relevant for building analytic systems. Processing, cleansing, and verifying the integrity of data used for analysis.', 'Experience in ad-hoc analysis and presenting results in a clear manner. Creating automated anomaly detection systems and tracking its performance', 'Good applied statistics skills, such as distributions, statistical testing, regression, etc.', 'Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.', 'Experience with common data science toolkits, such as Python, R, Scala, NumPy, MatLab, etc. Excellence in at least one of these is highly desirable', 'Experience with data visualization tools such as Oracle Analytics Cloud, Qlik, Tableau, D3.js, GGplot2, etc.', 'Proven expertise in creating detailed technical architectures and product solutions for specified needs. Solution sizing/costing and configuration.', 'Expertise in conducting PoCs tailored to customers’ needs and proof points.', 'Expertise in delivering Customer Hands-on Workshops', 'Ability to provide detailed product presentations to educate customers', 'Ability to provide thought leadership on big data solutions that benefit customers through the use of Oracle Cloud Services.', 'Ability to interact with all customer roles such as CIO, CTO, IT Architects, technical staff and business uses.', 'A proven and enthusiastic, high-energy, motivating leader who is visibly passionate and is capable of inspiring and galvanizing people around.', 'A balance of strategic and tactical skills, with a high level of intellectual agility and capacity for original thought.', 'An exceptional communicator who can write, present, and effectively adjust messages to meet individual audiences and organizations.', 'A proven ability to navigate and effectively collaborate with other groups and resources in a large complex environment.', 'A bachelors or masters in mathematics or computer science or related field is required. Ph.D. in a related field is desired.']",2020-09-24 13:55:23
Data Engineer,CVS Health,3.3 out of 5,"Wellesley, MA","['Job', 'Company', 'Assists in the development of large scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs.', 'Applies understanding of key business drivers to accomplish own work.', 'Uses expertise, judgment and precedents to contribute to the resolution of moderately complex problems.', 'Leads portions of initiatives of limited scope, with guidance and direction.', 'Writes ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processing.', 'Collaborates with client team to transform data and integrate algorithms and models into automated processes.', 'Uses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelines. Uses programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systems.', 'Builds data marts and data models to support clients and other internal customers.', 'Integrates data from a variety of sources, assuring that they adhere to data quality and accessibility standards.', 'Strong problem solving skills and critical thinking ability.', 'Strong collaboration and communication skills within and across teams.', '3 or more years of progressively complex related experience.', 'Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources.', 'Ability to understand complex systems and solve challenging analytical problems.', 'Experience with bash shell scripts, UNIX utilities & UNIX Commands.Knowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similar.', 'Knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment.', 'Experience building data transformation and processing solutions.', 'Has strong knowledge of large scale search applications and building high volume data pipelines.', ""Master’s degree or PhD preferred.Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline.""]",2020-09-24 13:55:23
"Data Engineer (Python, Pyspark, Airflow, AWS)",Nexient,3.4 out of 5,"Ann Arbor, MI",[],2020-09-24 13:55:23
"Data Engineer, Data Platform",TikTok,4.1 out of 5,"Mountain View, CA",[],2020-09-24 13:55:23
Data Center Operations Engineer,"Packet, an Equinix company",N/A,"Elk Grove, IL 60007","['Structured cabling of power, copper, and fiber network connections.', 'Configure and test all hardware for deployment to local and remote sites', 'Prepare pallets and supporting documentation (including waybill and export paperwork) for international shipment.', 'Work with our data center providers and internal engineering teams to optimize for creating as quick and efficient of a turn-up process as possible; maintain a positive overall relationship with our global vendors. Ideally this would also include a basic proficiency in coding/scripting to develop tools to help with our daily workflow.', 'Work with our network and systems engineering teams around turning up new data center locations and incremental rack-level infrastructure, as well as troubleshooting physical server hardware and network devices.', 'Ability to lift IT equipment, some of which may exceed (40) lbs per unit.', 'Data center, Computer Science, or Information Technology education or background required. We are looking for an individual with basic subject-matter experience, though we will provide extensive training around the Packet hardware platform and specific areas of responsibility.', 'Linux systems administration and scripting experience is a plus.', 'Optical network troubleshooting (e.g. use of a light meter and OTDR/OSA) and termination experience is a plus.', 'Familiarity with data center industry, and interacting with remote site technicians, is a plus.', 'We are hiring for a full-time (40 hours) position, with an ability to work nights and weekends as required. We will work with the candidate to build an optimal schedule based on his/her working preferences, as well as Packet’s needs to maximize around 24x7 global coverage.']",2020-09-24 13:55:23
Data Engineer,Edelman,3.7 out of 5,United States,"['Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.', 'Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.', 'Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.', 'Writes unit/integration tests and documents work.', 'Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.', 'Works closely with a team of product managers, and analysts.', 'Designs data integrations and data quality framework.', 'Designs and evaluates open source and vendor tools for data lineage.', 'Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.', 'Expert in cloud-based platforms, such as AWS and GCP', 'Knowledge of best practices and IT operations', 'Excellent problem solving and troubleshooting skills', 'Process oriented with great documentation skills', 'BS or MS degree in Computer Science or a related technical field', '4+ years of Python development experience', '4+ years of SQL experience (No-SQL experience is a plus)', '4+ years of experience with schema design and dimensional data modeling', 'Ability in managing and communicating data warehouse plans to internal clients', 'Experience with data warehouse services such as Redshift, Snowflake and/or Hive.', 'Experience with Business Intelligence tools such as Tableau, PowerBI and/or Looker.', 'Experience with collaborative data analytics services such as databricks.', 'Experience designing, building, and maintaining data processing systems']",2020-09-24 13:55:23
Data Center Mechanical Engineer (Field Engineering),"Amazon Data Services, Inc.",3.6 out of 5,"Umatilla, OR","['Job', 'Company', 'Bachelor’s Degree in Mechanical Engineering or equivalent experience', '3+ cumulative years of experience with industrial or commercial engineering in Mission Critical facilities. (Experienced Engineer)', 'Learn and Understand the design and functionality of the data centers within your assigned Region.', 'Troubleshoot problems and conduct Root Cause Analysis (RCA) and Corrective Action (CA) for design and equipment related failures. Field Engineers are expected to become stewards of Availability and directly support our Operations Team.', 'Direct Support to Operations technicians/staff including ad-hoc trainings and complex operating procedure review.', 'Own the design for existing data center upgrades and design-solutions including projects that add capacity, improve availability, and increase personnel or equipment safety.', 'Provide direct influence over all designs for construction of new data centers, including engineering support during the construction and commissioning phases of mechanical systems.', 'Interface with internal data center design engineering team, server hardware team, environmental health and safety team to promote standards that maintain consistency and reliability in services delivered.', 'Travel to your local site to support your workload, and up to 25% travel to other regions.', 'Work on concurrent projects, sometimes in multiple geographical regions.', 'Be a leader within the group as well as within other teams.', 'Be positive and offer creative out of the box solutions.', 'Provide immediate technical guidance to operations during critical events.', 'Have fun and work hard!', 'Coursework in commercial/industrial mechanical systems', 'Organized and have the ability to set priorities and meet deadlines and budget', 'Possess leadership and problem-solving skills', 'Experience using a variety of web based and other software tools for calculation and data processing.', 'Direct experience with the design, construction, operation, or maintenance of mission critical facilities, especially data centers.', 'Experience as resident engineer or hands-on (in the field) design consultant.', 'Knowledge of building codes and regulations for your region', 'Experience reading, interpreting, and creating construction drawings, specifications, and submittal documents.', 'Ability to carry design concepts through exploration, development, and into deployment/mass production', 'Possess excellent communication and writing skills, attention to detail, maintain high quality standards', 'Basic understanding of both mechanical and electrical equipment/design related to data centers (Including but not limited to: uninterruptable power sources , diesel generators, electrical switchgear, power distribution units, variable frequency drives, automatic/static transfer switches, chillers [air-cooled and water-cooled], pumps, cooling towers, heat exchangers, CRAHs, air economizers, etc...)', 'EPMS/SCADA/BMS Controls system experience (software and/or hardware)', 'Meets/exceeds Amazon’s leadership principles requirements for this role', 'Meets/exceeds Amazon’s functional/technical depth and complexity for this role']",2020-09-24 13:55:23
Software Engineer - Data/ Password Cracking,SpyCloud,N/A,"Austin, TX 78704","['Add new features to the password cracking platform', 'Manage day-to-day password cracking', 'Participate in a fast-paced environment', 'New college grad with a degree in Computer Science or related field OR at least 2 years of professional experience as a software developer', 'Experience with Python', 'An understanding of data structures and algorithms', 'Experience with a database (relational or NoSQL)', 'Experience with Linux', 'Excellent communication skills', 'Be self-motivated and be able to switch contexts as business needs change', 'Familiarity with an MVC web framework (e.g. Pyramid, Django, Ruby on Rails, etc)', 'Familiarity with front-end development (e.g. HTML, CSS, JavaScript)', 'Familiarity with building REST APIs', 'Familiarity with Bash scripting', 'Familiarity with AWS', 'Familiarity with a version control system. We use Git.', 'Familiarity with HashCat']",2020-09-24 13:55:23
Cloud Data Engineer,Twitter,4.1 out of 5,"San Francisco, CA 94103","[""Building a Petabyte-scale Data Warehouse (Google Cloud Next '18) https://youtu.be/APBF9Z3uBCc"", ""How Twitter Migrated its On-Prem Analytics to Google Cloud (Google Cloud Next '18) https://youtu.be/sitnQxyejUg"", 'Strong programming and algorithmic skills', 'Experience with data processing (such as Hadoop, Spark, Pig, Hive, MapReduce etc).', 'Proficiency with SQL (Relational, Redshift, Hive, Presto, Vertica)', 'Experience writing Big Data pipelines, as well as custom or structured ETL, implementation and maintenance', 'Experience with large-scale data warehousing architecture and data modeling', 'Proficiency with Java, Scala, or Python', 'Experience with GCP (BigQuery, BigTable, DataFlow)', 'Experience with Druid or Apache Flink', 'Experience with real-time streaming (Apache Kafka, Apache Beam, Heron, Spark Streaming)', 'Ability in managing and communicating data warehouse project plans to internal clients']",2020-09-24 13:56:04
District Engineer,"Helmerich & Payne, Inc.",4.1 out of 5,"Odessa, TX","['Assist in implementing performance improvement initiatives based on customer requests and data analytics (including support of FlexApps and HSE initiatives as necessary)', 'Manage projects to meet the needs of the district (rig upgrades, rig retrofits, FlexApp roll outs, etc.)', 'Liaison between the district and engineering as necessary for retrofits, rig equipment issues, etc.', 'Demonstrate the H&P Company values: Actively C.A.R.E., Service Attitude, Innovative Spirit, Teamwork and Do the Right Thing', 'Bachelor’s degree in Mechanical or Petroleum Engineering and 1-3 years industry experience preferred', 'Knowledge of Oil and Gas, field activity preferred', 'Proficient knowledge of rig activities required', 'Performance Engineer experience preferred', 'Self-starter, motivated and takes the initiative to find and complete projects', 'Proficient in the use of PC application skills, including visualization, spreadsheet, and database products', 'Ability to complete data analysis and provide solutions and recommendations based on insight', 'Works well in a collaborative and team-based environment', 'Excellent problem-solving, presentation, and communication / interpersonal skills', 'Willingness and ability to travel 25-50% of the time', 'Assist in implementing performance improvement initiatives based on customer requests and data analytics (including support of FlexApps and HSE initiatives as necessary)', 'Manage projects to meet the needs of the district (rig upgrades, rig retrofits, FlexApp roll outs, etc.)', 'Liaison between the district and engineering as necessary for retrofits, rig equipment issues, etc.']",2020-09-24 13:56:04
Sr. Test/Data Engineer,Rivian Automotive,3.7 out of 5,"Wittmann, AZ","['Oversee and configure all vehicle data loggers.', 'Manage the flow and initial post-processing of all vehicle logger data.', 'Coordinate the interactions between aftermarket data loggers, production telematics data collection, and external data acquisition.', 'Develop, specify, procure, use and train others in use of, and maintain data acquisition sensors, systems, practices and databases for all aspects of vehicle measurement (thermal, strain, NVH, and digital networks among others)', 'Execute Vehicle level design validation (DVP) testing', 'Preliminary fault analysis and reporting (hardware and software)', 'Plan and execute vehicle tests with a focus on instrumentation and data collection', 'Liaison across multiple engineering departments', '5+ years in a similar role', 'Mechanical/Mechatronics background', 'Embedded Controls knowledge preferred', 'Experience working hands-on with in-vehicle data acquisition systems including experiment design, installation, use, data analysis and detailed post-processing techniques', 'Direct experience working with CAN, LIN, and Ethernet vehicle data networks, including debugging and reverse engineering', 'Racing/professional driving background preferred', 'Experience with data logging systems (Intrepid preferred)', 'Proving grounds experience', 'Willing to travel upwards of 25% of the time', 'Eye for detail with a focus on quality', 'Proven experience with at least 2 major vehicle systems (EG, Electric powertrain, suspension, HVAC, Braking)']",2020-09-24 13:56:04
Engineer - Entry Level,R&D Tax Savers,N/A,"Syosset, NY 11791","['$47,500.00 - $52,500.00 per year', 'Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Parental leave', 'Retirement plan', 'Vision insurance', 'Supplemental Pay:', 'Work on client engagements related to our R&D tax credit studies and energy tax deduction studies which includes: client interface, data collection and analysis, and technical report writing.', 'Assist with marketing and business development activities', 'Research various topics for client related work and article publication', ""Bachelor's Degree - preferably an Engineering or technical background (which will help in grasping our clients' industries which include manufacturing, software, food science, biotechnology and beyond)."", 'Detail oriented, ability to multitask, and work well in a fast-paced, team oriented  environment', 'Exemplary writing and analytical skills', 'Proficiency in MS Excel, Word, PowerPoint', 'Application period through October 23', 'First Interviews scheduled October 26-30', 'Final Interviews scheduled November 2-6', 'Start date December 1', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Parental leave', 'Retirement plan', 'Vision insurance', 'Monday to Friday', 'Bonus pay', ""Bachelor's (Required)"", 'Syosset, NY 11791 (Required)', 'United States (Required)', 'One location', 'Waiting period may apply', 'Only full-time employees eligible', 'No']",2020-09-24 13:56:04
Wave Engineer,Zayo Group,2.8 out of 5,"Boulder, CO 80301","['Competitive compensation', 'Excellent benefits including health, dental, vision, 401 (k), disability and life insurance', 'Fitness membership discounts', 'Generous paid time off policy including paid parental leave', 'Manage projects on or before revenue commitment dates that are driving the projects.', 'Track all-in progress implementation orders and their dependencies with a readout on their specific timelines.', 'Organize to strong production levels using and reporting on metrics and SLAs.', 'Develop strong and supportive relationships with internal partners to drive the delivery of projects on time.', 'Develop efficiencies in process with internal and external partners to improve SLAs.', 'Design, engineer, and provide hardware solutions to link engineer and deliver services to customers in front of revenue and customer requested dates.', 'Serve as network project point-of-contact and escalation.', 'Serve as the interface between equipment vendor(s) and Zayo stakeholders as needed to validate technical specifications, hardware and software interoperability, and hardware delivery timelines.', 'Facilitate cross-functional communications amongst team members to foster timely resolution of project obstacles.', 'Bachelors’ degree in Telecommunications, Electrical Engineering, Computer Science, or 2+ years’ of relevant telecommunications engineering experience.', 'Working knowledge of optical fiber technical specifications, testing, and link engineering fundamentals.', 'Working knowledge of DWDM network architectures (i.e. FOADM/ROADM/PON/fixed and flex grid) and signal flow.', 'Working knowledge with telecommunications service protocol structure and testing (i.e. Ethernet/OTN/SONET/SDH/SAN).', 'Familiarity with the following optical transport platformsCienaInfineraNokiaCiscoADVAFujitsu', 'Familiarity with Metasolve/M6 database.', 'Understanding of telemetry (DCN) network design, IP subnetting, and routing protocols (i.e. OSPF).', 'Experience with data center and carrier hotel connectivity and telecommunications facility environments.', 'MS Office application capabilities required (i.e. Excel/Visio/Word) and programming/scripting skills preferred.', 'Excellent written and verbal communication/negotiating skills required for technical/non-technical audiences.', 'Ability to work with minimal supervision while being a constructive contributor to a team.', 'Competitive compensation', 'Excellent benefits including health, dental, vision, 401 (k), disability and life insurance', 'Fitness membership discounts', 'Generous paid time off policy including paid parental leave']",2020-09-24 13:56:04
Senior Asset Management Engineer,E.On,3.6 out of 5,Remote,"['The management and development of SCADA and associated KPI tools to develop advanced data analytics for performance and business steering.', 'Taking responsibility for the projects and day to day operational responsibilities, both budgetary and in implementation. You will make strategic recommendations and implement engineering and maintenance activities to improve the commercial performance of CES’s assets.', 'The full site integration and development of Iconics SCADA system for existing and new sites.', 'Technical support for the Operations business in areas of control, data acquisition and communications including the Central Control Room (CCR) based on London.', 'Performance project technical support for projects circa £0.5M to £1.5M per year.', 'Directly responsible for the delivery of control system and performance projects circa £0.1M to £0.5M per year, project managing third party contractors safely, to time and budget.', 'Responsible for the fleet contract management of key contracts such as SCADA support, fleet control system support and 24/7 emergency control system response.', 'Identification and management of strategic control system spares for the CE fleet. You will investigate new technologies and concepts to improve CES’s standing in the market pushing the envelope of technologies including using external market information and use machine learning (AI) tools and algorithms.', 'Educated to degree level in Engineering or Science in addition to significant experience gained in a relevant role.', 'In-depth knowledge and experience of control and SCADA systems.', 'In-depth knowledge and experience of data management and reporting techniques i.e. using appropriate software and analytical tools to create KPI dashboards and reports.', 'Ability to directly collaborate with individuals and a team to deliver performance improvements and day to day operational support.', 'Knowledge and experience of commercial and technical performance in power/heat plant including optimisation techniques.', 'Stakeholder Awareness with excellent networking, influencing and rapport building skills.', 'Excellent communications skills: written, verbal, presentational.', 'Experience of challenging the accepted way of doing things to push things forward.', 'A good working knowledge of health and safety and environmental legislation and standards to IBOSH or equivalent.', 'Developed critical and technical reasoning skills.', 'The ability to multitask, maintain focus under pressure and ensure accuracy and attention to detail at all times.', 'Chartered Member of a relevant Institution or professional body or actively working towards membership.', 'Ability to work across organisational and international cultures.', 'Ability to develop a strategic approach, gain support and commitment to deliver from within the business.', 'This role is home-based for 80% of the time with the remaining 20% spent visiting energy centre fleet or Citigen.', 'Our Citigen site is based at 47-53 Charterhouse Street, London, EC1M 6PB.', 'The salary for this role is £46,643 - £64,073.', 'Depending on home address, this role is eligible for a London Allowance of up to £3,550 pa.', 'This role is a permanent position.', 'Due to the nature of the role a Criminal Record Check will be required.', 'If you have any technical issues in applying please try this link: https://career2.successfactors.eu/sfcareer/jobreqcareerpvt?jobId=129241&company=EonProd&st=64C1E7C1BF02EB9B33DDC96E33A2B5635C0C6BA6', 'If you are still unable to apply please contact hannah.clackworthy@eon-uk.com for further support']",2020-09-24 13:56:04
"ID&C Engineer: Instrumentation, Data System, and Controls Engineer","Integration Innovation, Inc.",4.6 out of 5,"Tullahoma, TN","['Evaluate current methods and procedures used at AEDC and recommend solutions for Phoenix.', 'Provide instrumentation selections based off of requirements for all J5 Phoenix systems.', 'Provide equipment recommendations and standard configurations for all J5 Phoenix systems and work with each system engineer.', 'Provide problem solving support to field measurement techniques.', 'Support installation and checkout integrations with other systems within the Phoenix Project.', 'Develop best practice documentation of field configurations to supply to technicians when installing and checking out system components.', 'Work closely with functional, technical, and vendor teams to create and implement industry leading solutions.', 'Coordinate and participate in CONOPS development.', 'Maintain technical expertise in all data and controls system computer hardware, software, interconnection, and interfacing.', 'Evaluate, report, and make recommendations on new data system and control system technologies to enhance the capabilities of i3 and its partners.', 'Must be willing to participate in continuing education in the form of training, courses, PDUs, and certifications.', 'Bachelor’s degree in either electrical or computer engineering.', '5+ years total of relevant experience required.', 'Strong analytical and technical skills, understanding of system integration concepts.', 'Demonstrated ability to take ownership and responsibility for systems.', '3+ years of Instrumentation and Data Acquisition system design and maintenance experience.', '2+ years of knowledge and experience with controls system development.', 'Experience with working government contracts.', 'Knowledge of LabVIEW and Microsoft SQL Server', 'GE CIMPLICITY or other HMI/SCADA solution']",2020-09-24 13:56:04
Data Engineer,Bayer,4.2 out of 5,"Chesterfield, MO","['Work on development, deployment, and support of systems of data pipelines and computing solutions;', 'Collaborate with interdisciplinary scientists to gather requirements for data pipelines;', 'Optimize algorithms and data workers to scale horizontally and contribute to the development of new algorithms and capabilities that will enable connected pipeline analytics for all pipelines;', 'Work on all aspects of the design, development, validation, scaling and delivery of analytical or pipeline solutions;', 'Collaborate with analytics and discovery teams to design and plan data engineering solutions;', 'Develop and align roadmaps, delivery dates and integration efforts;', 'Provide reliable estimates for large scale project;', 'Implement, configure, and maintain critical third-party solutions related to engineering work, including compute environments, BI platforms, and cloud systems;', 'Design and maintain Extract, Transform, Load (ETL) workflows;', 'Integrate proactive strategies and best practices to ensure security of stored data;', 'Design, build, and maintain integrated data solutions such as ""data lakes"" and ""data warehouses"";', 'Design and maintain data storage systems and access patterns;', 'Have the ability to operate independently on work assignments with minimal guidance;', 'Be responsible for making decisions that impact business value;', 'Have the ability to work with and set priorities with both on site partner teams and teams at remote (U.S. and International) sites;', 'Help the team establish and improve processes and methodologies, like SCRUM or Kanban, and/or lead piloting new ones;', 'Facilitate and participate in code reviews, retrospectives, functional and integration testing and other team activities focused on improving quality of delivery;', 'Ensure the success of digital strategies within Plant Biotechnology by designing, creating, and operating engineered data solutions;', 'Partner with teams in data science, reporting, software engineering, and operations to accelerate strategies by ensuring the availability and quality of required data systems;', 'Have particular focus on bringing value through unique expertise in the creation and optimization of ""big data"" solutions and the design and execution of distributed computing workflows.', 'Bachelor’s degree in Computer Science, Electrical Engineering or a closely related field with at least five years of industry experience or master’s Degree in Computer Science, Electrical Engineering or a closely related field with at least two years of industry experience Doctorate in Computer Science, Electrical Engineering, or a closely related field;', 'Technical knowledge and at least two years of experience in at least two of the following, structure query language (SQL) and NoSQL databases (data warehousing, data modeling, etc.);', 'Experience with big data tools (Spark, Kafka, Flink, Hadoop, etc.);', 'Deep understanding of algorithms and data structures;', 'Experience with tools for authoring workflows & pipelines (Airflow, AWS Step Functions, KubeFlow, etc.);', 'Experience with cloudservices (EMR, S3, RedShift, EC2, etc.);', 'Experience with distributed systems;', 'Experience with python, Java, R, or Scala.', 'Network and Database administration;', 'Proven systems administration and operations experience;', 'Proven ability to plan, schedule and deliver quality software, DevOps methodology;', 'Experience in running production cloud systems and diagnosing and fixing problems.']",2020-09-24 13:56:04
Data Engineer,Doctors Without Borders | Médecins Sans Frontières,N/A,"New York, NY 10006","['You have data engineering experience to build and customize solutions and manage integrations with other systems. This might include designing, developing, testing and deploying custom solutions via Heroku.', 'You are experienced in continuous integration and agile development', 'You have an enthusiastic problem-solving mindset', 'Work with a Project Manager and data specialists to support a large implementation of Salesforce NPSP over the next 12 months. The Data Engineer ensures the integration of a complex data environment where Heroku, Salesforce and other third-party integrations have scalable and reliable data pipelines.Leverage MuleSoft to develop APIs for our new Salesforce ecosystemDevelop custom solutions which leverage Heroku platform with Salesforce for users in the fundraising departmentCommunicate with project managers, vendors, implementation partners and other developers to design cohesive project strategies and ensure effective collaboration throughout all phases of development, testing and deploymentWrite documentation according to best practicesCommunicate design, requirements, functionality, and limitations of systems/applicationsCollaborate with vendors and implementation partners on successful delivery of product enhancements and support / maintenance', ""Develop and improve our growing data engineering practiceOrchestrationBuild and maintain a growing data warehousePlan and execute the expansion of our systems architecture to support MSF-USA's growing analytic needsWork within SQL and analytical warehouses (Snowflake)Collaborate with Data Analyst and Director of Systems on key strategic projects"", 'A commitment to learn and improve how we work at MSF-USA through data by working collaboratively with other teams (see MSF principles here)', 'Support the departmental work of advancing and implementing data strategy at the organizational level', 'Work with internal departments to provide strategic recommendations for improving efficiencies of MSF’s enterprise data architecture', 'Fluent in new technologies for ETL, middleware and warehousing that will help MSF solve its data challenges with less time and money', 'Able to identify, clarify, and resolve issues and risks related to database design and data management, escalating them as needed', 'Recognize potential problem areas against the plan and identify and implement alternative solutions', 'Participate in the exchange of ideas and information within and outside the department to ensure best practices are shared throughout the organization', 'Ensure 100% adherence to all MSF-USA policies and procedures, especially as they relate to information security protocols and the protection of sensitive information', 'Bachelor’s degree (or equivalent experience) in a relevant technical field such as Computer Science or Information Systems.', '3+ Years professional experience designing and deploying production pipelines from the ground up', 'Proficient at building out scalable data systems in a Python environment', 'Hands-on experience with implementing ETL at scale with pipeline tools (for example: Airflow, Azure Data Factory, etc.)', 'SQL and warehouse technologies (Snowflake preferred)', 'Working knowledge of Spark or other cluster-computing frameworks', 'Demonstrated ability to automate data applications in a cloud environment (we use Azure)', 'Experience with Salesforce and consuming data through APIs (MuleSoft or equivalent tools)', 'Understanding of security best practices when implementing pipeline technologies', 'Commitment to MSF’s mission and humanitarian principles', 'Master’s degree preferred', 'Experience building out ML infrastructure', 'Demonstrated ability to maintain a Git environment', 'Advanced knowledge of data-related Python packages', 'Ability to enable language-agnostic analysis environments', 'Experience working within an Agile framework']",2020-09-24 13:56:04
Sr. Data Engineer,MasterClass,N/A,"San Francisco, CA","['Proactively drive the execution of our data engineering, business intelligence, and data warehouse roadmap', 'Understand and translate business needs into data models to support long-term, scalable, and reliable solutions', 'Create logical and physical data models using best practices to ensure high data quality and reduced redundancy', 'Drive data quality across the organization; develop best practices for standard naming conventions and coding practices to ensure consistency of data models and tracking', ""Define and manage SLA's for data sets and processes running in production"", 'Continuously improve our data infrastructure and stay ahead of technology', 'Design a system for data backup in case of system failure', 'Build strong cross-functional partnerships with Data Scientists, Analysts, Product Managers and Software Engineers to understand data needs and deliver on those needs', '4+ years of experience in Data Engineering and Data Warehousing', ""Bachelor's degree in a quantitative field, e.g. Computer Science, Math, Physics"", 'Experience scaling data environments with distributed/RT systems and self-serve visualization environments', 'Advanced proficiency with SQL, Perl, Python, Postgres, REST/GraphQL', 'Experience designing and implementing cloud based and SaaS data warehouse (e.g. WS, Hadoop, NoSQL) and developing ETL/ELT pipelines', 'Experience integrating and building data platform in support of BI, Analytics, Data Science, and real-time applications', 'Strong communication skills, with the ability to initiate and drive projects proactively and accurately', 'Work full-time in our San Francisco office']",2020-09-24 13:56:04
Sr. Data Engineer,MasterClass,N/A,"San Francisco, CA","['Interviews on the spot', 'Wednesday, September 30, 202012:00 PM - 3:00 PM US/Eastern', ""Interviewing via webYou'll receive an email on how to connect."", '111 slots left', '', ""Technical Marketing Engineer - Raleigh, NCFull-timeJob SummaryAs a Technical Marketing Engineer within the StorageGRID Group, you work cross-functionally to create technical content for NetApp StorageGRID solutions that are targeted to Customers, Field Tech Teams and Partners. The engineer will work closely with Product Management as well as Product and Solutions Engineering on the company's current and future strategies related to object storage and unstructured data management solutions. You will also work closely with third-party vendor organizations as required to achieve corporate goals in regard to product integration and best practices.Essential Functions:You will lead projects and be accountable for project deliverables working with cross-functional and business unit teams with limited supervision and occasionally lead inter-department cross functional teams. This may include managing and designing Partner integrations highlighting NetApp technologies.Establishing yourself as a Subject Matter Expert in specific technologies across departments solving difficult technical problems without management assistance and will continue to build your expertise with continued internal and external education. You will identify gaps in product/process and make proactive suggestions for improvement.Create and present technical presentations to customers and partners and gather feedback to influence product and solution offerings.You will be responsible for developing technical collateral in your focused areas of technical expertise to highlight best practices, including architectural design work, lab testing, and publishing documentation. This includes developing design, deployment and integration guides for products, solutions and reference architectures.You will collaborate on strategy with product management and other Technical Marketing Engineers to create and review Market and Solutions Requirement documents (MRD & SRD) This includes participating in cross functional teams to develop product and solution roadmaps.Job RequirementsAbility to communicate in a clear and concise professional manner, tailored to the appropriate audience; including both verbal and written communications.Ability to lead and work collaboratively within a business unit team and have strong influencing skills.Proven customer facing ability to describe technical concepts, deliver clear and concise demos, and define solutions to customer pain points. Experience presenting technical content in a variety of settings and scale is required.Ability to operate effectively and independently in a lab environment, deploy software in Linux/Windows environments, configure networking and virtualization technologies to build test and simulation environments for StorageGRID + third party solutions.Ability to drive and collaborate with development teams to create configuration management modules and other automation software for a variety of platforms.Ability to work on complex issues where analysis of situations or data requires an in-depth evaluation and may require collaboration across multiple technical teams.Hands on experience and expertise with other open source projects and tools including OpenStack, Docker, and KubernetesHands on experience with multiple Linux variants and the ability to develop moderate to complex scriptsMust be able to manage multiple priorities and complex tasks in a dynamic work environment.Ability to build strong working relationships across all levels of the organization, including remote areas.Problem solve difficult technical problems within the scope of the project and occasionally business unit related projects, without management assistanceExperience with commercial, open-source or cloud object storage solutions preferred.EducationTypically requires a minimum of 5 years of related experience with a Bachelor’s degree; or 3 years and a Master’s degree; or a PhD without experience; or equivalent work experience."", 'You will lead projects and be accountable for project deliverables working with cross-functional and business unit teams with limited supervision and occasionally lead inter-department cross functional teams. This may include managing and designing Partner integrations highlighting NetApp technologies.', 'Establishing yourself as a Subject Matter Expert in specific technologies across departments solving difficult technical problems without management assistance and will continue to build your expertise with continued internal and external education. You will identify gaps in product/process and make proactive suggestions for improvement.', 'Create and present technical presentations to customers and partners and gather feedback to influence product and solution offerings.', 'You will be responsible for developing technical collateral in your focused areas of technical expertise to highlight best practices, including architectural design work, lab testing, and publishing documentation. This includes developing design, deployment and integration guides for products, solutions and reference architectures.', 'You will collaborate on strategy with product management and other Technical Marketing Engineers to create and review Market and Solutions Requirement documents (MRD & SRD) This includes participating in cross functional teams to develop product and solution roadmaps.', 'Ability to communicate in a clear and concise professional manner, tailored to the appropriate audience; including both verbal and written communications.', 'Ability to lead and work collaboratively within a business unit team and have strong influencing skills.', 'Proven customer facing ability to describe technical concepts, deliver clear and concise demos, and define solutions to customer pain points. Experience presenting technical content in a variety of settings and scale is required.', 'Ability to operate effectively and independently in a lab environment, deploy software in Linux/Windows environments, configure networking and virtualization technologies to build test and simulation environments for StorageGRID + third party solutions.', 'Ability to drive and collaborate with development teams to create configuration management modules and other automation software for a variety of platforms.', 'Ability to work on complex issues where analysis of situations or data requires an in-depth evaluation and may require collaboration across multiple technical teams.', 'Hands on experience and expertise with other open source projects and tools including OpenStack, Docker, and Kubernetes', 'Hands on experience with multiple Linux variants and the ability to develop moderate to complex scripts', 'Must be able to manage multiple priorities and complex tasks in a dynamic work environment.', 'Ability to build strong working relationships across all levels of the organization, including remote areas.', 'Problem solve difficult technical problems within the scope of the project and occasionally business unit related projects, without management assistance', 'Experience with commercial, open-source or cloud object storage solutions preferred.', ""Technical Marketing Engineer - RemoteFull-timeJob SummaryAs a Technical Marketing Engineer within the StorageGRID Group, you work cross-functionally to create technical content for NetApp StorageGRID solutions that are targeted to Customers, Field Tech Teams and Partners. The engineer will work closely with Product Management as well as Product and Solutions Engineering on the company's current and future strategies related to object storage and unstructured data management solutions. You will also work closely with third-party vendor organizations as required to achieve corporate goals in regard to product integration and best practices.Essential Functions:You will lead projects and be accountable for project deliverables working with cross-functional and business unit teams with limited supervision and occasionally lead inter-department cross functional teams. This may include managing and designing Partner integrations highlighting NetApp technologies.Establishing yourself as a Subject Matter Expert in specific technologies across departments solving difficult technical problems without management assistance and will continue to build your expertise with continued internal and external education. You will identify gaps in product/process and make proactive suggestions for improvement.Create and present technical presentations to customers and partners and gather feedback to influence product and solution offerings.You will be responsible for developing technical collateral in your focused areas of technical expertise to highlight best practices, including architectural design work, lab testing, and publishing documentation. This includes developing design, deployment and integration guides for products, solutions and reference architectures.You will collaborate on strategy with product management and other Technical Marketing Engineers to create and review Market and Solutions Requirement documents (MRD & SRD) This includes participating in cross functional teams to develop product and solution roadmaps.Job RequirementsAbility to communicate in a clear and concise professional manner, tailored to the appropriate audience; including both verbal and written communications.Ability to lead and work collaboratively within a business unit team and have strong influencing skills.Proven customer facing ability to describe technical concepts, deliver clear and concise demos, and define solutions to customer pain points. Experience presenting technical content in a variety of settings and scale is required.Ability to operate effectively and independently in a lab environment, deploy software in Linux/Windows environments, configure networking and virtualization technologies to build test and simulation environments for StorageGRID + third party solutions.Ability to drive and collaborate with development teams to create configuration management modules and other automation software for a variety of platforms.Ability to work on complex issues where analysis of situations or data requires an in-depth evaluation and may require collaboration across multiple technical teams.Hands on experience and expertise with other open source projects and tools including OpenStack, Docker, and KubernetesHands on experience with multiple Linux variants and the ability to develop moderate to complex scriptsMust be able to manage multiple priorities and complex tasks in a dynamic work environment.Ability to build strong working relationships across all levels of the organization, including remote areas.Problem solve difficult technical problems within the scope of the project and occasionally business unit related projects, without management assistanceExperience with commercial, open-source or cloud object storage solutions preferred.EducationTypically requires a minimum of 5 years of related experience with a Bachelor’s degree; or 3 years and a Master’s degree; or a PhD without experience; or equivalent work experience."", 'You will lead projects and be accountable for project deliverables working with cross-functional and business unit teams with limited supervision and occasionally lead inter-department cross functional teams. This may include managing and designing Partner integrations highlighting NetApp technologies.', 'Establishing yourself as a Subject Matter Expert in specific technologies across departments solving difficult technical problems without management assistance and will continue to build your expertise with continued internal and external education. You will identify gaps in product/process and make proactive suggestions for improvement.', 'Create and present technical presentations to customers and partners and gather feedback to influence product and solution offerings.', 'You will be responsible for developing technical collateral in your focused areas of technical expertise to highlight best practices, including architectural design work, lab testing, and publishing documentation. This includes developing design, deployment and integration guides for products, solutions and reference architectures.', 'You will collaborate on strategy with product management and other Technical Marketing Engineers to create and review Market and Solutions Requirement documents (MRD & SRD) This includes participating in cross functional teams to develop product and solution roadmaps.', 'Ability to communicate in a clear and concise professional manner, tailored to the appropriate audience; including both verbal and written communications.', 'Ability to lead and work collaboratively within a business unit team and have strong influencing skills.', 'Proven customer facing ability to describe technical concepts, deliver clear and concise demos, and define solutions to customer pain points. Experience presenting technical content in a variety of settings and scale is required.', 'Ability to operate effectively and independently in a lab environment, deploy software in Linux/Windows environments, configure networking and virtualization technologies to build test and simulation environments for StorageGRID + third party solutions.', 'Ability to drive and collaborate with development teams to create configuration management modules and other automation software for a variety of platforms.', 'Ability to work on complex issues where analysis of situations or data requires an in-depth evaluation and may require collaboration across multiple technical teams.', 'Hands on experience and expertise with other open source projects and tools including OpenStack, Docker, and Kubernetes', 'Hands on experience with multiple Linux variants and the ability to develop moderate to complex scripts', 'Must be able to manage multiple priorities and complex tasks in a dynamic work environment.', 'Ability to build strong working relationships across all levels of the organization, including remote areas.', 'Problem solve difficult technical problems within the scope of the project and occasionally business unit related projects, without management assistance', 'Experience with commercial, open-source or cloud object storage solutions preferred.', 'Micro-Services Infrastructure Architect - Remote or Raleigh, NCFull-timeJob SummaryThe NetApp Solutions Architecture & Automation team is part of the Engineering Cloud & Infrastructure Services. You will be part of a team that is responsible for NetApp\'s internal engineering infrastructure and services. This work will span private and public cloud infrastructure, networking, storage, applications, and platforms. The team is responsible for planning, designing and implementing end-to-end, self-service solutions and coordinating with internal teams and outside vendors. You will engage in large projects, work through analysis, design and implementation to deliver viable cloud solutions to solve NetApp engineering challenges.Summary Description of the Ideal Candidate:As the industry is quickly moving to an SRE/DevOps approach, you will be aligned for success having a technical degree (computer science, engineering, etc.), and a long-standing passion for writing high-quality software. As a software technologist, you possess in-depth knowledge of modern software development techniques and practices. As a generalist, you enjoy learning new things, and solving new challenges at scale.Job RequirementsSolutions Architect responsible for cloud-based infrastructure automation capabilities to be used to host our containerized/microservice based applications. This role requires:5 years experience implementing/operating cloud based, on-prem infrastructure and containerized environmentExtensive Azure environment developmentExtensive experience in developing automation via tools such as Ansible, PuppetAbility to document designs, runbooks, KB articles, and provide TOIs/Training for operational support transitionAbility to multi-task and self-prioritize multiple parallel projectsAbility to lead troubleshooting and drive complex issues that requires multiple disciplines (network, security, compute, storage, etc.) to resolutionAbility to ""self-teach"" new technologies and become subject matter expert as neededIn-depth knowledge of Kubernetes/Container deployments (OpenShift and Rancher)Experience building/supporting cloud based environments (Azure) as well as on-prem cloud platforms (VMWare, Openstack, Openshift)Skills:Kubernetes, Docker, OpenShift as well as knowledge on how to migrate legacy platforms to containerized environments. (on-boarding users)OpenStack, KVM, RabbitMQ, MariaDB, MongoDB, ElasticSearchPuppet, AnsibleAzure ExpressRoute, Automation, RBACPrometheus, Grafana monitoringImplement and engineer Rancher on-prem for a potential PaaSManagement and implementation of NetApp HCI, Cisco UCSBuild/Develop containerized CI/CD pipelines (Jenkins, BitBucket, DevOps practices)Ability to learn and quickly come up to speed on new technologiesEducationTypically requires a minimum of 5 years of related experience with a Bachelor’s degree; or 3 years and a Master’s degree; or a PhD without experience; or equivalent work experience.', 'Solutions Architect responsible for cloud-based infrastructure automation capabilities to be used to host our containerized/microservice based applications. This role requires:', '5 years experience implementing/operating cloud based, on-prem infrastructure and containerized environment', 'Extensive Azure environment development', 'Extensive experience in developing automation via tools such as Ansible, Puppet', 'Ability to document designs, runbooks, KB articles, and provide TOIs/Training for operational support transition', 'Ability to multi-task and self-prioritize multiple parallel projects', 'Ability to lead troubleshooting and drive complex issues that requires multiple disciplines (network, security, compute, storage, etc.) to resolution', 'Ability to ""self-teach"" new technologies and become subject matter expert as needed', 'In-depth knowledge of Kubernetes/Container deployments (OpenShift and Rancher)', 'Experience building/supporting cloud based environments (Azure) as well as on-prem cloud platforms (VMWare, Openstack, Openshift)', 'Kubernetes, Docker, OpenShift as well as knowledge on how to migrate legacy platforms to containerized environments. (on-boarding users)', 'OpenStack, KVM, RabbitMQ, MariaDB, MongoDB, ElasticSearch', 'Puppet, Ansible', 'Azure ExpressRoute, Automation, RBAC', 'Prometheus, Grafana monitoring', 'Implement and engineer Rancher on-prem for a potential PaaS', 'Management and implementation of NetApp HCI, Cisco UCS', 'Build/Develop containerized CI/CD pipelines (Jenkins, BitBucket, DevOps practices)', 'Ability to learn and quickly come up to speed on new technologies', 'DevOps Engineer - Raleigh, NCFull-timeResponsibilitiesAs a DevOps engineer, you can expect your day-to-day responsibilities to include:Create CI/CD pipelines.Extend, or implement, CI/CD pipelines via Jenkins/GitOpsCollaborate across time zones (CA, RTP, Bengaluru), teams, and business functions as needed for team projects.Promote our DevOps best practices by collaborating with developers/managers during various phases of development.Support services, tools, modules, and applications to improve the quality of life for software development engineers and operations engineers.Debugging issues that arise for applications/services running in our Kubernetes clusters.Implement tooling and integrations that improve security posture of platform and our customers/teams.Automation and simplification of existing processes and runbooks.Job Qualifications:You will need to have hands-on experience, or certifications, in the following:Kubernetes (AKS, AWS EKS, GKE, K3S, OpenShift)Amazon Web Services (AWS) / Microsoft Azure / Google CloudHelmJenkinsSource code management tools such as GitHub/GitLab/BitbucketEducationTypically requires a minimum of 5 years of related experience with a Bachelor’s degree; or 3 years and a Master’s degree; or a PhD without experience; or equivalent work experience.Education / Experience:Bachelors/Master’s degree in a technical discipline (or 5+ years of industry experience)3+ years of relevant technical experience in a DevOps3+ years of software development experience with OO languages (ruby, python, java, c++, etc.)5+ years of relevant technical experience with the Linux operating system.', 'Create CI/CD pipelines.', 'Extend, or implement, CI/CD pipelines via Jenkins/GitOps', 'Collaborate across time zones (CA, RTP, Bengaluru), teams, and business functions as needed for team projects.', 'Promote our DevOps best practices by collaborating with developers/managers during various phases of development.', 'Support services, tools, modules, and applications to improve the quality of life for software development engineers and operations engineers.', 'Debugging issues that arise for applications/services running in our Kubernetes clusters.', 'Implement tooling and integrations that improve security posture of platform and our customers/teams.', 'Automation and simplification of existing processes and runbooks.', 'You will need to have hands-on experience, or certifications, in the following:', 'Kubernetes (AKS, AWS EKS, GKE, K3S, OpenShift)', 'Amazon Web Services (AWS) / Microsoft Azure / Google Cloud', 'Helm', 'Jenkins', 'Source code management tools such as GitHub/GitLab/Bitbucket', 'Bachelors/Master’s degree in a technical discipline (or 5+ years of industry experience)', '3+ years of relevant technical experience in a DevOps', '3+ years of software development experience with OO languages (ruby, python, java, c++, etc.)', '5+ years of relevant technical experience with the Linux operating system.', ""Site Reliability Engineer - Raleigh, NCFull-timeJob SummaryAs a Site Reliability Engineer, you’ll work to maintain cloud services performing at levels both promised and expected by our external customer base. You'll work in a highly collaborative environment deploying, monitoring, and maintaining systems hosting our IaaS model. This position includes on-call work due to the critical nature of the services we support.Job RequirementsAutomate repetitive and error prone tasks and processes, using tools like Docker, GitLab, Ansible, C#, Python, Bash and other languages.Administer NetApp remote, cloud-based storage solutions. Experience with managing NetApp storage solutions is a big plus.Administer cloud-based solutions and orchestrate the deployment of Kubernetes containerized applications.Ensure adequate monitoring is in place and enhance or adjust where needed, using tools like Prometheus in addition to proprietary NetApp monitoring solutions and home-grown scripts / automation. You'll continuously measure the availability, latency and overall system health.Secure our environment from security threats deploying patches and least-privilege configurations.Respond to incidents and drive change preventing issues from re-occurring. You will also look for opportunities to automate the recovery for certain incidents that may be difficult to prevent. You will use Atlassian Jira to track issues to resolution based on their priority.Design and implement tools for automated deployment and monitoring of multiple environments.Document findings and solutions you create using Atlassian Confluence as well as well-documented automation.EducationTypically requires a minimum 5 years of related experience with a bachelor’s degree; or 3 years and a Master’s degree; or a PhD without experience; or equivalent work experience."", 'Automate repetitive and error prone tasks and processes, using tools like Docker, GitLab, Ansible, C#, Python, Bash and other languages.', 'Administer NetApp remote, cloud-based storage solutions. Experience with managing NetApp storage solutions is a big plus.', 'Administer cloud-based solutions and orchestrate the deployment of Kubernetes containerized applications.', ""Ensure adequate monitoring is in place and enhance or adjust where needed, using tools like Prometheus in addition to proprietary NetApp monitoring solutions and home-grown scripts / automation. You'll continuously measure the availability, latency and overall system health."", 'Secure our environment from security threats deploying patches and least-privilege configurations.', 'Respond to incidents and drive change preventing issues from re-occurring. You will also look for opportunities to automate the recovery for certain incidents that may be difficult to prevent. You will use Atlassian Jira to track issues to resolution based on their priority.', 'Design and implement tools for automated deployment and monitoring of multiple environments.', 'Document findings and solutions you create using Atlassian Confluence as well as well-documented automation.', ""Site Reliability Engineer - TS/SCI with POLY - Vienna, VAFull-timeJob SummaryAt NetApp, we have an amazing opportunity to transform industries with cutting-edge data services. We are developing a broad portfolio of solutions that harness the power of data. NetApp public/private cloud offerings, high performance & highly scalable storage products are stretching what’s possible for our customers & partners. These solutions change how data is stored, consumed & interpreted unleashing innovation. Join our team & push the boundaries of what’s possible.As a Site Reliability Engineer, you’ll work to maintain cloud services performing at levels both promised and expected by our external customer base. You'll work in a highly collaborative environment deploying, monitoring, and maintaining systems hosting our IaaS model. This role is an office-based position in the Washington D.C or RTP, NC areas. This position includes on-call work due to the critical nature of the services we support.Duties and ResponsibilitiesAdminister NetApp remote and cloud-based storage solutions. Assist with capacity planning to ensure continuous performance expectations are met.Automate repetitive and error prone tasks and processes, using tools like Docker, GitLab, Ansible, Python, Bash and other scripting languages.Administer SaaS / cloud-based solutions like OpenShift or Kubernetes that deploy and orchestrate containerized applications.Ensure adequate monitoring is in place and enhance or adjust where needed, using tools like Observium, ElasticSearch, Prometheus in addition to proprietary NetApp monitoring solutions and home-grown scripts / automation. You'll continuously measure the availability, latency and overall system health.Secure our environment from security threats deploying patches and least-privilege configurations.Respond to incidents and drive change preventing issues from re-occurring. You will also look for opportunities to automate the recovery for certain incidents that may be difficult to prevent. You will use Atlassian Jira to track issues to resolution based on their priority.Design and implement tools for automated deployment and monitoring of multiple environments.Document findings and solutions you create using Atlassian Confluence as well as well-documented automation.Key CharacteristicsDoD TS/SCI security clearance requiredYou are generally curious and highly motivated with a passion for ensuring scalable and highly available solutions.Strong interpersonal skills including verbal and written communication skills.You are great at solving problems, sorting meaningful information from noise, and taking action.Familiarity with operating systems such as Linux, CentOS, Ubuntu and Windows.A basic understanding of at least one scripting language similar to Bash, Python, or Pearl, Ruby.A basic understanding of public cloud vendors such as AWS, Azure, Google Cloud or others.A Bachelor of Science Degree is preferred.EducationTypically requires a minimum 5 years of related experience with a bachelor’s degree; or 3 years and a Master’s degree; or a PhD without experience; or equivalent work experience."", 'Administer NetApp remote and cloud-based storage solutions. Assist with capacity planning to ensure continuous performance expectations are met.', 'Automate repetitive and error prone tasks and processes, using tools like Docker, GitLab, Ansible, Python, Bash and other scripting languages.', 'Administer SaaS / cloud-based solutions like OpenShift or Kubernetes that deploy and orchestrate containerized applications.', ""Ensure adequate monitoring is in place and enhance or adjust where needed, using tools like Observium, ElasticSearch, Prometheus in addition to proprietary NetApp monitoring solutions and home-grown scripts / automation. You'll continuously measure the availability, latency and overall system health."", 'Secure our environment from security threats deploying patches and least-privilege configurations.', 'Respond to incidents and drive change preventing issues from re-occurring. You will also look for opportunities to automate the recovery for certain incidents that may be difficult to prevent. You will use Atlassian Jira to track issues to resolution based on their priority.', 'Design and implement tools for automated deployment and monitoring of multiple environments.', 'Document findings and solutions you create using Atlassian Confluence as well as well-documented automation.', 'DoD TS/SCI security clearance required', 'You are generally curious and highly motivated with a passion for ensuring scalable and highly available solutions.', 'Strong interpersonal skills including verbal and written communication skills.', 'You are great at solving problems, sorting meaningful information from noise, and taking action.', 'Familiarity with operating systems such as Linux, CentOS, Ubuntu and Windows.', 'A basic understanding of at least one scripting language similar to Bash, Python, or Pearl, Ruby.', 'A basic understanding of public cloud vendors such as AWS, Azure, Google Cloud or others.', 'A Bachelor of Science Degree is preferred.', 'Sr. Director Product and UX Transformation - GA, TX, NC, RemoteFull-timeJob SummaryNetApp is seeking a visionary leader for product transformation of our existing hybrid-cloud portfolio of products. This leader will own the simplified customer experience across the portfolio, accelerating the path to SaaS readiness and an API first approach. NetApp is seeking someone who embraces disruptive innovation to make a fast and furious transformation by creating and executing on a collaborative product vision for UX across engineering while building alignment and alliances across all business units. This role will report directly to the VP of Engineering for Manageability and Data Protection.You are a fit for this role if you have led UX transformations and have strong corporate leadership experience. The best candidate will bring a strategic consultative approach to the organization for end-to-end customer experience across the portfolio for enhancements to existing products, as well as new SaaS focused product development. NetApp is seeking a charismatic leader who is adept at deep diving at the technical level and working closely with product management and technical leaders across all aspects of the product. The top candidate for this role has been responsible for curating and maintaining a holistic user, business and technology appropriate experience. NetApp is seeking someone that has a proven record of being able to optimize and enhance the consumer experience by striking a balance between the best way to solve technical problems and the user experience.This leader should have the ability to ignite passion, excitement, and action among people throughout NetApp. He/she should have a designer mindset to take the organizational capabilities and turn them into experience offerings. He/she should have an orchestrator mindset to align the various elements of the product to fit into a cohesive whole through a customer-delighting theme. He/she should have an evangelist mindset to fight for the needs, wants and desires of customers and make sure that the company’s offerings create value on behalf of each individual guest.Job RequirementsKey responsibilities for this role include:Enrich UX by bringing a transformation of various NetApp value streams under a unified experience for customers. Ability to eliminate the complexity from our core products. Understand the industry and our enterprise customer base.Fostering an understanding throughout the organization of the buyer’s journey and customer life cycle and how they will be evolving as the industry moves to SaaS model. Advocating for consumer needs in the development and deployment of projects and strategies throughout the organization.Managing a product team including UX designers and researchers.Measuring and tracking overall customer experience including APIs.Lead continuous transformation to improve efficiency and increase speed of innovation in line with the company strategy.Essential Job functions:Gain extensive awareness on the product’s strengths and limitations relative to market/consumer trends, competitive threats, market opportunities, and more importantly, consumer experience.Identify and prioritize design problems in the user journeys of our current portfolio of products and devise elegant solutions. Conceptualizing improvements and translating ideas to design and development teams and how they will be evolving as the industry moves to SaaS modelDevelop and evangelize UX vision throughout the organizationMake strategic design and user-experience decisions related to core and new, functions and features.Partner with product management to drive roadmap planning and prioritization discussionsProvide UX direction and guidance to engineering leadership and executive staff, as well as individual contributors. Successfully solve strategic and product UX challenges.Collaborate with cross-functional groups across the organization on corporate UX strategyContinually evaluate practices, methods and strategies to improve customer interactions in line with relevant technology and industry trendsEmphasizing to employees and internal teams the importance of understanding consumers and their motivations, the ease of their encounters and their takeawaysHaving an appreciation for collecting and analyzing data to continuously modify and improve the user experience.Provide leadership, mentoring and guidance to senior technical staff membersEducationB.S or M.S5-8 years of experience in SaaS centric UX transformation of enterprise class productsStrong understanding of Server and compute virtualization. Deep understanding of the container ecosystem with Docker and Kubernetes.Experience with APIs. AI/ML experience a bonus.Common soft skills exemplary written and verbal communication abilities, leadership prowess and an aptitude for problem solving.', 'Enrich UX by bringing a transformation of various NetApp value streams under a unified experience for customers. Ability to eliminate the complexity from our core products. Understand the industry and our enterprise customer base.', 'Fostering an understanding throughout the organization of the buyer’s journey and customer life cycle and how they will be evolving as the industry moves to SaaS model. Advocating for consumer needs in the development and deployment of projects and strategies throughout the organization.', 'Managing a product team including UX designers and researchers.', 'Measuring and tracking overall customer experience including APIs.', 'Lead continuous transformation to improve efficiency and increase speed of innovation in line with the company strategy.', 'Gain extensive awareness on the product’s strengths and limitations relative to market/consumer trends, competitive threats, market opportunities, and more importantly, consumer experience.', 'Identify and prioritize design problems in the user journeys of our current portfolio of products and devise elegant solutions. Conceptualizing improvements and translating ideas to design and development teams and how they will be evolving as the industry moves to SaaS model', 'Develop and evangelize UX vision throughout the organization', 'Make strategic design and user-experience decisions related to core and new, functions and features.', 'Partner with product management to drive roadmap planning and prioritization discussions', 'Provide UX direction and guidance to engineering leadership and executive staff, as well as individual contributors. Successfully solve strategic and product UX challenges.', 'Collaborate with cross-functional groups across the organization on corporate UX strategy', 'Continually evaluate practices, methods and strategies to improve customer interactions in line with relevant technology and industry trends', 'Emphasizing to employees and internal teams the importance of understanding consumers and their motivations, the ease of their encounters and their takeaways', 'Having an appreciation for collecting and analyzing data to continuously modify and improve the user experience.', 'Provide leadership, mentoring and guidance to senior technical staff members', 'B.S or M.S', '5-8 years of experience in SaaS centric UX transformation of enterprise class products', 'Strong understanding of Server and compute virtualization. Deep understanding of the container ecosystem with Docker and Kubernetes.', 'Experience with APIs. AI/ML experience a bonus.', 'Common soft skills exemplary written and verbal communication abilities, leadership prowess and an aptitude for problem solving.', ""Senior Endpoint Engineer - Raleigh, NC or RemoteFull-timeJob SummaryThis position has primary responsibility for analysis, design, implementation, maintenance, and operational aspects of the Endpoint Security tools and systems. Responsible for service ownership and operation of WIN10 OS and applicable security agents for admin rights management, data loss prevention, encryption, endpoint discovery and response etc.Responsible for acquiring, installing, or upgrading security components and software, providing routine automation, maintaining security policies, troubleshooting, training staff, and offering technical support for projects.Must have skills:Experience directly managing multiple endpoint security products including Antivirus, Admin Rights Management, Data loss prevention, encryption, endpoint discovery and response.Understand inner workings of WIN10 and how best to secure or harden itAbility to clearly explain and justify ideas when faced with competing alternativesAbility to quickly ramp up, understand complex problems, and create solutions across many products (e.g. Windows, Office, Enterprise Management, Azure)Strong understanding of infrastructure and related technologies (hardware, virtualization, networking)Strong understanding of enterprise productivity and communications related technologies (messaging, unified communications, collaboration)Experience in complex projects with division or company-wide scopeBe a self-starter who can flourish in a dynamic technology companyRemains current on emerging technologies and conducts independent research to support business needs and requirements.Job RequirementsStrong working knowledge in Office365 and its related online products (e.g. SharePoint Online, Exchange Online, Teams/Skype, Azure AD, Security and Compliance)Ability to work independently with some guidance from supervisor/managerStrong analytical skills; Able to assess and solve issues in a high-pressure environment.Able to work effectively with other groups and teams.Scripting and/or programming (Power Shell, Python, .net or other)Ability to interface with customers to quickly understand the problem, relate to the customer and remain calm under pressureAble to partner with peers to brainstorm, troubleshoot and collaboration on solutionsStrong experience in vendor management and participation in depth technical troubleshootingWillingness and ability to mentor junior members of the teamSkilled in device compliance monitoring and reportingJob Requirements Con't & EducationYou might also have:A degree or equivalent experience in Computer Science or related field.SQL Reporting and query writing experienceStrong familiarity with PowerBI and other reporting toolsExperience with Microsoft cloud technologies such as Azure AD, Azure Information Protection, Cloud App Security and Defender ATPAutomation skills (tool agnostic) and the ability to drive initiatives to automate processes.Experience with managing and administrating IntuneExperience in cyber security and red team/blue team activitiesEducationPreferred 5 years of related experience with a Bachelor’s degree or equivalent work experience."", 'Experience directly managing multiple endpoint security products including Antivirus, Admin Rights Management, Data loss prevention, encryption, endpoint discovery and response.', 'Understand inner workings of WIN10 and how best to secure or harden it', 'Ability to clearly explain and justify ideas when faced with competing alternatives', 'Ability to quickly ramp up, understand complex problems, and create solutions across many products (e.g. Windows, Office, Enterprise Management, Azure)', 'Strong understanding of infrastructure and related technologies (hardware, virtualization, networking)', 'Strong understanding of enterprise productivity and communications related technologies (messaging, unified communications, collaboration)', 'Experience in complex projects with division or company-wide scope', 'Be a self-starter who can flourish in a dynamic technology company', 'Remains current on emerging technologies and conducts independent research to support business needs and requirements.', 'Strong working knowledge in Office365 and its related online products (e.g. SharePoint Online, Exchange Online, Teams/Skype, Azure AD, Security and Compliance)', 'Ability to work independently with some guidance from supervisor/manager', 'Strong analytical skills; Able to assess and solve issues in a high-pressure environment.', 'Able to work effectively with other groups and teams.', 'Scripting and/or programming (Power Shell, Python, .net or other)', 'Ability to interface with customers to quickly understand the problem, relate to the customer and remain calm under pressure', 'Able to partner with peers to brainstorm, troubleshoot and collaboration on solutions', 'Strong experience in vendor management and participation in depth technical troubleshooting', 'Willingness and ability to mentor junior members of the team', 'Skilled in device compliance monitoring and reporting', 'A degree or equivalent experience in Computer Science or related field.', 'SQL Reporting and query writing experience', 'Strong familiarity with PowerBI and other reporting tools', 'Experience with Microsoft cloud technologies such as Azure AD, Azure Information Protection, Cloud App Security and Defender ATP', 'Automation skills (tool agnostic) and the ability to drive initiatives to automate processes.', 'Experience with managing and administrating Intune', 'Experience in cyber security and red team/blue team activities', 'Product Configuration Manager - Raleigh, NCFull-timeJob SummaryThe Product Configuration Manager (PCM) will be part of a highly collaborative and energetic Agile team responsible for enabling products and services in NetApp’s configuration/quoting platform. The PCM will report to the Manager of the Product Configuration Management team. The selected person will partner with the business and act as a trusted advisor/consultant to help deliver end-to-end solutions to our sales force and partners. Forming strong partnerships with organizations across the Enterprise such as Product Management, Manufacturing Operations and Sales is critical. The successful candidate will have a demonstrated track record of strategic leadership and providing innovative approaches to problem solving, while maintaining a detail oriented outlook. Ability to understand the current IT environment, with an emphasis on the Agile Software Development Lifecycle (SDLC) approach product ownership role, while possessing a depth of product knowledge that will allow this candidate to define solutions fitting into NetApp’s manufacturing and sales processes. A key success factor for the individual in this role will be to work collaboratively with numerous IT and business teams as a Product Owner.Job RequirementsEssential Functions: Provide vision, strategy and leadership in creating, evolving and driving NetApp’s Product introduction and enhancement process. Partner with delivery leads during the execution of projects and support the use of software development methodologies, change management, QA and Release Management processes consistent with the standards established by IT. Facilitate communication and collaboration across Strategic Enablement and IT teams to ensure strong teamwork. SKU and Bill of Material creation and lifecycle management. Own the creation, management, testing and grooming of user stories and managing quality. Manage special projects as assigned.\t\xa0Requirements: Solid understanding of Quote to Invoice business processes. Excellent verbal and written communications skills; presentation, customer service, business, and negotiation skills. Ability to build strong working relationships across all levels of the organization. Effective leadership skills needed to manage cross-functional teams successfully. Agile and/or Oracle bill of material experience, including a strong background in understanding complex product structures. Ability to be successful in a fast-paced, dynamic environment with competing priorities. Broad understanding of NetApp’s products and services technologies highly desired. Practical work experience with Agile methodologies. Working knowledge of SaaS principles: Quoting, Subscription Management, Billing and Revenue Recognition.\t\xa0Interaction: This individual must work effectively with Staff to Sr. Director level employees within the function, across functions and with external parties. Play a significant role in assigned scrum teams including sprint execution, testing, and review & release. Limited supervision and direction is provided as this individual can operate and drive results and set priorities independently. The ideal candidate will be a proactive contributor and subject matter expert. To be successful, this individual must demonstrate favorable results through regular leadership and influencing others.Education5-8 years of experience is preferredA Bachelor of Arts or Science degree is required (or equivalent experience).Oracle Cloud CPQ experience is a plus', 'Essential Functions: Provide vision, strategy and leadership in creating, evolving and driving NetApp’s Product introduction and enhancement process. Partner with delivery leads during the execution of projects and support the use of software development methodologies, change management, QA and Release Management processes consistent with the standards established by IT. Facilitate communication and collaboration across Strategic Enablement and IT teams to ensure strong teamwork. SKU and Bill of Material creation and lifecycle management. Own the creation, management, testing and grooming of user stories and managing quality. Manage special projects as assigned.', 'Requirements: Solid understanding of Quote to Invoice business processes. Excellent verbal and written communications skills; presentation, customer service, business, and negotiation skills. Ability to build strong working relationships across all levels of the organization. Effective leadership skills needed to manage cross-functional teams successfully. Agile and/or Oracle bill of material experience, including a strong background in understanding complex product structures. Ability to be successful in a fast-paced, dynamic environment with competing priorities. Broad understanding of NetApp’s products and services technologies highly desired. Practical work experience with Agile methodologies. Working knowledge of SaaS principles: Quoting, Subscription Management, Billing and Revenue Recognition.', 'Interaction: This individual must work effectively with Staff to Sr. Director level employees within the function, across functions and with external parties. Play a significant role in assigned scrum teams including sprint execution, testing, and review & release. Limited supervision and direction is provided as this individual can operate and drive results and set priorities independently. The ideal candidate will be a proactive contributor and subject matter expert. To be successful, this individual must demonstrate favorable results through regular leadership and influencing others.', '5-8 years of experience is preferred', 'A Bachelor of Arts or Science degree is required (or equivalent experience).', 'Oracle Cloud CPQ experience is a plus', ""Licensing Product Manager - Raleigh, NCFull-timeJob SummaryAs a Licensing Product Manager, you will develop and manage the licensing requirements and implementation models required to support the entitlement management of NetApp’s hardware and software portfolio. This will be accomplished through a thorough understanding of the monetization methods the offerings provide and alignment with NetApp’s strategic intent of developing new business models. This will be accomplished through analyzing and understanding customer needs, market trends, market segmentations, technology shifts, and the competitive environment. Your primary role will be in developing and implementing licensing strategies and implementation models for NetApp’s portfolio.As a member of NetApp’s Licensing team, you will:Design company strategies for licensing models and entitlement management requirements, help resolve compliance issues and perform research for product competitionCoordinate with product management team to deliver licensing solutions that align to GTM models and monetization objectivesPartner with Pricing leads and Product owners on developing GTM methodologies as it relates to licensing and pricing objectivesCollaborate with field sales personnel and evaluate all process activities and establish operational policies to ensure simple, smooth delivery of any entitlement solutionsManage and evaluate ability to comply to entitlement objectives, any corporate governance regulations for licensing activities and ensure implementation aligns to those objectivesMaintain knowledge on compliance trends and recommend changes for all company processesAnalyze and recommend improvements to all internal procedures and implement sameJob RequirementsExperience in the licensing domain, ideally with an enterprise software or hardware organizationExperience in migrating perpetual licensing models to more dynamic, fluid models such as consumption, subscription and or Cloud based licensing infrastructuresStrong analytical skills and ability to work both independently and lead cross functional teamsExcellent verbal and written communications skills; presentation, customer service, business, and negotiation skillsAbility to build strong working relationships across all levels of the organization, including remote areasAbility to function well in a fast-paced, dynamic environment with competing prioritiesExcellent understanding of NetApp's products and services technologies/concepts in a distributed environmentResponsibility and Interaction:Responsibility:The tasks this individual is responsible for are often unstructured, have wide implications and there are multiple outcomesThis individual will apply broad expertise or unique technical/industry knowledge in solving problems that are unique and complex given time, budget and resource constraintsDemonstrate leadership and vision in determining and driving strategy decisionsInteraction:This individual must work effectively with Staff to Vice President level employees within the function, across functions and with external partiesUnder limited supervision, this individual can operate, drive results, and set priorities independentlyThe ideal candidate will be a proactive contributor and subject matter expertTo be successful, this individual must demonstrate favorable results through leadership and influencing multiple individuals and groups.Often acts as mentor or facilitator to peer groups in IT, Finance, Sales Operations, and or Product Management teamsEducationA minimum of 8 years of experience is required.The position requires a bachelor’s degree in business administration, engineering, or a related analytical field and at least three years of experience in a licensing implementation, licensing management and or licensing strategy position with an enterprise technology vendor.Must have the following skill set (evidenced by prior experience or graduate-level coursework): licensing implementation, entitlement management, licensing methodologies and tactics; predicting market trends; competitive research; product research; product release; and giving presentations to large audiences."", 'Design company strategies for licensing models and entitlement management requirements, help resolve compliance issues and perform research for product competition', 'Coordinate with product management team to deliver licensing solutions that align to GTM models and monetization objectives', 'Partner with Pricing leads and Product owners on developing GTM methodologies as it relates to licensing and pricing objectives', 'Collaborate with field sales personnel and evaluate all process activities and establish operational policies to ensure simple, smooth delivery of any entitlement solutions', 'Manage and evaluate ability to comply to entitlement objectives, any corporate governance regulations for licensing activities and ensure implementation aligns to those objectives', 'Maintain knowledge on compliance trends and recommend changes for all company processes', 'Analyze and recommend improvements to all internal procedures and implement same', 'Experience in the licensing domain, ideally with an enterprise software or hardware organization', 'Experience in migrating perpetual licensing models to more dynamic, fluid models such as consumption, subscription and or Cloud based licensing infrastructures', 'Strong analytical skills and ability to work both independently and lead cross functional teams', 'Excellent verbal and written communications skills; presentation, customer service, business, and negotiation skills', 'Ability to build strong working relationships across all levels of the organization, including remote areas', 'Ability to function well in a fast-paced, dynamic environment with competing priorities', ""Excellent understanding of NetApp's products and services technologies/concepts in a distributed environment"", 'The tasks this individual is responsible for are often unstructured, have wide implications and there are multiple outcomes', 'This individual will apply broad expertise or unique technical/industry knowledge in solving problems that are unique and complex given time, budget and resource constraints', 'Demonstrate leadership and vision in determining and driving strategy decisions', 'This individual must work effectively with Staff to Vice President level employees within the function, across functions and with external parties', 'Under limited supervision, this individual can operate, drive results, and set priorities independently', 'The ideal candidate will be a proactive contributor and subject matter expert', 'To be successful, this individual must demonstrate favorable results through leadership and influencing multiple individuals and groups.', 'Often acts as mentor or facilitator to peer groups in IT, Finance, Sales Operations, and or Product Management teams', 'A minimum of 8 years of experience is required.', 'The position requires a bachelor’s degree in business administration, engineering, or a related analytical field and at least three years of experience in a licensing implementation, licensing management and or licensing strategy position with an enterprise technology vendor.', 'Must have the following skill set (evidenced by prior experience or graduate-level coursework): licensing implementation, entitlement management, licensing methodologies and tactics; predicting market trends; competitive research; product research; product release; and giving presentations to large audiences.', 'Technical Director - Raleigh, NCFull-timeJob SummaryNetApp is seeking a Technical Director for Manageability and Data protection domain. As a Technical Director of Software Engineering you hold the most senior position in the R & D function as an individual contributor. You provide strong leadership and a strategic consultative role to the organization as related to driving product development and strategy. As part of the Research and Development function, the overall focus of the group is on competitive market and customer requirements, technology advances, product quality, product cost and time-to-market. The Software Development function is responsible for enhancements to existing products as well as new product development.Job ResponsibilitiesA major part of your responsibility will be to work on issues that impact development success or address future concepts, products or technologies.Develop and evangelize technical vision within engineering organization and extend NetApp’s IP portfolioPartner with product management to drive roadmap planning and prioritization discussionsAbility to translate product requirements and challenges into a scalable and sustainable architecture influencing the technical directionProvide technical direction and guidance to engineering leadership and executive staff.Successfully solve strategic and product execution challenges.Align product direction by successfully recognizing relevant technology and industry trendsProvide leadership, mentoring and guidance to senior technical staff membersSuccessfully negotiate strategic and other issues which effect the business internally and externally.Must be a seasoned communicator and presenter.Maintain affiliations and relationships with academic and industry technical experts globally and serve as external spokesperson for the company.Job RequirementsStrong understanding of Server and compute virtualization, hypervisors and virtual machine management.Knowledge of multiple hypervisor stacks, namely VMware and KVMContainers and OS virtualization – deep understanding of the container ecosystem with Docker and Kubernetes.Able to design complex microservices based architecturesProficiency with automating deployment, scaling, load balancing and management of containerized applicationsGood understanding of networking internals, L2 and L3 switching/routing, Virtual and Software Defined networkingStrong concepts around Virtual Private Cloud, network security (IPSec/TLS)Knowledge of network congestion management and complex system managementEducationTypically requires a minimum of 15 years of related experience with a Bachelor’s degree; or 12 years and a Master’s degree; or a PhD with 8 years experience; or equivalent experience.', 'A major part of your responsibility will be to work on issues that impact development success or address future concepts, products or technologies.', 'Develop and evangelize technical vision within engineering organization and extend NetApp’s IP portfolio', 'Partner with product management to drive roadmap planning and prioritization discussions', 'Ability to translate product requirements and challenges into a scalable and sustainable architecture influencing the technical direction', 'Provide technical direction and guidance to engineering leadership and executive staff.', 'Successfully solve strategic and product execution challenges.', 'Align product direction by successfully recognizing relevant technology and industry trends', 'Provide leadership, mentoring and guidance to senior technical staff members', 'Successfully negotiate strategic and other issues which effect the business internally and externally.', 'Must be a seasoned communicator and presenter.', 'Maintain affiliations and relationships with academic and industry technical experts globally and serve as external spokesperson for the company.', 'Strong understanding of Server and compute virtualization, hypervisors and virtual machine management.', 'Knowledge of multiple hypervisor stacks, namely VMware and KVM', 'Containers and OS virtualization – deep understanding of the container ecosystem with Docker and Kubernetes.', 'Able to design complex microservices based architectures', 'Proficiency with automating deployment, scaling, load balancing and management of containerized applications', 'Good understanding of networking internals, L2 and L3 switching/routing, Virtual and Software Defined networking', 'Strong concepts around Virtual Private Cloud, network security (IPSec/TLS)', 'Knowledge of network congestion management and complex system management', 'Data Warehouse Engineer - Raleigh, NCFull-timeJob SummaryYou will be part of Enterprise Data & Analytics team responsible for identifying analytical needs, exploring new technologies, and applying data sciences/machine learning concepts to maximize value from data assets. Senior Data Engineer will work closely with key stakeholders both IT and Business to turn data into critical information and knowledge that can be used to make sound business decisions. The individual must have an in-depth understanding of the business environment, an interest in going beyond the obvious, aptitude for new tools/technologies, and obsession for customer success.Essential FunctionsOrganize, lead, and facilitate multiple teams on highly complex, cross-functional, enterprise data and analytics initiativesDevelop and maintain scalable data pipelines and build out new integrations to support continuing increases in demand for various types of dataCollaborate with business, solution/enterprise architects to translate business requirements into scalable solution options and provide input to Business Analytics and Master Data roadmap/strategyProvide input to business requirements and prepares functional requirement document along with solution optionsCollaborate with key stakeholders to define KPI and build data metrics to measure KPI’sPartner with business in data analysis (small and big) and demonstrate good judgment in solving problems as well as proactively identifying and resolving data issuesAnalyze data with new perspectives and creative approaches to less defined issues involving unstructured and ambiguous dataExplores enterprise data and discovers patterns, meaningful relationships, anomalies and trends to generate actionable insightsDesign and Implement reconciliation processes and systems to monitor data quality to ensure data is accuracy, completeness, and that reconciles with source systemsJob RequirementsMust possess strong subject matter expertise in at least two domains of Sales, Marketing, Install Base, Finance, and Customer Support areas.Demonstrated ability to have completed multiple, complex technical projectsData modeling experience in Enterprise Data Warehouse and DataMartHands-on experience in SQL, Python, NoSQL, JSON, XML, SSL, RESTful APIs, and other related standardsHands-on emphasis with a proven track record of building and evaluating data pipes, and delivering systems for final productionMust have strong data orientation and keen aptitude to explore innovative ways to analyze dataExposure to Big Data Analytics (data and technologies), Data Sciences, predictive analytics, modelling, machine learning, in-memory applicationsExperience with various data systems like Oracle Data Warehouse, SAP HANA, Hadoop/Hive, Vertica, Redshift, Presto, MangodbExperience in all phases of a Software Development Life Cycle. Well versed in different project life cycle management methodologies – Waterfall and Agile.Strong understanding devops, on-premise, and cloud deployments - AWS, Google, AzureStrong written and verbal communication skillsExcellent problem solving and troubleshooting skillsEducationA minimum of 7 years of experience is required, including 3+ years solid relevant experience in Business Analytics.Bachelor of Science Degree in Computer Science, Management Information Systems, or Business, or related field is required', 'Organize, lead, and facilitate multiple teams on highly complex, cross-functional, enterprise data and analytics initiatives', 'Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in demand for various types of data', 'Collaborate with business, solution/enterprise architects to translate business requirements into scalable solution options and provide input to Business Analytics and Master Data roadmap/strategy', 'Provide input to business requirements and prepares functional requirement document along with solution options', 'Collaborate with key stakeholders to define KPI and build data metrics to measure KPI’s', 'Partner with business in data analysis (small and big) and demonstrate good judgment in solving problems as well as proactively identifying and resolving data issues', 'Analyze data with new perspectives and creative approaches to less defined issues involving unstructured and ambiguous data', 'Explores enterprise data and discovers patterns, meaningful relationships, anomalies and trends to generate actionable insights', 'Design and Implement reconciliation processes and systems to monitor data quality to ensure data is accuracy, completeness, and that reconciles with source systems', 'Must possess strong subject matter expertise in at least two domains of Sales, Marketing, Install Base, Finance, and Customer Support areas.', 'Demonstrated ability to have completed multiple, complex technical projects', 'Data modeling experience in Enterprise Data Warehouse and DataMart', 'Hands-on experience in SQL, Python, NoSQL, JSON, XML, SSL, RESTful APIs, and other related standards', 'Hands-on emphasis with a proven track record of building and evaluating data pipes, and delivering systems for final production', 'Must have strong data orientation and keen aptitude to explore innovative ways to analyze data', 'Exposure to Big Data Analytics (data and technologies), Data Sciences, predictive analytics, modelling, machine learning, in-memory applications', 'Experience with various data systems like Oracle Data Warehouse, SAP HANA, Hadoop/Hive, Vertica, Redshift, Presto, Mangodb', 'Experience in all phases of a Software Development Life Cycle. Well versed in different project life cycle management methodologies – Waterfall and Agile.', 'Strong understanding devops, on-premise, and cloud deployments - AWS, Google, Azure', 'Strong written and verbal communication skills', 'Excellent problem solving and troubleshooting skills', 'A minimum of 7 years of experience is required, including 3+ years solid relevant experience in Business Analytics.', 'Bachelor of Science Degree in Computer Science, Management Information Systems, or Business, or related field is required', ""Channel Development Manager - Vienna, VAFull-timeJob SummaryAs a Channel Development Manager you will focus on current and prospective Channel Partners in a specific area and develop strategies to increase NetApp's Products and Services sales through those defined Partners. The role requires strong communication and collaboration skills combined with a sense of urgency to drive revenue generation for the assigned Region and Area. This role is based in NetApp's Vienna, VA office with a focus on the US Federal government.Job RequirementsEssential Functions:Maintain and deepen relationships with Channel Partners to create increased sales opportunities.Develop and maintain a sales strategy and business plan for account and communicating to regional sales managers and district sales. Use the business plan as a roadmap for a 'Go to Market' and program development, including sales goals.Contract management.Develop sales forecasts while achieving monthly, quarterly, and annual sales targets.Act as a trusted and valued resource to our Channel Partners.Collaborate with field marketing organization to plan, deliver, and manage an effective communication and demand generation campaign for Channel Partners.Requirements:Excellent verbal and written communications skills, presentation, customer service, business and negotiation skills.Ability to travel within assigned region, working closely with Districts Managers, Sales Representatives, and Channel Partners.A strong understanding of the sales process and Channel Sales.High energy with the capability to multi-task in a dynamic, rapidly growing organization.A thorough understanding of go-to-market strategies including account segmentation, products, marketing strategies, etc.Broad exposure to a variety of technologies/concepts in a distributed environment.Education8 to 12 years of experience is preferred.Must be a US citizen.Past experience selling to the US Federal government is required.Past experience successfully selling Storage Management Solutions with Channel Partners.A Bachelor of Arts or Sciences Degree; or related field is preferred.Experience which demonstrates a strong level of expertise in technical specifications required to sell NetApp products and services is required."", 'Maintain and deepen relationships with Channel Partners to create increased sales opportunities.', ""Develop and maintain a sales strategy and business plan for account and communicating to regional sales managers and district sales. Use the business plan as a roadmap for a 'Go to Market' and program development, including sales goals."", 'Contract management.', 'Develop sales forecasts while achieving monthly, quarterly, and annual sales targets.', 'Act as a trusted and valued resource to our Channel Partners.', 'Collaborate with field marketing organization to plan, deliver, and manage an effective communication and demand generation campaign for Channel Partners.', 'Excellent verbal and written communications skills, presentation, customer service, business and negotiation skills.', 'Ability to travel within assigned region, working closely with Districts Managers, Sales Representatives, and Channel Partners.', 'A strong understanding of the sales process and Channel Sales.', 'High energy with the capability to multi-task in a dynamic, rapidly growing organization.', 'A thorough understanding of go-to-market strategies including account segmentation, products, marketing strategies, etc.', 'Broad exposure to a variety of technologies/concepts in a distributed environment.', '8 to 12 years of experience is preferred.', 'Must be a US citizen.', 'Past experience selling to the US Federal government is required.', 'Past experience successfully selling Storage Management Solutions with Channel Partners.', 'A Bachelor of Arts or Sciences Degree; or related field is preferred.', 'Experience which demonstrates a strong level of expertise in technical specifications required to sell NetApp products and services is required.', 'Solution Architect - Vienna, VAFull-timeJob SummaryAs a Solution Architect, you will demonstrate in-depth understanding across a wide range of technology domains. You will have strong interpersonal skills and demonstrate a passion for solving customer business problems. As a member of the sales team, you will help drive revenue growth across your region. You will be adept in interacting, communicating, and partnering with customers, strategic partners, product teams, professional services, and marketing. You will be an advocate and help customers and partners understand NetApp’s best practices, solutions, and products. You will be a key strategic partner and trusted advisor across a variety of Intelligence Community (IC) elements, helping them achieve their goals of digital transformation while maximizing NetApp’s position in current and new accounts. As a Solution Architect, you will report to the Solutions Engineering Manager (SEM), support the sales team in all aspects of the technical sales process, and be an extension of the CTO business unit to facilitate the delivery of road map presentations to strategic partners and customers.Interaction:A Solution Architect spends his or her day listening to and internalizing customer requirements, then helping them to understand how the NetApp portfolio can help their teams retain control of the customer’s most valuable asset, their data. This includes a deep understanding of how the various on-prem and cloud products weave together to form the data fabric, articulating the value that these tools bring to a DevOps environment as well as staying up-to-date on industry trends to act as a consultant to the customer.Job Requirements:Excellent and verbal communication skills.Good interpersonal communication and customer service skills are needed in order work successfully with prospects, customers, and cross-functional teams to meet sales goals.Account management and project management experience.Strong aptitude for learning new technologies and understanding how to utilize them in a customer-facing environment.Ability to follow standard engineering principles and practices.Creative approach to problem solving.Aptitude to align technology solutions to solve customer business challenges.Qualifications:Experience in a customer-facing, sales role such as pre-sales engineer, sales consultant, solutions engineer or solutions architect.Demonstrated ability to quickly adapt to new technologies and concepts.Professional experience architecting large scale solutions in edge, core, and multi-cloud environments.Ability to influence and align teams and business partners to a future state with a focus on value.EducationA minimum of 8 years of experience as an individual contributor.A Bachelor of Arts of Sciences Degree in Electrical Engineering, Computer Science; or related field is required; a Graduate Degree is preferred.Experience which demonstrates a significant level of expertise in technical specifications required to sell NetApp products and services.Knowledge in breadth and depth across a wide variety of enterprise technologies.Security Clearance: Active TS/SCI required; full poly preferred', 'Excellent and verbal communication skills.', 'Good interpersonal communication and customer service skills are needed in order work successfully with prospects, customers, and cross-functional teams to meet sales goals.', 'Account management and project management experience.', 'Strong aptitude for learning new technologies and understanding how to utilize them in a customer-facing environment.', 'Ability to follow standard engineering principles and practices.', 'Creative approach to problem solving.', 'Aptitude to align technology solutions to solve customer business challenges.', 'Experience in a customer-facing, sales role such as pre-sales engineer, sales consultant, solutions engineer or solutions architect.', 'Demonstrated ability to quickly adapt to new technologies and concepts.', 'Professional experience architecting large scale solutions in edge, core, and multi-cloud environments.', 'Ability to influence and align teams and business partners to a future state with a focus on value.', 'A minimum of 8 years of experience as an individual contributor.', 'A Bachelor of Arts of Sciences Degree in Electrical Engineering, Computer Science; or related field is required; a Graduate Degree is preferred.', 'Experience which demonstrates a significant level of expertise in technical specifications required to sell NetApp products and services.', 'Knowledge in breadth and depth across a wide variety of enterprise technologies.', 'NetApp, Raleigh, NC 27709 US', 'NetApp, Atlanta, GA 30342 US', 'NetApp, Austin, TX 78759 US', 'NetApp, Vienna, VA 22182 US', 'Interviews on the spot', 'Wednesday, September 30, 202012:00 PM - 3:00 PM US/Eastern', ""Interviewing via webYou'll receive an email on how to connect."", '111 slots left', 'United States+1', 'United Kingdom+44', '', 'Afghanistan (\u202bافغانستان\u202c\u200e)+93', 'Albania (Shqipëri)+355', 'Algeria (\u202bالجزائر\u202c\u200e)+213', 'American Samoa+1684', 'Andorra+376', 'Angola+244', 'Anguilla+1264', 'Antigua and Barbuda+1268', 'Argentina+54', 'Armenia (Հայաստան)+374', 'Aruba+297', 'Australia+61', 'Austria (Österreich)+43', 'Azerbaijan (Azərbaycan)+994', 'Bahamas+1242', 'Bahrain (\u202bالبحرين\u202c\u200e)+973', 'Bangladesh (বাংলাদেশ)+880', 'Barbados+1246', 'Belarus (Беларусь)+375', 'Belgium (België)+32', 'Belize+501', 'Benin (Bénin)+229', 'Bermuda+1441', 'Bhutan (འབྲུག)+975', 'Bolivia+591', 'Bosnia and Herzegovina (Босна и Херцеговина)+387', 'Botswana+267', 'Brazil (Brasil)+55', 'British Indian Ocean Territory+246', 'British Virgin Islands+1284', 'Brunei+673', 'Bulgaria (България)+359', 'Burkina Faso+226', 'Burundi (Uburundi)+257', 'Cambodia (កម្ពុជា)+855', 'Cameroon (Cameroun)+237', 'Canada+1', 'Cape Verde (Kabu Verdi)+238', 'Caribbean Netherlands+599', 'Cayman Islands+1345', 'Central African Republic (République centrafricaine)+236', 'Chad (Tchad)+235', 'Chile+56', 'China (中国)+86', 'Christmas Island+61', 'Cocos (Keeling) Islands+61', 'Colombia+57', 'Comoros (\u202bجزر القمر\u202c\u200e)+269', 'Congo (DRC) (Jamhuri ya Kidemokrasia ya Kongo)+243', 'Congo (Republic) (Congo-Brazzaville)+242', 'Cook Islands+682', 'Costa Rica+506', 'Côte d’Ivoire+225', 'Croatia (Hrvatska)+385', 'Cuba+53', 'Curaçao+599', 'Cyprus (Κύπρος)+357', 'Czech Republic (Česká republika)+420', 'Denmark (Danmark)+45', 'Djibouti+253', 'Dominica+1767', 'Dominican Republic (República Dominicana)+1', 'Ecuador+593', 'Egypt (\u202bمصر\u202c\u200e)+20', 'El Salvador+503', 'Equatorial Guinea (Guinea Ecuatorial)+240', 'Eritrea+291', 'Estonia (Eesti)+372', 'Ethiopia+251', 'Falkland Islands (Islas Malvinas)+500', 'Faroe Islands (Føroyar)+298', 'Fiji+679', 'Finland (Suomi)+358', 'France+33', 'French Guiana (Guyane française)+594', 'French Polynesia (Polynésie française)+689', 'Gabon+241', 'Gambia+220', 'Georgia (საქართველო)+995', 'Germany (Deutschland)+49', 'Ghana (Gaana)+233', 'Gibraltar+350', 'Greece (Ελλάδα)+30', 'Greenland (Kalaallit Nunaat)+299', 'Grenada+1473', 'Guadeloupe+590', 'Guam+1671', 'Guatemala+502', 'Guernsey+44', 'Guinea (Guinée)+224', 'Guinea-Bissau (Guiné Bissau)+245', 'Guyana+592', 'Haiti+509', 'Honduras+504', 'Hong Kong (香港)+852', 'Hungary (Magyarország)+36', 'Iceland (Ísland)+354', 'India (भारत)+91', 'Indonesia+62', 'Iran (\u202bایران\u202c\u200e)+98', 'Iraq (\u202bالعراق\u202c\u200e)+964', 'Ireland+353', 'Isle of Man+44', 'Israel (\u202bישראל\u202c\u200e)+972', 'Italy (Italia)+39', 'Jamaica+1', 'Japan (日本)+81', 'Jersey+44', 'Jordan (\u202bالأردن\u202c\u200e)+962', 'Kazakhstan (Казахстан)+7', 'Kenya+254', 'Kiribati+686', 'Kosovo+383', 'Kuwait (\u202bالكويت\u202c\u200e)+965', 'Kyrgyzstan (Кыргызстан)+996', 'Laos (ລາວ)+856', 'Latvia (Latvija)+371', 'Lebanon (\u202bلبنان\u202c\u200e)+961', 'Lesotho+266', 'Liberia+231', 'Libya (\u202bليبيا\u202c\u200e)+218', 'Liechtenstein+423', 'Lithuania (Lietuva)+370', 'Luxembourg+352', 'Macau (澳門)+853', 'Macedonia (FYROM) (Македонија)+389', 'Madagascar (Madagasikara)+261', 'Malawi+265', 'Malaysia+60', 'Maldives+960', 'Mali+223', 'Malta+356', 'Marshall Islands+692', 'Martinique+596', 'Mauritania (\u202bموريتانيا\u202c\u200e)+222', 'Mauritius (Moris)+230', 'Mayotte+262', 'Mexico (México)+52', 'Micronesia+691', 'Moldova (Republica Moldova)+373', 'Monaco+377', 'Mongolia (Монгол)+976', 'Montenegro (Crna Gora)+382', 'Montserrat+1664', 'Morocco (\u202bالمغرب\u202c\u200e)+212', 'Mozambique (Moçambique)+258', 'Myanmar (Burma) (မြန်မာ)+95', 'Namibia (Namibië)+264', 'Nauru+674', 'Nepal (नेपाल)+977', 'Netherlands (Nederland)+31', 'New Caledonia (Nouvelle-Calédonie)+687', 'New Zealand+64', 'Nicaragua+505', 'Niger (Nijar)+227', 'Nigeria+234', 'Niue+683', 'Norfolk Island+672', 'North Korea (조선 민주주의 인민 공화국)+850', 'Northern Mariana Islands+1670', 'Norway (Norge)+47', 'Oman (\u202bعُمان\u202c\u200e)+968', 'Pakistan (\u202bپاکستان\u202c\u200e)+92', 'Palau+680', 'Palestine (\u202bفلسطين\u202c\u200e)+970', 'Panama (Panamá)+507', 'Papua New Guinea+675', 'Paraguay+595', 'Peru (Perú)+51', 'Philippines+63', 'Poland (Polska)+48', 'Portugal+351', 'Puerto Rico+1', 'Qatar (\u202bقطر\u202c\u200e)+974', 'Réunion (La Réunion)+262', 'Romania (România)+40', 'Russia (Россия)+7', 'Rwanda+250', 'Saint Barthélemy+590', 'Saint Helena+290', 'Saint Kitts and Nevis+1869', 'Saint Lucia+1758', 'Saint Martin (Saint-Martin (partie française))+590', 'Saint Pierre and Miquelon (Saint-Pierre-et-Miquelon)+508', 'Saint Vincent and the Grenadines+1784', 'Samoa+685', 'San Marino+378', 'São Tomé and Príncipe (São Tomé e Príncipe)+239', 'Saudi Arabia (\u202bالمملكة العربية السعودية\u202c\u200e)+966', 'Senegal (Sénégal)+221', 'Serbia (Србија)+381', 'Seychelles+248', 'Sierra Leone+232', 'Singapore+65', 'Sint Maarten+1721', 'Slovakia (Slovensko)+421', 'Slovenia (Slovenija)+386', 'Solomon Islands+677', 'Somalia (Soomaaliya)+252', 'South Africa+27', 'South Korea (대한민국)+82', 'South Sudan (\u202bجنوب السودان\u202c\u200e)+211', 'Spain (España)+34', 'Sri Lanka (ශ්\u200dරී ලංකාව)+94', 'Sudan (\u202bالسودان\u202c\u200e)+249', 'Suriname+597', 'Svalbard and Jan Mayen+47', 'Swaziland+268', 'Sweden (Sverige)+46', 'Switzerland (Schweiz)+41', 'Syria (\u202bسوريا\u202c\u200e)+963', 'Taiwan (台灣)+886', 'Tajikistan+992', 'Tanzania+255', 'Thailand (ไทย)+66', 'Timor-Leste+670', 'Togo+228', 'Tokelau+690', 'Tonga+676', 'Trinidad and Tobago+1868', 'Tunisia (\u202bتونس\u202c\u200e)+216', 'Turkey (Türkiye)+90', 'Turkmenistan+993', 'Turks and Caicos Islands+1649', 'Tuvalu+688', 'U.S. Virgin Islands+1340', 'Uganda+256', 'Ukraine (Україна)+380', 'United Arab Emirates (\u202bالإمارات العربية المتحدة\u202c\u200e)+971', 'United Kingdom+44', 'United States+1', 'Uruguay+598', 'Uzbekistan (Oʻzbekiston)+998', 'Vanuatu+678', 'Vatican City (Città del Vaticano)+39', 'Venezuela+58', 'Vietnam (Việt Nam)+84', 'Wallis and Futuna (Wallis-et-Futuna)+681', 'Western Sahara (\u202bالصحراء الغربية\u202c\u200e)+212', 'Yemen (\u202bاليمن\u202c\u200e)+967', 'Zambia+260', 'Zimbabwe+263', 'Åland Islands+358']",2020-09-24 13:56:04
Data Engineer,Shift4 Payments,2.8 out of 5,United States,"['Helping design, develop, debug and optimize stored procedures and views producing data suitable for reporting purposes', 'Ensuring code standards are followed on all code', 'Refactoring existing code based on existing DBs and modifying it for newer models', 'Validating data, performing cross reference checking between source data and outputs', 'Working with stakeholders and Technology Group to fine tune outputs to ensure all requirements are met for reports', 'Working closely on related issues with internal business units', ""Bachelor's degree in Computer Science or equivalent work experience"", '5+ years of experience with SQL Server.', 'Experience with SSIS and SSRS essential. SSAS preferred but not required.', 'Thorough understanding of SDLC and how it pertains to the database.', 'Experience with Jira and Confluence', 'Excellent written communication skills, particularly in the realm of technical documentation', 'Basic VB & C# experience a plus.', 'Experience with an Agile SDLC a plus.', 'Ability to communicate technical issues to all levels', 'Bachelor of Science degree and/or relevant work experience']",2020-09-24 13:56:04
"Software Engineer, Data Interoperability",One Medical,3.6 out of 5,"San Francisco, CA","['Taking care of you today', 'Paid sabbatical after 5 and 10 years', 'Employee Assistance Program - Free confidential advice for team members who need help with stress, anxiety, financial planning, and legal issues', 'Competitive Medical, Dental and Vision plans', 'Free One Medical memberships for yourself, your friends and family', 'Pre-Tax commuter benefits', 'PTO cash outs - Option to cash out up to 40 accrued hours per year', 'Company-paid maternity and paternity leave', 'Paid Life Insurance - One Medical pays 100% of the cost of Basic Life Insurance', 'Disability insurance - One Medical pays 100% of the cost of Short Term and Long Term Disability Insurance', 'Minimum of 2 years of experience in object-oriented design and implementation skills', 'Excellent communication skills to collaborate with partners across the team', 'Understanding of relational databases such as MySQL or Postgres', 'Familiarity with Amazon Web Services (AWS)', 'Ruby on Rails experience', 'Experience developing software in a service-oriented environment', 'Experience with server and/or client-side performance tuning', 'Paid sabbatical after 5 and 10 years', 'Employee Assistance Program - Free confidential advice for team members who need help with stress, anxiety, financial planning, and legal issues', 'Competitive Medical, Dental and Vision plans', 'Free One Medical memberships for yourself, your friends and family', 'Pre-Tax commuter benefits', 'PTO cash outs - Option to cash out up to 40 accrued hours per year', '401K match', 'Credit towards emergency childcare', 'Company-paid maternity and paternity leave', 'Paid Life Insurance - One Medical pays 100% of the cost of Basic Life Insurance', 'Disability insurance - One Medical pays 100% of the cost of Short Term and Long Term Disability Insurance']",2020-09-24 13:56:04
Senior Data Engineer (Data ELT/ETL Engineer),Safelite Group Inc,3.3 out of 5,"Columbus, OH 43235","['Migrate data and tools (modernize) from on premise to Cloud technologies', 'Design and create data models/semantic layers', 'Design, develop, automate, monitor and maintain ELT applications using Safelite preferred tools and techniques', 'Performance tune ELT to manage high volume batch data transfer to and from internal and external system locations', 'Recommend solutions and lead team through the process', 'Interact with cross-functional teams, project managers and agile teams to estimate development efforts and ensure complete delivery of solutions and accurate requirement fulfillment', 'Influence the business and leadership on processes and procedures that will drive value within the business and across the technical landscape', 'Communicate effectively and efficiently both written and verbally', ""Bachelor's Degree (BA/BS/BFA) or Equivalent"", '7-10 years related work experience', 'Experience with AWS technologies with, preferably, Snowflake as the backend', 'Extensive experience with delivery using ELT tools and techniques (i.e., Informatica, DataStage, SSIS, Talend, etc)', 'Expert understanding of data warehouse and master data management approaches, ELT industry standards and best practices', 'Experience building Data Vault and/or Star Schema models', 'Experience with BI reporting tools a plus such as Tableau or Looker', 'Possess strong communication skills and the ability to work with technical teams and business teams']",2020-09-24 13:56:04
Data Scientist / Machine Learning Engineer,INFISWIFT TECHNOLOGIES,N/A,"Milpitas, CA","['Optimization of complex manufacturing assembly lines by doing Big Data processing and applying machine learning algorithms to analyze the performance from hundreds of IoT sensors. The goal is to increase the rate of production by reducing bottlenecks and predicting and preventing downtime that would save hundreds of millions of dollars.', 'AI-based product defect classification using machine learning and image processing. The goal is to reduce time and money by avoiding installation of defective products in oil and gas wells.', 'Conversion of unstructured data to structured data using Machine Learning, Natural Language Processing, OCR and other such techniques. The goal is to digitize decades of historical data and use that vast knowledge to build a AI-based recommendation system that can predict the reliability of future system designs.', 'Predicting power generation from ground-mounted as well as rooftop Photovoltaic (PV) systems, forecasting demand for residential/industrial battery usage based on consumption patterns, remotely controlling the charge/discharge of millions of batteries based on constraint-aware optimization algorithms, etc. The goal is to build applications that help ensure energy security in the wake of natural disasters as well as build virtual power plants that help monetize the investments in energy storage.', 'Perform exploratory data analysis on tons of data generated by IoT sensors ingested into Big Data infrastructure', 'Build machine learning models to predict the desired outcome based on supervised learning and build unsupervised learning algorithms where applicable.', 'Design, code and test various AI algorithms to solve the complex problems mentioned above.', 'Solid problem solving skills in data science and machine learning.', 'Ability to design and implement machine learning algorithms, heuristics-based AI algorithms', 'Ability to write solid code in Python with minimal supervision to implement, test and verify the algorithms.', 'Bachelor’s Degree or relevant experience in Computer Science or Electrical Engineering, Mathematics, Statistics, Business Analytics.']",2020-09-24 13:56:04
Data Scientist / Machine Learning Engineer,INFISWIFT TECHNOLOGIES,N/A,"Milpitas, CA","['Optimization of complex manufacturing assembly lines by doing Big Data processing and applying machine learning algorithms to analyze the performance from hundreds of IoT sensors. The goal is to increase the rate of production by reducing bottlenecks and predicting and preventing downtime that would save hundreds of millions of dollars.', 'AI-based product defect classification using machine learning and image processing. The goal is to reduce time and money by avoiding installation of defective products in oil and gas wells.', 'Conversion of unstructured data to structured data using Machine Learning, Natural Language Processing, OCR and other such techniques. The goal is to digitize decades of historical data and use that vast knowledge to build a AI-based recommendation system that can predict the reliability of future system designs.', 'Predicting power generation from ground-mounted as well as rooftop Photovoltaic (PV) systems, forecasting demand for residential/industrial battery usage based on consumption patterns, remotely controlling the charge/discharge of millions of batteries based on constraint-aware optimization algorithms, etc. The goal is to build applications that help ensure energy security in the wake of natural disasters as well as build virtual power plants that help monetize the investments in energy storage.', 'Perform exploratory data analysis on tons of data generated by IoT sensors ingested into Big Data infrastructure', 'Build machine learning models to predict the desired outcome based on supervised learning and build unsupervised learning algorithms where applicable.', 'Design, code and test various AI algorithms to solve the complex problems mentioned above.', 'Solid problem solving skills in data science and machine learning.', 'Ability to design and implement machine learning algorithms, heuristics-based AI algorithms', 'Ability to write solid code in Python with minimal supervision to implement, test and verify the algorithms.', 'Bachelor’s Degree or relevant experience in Computer Science or Electrical Engineering, Mathematics, Statistics, Business Analytics.']",2020-09-24 13:56:47
Data Engineer,Save-A-Lot,3.4 out of 5,"Saint Ann, MO 63074","['Create data interfaces and scripts to load the enterprise data warehouse, data lake, data marts and other analytics environments to support enterprise-wide data consumption.', 'Design and develop ETL (Extract, Transform, and Load) jobs within the data warehouse and other data platforms.', 'Create templates and engineering patterns to reduce the time-to-deploy new data assets or changes to an existing data model or analytics solution.', 'Provide technical expertise on the different data solutions (expertise in SQL, Azure Data Warehouse, Azure Data Lake, and Azure Data Factory nice to have).', 'Assist in optimizing and tuning data interfaces, jobs, and workflows and look for ways to improve efficiencies and effectiveness of existing solutions.', 'Partner with key business teams to understand their data needs and assist them in building the appropriate data interfaces to meet their business needs.', 'Partner with the security and risk teams to build appropriate security and compliance into the data platforms.', 'Partner with the enterprise technology function to ensure effective and efficient operation of all data environments.', 'Foster continuous process improvement within the data & insights organization and functions.', 'Cultivate strong relationships with all stakeholders of the data & insights team.', 'Experience in designing, delivering, and optimizing data integration and data warehouse solutions on Multi-Parallel Processing environments (Azure SQL DW, Teradata, etc.) and using integration tools like Azure Data Factory, Azure Logic Apps, or Boomi.', 'Experience profiling, modeling, and writing data interface scripts to load data into platforms like an Enterprise Data Warehouse, Azure Data Lake, Power BI, Azure Logic Apps, etc.', 'Experience working on large portfolios of inter-related projects to deliver an enterprise data ecosystem, achieving target outcomes and business value within budget and timeline.', 'Able to quickly adapt techniques to the target environment and stakeholders. Experience in a retail environment preferred.', 'Excellent communication skills, both written and verbal, with ability to communicate effectively at all levels of the organization.', ""Bachelor's degree in computer science, engineering or related field of study"", '2+ years IT experience', '2+ years of experience delivering high-profile projects in a complex enterprise environment', '1+ years developing and delivering data warehouses', 'Experience with SQL and scripting tools like Power Shell, Multi-Parallel Processing databases like Azure SQL DW, Teradata, or RedShift, ETL tools like Boomi, Azure Data Factory, or SSIS, and integration tools like Azure Logics Apps.', 'Experience integrating data in diverse technical environments.', 'Experience with agile and iterative development approaches (Scrum, Kanban, etc.)', 'Ability to travel up to ~10% of the time, which may include weekends and evenings, as needed.', 'Most work is performed in a temperature-controlled environment', 'Incumbent may sit for long periods of time at a desk or computer terminal', 'Incumbent may use calculators, keyboards, telephone and other office equipment in the course of a normal workday', 'Stooping, bending, twisting and reaching may be required in completion of job duties']",2020-09-24 13:56:47
Software Engineer,Handy,2.7 out of 5,New York State,"['Competitive salary and equity commensurate with experience and performance', 'Full medical, dental, vision package to fit your needs', 'Be part of a team that builds impactful features for our customers and pros everyday', 'Collaborate with product and business teams to review specs and breakdown features into releasable chunks and work on those features', 'Contribute to code reviews, architectural and design reviews, evangelize best engineering practices, and participate in Handy lunch & learn sessions (""Nuts & Bolts"")', 'Be part of our production on-call rotation to support what you built', 'A skillful engineer with at least 1+ years of full-time, hands-on experience in a web stack', 'Well-versed in at least one object oriented programming language: Ruby, Python, Java, etc.', 'Always eager to understand and solve impactful business problems', 'A great collaborator with both technical and non-technical team members', 'Have a good foundational knowledge of programming languages, databases, operating systems, data structures, algorithms, and complexity trade-offs', 'Having worked at or founded a growth-stage startup is a plus', 'Competitive salary and equity commensurate with experience and performance', 'Full medical, dental, vision package to fit your needs', 'Monthly Handy credits', 'Unlimited vacation policy; work hard and take time when you need it', 'A fun office in the heart of the Flatiron district, always stocked with coffee, snacks and drinks; catered lunch and dinner, foosball, office events and team outings', 'Ground floor opportunity with the team', 'The rare opportunity to work with sharp, motivated teammates solving some of the most unique challenges and changing the world']",2020-09-24 13:56:47
Entry Level Unity Programmer/Internship Level,GeoSpace Labs,N/A,"Ocala, FL 34471","['Pay:', '$18.00 - $25.00 per hour', 'Working understanding of Unity development and how to build shared VR interactive environments.', 'Ability to understand distributed systems architecture and general data stream strategies to sync multiple users to a single experience.', 'Some skill at environment 3D modeling.', 'Ability to own your work and get the job done.', 'Accountability. Every team member must perform to the best of their ability, without seeking recognition or assigning blame. GeoSpace team members are accountable to users, fellow team members, and vendors for commitments made.', 'Integrity. GeoSpace team members adhere to a firm moral standard.', 'Passion. A contagious enthusiasm about the company and the technology it provides.', 'Respect. Shows consideration for fellow team members, users, and vendors while earning their trust.', 'Service. A commitment to deliver value to users and to be pleasant to work with at every level of the organization.', 'Excellence. The commitment to do things right the first time and to constantly look for opportunities to improve themselves and GeoSpace technology products.', 'Monday to Friday', '9AM', '3PM', 'No: Not providing sponsorship for this job', 'Open to applicants who do not have a college diploma', 'geospacelabs.com', 'Only full-time employees eligible', 'No']",2020-09-24 13:56:47
Data Engineer,adidas,4 out of 5,"Portland, OR",[],2020-09-24 13:56:47
Fantelligence Data Engineer,Fanatics Inc.,3.7 out of 5,"Jacksonville, FL",[],2020-09-24 13:56:47
Data Engineer,Olsten Staffing,3.9 out of 5,"Sunnyvale, CA","['Pay:', 'From $60.00 per hour', 'Monday to Friday', 'Hive/Spark: 5 years (Required)', 'Hadoop : 6 years (Required)', 'Data engineer: 9 years (Required)', 'Scripting language: 3 years (Required)']",2020-09-24 13:56:47
"Senior Scala Engineer, Customer Data Portal",Disney Streaming Services,3.3 out of 5,"New York, NY","['Senior Scala developer on internally-facing web applications', 'Coach other developers on best practices & quality thru code review & instruction', 'Collaborate with Marketing Technology Product Managers to create scalable and user-friendly solutions for the Customer Data Portal.']",2020-09-24 13:56:47
Data Engineer - CIMD Technology,Goldman Sachs,4 out of 5,"Richardson, TX 75040","['Design, develop and enhance the Marcus Data Platform', 'Develop data flows and pipelines in python and spark to support business needs', 'Create data tools for analytics and data scientist team members that can assist them in building and optimizing our product into an innovative industry leader', 'Work with data and analytics experts to strive for greater functionality in our data systems', 'Conduct POC to help define the components for the Big Data platform', '3+ years academic or industry experience', 'Strong data warehousing concepts, especially in the ETL space', 'Experience with any one ETL tool', 'Strong in data structures and algorithms', 'Programming experience in either python or java.', 'Advanced SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets']",2020-09-24 13:56:47
Data Engineer,Invitae,3.6 out of 5,"Seattle, WA","['Understand our complex data ecosystem and build ETL solutions', 'Develop a real-time streaming infrastructure that supports critical business functions', 'Design and develop tools to enable teams to consume and understand data faster', 'Collaborate with multiple teams and own solutions from end-to-end', 'Are self-starters and can work towards a larger goal with minimal guidance', 'Prior experience utilizing data warehousing or building out data warehouses', 'Have at least 3 years of hands-on experience working with large datasets, pipelines, and warehouses', 'Have a focus on high-quality code, including automated testing and coding best practices', 'Have experience with messaging/queuing systems or stream processing systems', 'Have architected distributed systems with infrastructure automation, monitoring and alerting']",2020-09-24 13:56:47
Looker Data Engineer,MHI,3.2 out of 5,"Austin, TX","['MHI offers competitive base salary + incentive pay as well as training and certification in a variety of products and professional skill sets', 'MHI offers a company health insurance policy that covers 100% of premiums for the individual', 'Ingestion of data from multiple sources using Looker', 'Migrating legacy visualizations to Looker Looks and Dashboards', 'Implementing Looker Best Practices', 'Designing Looker based solutions for both external and internal stakeholders', '2+ years of relevant professional experience', 'Experience with multiple visualization tools', 'Experience with BigQuery required', 'Proficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle, Snowflake)', 'Good understanding of SQL Engine and able to conduct query performance tuning', 'Experience with at least one of the following Visualization Tools (PowerBI, Microstrategy, or Tableau) and Looker', 'Implementation of a Looker Environment', 'Business Analysis Skills', 'Myers-Holum is a technology and management consulting firm founded in 1981 and based in New York, New York.', 'HQ in Manhattan', '80 consultants working across the US focused on Information Mgmt, Enterprise Data Warehousing, Google BigQuery and NetSuite ERP implementations', 'Website: www.myersholum.com', 'MHI offers competitive base salary + incentive pay as well as training and certification in a variety of products and professional skill sets', 'In US: MHI offers a company health insurance policy that covers 100% of premiums for the individual', 'Remote working opportunity when not traveling for client requirements with full access to the team through technology']",2020-09-24 13:56:47
Junior Internal Software Engineer - Full-Stack Development,HackerU,4.8 out of 5,Florida,"['Meet with internal stakeholders to gather project requirements and identify workflow pain points that could be solved with software', 'Work with part-time volunteers across various teams to define clear and measurable project requirements and user stories', 'Develop strategies to improve organizational efficiency in the short-term while working towards the longer-term goals of a sustainable internal information architecture', 'Write and maintain quality software', 'Develop documentation and presentations which communicate the objectives of developed software and tools, to earn team buy-in and adoption', 'Identify opportunities for improved efficiency or visibility through software integrations as you work with different teams on a variety of otherwise disconnected internal tools', 'Work with curriculum teams to review and revise curriculum content for full stack and data science programs', 'Experience with full stack application development', 'Experience with declarative UI models, such as HTML', 'Experience programming with JavaScript', 'Experience with PHP, Python, NodeJS, and React is a plus', 'Able to plan projects with an Agile mentality', 'Able to design software and normalized data schemas', 'Willing to meet the challenge of working in a fast growing hi-tech company', 'Can effectively manage a variety of complex initiatives in varying environments and cultures', 'Ability to multitask and prioritize competing deadlines and projects', 'Highly motivated and determined to reach target-driven goals', 'Excellent command of the English language, in both written and verbal communications', 'Behavioral elements such as adaptability, resilience, resourcefulness, enthusiastic and meticulous are highly preferred']",2020-09-24 13:56:47
Distinguished Data Engineer - Director,Capital One - US,3.9 out of 5,"McLean, VA","['Deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices', 'Visionaries, collaborating on Capital One’s toughest issues, to deliver on business needs that directly impact the lives of our customers and associates', 'Role models and mentors, helping to coach and strengthen the technical expertise and know-how of our engineering and product community', 'Evangelists, both internally and externally, helping to elevate the DistinguishedEngineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities', 'Leaders who gain the trust and confidence of those around them, from hands on engineers to executives', 'Design and develop cutting-edge solutions, using existing and emerging technology platforms', 'Leverage sound judgment and problem solving to tackle some of Capital One’s most critical problems and connect the dots to broader implications of the work', 'Provide technical vision, technical solutions and directions to build complex and sustainable data ecosystem / platform', 'Lead, manage and grow our data ingestion, data refinement and data consumption teams.', 'Design, develop, deploy and manage a highly reliable and scalable data pipeline.', 'Build/Modernize our data refinement/ETL processes', 'Oversee the implementation of solutions for tracking data quality, data consistency and lineage..', 'Embrace and incubate emerging technology and open source products across all platforms', 'Collaborate with enterprise teams on developing and adhering to the company standards in terms of validation rules, nomenclature, design and deployments.', 'Collaborate with internal teams to find areas of opportunities for automation and machine learning.', 'Steamline the entire data ecosystem from end to end to ensure the most efficient , standard, privacy compliant processes possible.', 'Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One’s Tech talent', 'Bachelor’s Degree', 'At least 8 years of experience in database management and data warehousing', 'At least 5 years of experience developing in Spark, Python, SQL, Java, or Scala', 'At least 2 years of experience working with Cloud technologies', 'Masters’ Degree', '10+ years experience architecting and delivering software systems or platforms', '10+ years of data governance and security controls', '8+ years of experience with Python', '4+ years of experience with AWS', '4+ years of experience with Go', '4+ years experience working with Docker', '2+ years of experience building and managing Kubernetes']",2020-09-24 13:56:47
"Data Engineer, Analytics (Instagram Ecosystems)",Facebook,4.2 out of 5,"New York, NY","['Craft and own the optimal data processing architecture and systems for new data and ETL pipelines', 'Build canonical datasets as well as scalable and fault-tolerant pipelines', 'Build data anomaly detection, data quality checks, and optimize pipelines for ideal compute and storage', 'Define and own the data engineering roadmap for Ecosystems', 'Collaborate with Software Engineers and Data Scientists to design technical specification for logging and add logging to production code to generate metrics both online as well as offline', 'Work with different cross functional partners - Data Scientists, Infra Engineering, Logging Framework Infra Teams, Product Managers', 'Build visualizations to provide insights into the data & metrics generated', 'Work with data infrastructure teams to suggest improvements and influence their roadmap', 'Immerse yourself in all aspects of the product, understand the problems, and tie them back to data engineering solutions', 'Recommend improvements and modifications to existing data and ETL pipelines', 'Communicate and influence strategies and processes around data modeling and architecture to multi-functional groups and leadership', 'Drive internal process improvements and automating manual processes for data quality and SLA management', 'Provide ongoing proactive communication and collaboration throughout the organization', ""4+ years' experience in the data warehouse space"", ""4+ years' experience working with either a MapReduce or an MPP system"", ""7+ years' experience in writing complex SQL and ETL processes"", ""4+ years' experience with object-oriented programming languages"", ""7+ years' experience with schema design and dimensional data modeling""]",2020-09-24 13:56:47
Junior Data Analyst - Fabletics,TechStyle Fashion Group,3.3 out of 5,"El Segundo, CA","['Write SQL queries to extract data', 'Partner with business users to deliver robust data solutions', 'Analyze data to answer business questions and provide valuable data insights', 'Build automated reports using visualization tools such as Tableau', 'Work cross-functionally with stakeholders, including tech, business, finance, and design teams', 'Assist with any ad hoc reporting needs', 'Bachelor’s degree in quantitative discipline (i.e. Mathematics, Economics, Business, Computer Science, Statistics etc.)', '1-2 years analytics and/or data coding experience (work, internship, or coursework related)', 'Experience coding in SQL, and excited to learn how to use SQL and Tableau to bring the business valuable data insights', 'Proficient in full suite of Microsoft office', 'Analytical thinker with logical structuring skills and ability to communicate thought processes articulately', 'Excellent communication and interpersonal skills', 'Ability to learn quickly and multi-task in a fast-paced, dynamic environment', 'Strong attention to detail', 'Tableau / Other data visualization tools', 'Understanding of statistical / AB testing methodology', 'Python / R / Other statistical software']",2020-09-24 13:56:47
"Senior Scala Engineer, Customer Data Portal",Disney Streaming Services,3.3 out of 5,"New York, NY","['Senior Scala developer on internally-facing web applications', 'Coach other developers on best practices & quality thru code review & instruction', 'Collaborate with Marketing Technology Product Managers to create scalable and user-friendly solutions for the Customer Data Portal.']",2020-09-24 13:57:29
Data Engineer - CIMD Technology,Goldman Sachs,4 out of 5,"Richardson, TX 75040","['Design, develop and enhance the Marcus Data Platform', 'Develop data flows and pipelines in python and spark to support business needs', 'Create data tools for analytics and data scientist team members that can assist them in building and optimizing our product into an innovative industry leader', 'Work with data and analytics experts to strive for greater functionality in our data systems', 'Conduct POC to help define the components for the Big Data platform', '3+ years academic or industry experience', 'Strong data warehousing concepts, especially in the ETL space', 'Experience with any one ETL tool', 'Strong in data structures and algorithms', 'Programming experience in either python or java.', 'Advanced SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets']",2020-09-24 13:57:29
Data Engineer,Invitae,3.6 out of 5,"Seattle, WA","['Understand our complex data ecosystem and build ETL solutions', 'Develop a real-time streaming infrastructure that supports critical business functions', 'Design and develop tools to enable teams to consume and understand data faster', 'Collaborate with multiple teams and own solutions from end-to-end', 'Are self-starters and can work towards a larger goal with minimal guidance', 'Prior experience utilizing data warehousing or building out data warehouses', 'Have at least 3 years of hands-on experience working with large datasets, pipelines, and warehouses', 'Have a focus on high-quality code, including automated testing and coding best practices', 'Have experience with messaging/queuing systems or stream processing systems', 'Have architected distributed systems with infrastructure automation, monitoring and alerting']",2020-09-24 13:57:29
Looker Data Engineer,MHI,3.2 out of 5,"Austin, TX","['MHI offers competitive base salary + incentive pay as well as training and certification in a variety of products and professional skill sets', 'MHI offers a company health insurance policy that covers 100% of premiums for the individual', 'Ingestion of data from multiple sources using Looker', 'Migrating legacy visualizations to Looker Looks and Dashboards', 'Implementing Looker Best Practices', 'Designing Looker based solutions for both external and internal stakeholders', '2+ years of relevant professional experience', 'Experience with multiple visualization tools', 'Experience with BigQuery required', 'Proficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle, Snowflake)', 'Good understanding of SQL Engine and able to conduct query performance tuning', 'Experience with at least one of the following Visualization Tools (PowerBI, Microstrategy, or Tableau) and Looker', 'Implementation of a Looker Environment', 'Business Analysis Skills', 'Myers-Holum is a technology and management consulting firm founded in 1981 and based in New York, New York.', 'HQ in Manhattan', '80 consultants working across the US focused on Information Mgmt, Enterprise Data Warehousing, Google BigQuery and NetSuite ERP implementations', 'Website: www.myersholum.com', 'MHI offers competitive base salary + incentive pay as well as training and certification in a variety of products and professional skill sets', 'In US: MHI offers a company health insurance policy that covers 100% of premiums for the individual', 'Remote working opportunity when not traveling for client requirements with full access to the team through technology']",2020-09-24 13:57:29
Junior Internal Software Engineer - Full-Stack Development,HackerU,4.8 out of 5,Florida,"['Meet with internal stakeholders to gather project requirements and identify workflow pain points that could be solved with software', 'Work with part-time volunteers across various teams to define clear and measurable project requirements and user stories', 'Develop strategies to improve organizational efficiency in the short-term while working towards the longer-term goals of a sustainable internal information architecture', 'Write and maintain quality software', 'Develop documentation and presentations which communicate the objectives of developed software and tools, to earn team buy-in and adoption', 'Identify opportunities for improved efficiency or visibility through software integrations as you work with different teams on a variety of otherwise disconnected internal tools', 'Work with curriculum teams to review and revise curriculum content for full stack and data science programs', 'Experience with full stack application development', 'Experience with declarative UI models, such as HTML', 'Experience programming with JavaScript', 'Experience with PHP, Python, NodeJS, and React is a plus', 'Able to plan projects with an Agile mentality', 'Able to design software and normalized data schemas', 'Willing to meet the challenge of working in a fast growing hi-tech company', 'Can effectively manage a variety of complex initiatives in varying environments and cultures', 'Ability to multitask and prioritize competing deadlines and projects', 'Highly motivated and determined to reach target-driven goals', 'Excellent command of the English language, in both written and verbal communications', 'Behavioral elements such as adaptability, resilience, resourcefulness, enthusiastic and meticulous are highly preferred']",2020-09-24 13:57:29
Distinguished Data Engineer - Director,Capital One - US,3.9 out of 5,"McLean, VA","['Deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices', 'Visionaries, collaborating on Capital One’s toughest issues, to deliver on business needs that directly impact the lives of our customers and associates', 'Role models and mentors, helping to coach and strengthen the technical expertise and know-how of our engineering and product community', 'Evangelists, both internally and externally, helping to elevate the DistinguishedEngineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities', 'Leaders who gain the trust and confidence of those around them, from hands on engineers to executives', 'Design and develop cutting-edge solutions, using existing and emerging technology platforms', 'Leverage sound judgment and problem solving to tackle some of Capital One’s most critical problems and connect the dots to broader implications of the work', 'Provide technical vision, technical solutions and directions to build complex and sustainable data ecosystem / platform', 'Lead, manage and grow our data ingestion, data refinement and data consumption teams.', 'Design, develop, deploy and manage a highly reliable and scalable data pipeline.', 'Build/Modernize our data refinement/ETL processes', 'Oversee the implementation of solutions for tracking data quality, data consistency and lineage..', 'Embrace and incubate emerging technology and open source products across all platforms', 'Collaborate with enterprise teams on developing and adhering to the company standards in terms of validation rules, nomenclature, design and deployments.', 'Collaborate with internal teams to find areas of opportunities for automation and machine learning.', 'Steamline the entire data ecosystem from end to end to ensure the most efficient , standard, privacy compliant processes possible.', 'Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One’s Tech talent', 'Bachelor’s Degree', 'At least 8 years of experience in database management and data warehousing', 'At least 5 years of experience developing in Spark, Python, SQL, Java, or Scala', 'At least 2 years of experience working with Cloud technologies', 'Masters’ Degree', '10+ years experience architecting and delivering software systems or platforms', '10+ years of data governance and security controls', '8+ years of experience with Python', '4+ years of experience with AWS', '4+ years of experience with Go', '4+ years experience working with Docker', '2+ years of experience building and managing Kubernetes']",2020-09-24 13:57:29
"Data Engineer, Analytics (Instagram Ecosystems)",Facebook,4.2 out of 5,"New York, NY","['Craft and own the optimal data processing architecture and systems for new data and ETL pipelines', 'Build canonical datasets as well as scalable and fault-tolerant pipelines', 'Build data anomaly detection, data quality checks, and optimize pipelines for ideal compute and storage', 'Define and own the data engineering roadmap for Ecosystems', 'Collaborate with Software Engineers and Data Scientists to design technical specification for logging and add logging to production code to generate metrics both online as well as offline', 'Work with different cross functional partners - Data Scientists, Infra Engineering, Logging Framework Infra Teams, Product Managers', 'Build visualizations to provide insights into the data & metrics generated', 'Work with data infrastructure teams to suggest improvements and influence their roadmap', 'Immerse yourself in all aspects of the product, understand the problems, and tie them back to data engineering solutions', 'Recommend improvements and modifications to existing data and ETL pipelines', 'Communicate and influence strategies and processes around data modeling and architecture to multi-functional groups and leadership', 'Drive internal process improvements and automating manual processes for data quality and SLA management', 'Provide ongoing proactive communication and collaboration throughout the organization', ""4+ years' experience in the data warehouse space"", ""4+ years' experience working with either a MapReduce or an MPP system"", ""7+ years' experience in writing complex SQL and ETL processes"", ""4+ years' experience with object-oriented programming languages"", ""7+ years' experience with schema design and dimensional data modeling""]",2020-09-24 13:57:29
Junior Data Analyst - Fabletics,TechStyle Fashion Group,3.3 out of 5,"El Segundo, CA","['Write SQL queries to extract data', 'Partner with business users to deliver robust data solutions', 'Analyze data to answer business questions and provide valuable data insights', 'Build automated reports using visualization tools such as Tableau', 'Work cross-functionally with stakeholders, including tech, business, finance, and design teams', 'Assist with any ad hoc reporting needs', 'Bachelor’s degree in quantitative discipline (i.e. Mathematics, Economics, Business, Computer Science, Statistics etc.)', '1-2 years analytics and/or data coding experience (work, internship, or coursework related)', 'Experience coding in SQL, and excited to learn how to use SQL and Tableau to bring the business valuable data insights', 'Proficient in full suite of Microsoft office', 'Analytical thinker with logical structuring skills and ability to communicate thought processes articulately', 'Excellent communication and interpersonal skills', 'Ability to learn quickly and multi-task in a fast-paced, dynamic environment', 'Strong attention to detail', 'Tableau / Other data visualization tools', 'Understanding of statistical / AB testing methodology', 'Python / R / Other statistical software']",2020-09-24 13:57:29
Big Data Engineer,Deloitte,4 out of 5,"Rosslyn, VA 22209","['Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platforms', 'Leverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actions', 'Drive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements', 'Bachelors Degree In (Computer Science. Mathematics, Information Technology, Computer Engineering or related field)', 'Experience with Big Data Technologies (Cloudera, Hadoop, Spark, Kafka, ETL, Flume, ect.', 'Experience hands on engineering and building data pipelines.', 'Experience providing insight into the changing database storage and utilization requirements for the team and offer solutions.', 'Experience developing database design Experience analyzing database implementation methods to make sure they are in line with clients needs and policies.']",2020-09-24 13:57:29
Big Data Engineer,The Goal Inc.,N/A,United States,"['Analyze system requirements and design responsive algorithms and solutions', 'Use big data and cloud technologies to produce production quality code', 'Engage in performance tuning and scalability engineering', 'Work with team, peers and management to identify objectives and set priorities', 'Perform related SDLC engineering activities like sprint planning and estimation', 'Work effectively in small agile teams', 'Provide creative solutions to problems', 'Identify opportunities for improvement and execute', 'Experience developing with cloud based Big Data technologies', 'Proficiency in Hive and Spark SQL', 'Experience with one or more programming languages like Python, Scala or Java', 'Ability to push the frontier of technology and independently pursue better alternatives']",2020-09-24 13:57:29
Data Engineer,UnitedHealth Group,3.7 out of 5,"San Juan, PR 00902","['Create and maintain optimal data pipeline architecture', 'Assemble large, complex data sets that meet functional / non-functional business requirements', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs', 'Work with data and analytics experts to strive for greater functionality in our data systems', 'Data Governance - Identify, source, transform the data needed for predictive analysis & Business analysis. Create data pipelines using Big Data & ETL tech stack', 'Big Data / Hadoop Solutions - Identify the appropriate Big Data tools and need to work various tools on big data platform.', 'Design & Develop solutions using Big Data, Java Tech Stack', 'Lead POC’s to evaluate Open Source Tools & Technologies in Big Data, Hadoop', 'Design Data Architecture for Big Data platforms, Design ETL pipelines, etc.', 'Develop search based solutions using Elastic Search, Solr, NoSQL technologies', 'Participate in JAD sessions with Product owners & provide inputs on the Technology roadmap', 'Bachelor’s degree in Computer Science, Engineering, Business, Finance, Quantitative or related field', '1 + years of business analytics and data base management', '1+ year of experience in Big Data Tools (Hadoop, Spark, Kafka, Hive)', '2+ years of experience with relational SQL', 'Available to work (40 hours/week) Monday- Friday. Flexible to work any of our 8-hour shift schedules during our normal business hours of (7:00am to 4:00pm AST) It may be necessary, given the business need, to work occasional overtime or weekends.', 'Are to work in Puerto Rico or willing to relocate', 'English Proficiency', 'Experience working with SAS', 'Experience in building ETL Pipelines on Spark using PySpark or Spark SQL', 'Experience with data pipeline and workflow management tools: Oozie, Airflow etc.', 'Experience in Java/Scala', 'Experience in NoSQL databases']",2020-09-24 13:57:29
Data Engineer,Markel Corporation,3.7 out of 5,"Richmond, VA 23219","['Creating order out of data chaos by pulling together seemingly disparate datasets expediting the experimentation and gleaning of insight', 'Partnering with underwriting, actuarial, claims, operations and technology teams to develop new ways of thinking about data as an asset', 'Partnering with the business to identify and evaluate opportunities to leverage both internally and externally available data to solve compelling business needs', 'Elevating the art of listening to drive business need into use cases Information Management will solve with data.', 'Partner with technology teams to determine database schema, size, and DRP requirements for data assets', 'Working across business and technology teams to turn prototypes into robust solutions', 'Ability to complete the lifecycle for data integration (design, write, test-performance and integration)', 'Collaborating with the data science team to transform data and integrate algorithms and models into highly available, production uses', 'Promoting the Information Management value proposition throughout the organization', 'Continual development of your own insurance SME, analytic capabilities, and technical skills', 'You love growing others understanding of complex data structures and thrive on building highly available data products', 'You enjoy an agile, fast paced and highly technical environment', 'You are comfortable with tackling a problem, driving a solution from inception to birth, leading cross-functional collaborations, and communicating technical and non-technical information across multiple functions and levels', 'You are dedicated to engineering excellence yet pragmatic enough to balance quality principles, regulatory compliance and business needs', 'Strategic thinker with natural curiosity and creative thinking', 'Undergraduate degree – Computer Science, Mathematics, Information Systems or related field', 'In-depth knowledge of large scale data driven consumer facing applications that require high volume data pipelines', 'Experience with SQL Server or other relational databases', 'Experience with Python development for preparing data sets for integration with customer facing tools', 'Experience developing insight from data and supporting a variety of customer group with disparate needs', 'Experience working with large data sets and a variety of relational databases', 'Exposure to project management / Agile delivery, stakeholder/customer management, change management approaches', 'Excellent verbal and written communication skills', 'Self-starter, able to work independently and as part of a team', 'Able to collaborate with people from multiple functions; able to establish trusting relationships with business partners', 'Experience with teaching / coaching others regardless of technical ability', 'Undergraduate degree in applied science or computer science', 'Implementation of CI/CD & TDD practices', 'Work experience with P&C insurance industry', 'Experience leading cross functional efforts', 'Cloud based deployment / tooling is a plus']",2020-09-24 13:57:29
Data Engineer,"Interos, Inc.",N/A,"Arlington County, VA","['BENEFITS', 'Comprehensive Health & Wellness package (Medical, Dental and Vision)', '10 Paid Holiday Days Off', 'Accrued Paid Time Off (PTO)', '401(k) Employer Matching', 'Stock Options', 'Career advancement opportunities', 'Casual Dress', 'On-site gym and dedicated Peloton room at headquarters', 'Company Events (Sports Games, Fitness Competitions, Birthday Celebrations, Contests, Happy Hours)', 'Collaborate with Research Analysts, Data Quality Analysts, and Data Operations Specialists to augment workflows with data technologies', 'Partner with Product to ensure external data sources are democratized (centralized, documented, unified, and accessible)', 'Partner with Technology teams to ensure our data lake adds value to the Interos platform', 'Create automated data pipelines that provide analysts with clean data ready for analysis', 'Maintain data the Interos data dictionary', 'Partner with other teams to ensure effectiveness of data centralization processes', 'Resolve all internal data exceptions in timely and accurate manner', 'Analyze, query and manipulate data according to defined business rules and procedures', 'Be a change agent and drive innovation with your own ideas', 'Daily monitoring of data load processes to identify holes in data', 'Collaborate with other team members to design and implement improvement approaches', 'Assists with technology improvement activities to ensure continuous enhancements of core platforms', 'Support ad-hoc data requests from internal/external clients for business continuity and ad-hoc analytics', ""Bachelor's degree in Computer Science or closely related field or a foreign equivalent"", '2+ years of software development experience', 'Ideal candidates will have experience with graph databases', 'Be comfortable working in and presenting data in spreadsheets', 'Experience with streaming data solutions / Kafka', 'Proven passion and expertise for the data quality discipline: Data profiling, Data Discovery, Information Chain and Root Cause analysis.', 'Familiarity with AWS S3, Snowflake, and other modern data warehouse & data lake technologies', 'Passionate about ELT and using tools that support agile data processes', 'Have a demonstrated passion for data and working in data-driven organizations', 'Have familiarity with data warehouse technologies and best practices.', 'Exceptional attention to detail', 'Excellent written and verbal skills', 'Comprehensive Health & Wellness package (Medical, Dental and Vision)', '10 Paid Holiday Days Off', 'Accrued Paid Time Off (PTO)', '401(k) Employer Matching', 'Stock Options', 'Career advancement opportunities', 'Casual Dress', 'On-site gym and dedicated Peloton room at headquarters', 'Company Events (Sports Games, Fitness Competitions, Birthday Celebrations, Contests, Happy Hours)', 'Annual company party', 'Employee Referral Program']",2020-09-24 13:57:29
Data Protection Engineer,Regions Bank,3.6 out of 5,"Hoover, AL","['Creates new ways to solve existing production security issues', 'Investigates intrusion incidents, conducts forensic investigations, and mounts incident responses', 'Evaluates new technologies and processes that enhance security capabilities', 'Establishes plans and protocols to protect data and information systems against unauthorized access, modification, and/or destruction', 'Delivers technical reports on daily activities', 'Analyzes and advises on new security technologies and program conformance', 'Maintains knowledge with current emerging technologies and advancements within Information Security', 'Takes initiative and responsibility for achieving desired results', 'High school diploma or GED', 'Nine (9) years of related post-secondary education and/or experience in Information Security or Information Technology', ""Bachelor's degree in Computer Science, Management Information Systems, or directly related field"", 'Relevant security certifications', 'Financial services experience', 'Strong organizational, research, analytical and/or problem-solving skills to evaluate situations, make recommendations, and take effective action', 'Ability to articulate complex technical concepts or scenarios to both technical and non-technical audiences', 'Subject Matter Expert (SME) in one or more security domains']",2020-09-24 13:57:29
Clinical Data Engineer,Dascena,N/A,"Oakland, CA 94612","['Health benefits', 'Health Insurance', 'Paid Time Off', 'Schedule:', 'Design and implement optimal and compliant data pipeline architecture', 'Assemble complex data sets that meet business requirements', 'Identify, design, and implement internal process improvements, including CI/CD for automated testing and deployment, and scalable data transformation and delivery processes', 'Build analytics tools that utilize the data pipeline to better support data science research projects and applications', 'Work with stakeholders including the Executive, Data, and Writing teams to assist with data-related technical issues and support their data infrastructure needs.', 'Keep our data and infrastructure secure and maintain compliance with the regulatory requirements', 'Bachelor’s degree in Computer Science, Data Science, or similar discipline', '2+ years of experience in building scalable data solutions', 'Advanced working knowledge of SQL and NoSQL databases, including Postgres and MongoDB', 'Experience building and optimizing scalable data pipelines and architectures', 'Working knowledge of message queuing, stream processing, scalable data stores, and distributed computing', 'Strong Python skills, and experience with the numeric libraries and distributed computing frameworks in the Python ecosystem', 'Experience with CI/CD pipelines and application deployment in the cloud', 'Excellent understanding of security principles, best practices, and compliance', 'Knowledge and experience with the healthcare industry is a plus', 'Experience with healthcare data and data formats (e.g. HL7) is a plus', 'Experience working with clinical data in a machine learning setting is a plus', 'Excellent communication skills', 'Experience supporting and working with cross-functional teams in a dynamic environment', 'Competitive compensation', 'Health benefits', 'Flexible hours and PTO', 'Remote work', 'Flexible Schedule', 'Health Insurance', 'Paid Time Off', 'Monday to Friday', 'Python: 1 year (Preferred)', ""Bachelor's (Required)"", 'Fully Remote', 'https://www.dascena.com', 'Yes']",2020-09-24 13:57:29
Logistics Data Engineer,Lineage Logistics,3.2 out of 5,"Novi, MI 48377","['Job', 'Company', 'Benefits', 'Lineage provides safe, stable, reliable work environments, competitive pay, excellent Health and Dental benefits, 401K, and Paid Time Off and Sick Days.', 'Perform benchmarking and costs savings analysis, specifically with carrier rates and RFQ results', 'Support new business pursuits with analytical pricing, design and cost benefit studies', 'In-depth data analysis utilizing data from our TMS system and SQL server data warehouse including detailed analysis of costs along with opportunity identification and implementation', 'Analyze contribution margin for existing customers utilizing consolidation programs', 'Support internal/customer metrics and continuous improvement opportunities', 'Ensure usage of TMS is optimized to support operations requirements', 'Interface with customer bases to facilitate problem resolution and improvement opportunities', 'Develop models to support compliance to optimization and continuous improvement', 'Partner with operations team to ensure customer requirements are met/exceeded', 'Manage multiple projects in a fast-paced environment', 'Operationalize and automate route designs and consolidations across the North America network utilizing our TMS software tools supporting our centralized freight management team', 'Bachelor’s Degree in Supply Chain, Finance, or similar. Will consider equivalent years of experience or combination of education and experience in lieu of degree', '1+ years of experience in Third Party Logistics (3PL) or similar transportation industry utilizing transportation optimization tools and background in performing analytical support for transportation and supply chain operations', 'Experience in the performance of analytical support for transportation and supply chain operations', 'Experience with Transportation Management Software (TMS). examples would include i2, Manugistics, JDA/Red Prairie, Manhattan TMS, Lean Logistics LeanTMS, BluJay Solutions TMS, SAP TM, Oracle or MercuryGate', 'Well versed in Microsoft office suite of products, including advanced experience with Excel']",2020-09-24 13:58:11
Sr. Data Engineer,Safelite Solutions LLC,3.3 out of 5,"Columbus, OH 43235","['Job', 'Company', 'Migrate data and tools (modernize) from on premise to Cloud technologies', 'Design and create data models/semantic layers', 'Design, develop, automate, monitor and maintain ELT applications using Safelite preferred tools and techniques', 'Performance tune ELT to manage high volume batch data transfer to and from internal and external system locations', 'Recommend solutions and lead team through the process', 'Interact with cross-functional teams, project managers and agile teams to estimate development efforts and ensure complete delivery of solutions and accurate requirement fulfillment', 'Influence the business and leadership on processes and procedures that will drive value within the business and across the technical landscape', 'Communicate effectively and efficiently both written and verbally', ""Bachelor's Degree (BA/BS/BFA) or Equivalent"", '7-10 years related work experience', 'Experience with AWS technologies with, preferably, Snowflake as the backend', 'Extensive experience with delivery using ELT tools and techniques (i.e., Informatica, DataStage, SSIS, Talend, etc)', 'Expert understanding of data warehouse and master data management approaches, ELT industry standards and best practices', 'Experience building Data Vault and/or Star Schema models', 'Experience with BI reporting tools a plus such as Tableau or Looker', 'Possess strong communication skills and the ability to work with technical teams and business teams']",2020-09-24 13:58:11
Mechanical Engineer,QUALITY AIRCRAFT PARTS,2.5 out of 5,"Miami Gardens, FL","['Order and maintain engineer department supplies', 'Assist staff on various levels within the organization as required', 'Proficient with Microsoft Office programs, particularly MS Word and Excel', 'Proficient in Labview and SolidWorks', 'Ability to adapt in a fast-paced environment', 'Must have strong attention to detail and communication skills, both oral and written', 'Ability to multitask and meet deadlines']",2020-09-24 13:58:11
Data Science Engineer,Nomi Health,N/A,"Austin, TX 73301","['Contribute to the development of the ML capabilities for the Nomi Health', 'Develop and implement data models to guide business decisions', 'Mapping data sources, including descriptions of the business meaning of the data, its uses, its quality, the applications that maintain it and the database technology in which it is stored. Documentation of a data source must describe the semantics of the data so that the occasional subtle differences in meaning are understood.', 'Documenting interfaces and data movement by recording how mapped data is moved around the virtual enterprise. This includes the frequency of movement, the source and destination of each step, how the data is transformed as it moves, and any aggregation or calculations.', 'Designing the movement of data through the enterprise, including sources of data and how the data is moved around in order to be improved.', 'Defining integrative views of data to draw together data from across the enterprise. Some views will use a database of extracted data and others will bring together data in near real time, considering data currency, availability, response times and data volumes. Designing canonical data views to limit technical debt as data flows from point-to-point transformation.', 'Defining technical standards and guidelines. Assess and document when and how to use the architected producers and consumers, the technologies to be used for various purposes, and models of selected entities, objects and processes. The guidelines should encourage reuse of existing data stores, as well as address issues of security, timeliness and quality.', 'Investigate and participate in emerging technologies and new release Proofs of Concept (PoCs).', 'Leveraging existing [core] data assets.', 'Managing related metadata to include business descriptions of the data, details of any calculations or summaries, descriptions of the sources of the data, and indications of data quality and currency.', 'Communicating the data architecture across the enterprise.', 'Ensuring a focus on data quality by working effectively with data stewards so they can understand data semantics and identify opportunities for improving data quality.', ""Bachelor's degree in Computer Science, Computer Engineering or relevant field."", 'A minimum of 2-3 years experience in a similar role.', 'Must have AWS or Azure experience. (Snowflake, Databricks, S3 desirable)', 'Must have ELT/ETL experience (Talend, MDM, other ETL/ELT tools)', 'Must have coding experience (python, JAVA, R),', 'Familiarity of system concepts and tools within an enterprise architecture framework.', 'Knowledge of various modern data formats, tools, and methodologies. (Infomatics desirable)', 'Excellent organizational and analytical abilities.', 'Outstanding problem solver.', 'Good written and verbal communication skills.']",2020-09-24 13:58:11
"Software Engineer I, Data",Wellframe,N/A,"Boston, MA 02210","['Work closely with product managers and scrum masters to understand the business problems.', 'Collaborate with designers to ensure we deliver the optimal user experience.', 'Work with senior engineers to validate approach.', 'Write automated tests to ensure code is of the highest quality.', 'Help monitor and maintain operational functionality of data pipelines and other jobs that fall under the ETL domain.', 'Work with our customer support team to debug and fix bugs affecting our users.', 'Work with senior engineers to develop proof of concepts and estimates for future work.', 'A B.S. or M.S. degree in Computer Science, Computer Engineering, or a closely related field of study.', 'JavaScript and React experienceProficient in SQL and a modern scripting language such as Python.', 'Development experience building ETL pipelinesMakes good trade-offs for core design decisions — knows when to stick to convention, but also when to break it.', 'Excellent communicator, comfortable explaining technical problems and plans in person and in writing.', 'Values the difference between good code and correct code, and cares about test-driven development without dogma.', 'Thrives on diverse technical challenges — our system integrates a wide variety of healthcare and other technologies.', 'Passionate about leveraging their technical skills to help improve patient care.', 'Works effectively in fast-paced, agile startup environment, and finds fulfillment delivering innovative solutions.']",2020-09-24 13:58:11
IT Support Engineer I,Amazon.com Services LLC,3.6 out of 5,"Kent, WA","['Job', 'Company', 'Amazon offers competitive compensation packages including comprehensive healthcare benefits starting on Day 1, matching 401(k) program, and up to 20 weeks of paid parental leave.', 'But wait there’s more: we don’t wear suits and ties!', 'High School diploma or GED equivalent', '2+ Years of experience in one or more of the following: Microsoft Administration, Linux Administration, or Cisco IOS (CLI)', '2+ years of experience of troubleshooting in a multi-user high availability environment', '2+ years or experience with networking concepts such as DNS, DHCP, SSL, OSI Model, and TCP/IP', '2+ years of experience in PC repair, troubleshooting, deployment, and liquidation', '1+ years IT experience with client, server, and network service delivery', 'Ability to move up to 49lbs as well as stand and walk for 10-12 hours at a time with or without reasonable accommodation.', 'Network engineering and troubleshooting, data cabling and systems administration in a variety of software and hardware environments.', 'Ensure infrastructure networking and computing systems remain available during production hours.', 'Interact with management and staff to provide analytical and technical assistance for continuous improvement of IT solutions.', 'Manage local technical projects.', 'Maintain or create policies, procedures, and processes.', 'Identify root-causes of operational issues and process inefficiencies.', 'Bachelor’s degree in Computer science or IT related field.', 'Microsoft MCSE, MCITP Systems Administrator (Active Directory)', 'Cisco CCENT certification', 'Data center infrastructure and facilities experience', 'Ability to explain complex IT concepts in simple terms', 'Ability to manage high priority projects', 'Excellent written and verbal communication skills', 'Proven ability to work successfully with limited supervision', 'Ability to travel up to 25%']",2020-09-24 13:58:11
Data Scientist/ Statistician Intern (PT/Remote Work) Fall 2020,Lubrizol Corporation,3.9 out of 5,"Wickliffe, OH 44092","['Text analytics to mine for critical insights', 'Exploring cloud migration of data analytics activity', 'Predictive modeling of complex data using advanced algorithms', 'Simulation modeling of complex processes', 'Algorithm assessment, development and/or implementation', 'Creation of infographics using Highcharts JS, Shiny (R), Tableau or other approaches', 'Assisting members of the department with data science tasks', 'Enrolled in a data analytics, statistics, mathematics, computer science or closely related bachelor or graduate program; 3rd year bachelor student or above', 'Minimal GPA of 3.5 in statistics and computer sciences courses', 'Significant course work in statistics or data analytics; experience using advanced statistical software such as R or Python', 'Demonstrated computer programming skills, such as formal course work in C/C++, Java, or Python; knowledge of JavaScript, relational databases and SQL are added pluses', 'Strong problem solving and deductive reasoning skills', 'Ability to interact effectively with others involved in data science efforts', 'Creativity and curiosity with the ability to learn and apply new concepts quickly']",2020-09-24 13:58:11
Frontend Software Engineer,Textio,N/A,"Seattle, WA 98104","['Use frontend technologies like React, TypeScript, GraphQL, and CSS-in-JS to build modern, scalable, and beautiful web applications', ""Share what you've learned about crafting outstanding user experiences with your teammates, so we can all grow faster"", 'Participate in technical architecture discussions from the early exploration of ideas to deciding on a concrete path forward', 'Work in squads with teammates across Design, Product, Data Science, and Backend Engineering to drive complex features from start to finish', 'You take pride in creating powerful experiences that are simple and intuitive for users', ""You're naturally curious about the technologies you use and take initiative to dive in, ask questions, and figure things out"", 'You thrive in an environment that tests ideas by building', 'You have a track record of trying and learning new things', 'You have a point of view but are low ego']",2020-09-24 13:58:11
Data Engineer,Payfone,3.5 out of 5,"Denver, CO 80202","['Create and maintain optimal data pipeline architecture', 'Assemble large, complex data sets that meet functional / non-functional business requirements', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re- designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Non-SQL technologies', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader', 'Work with data and analytics experts to strive for greater functionality in our data systems', 'Promote, maintain and enhance our cultural values of humility, passion, inclusion and leadership', 'Exhibit a strong passion for learning our products and markets through in-house and external training', 'CS degree in Computer Science of Software engineering, or relevant experience', '2 to 5 years of industry experience including:', '> Leveraging advanced SQL knowledge and experience working with relational databases', '> Automation frameworks like Pentaho, Luigi, etc', '> Python, Java, C++, or Scala', 'Experience with stream processing systems like Kafka, Storm, Spark-Streaming, etc is a plus', 'Experience with enabling and supporting a data science and product team']",2020-09-24 13:58:11
Certified Azure Data Engineer,"Iver Solutions, LLC",N/A,"Atlanta, GA",['Temporarily due to COVID-19'],2020-09-24 13:58:11
New Graduate Roles,Lynk,5 out of 5,"Falls Church, VA","[""Completed at least a bachelor's degree (or better) in a STEM- related"", 'Strong interpersonal skills and ability to work effectively in a team environment, accomplishing tasks with limited resources at a rapid', 'Proficiency skill level using Windows and Linux OS, and proficiency with some other technical software package or programming', 'Hands-on experience with lab research, engineering project teams, or prior relevant internship or work']",2020-09-24 13:58:11
"Software Development Engineer, Clinical Data Pipeline",Ovation.io,N/A,"Seattle, WA","['$75,000.00 - $125,000.00 per year', 'Benefits:', '401(k)', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'Rapidly ramp on our product capabilities, our data pipeline and on the clinical informatics domain. Establish credibility and contribute quickly.', 'As part of a small team, design, develop, maintain and operate a scalable, fault-tolerant data pipeline for clinical and genomic information, including de-identification, correction and augmentation and a robust continuous flow to our market through APIs and file-based delivery models.', 'Apply machine learning techniques to data quality, data privacy and correlation discovery', 'Help us create an innovative and efficient genomics pipeline', 'Design, deliver and maintain systems that protect health information', 'Learn our core SaaS product inside and out. Participate in product maintenance; respond to and mitigate occasional 24x7 pages when on call.', 'Understand and improve requirements by working with other engineers, product management, field-facing staff, 3rd-parties and customers.', 'Deliver quality quickly… and with supporting test automation to keep it that way', 'Build and maintain data visualization, both internal- and customer-facing', 'Bachelor of Science in Computer Science (or Data Science, Statistics or similar discipline)', 'Full-stack web app basics (JS frameworks, SPA, REST, back-end app services, relational data, cloud infrastructure and operations)', 'Strong grasp and evidence of practical application of software engineering skills', 'Mastery of SQL and relational modeling', 'At least one demonstrated application of practical machine learning techniques in the cloud', '3 years of creating and supporting commercial software in the cloud; at least 2 years using all core AWS services; at least 1 year working on an operational data pipeline', 'Exposure to high-volume, high-speed storage and retrieval technology', 'Experience with healthcare data and data formats (e.g. HL7, FHIR)', 'Seattle area (also Cambridge, MA; Portland, ME; or Indianapolis)', '401(k)', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'On Call', 'Core AWS Services: 2 years (Required)', 'Mastery of SQL and relational modeling: 5 years (Required)', 'Supporting Commercial Software in the Cloud: 3 years (Required)', ""Bachelor's (Required)"", 'One location', 'Multiple locations', 'Fully Remote', 'www.ovation.io', 'Yes']",2020-09-24 13:58:11
Data Engineer,Physicians Mutual,3.6 out of 5,"Omaha, NE 68131","['Job', 'Company', 'Bachelor’s degree in Computer Science, MIS or related field or equivalent experience is required.', 'Post graduate degree or coursework a plus.', 'Minimum of 3 to 5 years IT experience and at least 2 years of experience required in data warehousing, relational database management systems, multi-dimensional database management systems', 'Demonstrated knowledge of at least one ETL tool such as IBM InfoSphere DataStage (or comparable ETL tool) is required. In addition to that, hands-on experience in creating ETL solutions with Python/Spark is required.', 'Demonstrated knowledge of Data Warehousing data population techniques for target structures such as Star Schemas, Snowflake Schemas, highly normalized data models, and file structures.', 'Demonstrates knowledge of source to target mappings.', 'Demonstrates relational database knowledge; possesses a broad understanding of the current and prospective data architecture, and database performance tuning.', 'Experience with programming languages such as PySpark, UNIX scripting, Java is desirable.', 'Demonstrates ETL staging environment development skills and strong SQL programming skills in a DB2 environment.', 'Demonstrates verbal and written communication skills.', 'Has ability to establish and maintain effective working relationships with external and internal personnel.', 'Must be customer focused and excel in coordination of problem resolution.', 'Flexibility to work in a changing, fast-paced environment and work with a sense of urgency and accountability.', 'Experience with Agile methodologies is desirable.', 'Rotational On-Call support is expected.']",2020-09-24 13:58:11
Technical Data Engineer: Engines,Ascension Global Solutions,N/A,"Warner Robins, GA 31088","['Benefits:', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'The Technical Data Engineer II is responsible for the overall execution and day to day operation of all areas of the Korean F-15 Aircraft Engine Country Standard Technical Orders (CSTOs)', 'Interpret engineering data, engineering change proposals and other changes and directives and incorporate them into F-15 Aircraft Engine CSTOs', 'Develop maintenance data on new systems incorporated into the aircraft', 'Interface with USAF, Customer and other contractor personnel', 'Help other team members during periods of peak production requirements', 'Continue building the technical strength of the group to support future program needs', 'Ability to utilize Adobe FrameMaker, Photoshop and Distiller software to update existing and develop new CSTOs and illustrations a plus', 'US Citizenship', 'Valid DOD Secret Clearance', 'Possess the advanced knowledge, experience and recognized ability to be considered an expert in technical field', 'Possess the ability to perform tasks and oversee the efforts of junior and mid-level personnel within the technical field', 'Travel in support of technical data conferences, meetings, reviews, validations, verifications, and other technical data related activities when requested (Such travel may be both CONUS and OCONUS)', 'Familiar with U.S. Air Force (USAF) field and depot level maintenance activities, USAF technical data, material qualification and acquisition systems, and USAF maintenance policies & programs', 'Associate’s Degree or equivalent experience in a related field', 'Min 5 yrs technical data update experience in a related field', 'Min 5 yrs directly related experience or 10 years of experience with proper certifications', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'technical data: 5 years (Preferred)', 'related: 5 years (Preferred)', 'One location']",2020-09-24 13:58:11
Data Engineer,ComResource,4.1 out of 5,"Cincinnati, OH","['Responsible for design, Development, and Support of data solutions, APIs, tools, and processes to enable rapid delivery of business capabilities.', 'Work closely with IT application teams, Enterprise architecture, infrastructure, information security, and LOB stakeholders to translate business and technical strategies into data-driven solutions for the Bank.', 'Act as a technical Expert addressing problems related to system and application design, performance, integration, security, etc.', 'Conduct research and Development based on current trends and technologies related to the banking industry, data engineering and architecture, data security, and related topics.', 'Work with developers to Build CI/CD pipelines, Self-service Build tools, and automated deployment processes.', 'Evaluate software products and Provide documented recommendations as needed.', 'Provide Support and troubleshooting for data platforms. Must be willing to Provide escalated on-call Support for complicated and/or critical incidents.', 'Participate in the planning process for hardware and software.', 'Plan and work on internal projects as needed, including legacy system replacement, Monitoring and analytics improvements, tool Development, and technical documentation.', 'Provide technical guidance and mentoring for other team members.', 'Manage and prioritize multiple assignments.', ""Bachelor's degree in Computer Science/Information Systems or equivalent combination of education and experience."", 'Must be able to communicate ideas both verbally and in writing to management, business and IT sponsors, and technical resources in language that is appropriate for each group.', 'Fundamental understanding of distributed computing principles', 'Knowledge of application and data security concepts, best practices, and common vulnerabilities.', 'Conceptual understanding of one or more of the following disciplines preferred big data technologies and distributions, metadata management products, commercial ETL tools, BI and reporting tools, messaging systems, data warehousing, Java (language and run time environment), major version control systems, continuous integration/delivery tools, infrastructure automation and virtualization tools, major cloud, or rest API design and development.']",2020-09-24 13:58:11
"Sr. Business Intelligence Engineer, Amazon Advertising (open to all",Amazon.com Services LLC,3.6 out of 5,Remote,"['5+ years of experience in the data/BI space', 'Experience with SQL', 'Experience with data visualization using Tableau, Quicksight, or similar tools', 'Experience working directly with business stakeholders to translate between data and business needs', 'Define requirements for data manipulation, analysis and reporting of customer behavior metrics', 'Investigate, gain access to, and operationalize the use of existing and new data sources', 'Design, develop, document, and maintain ongoing metrics, reports, analyses, and dashboards', 'Derive insights from customer data and work with the marketing team to generate insight-based actions', 'Present findings to partner teams and organizational leadership', 'Partner with the marketing teams around the globe, providing support as a service', 'Masters in computer science, mathematics, statistics, economics, engineering or other quantitative field', '5+ years of experience as a data/software developer/scientist or related technical portfolio', 'Excellent verbal and written communication skills and technical writing skills', 'Experience providing technical leadership and mentoring other engineers for best practices on data engineering.', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations', 'Experience developing cloud software services and an understanding of design for scalability, performance, privacy, security and reliability', 'Experience with using business intelligence reporting tools to produce actionable insights', 'Ability to provide data-driven decision support and business intelligence that is timely, accurate, and actionable']",2020-09-24 13:58:52
Big Data Engineer,Talenthireconsulting,N/A,"Herndon, VA","['Support the team in the writing of deployment scripts and place strong emphasis in automated deployment, infrastructure automation solutions, and continuous delivery process.', 'Work with product owners and other development team members to determine new features and user stories needed in large/complex development projects', 'Create or Update documentation in support of development efforts. Documents may include detailed specifications, implementation guides, architecture diagrams or design documents.', 'Participate in code reviews with peers and managers to ensure that each increment adheres to original vision as described in the user story and all standard resource libraries and architecture patterns as appropriate.', 'Respond to trouble/support calls for applications in production in order to make quick repair to keep application in production.', 'Serve as a technical lead for an Agile team and actively participate in all Agile ceremonies.', 'Participate in all team ceremonies including planning, grooming, product demonstration and team retrospectives', 'Mentor or provide technical guidance to less experienced staff; may use high end development tools to assist or facilitate development process.', 'Leverage Fannie Mae DevOps tool stack to build, inspect, deploy, test and promote new or updated features.', 'May serve as technical lead, architect, project lead or principle developer in course of large or complex project.', 'Expert proficiency in unit testing as well as coding in 1-2 languages (e.g. Java, etc).', 'Expert proficiency in Object Oriented Design (OOD) and analysis.', 'Expert proficiency in application of analysis/design engineering functions.', 'Expert proficiency in application of non-functional software qualities such as resiliency, maintainability, etc.', 'Expert proficiency in advanced behavior-driven testing techniques.', 'Provide expertise for teams in all matters related to deployment, building and release process.', '8-10 years of related experience; Highly experienced with Agile practices/methodologies (e.g. Scrum, TDD, BDD, etc).', 'Highly experienced in the use continuous integration tools (e.g. Jenkins, Hudson, etc) and infrastructure automation (VM Ware, Puppet, Chef, Vagrant, Docker, etc).', 'Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.', 'Strong analytic skills related to working with unstructured datasets', 'A successful history of manipulating, processing and extracting value from large disconnected datasets', 'Build the infrastructure required to process data from a variety of data sources using SQL.', 'Create data tools for analytics and data scientists to optimize data', 'Experience working with either a Map Reduce or an MPP system on any size/scale', 'Experience with big data tools: Hadoop, Spark, Kafka, etc.', '5+ years of Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, et', 'AWS cloud services: EC2, EMR, RDS, Redshift', 'SQL experience and No-SQL experience is a plus', 'No']",2020-09-24 13:58:52
Senior Data Engineer,"Lumos Labs, Inc.",N/A,"San Francisco, CA 94107","['Drive the design and implementation of systems at the core of our data infrastructure on a small, but effective team of data engineers', 'Work with our data scientists to build high-throughput systems that allow us to continually invest in a rich, engaging experience', 'Help envision, implement, and evangelize new features, pipelines, and platforms that not only deliver data, but insight', 'Collaborate with product, engineering, and analysis teams across the organization, as our systems are loosely-coupled, but highly utilized', 'A consistent track record of building highly-available back-end systems that scale', 'A deep understanding of patterns of data architecture, back-end system design', 'Proficiency in Scala, Python, Java, or other modern systems languages', 'Experience with databases such as RDBMS or columnar DB', 'Experience with Kafka, Spark, Flink, Storm, or similar', 'Strong analytical and debugging skillsA dedication to engineering excellence', 'Not required, but nice to haves:', 'Exposure to the principles of functional programming (nice to have)', 'Some experience with front-end technologies and/or statistical analysis tools (nice to have)', 'Experience with A/B testing or machine learning infrastructure (nice to have)', 'Competitive compensation, including salary and benefits on par with later-stage companies and equity compensation on par with earlier-stage ones.', 'The excitement and fun of the early-stage startup paired with the maturity and stability of a later-stage business with substantial revenue and company infrastructure.', 'An egoless environment that fosters collaboration of all types. We have a culture of ownership, trust, camaraderie, and fun.', 'A focus on sustainability - in our products, our business, and for our employees.', 'A culture that values coming together and sharing our varied interests to illuminate new and inspiring ideas, all with a focus on helping our users make meaningful improvements in their lives.', 'The opportunity to learn, grow, and bond with a tight community of co-workers based in SF, and with teammates around the world (NY, Portland, Minnesota, Brazil, Serbia, Ukraine, India).', 'All of the perks that one would expect from a modern-day SF tech company.']",2020-09-24 13:58:52
Sr. Big Data Engineer,tekmindz pvt ltd,N/A,"Burlingame, CA","['Have ownership of the data governance, data models, schema design, and databases including tuning, space management, performance management and policy execution', 'Monitor and manage databases across environments, including assisting in the software release process', 'Monitor and manage backend data synchronization applications and external data source retrieval, APIs and applications', 'Expand and optimize our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.', 'Perform validation procedures to ensure data quality', 'Recommend and implement ways to improve data reliability, efficiency, and quality', 'Conduct systems tests for security, performance, and availability', 'Promote data architecture best practices and standardize on endorsed data storage and message distribution technologies', 'Define security and backup procedures', 'Develop and maintain schema design, data model, API, and troubleshooting documentation', 'Work with the engineering teams to help choose technologies, design system architecture and model data in a scalable and efficient way', 'Advanced working knowledge in SQL and experience working with relational databases', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores', 'A successful history of manipulating, processing and extracting value from large disconnected datasets', 'Strong experience with object-oriented/object function scripting languages such as Python, Java, etc. (Java is required)', 'Experience with stream-processing systems such as Amazon Kinesis, Spark-Streaming, etc.', 'Ability to use a wide variety of open source technologies and cloud services (experience with AWS, Docker, Kubernetes and Elastic Cloud is required)', 'Experience with AWS cloud services: EC2, ECS/EKS, RDS, SQS, Lambda, Redshift, Glacier, Amazon IoT etc.', 'Significant experience scaling solutions that run on private, public, and hybrid cloud infrastructures', 'Strong background in Linux/Unix Administration', 'Experience with data pipeline workflow management tools (Azkaban, Luigi, Airflow)', 'Bachelor’s degree in Computer Science, Engineering, or relevant field', '5+ years’ experience as a Data Engineer or equivalent software-engineering role', 'Able to empathize, sell ideas, and influence others', 'Able to multitask, prioritize, and manage time efficiently', '401(k)', 'Health insurance', 'Monday to Friday']",2020-09-24 13:58:52
Data Engineer,"CSAA Insurance Group, a AAA Insurer",3.3 out of 5,"Glendale, AZ 85308","['Impact - Do you like reinventing data products and deliver new capabilities to organization to better understand customer and provide better services. Be part of modern data team who is innovating the way data can be leveraged to generate new insights.', 'Recognition. We offer a competitive total compensation package including base salary, both annual and long-term lucrative performance bonuses, benefits, and 401(k) Company match with additional discretionary contribution potential.', 'Lifestyle. We do honorable work, and we practice our values: respect, integrity, teamwork, and service.', 'Contribute to collaborative, multi-disciplinary project team efforts in an agile environment', 'Design and develop next generation data and analytics platform based on latest technology stack', 'Design and build data pipelines that transform data into usable formats', 'Evaluate and conduct POC on new technologies for fitment in next generation data platform ecosystem', 'Assist in the development and support of data products. Develop automated processes for data mining, modeling, and enrichment', 'Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy', 'Experience with database and data warehouse services in Snowflake, EC2, S3 and experience with SQL and NoSQL databases', 'Experience as a backend engineer or data engineer with experience in programming languages like Python, Spark, Java, SQL/Hive', 'Experience working within a multidisciplinary, agile team format', 'Excellent in communicating clearly to technical and non-technical audiences', 'Master’s Degree in Computer Science or related field', 'Solid analytical and problem-solving skills; ability to think strategically.', 'Ability to adapt quickly to changing priorities, assignments, and roles.', 'Ability to communicate your ideas and solutions in simple language to your team', 'Comprehensive health care plans, including medical, dental, vision, and tax-deferred spending accounts.', 'Employee assistance, healthy pregnancy and wellness programs.', 'Paid time off, plus nine paid holidays and 24 hours of volunteer time off.', '401(k) plus company matching up to 6% and a cash balance pension program.', 'Paid training, tuition reimbursement, self-service training and career development opportunities.']",2020-09-24 13:58:52
Big Data Engineer (DW/ETL),Intuit,4.2 out of 5,"San Diego, CA 92101","['BS or MS in Computer Science or related field or equivalent work experience', '3+ years of core development experience', 'Skilled in developing Software for Java (Spring & Springboot), Scala for spark streaming & spark applications, or other JVM based languages.', 'Working Knowledge of XML, JavaScript, JSON, YML and Linux', 'Advanced experience with scripting language – Python or Shell is a must have', 'Strong knowledge of software development methodologies and practices', 'Experience working in Agile development teams; working knowledge of Agile (Scrum) development methodologies', 'Experience with Amazon web services: EC2, S3, and EMR (Elastic Map Reduce) or equivalent cloud computing approaches', 'Strong expertise in Data Warehousing and analytic architecture', 'Experience working with large data volumes', 'Experience in HTML5, CSS, and other Web technologies a plus.', 'Experience with low-latency NoSQL datastores (such as DynamoDB, HBase, Cassandra, MongoDB) is a plus', 'Experience with building stream-processing applications using Spark Streaming, Kinesis, etc. is a plus', 'Exposure to unit testing frameworks', 'Hands on experience with Hadoop stack of technologies – Hive, Pig, pig-udf', 'Ability to research and integrate 3rd party solutions', 'Evolving a mature code base into new technologies', 'Experience creating and consuming SOAP based or JSON/REST web services and communicating with systems.', 'Experience developing web services', '70-85% hands-on development in all phases of the software life cycle.', 'Rapidly fix bugs and solve problems', 'Conduct design and code reviews', 'Defect remediation', 'Technical design specification', 'Automated unit tests', 'Estimates and sequence of individual activities as inputs to project plans', 'Analyzes and synthesizes a variety of inputs to create software and services.', 'Identify dependencies as inputs to project plans', 'Collaborates effectively with peer engineers and architects to solve complex problems spanning their respective areas to deliver end-to-end quality in our technology and customer experience.', 'Influences and communicates effectively with non-technical audiences including senior product and business management.', 'Designing/developing ETL jobs across multiple big data platforms and tools including S3, EMR, Hive, Vertica']",2020-09-24 13:58:52
Data Engineer,Billings Clinic,3.7 out of 5,"Billings, MT 59101","['B.S or equivalent degree in IT or Computer Science related field.', '0 - 3 years related work experience.', 'College course work in ETL programming, and version control software, Hadoop, multiple parallel database processing a plus.', 'Familiarity with large-scale Data Warehouse concepts.', 'Knowledge or course work in database utilities (e.g., TOAD, AQT).', 'Familiarity with client/server job scheduling software knowledge.', 'Experience with coordination of and executing migrations in Development, Test and Production environments.', 'Knowledge of environment configuration and migration activities.', 'Familiarity with root cause analysis and problem resolution.', 'Strong verbal and written communication skills, ability to perform under pressure, attention to detail and appreciation for rigorous release management process is important.', 'Minimum of 3 years related work experience.', 'Minimum of 2 years’ experience in ETL programming, Unix scripting (Perl, Shell), and version control software, Hadoop, multiple parallel database processing, large-scale Oracle Data Warehouse and/or Teradata MPP platform and database utilities (e.g., TOAD, AQT).', 'Minimum of 2 years’ experience in coordinating (Informatica, Oracle) and executing (Unix) migrations in Development, Test and Production environments.', 'Minimum of 2 years’ experience in environment configuration and migration activities.', '1 year experience with Hadoop platform and client/server job scheduling software knowledge.', '1 year experience in Vendor relationships.', 'Demonstrated experience in root cause analysis and problem resolution.', 'Must be able to perform duties of the Data Warehouse ETL Programmer whenever the department deems necessary.', 'Strong verbal and written communication skills, ability to perform under pressure, attention to detail and appreciation for rigorous release management process is important.', 'Minimum of 5 years related work experience', 'Minimum of 3 years’ experience in ETL programming, Unix scripting (Perl, Shell), and version control software, Hadoop, multiple parallel database processing, large-scale Oracle Data Warehouse and/or Teradata MPP platform and database utilities (e.g., TOAD, AQT).', 'Minimum of 3 years’ experience in coordinating (Informatica, Oracle) and executing (Unix) migrations in Development, Test and Production environments.', 'Minimum of 3 years’ experience in environment configuration and migration activities.', '2 years’ experience with Hadoop platform and Vendor relationships.', '1 year client/server job scheduling software knowledge.', 'Must be able to perform duties of the Data Warehouse ETL Programmer, whenever the department deems necessary.', 'Strong verbal and written communication skills, ability to perform under pressure, attention to detail and appreciation for rigorous release management process is important.', 'Minimum of 8 years related work experience.', 'Minimum of 5 years’ experience in ETL programming version control software, Hadoop, multiple parallel database processing, large-scale Oracle Data Warehouse, and database utilities (e.g., TOAD, AQT).', 'Minimum of 5 years’ experience in coordinating (Informatica, Oracle) and executing (Unix) migrations in Development, Test and Production environments.', 'Minimum of 5 years’ experience in environment configuration and migration activities.', '3 years’ experience in Vendor relationship.', '2 years client/server job scheduling software knowledge.', 'Must be able to perform duties of the Data Warehouse ETL Programmer, whenever the department deems necessary.', 'Strong verbal and written communication skills, ability to perform under pressure, attention to detail and appreciation for rigorous release management process is important.']",2020-09-24 13:58:52
Data Engineer,Capgemini,3.8 out of 5,"New York, NY 10003","['Advanced SQL: Candidate Must Have Advanced SQL skills and experience. Experience with Snowflake SQL is a plus.', 'Strong Communicator: Candidate Must Have ability to clearly and confidently communicate with business client, IT client and 3rd party partners.', 'Python Programming Language: The candidate Should Have Python skills and experience. Or, they should have some Python training and at least have experience with other procedural language of similar or higher complexity such as Java, Scala, etc.', 'Snowflake DB: Experience with the Snowflake DB is a plus.', 'Apache Airflow: The candidate Should Have experience with an ETL Orchestration tool. Airflow experience is preferred, but experience with another ETL orchestration tool of similar or equal complexity such as NiFi would work as well.', 'AWS: Candidate Should Have experience with AWS (and products such as Spark).', 'Github: Experience with Github is a plus- or, experience could be with a similar version control tool such as Bitbucket.', 'Jira: Experience with Jira is a plus- or, experience could be with a similar Agile development life cycle too such as VersionOne or Rally']",2020-09-24 13:58:52
Data Solutions Engineer,"Retail Solutions, Inc.",N/A,"Providence, RI 02909","['Creating dashboards and analytics leveraging our big data ingestion and data platforms leveraging data sets exceeding billion records', 'Individual should be experienced in R, Python, PowerBI, SQL and In Memory data models', 'Individual should have experience in retail and supply chain', 'Collaborate with development and quality assurance teams to ensure optimal performance, data quality, and delivery', 'Guide our Customer Success team on overall end user functionality along with product roadmap and upcoming new features', 'Have a keen eye on industry challenges along with a creative mindset to envision solutions to these challenges', '1+ years of software development experience or equivalent education', '1+ years of PowerBI use case and analytic creation', 'Experience with R, Python, PowerBI, SQL', 'Experience with big data and ingestion, aggregation techniques', 'Experience with relational databases and SSAS tabular', 'Understanding and conceptualizing of data visualization techniques and design patterns', 'Need to have attention to detail in requirements to global stakeholders', 'Bachelor’s in Computer Science, Data Science, Business Management', 'Experience with Supply Chain Management', 'Business analysis & delivery for projects with visualization is a differentiator', 'Portfolio of past work showcasing past initiatives utilizing BI Tools']",2020-09-24 13:58:52
Data Engineer (State Coordinated Campaign),Democratic National Committee,4.1 out of 5,Remote,"['Help set up pipelines for efficient data collection, tracking, reporting and analysis of data collected from various platforms utilized by the Organizing, Digital & Voter Protection teams', 'Work with the Analytics Engineering team to help ensure database reliability, and performance', 'Assist analysts in code optimization & query performance', 'Work with a cohesive team to execute projects with accuracy, attention to detail, and timeliness', '1-2+ years of experience using SQL. Python experience preferred', 'Experience with common tools, datasets and apps used in progressive spaces - VAN, Voter File, Mobilize, peer-to-peer texting apps, dialer platforms', 'One previous cycle of campaign experience or equivalent political experience in a technical role', 'A track record of prioritizing projects with the ability to be self-directed', 'Strong organizational skills and attention to detail', 'A desire to thrive in a fast-paced work environment and implement creative solutions to unique problems']",2020-09-24 13:58:52
Business Intelligence Engineer,OneSignal,N/A,"San Mateo, CA","['Help query data from our systems to build reports and analysis to derive actionable insight for the sales team, customer success, marketing, support, product', 'Run SQL queries for teams to better acquire and retain customers, develop marketing strategies, bill our customers, as well as inform related product decisions', 'Develop in depth reports and dashboards for individual groups across the organization', 'Help evaluate and develop and build automated tracking of KPIs across the business as well', 'Create automated cohort analysis and revenue bridges to monitor acquisition, expansion, and churn and other Saas metrics', 'Evaluate ways to increase the efficiency of internal data flows and centralize sources of truth including generating a universal customer ID that can span across the organization', 'Build a tool that will allow people across the company to have access to data that will scale with the company growth', 'Connect SaaS tool data into a data warehouse. This could include data from Salesforce, NetSuite, Recurly, and backend entitlement data', 'Assist in architecting and designing a scalable data warehouse that can be connected to a business intelligence tool.', 'Connect SaaS tool data into a data warehouse. This could include data from Salesforce, NetSuite, Recurly, and backend entitlement data', 'Evaluate ways to increase the efficiency of internal data flows and centralize sources of truth', 'Minimum of 2+ years of experience', 'Skilled at querying relational databases (SQL) and ability to create ETL pipelines', 'Proficiency with programming languages such as Python, Ruby, Java, etc.', 'In-depth experience with business intelligence and analytics tools', 'Strong critical thinking skills and attention to detail', 'Knowledge of database systems such as Postgresql, Hadoop, Hive, Spark, Kafka, etc', 'Experience working at a SaaS company is helpful']",2020-09-24 13:58:52
Data Engineer,FanDuel,4.3 out of 5,"Los Angeles, CA","['FanDuel — A game-changing real-money fantasy sports app', ""FanDuel Sportsbook — America's #1 sports betting app"", 'TVG — The best-in-class horse racing TV/media network and betting platform', 'FanDuel Racing — A horse racing app built for the average sports fan', 'FanDuel Casino & Betfair Casino — Fan-favorite online casino apps', 'FOXBet — A world-class betting platform', 'PokerStars — The premier online poker product', 'An exciting environment with real growth', 'Contribute to exciting products used by a highly passionate user base', 'Personal learning and development opportunities', 'Flexible holiday allowance', '401K plan with company match', 'Attractive health insurance premiums']",2020-09-24 13:58:52
Junior Data Scientist,"Eastern Research Group, Inc.",N/A,"Chantilly, VA 20151","['Minimum of BA/BS in Mathematics, Economics, Computer Science, Information Management, Statistics or a related field, Engineering, Environmental Science or technical certification, or equivalent experience.', 'Experience in relational database management design such as MS Access, MS SQL Server, MySQL, Oracle;', 'Hands-on data management experience; developing and implementing data analyses, data collection systems and other strategies that optimize data quality; interpreting data, analyzing results using statistical techniques;', 'Demonstrable experience filtering and ""cleaning"" data to locate and correct code problems;', 'Experience with data conversion activities and crafting high-quality, reliable, and maintainable software code;', 'Understanding of version control using git, continuous integration and best practices in monitoring and deployment of applications;', 'A passion for learning and growing your skills, enthusiastically keeping up with the latest trends and methods for developing software and managing/analyzing data, and taking on interesting and challenging problems and leadership roles; and', 'Excellent written and verbal communication abilities.', 'Web development using a .NET MVC, Python, or R programming languages;', 'Developing REST based web services and accompanying JSON data structures.', 'Strong knowledge of and experience with reporting packages, databases (SQL, Stored Procedures), and ETL']",2020-09-24 13:58:52
Senior Data Engineer,Vanguard,3.8 out of 5,"Malvern, PA","['Deep technical knowledge – including proficiency in at least two of Python, SQL, Hive, Spark, Amazon Web Services / cloud computing (e.g., Elastic MapReduce, EC2, S3), Bash shell scripting', 'Experience writing production quality code to create data products', 'Ability to effectively communicate technical concepts to non-technical audiences', 'Understanding and applied knowledge of Agile delivery methodologies', 'Writes ETL (Extract / Transform / Load) processes, designs database systems and, develops tools for real-time and offline analytic processing.', 'Troubleshoots software and processes for data consistency and integrity. Integrates complex and large scale data from a variety of sources for business partners to generate insight and make decisions.', 'Translates business specifications into design specifications and code. Responsible for writing complex programs, ad hoc queries, and reports. Ensures that all code is well structured, includes sufficient documentation, and is easy to maintain and reuse.', 'Partners with internal clients to gain an expert understanding of business functions and informational needs. Works closely with other technical and data analytics experts across the business to implement data solutions.', 'Leads all phases of solution development. Explains technical considerations at related meetings, including those with internal clients and less experienced team members.', 'Assesses data quality and tests code thoroughly for accuracy of intended purpose. Provides data analysis guidance and serves as a technical consultant for the client.', 'Educates and develops junior data engineers on the team while applying quality control to their work. Develops data engineering standards and contributes expertise to other data expert teams across Vanguard.', 'Tests and implements new software releases through regression testing. Identifies issues and engages with vendors to resolve and elevate software into production.', 'Participates in special projects and performs other duties as assigned.', 'Minimum of five years data analytics, programming, database administration, or data management experience.', 'Undergraduate degree or equivalent combination of training and experience.']",2020-09-24 13:58:52
Data Engineer - Quantumblack,McKinsey & Company,4.3 out of 5,"New York, NY 10022","['Degree educated in Computer Science, Engineering, Mathematics, or equivalent experience', 'Previous commercial experience in a data-driven role', 'Ability to write clean, maintainable, and robust code in Python, Scala, Java or similar languages', 'Knowledge of software engineering concepts and best practices', 'Familiarity with the latest OSS, cloud, container, query and database technologies as well as query languages', 'Confirmed experience building data pipelines in production and ability to work across structured, semi-structured and unstructured data', 'Experience preparing data for analytics and following a data science workflow', 'Commercial client-facing or senior stakeholders management experience', 'Partner with our clients, from data owners and users to C-level executives, to understand their needs and build impactful analytics solutions', 'Design and build data pipelines to support data science projects following software engineering best practices', 'Use state of the art technologies to acquire, ingest and transform big datasets', 'Map data fields to hypothesis, curate, wrangle and prepare data to be used in advanced analytics models', 'Create and manage data environments in the cloud or on premise', 'Ensure information security standards are maintained at all time', 'Contribute to cross-functional problem-solving sessions with your team and deliver presentations to colleagues and clients', ""Be flexible to travel to our clients' offices to deliver presentations, gather information or share knowledge"", 'Have the opportunity to contribute to R&D and internal asset development projects', 'Real-World Impact– No project is ever the same. We work with top-tier clients across multiple sectors, providing unique learning and development opportunities internationally.', 'Fusing Tech & Leadership– We work with the latest technologies and methodologies and offer first class learning programmes at all levels.', 'Multidisciplinary Teamwork- Our teams include data scientists, engineers, project managers, UX and visual designers who work collaboratively to enhance performance.', 'Innovative Work Culture– Creativity, insight and passion come from being balanced. We cultivate a modern work environment through an emphasis on wellness, insightful talks and training sessions.', 'Striving for Diversity– With colleagues from over 40 nationalities, we recognise the benefits of working with people from all walks of life.']",2020-09-24 13:58:52
Data Engineer - Quantumblack,McKinsey & Company,4.3 out of 5,"New York, NY 10022","['Degree educated in Computer Science, Engineering, Mathematics, or equivalent experience', 'Previous commercial experience in a data-driven role', 'Ability to write clean, maintainable, and robust code in Python, Scala, Java or similar languages', 'Knowledge of software engineering concepts and best practices', 'Familiarity with the latest OSS, cloud, container, query and database technologies as well as query languages', 'Confirmed experience building data pipelines in production and ability to work across structured, semi-structured and unstructured data', 'Experience preparing data for analytics and following a data science workflow', 'Commercial client-facing or senior stakeholders management experience', 'Partner with our clients, from data owners and users to C-level executives, to understand their needs and build impactful analytics solutions', 'Design and build data pipelines to support data science projects following software engineering best practices', 'Use state of the art technologies to acquire, ingest and transform big datasets', 'Map data fields to hypothesis, curate, wrangle and prepare data to be used in advanced analytics models', 'Create and manage data environments in the cloud or on premise', 'Ensure information security standards are maintained at all time', 'Contribute to cross-functional problem-solving sessions with your team and deliver presentations to colleagues and clients', ""Be flexible to travel to our clients' offices to deliver presentations, gather information or share knowledge"", 'Have the opportunity to contribute to R&D and internal asset development projects', 'Real-World Impact– No project is ever the same. We work with top-tier clients across multiple sectors, providing unique learning and development opportunities internationally.', 'Fusing Tech & Leadership– We work with the latest technologies and methodologies and offer first class learning programmes at all levels.', 'Multidisciplinary Teamwork- Our teams include data scientists, engineers, project managers, UX and visual designers who work collaboratively to enhance performance.', 'Innovative Work Culture– Creativity, insight and passion come from being balanced. We cultivate a modern work environment through an emphasis on wellness, insightful talks and training sessions.', 'Striving for Diversity– With colleagues from over 40 nationalities, we recognise the benefits of working with people from all walks of life.']",2020-09-24 13:59:32
Data Analyst,BrainPOP,4 out of 5,"New York, NY 10010","['Using data insights to inform product teams as they execute new products', 'Cleaning and processing large-scale datasets', 'Growing and fostering data-driven company culture', 'Working with designers and user testing teams to set up experiments, and collect and analyze data', 'Enthusiastic about improving education for all students', 'Passionate about learning and always seeking opportunities to expand your knowledge', 'A team player with the time management and organizational skills to also work independently', 'Eager to tell stories through data', 'A thorough and creative problem solver', 'Proficiency with R or Python, and with SQL', 'Demonstrated experience working with large-scale data sets', 'A basic understanding of multiple statistics techniques, ideally in the social sciences', 'Experience working in education or with educators, or a degree in an education-related field.', 'Excellent data communication skills', 'Experience with LookML', 'Familiarity with evidence-centered design methodology', 'Experience designing and executing research projects', 'A Data Bootcamp, or a BA or MA in a related field', 'Corporate Donation Matching', 'Medical, Dental, Vision and Paid Life Insurance', '401K with a company match', 'Friends & Family BrainPOP Subscription', 'Learning & Development Stipend', 'Wellness Activities (ClassPass Membership)', 'Annual Performance Bonus & Equity Appreciation Plan', 'Company Events (happy hours, volunteering opportunities, trivia nights and monthly Town Halls)']",2020-09-24 13:59:32
Software Support Engineer,Tesla,3.5 out of 5,"Fremont, CA","['Follow-up on tickets resolved by internal IT teams to ensure communication to the customer with high degree of satisfaction based on results and level of service.', 'Liaison for Level III Information Technology development support.', 'Executes monitors and completes assigned tasks on multiple computer systems and platforms.', 'Documents and maintains shift documentation in ticket management system.', 'Work closely with the US/Offshore counterparts and Leads in ensuring timely resolution of issues.', 'Works with high integrity, follows procedures and policies with the handling of sensitive data']",2020-09-24 13:59:32
Data Migration Engineer,Levitek LLC,N/A,"Spokane, WA 99223","['Participate in data migration projects for various PDM/PLM systems', 'Work directly with customers and PDM/PLM consultants to meet unique project requirements', 'Participate in extracting data from various PDM/PLM database systems', 'Configure and automate migration software and processes', 'Apply multiple techniques to load data into PDM/PLM systems', 'Perform root-cause analysis, troubleshoot Migration and data management related issues', 'Bachelor’s Degree in Mechanical Engineering, Manufacturing Engineering, Computer Science, Computer Information Systems, or a technology related field desired', 'US Citizenship required', 'Knowledge of Microsoft SQL Server and/or Oracle Server', 'Programming experience with C#, Java or Visual Basic', 'Exposure to Mechanical-CAD (E.g. SolidWorks, Creo, NX, CATIA, or Inventor)', 'Exposure to PDM / PLM (E.g. Workgroup PDM, PDM Professional, Enterprise PDM, Windchill, Teamcenter, Agile, SmarTeam, Enovia, Aras)', 'Exposure to data / information management systems', 'Ability to learn new skills and technologies', 'Strong problem solving, analytical ability and attention to detail', 'Ability to work independently as well as within a team environment', 'Ability to communicate in a positive manner both orally and in writing', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Parental leave', 'Professional development assistance', 'Monday to Friday', 'Bonus pay', ""Bachelor's (Required)"", 'United States (Required)', 'Temporarily due to COVID-19']",2020-09-24 13:59:32
"Software Engineer, Data Platform",Tesla,3.5 out of 5,"Palo Alto, CA","['Employ and improve industry-leading, scalable, distributed open-source technologies', 'Build back-end systems from scratch that are capable of handling trillion+ events per day', 'Facilitate operation of highly-available distributed systems at scale and across multiple locations', 'Facilitate others in deploying, operating, and extending upon your clean, tested code', 'Help define a platform that is highly leveraged, multi-tenant, and self-serviced', 'Work with data engineers and data scientists to drive efficient solutions from the platform', 'Help define the data story and enable data-driven solutions at Tesla, both technically and culturally', 'Strong programming fundamentals, particularly in data structures, concurrency, and Java', 'Deep understanding of a complex distributed system, such as Kafka, Spark, HBase, ElasticSearch', 'Have built and optimized highly available, scalable, distributed back-end services', 'Ability to break down and deeply understand complex problems and communicate complex matters efficiently', 'Strong problem solving skills, optimizing for the simplest, most robust yet practical solutions', 'Reliable, dependable, trustworthy, participating team member', 'Smart but humble, with a bias for action', 'Proficiency in Python or Scala', 'Experience with cloud infrastructure such as AWS', 'Robust DevOps/SRE abilities']",2020-09-24 13:59:32
Data Engineer,"Lithia Motors, Inc.",3.2 out of 5,"Medford, OR 97501","['Participate in design, implementation, and support of a data warehouse and analytics platform utilizing Azure cloud technology', 'Design and implement data load processes from On Premises sources into Azure Data Lake and subsequent Azure SQL & SQL Data Warehouse', 'Migrate existing processes and data from our On Premises SQL Server and other environments to Azure Data Lake', 'Design, develop, and support Azure SQL Database Data Marts for functional area data consumers', 'Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using Microsoft SSIS and/or Azure cloud technology.', 'Troubleshoot and support Microsoft SSIS ETL processes for On Premises SQL Data Warehouse', 'Explore and learn the latest Azure technologies to provide new capabilities and increase efficiency', 'Work with top-notch technical professionals developing complex systems at scale and with a focus on sustained operational excellence', 'Collaborate with DW developers; for products that require reporting data and ensure that datasets are in place and are used consistently internally/externally', 'Collaborate with data governance; ensure all existing data is created in the right way, and that new data is created according to appropriate standards and with proper documentation', 'Read, write, and configure code for end-to-end service telemetry, alerting and self-healing capabilities', 'Strive for continuous improvement of code quality and development practices', 'Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers', '5+ years of experience in working as an analytics or data engineering member working with cross functional teams', '5+ years of SQL Server development or equivalent', '2+ years of experience designing solutions in Azure specializing in any of the following technologies: Azure Data Factory, Azure Data Lake, Azure SQL & Azure SQL Data Warehouse, Azure Functions', '2+ years of Spark, Python and PowerShell development', 'Bachelor’s Degree in computer sciences, Analytics, Systems Eng., Statistics or related field', 'Strong attention to detail and sense of urgency', 'Excellent communication skills both written and oral', 'Hands-on experience in R/python', 'DevOps and automation experience integrating azure resources with CICD technologies', 'Competitive pay', 'Medical, Dental and Vision Plans', 'Paid Holidays & PTO', 'Short and Long-Term Disability', 'Paid Life Insurance', '401(k) Retirement Plan', 'Employee Stock Purchase Plan', 'Lithia Learning Center', 'Vehicle Purchase Discounts', 'Wellness Programs']",2020-09-24 13:59:32
Data Engineer,FlightSafety International,3.7 out of 5,"Moonachie, NJ 07074","['Build new micro-services, libraries, and features that form the platform to support cognitive analytic products', 'Design and develop batch jobs, web applications and web services', 'Deploy scalable machine learning models to production', 'Communicate technical concepts and solutions in a clear fashion that business stakeholders and other developers can understand and collaborate', 'Work with app dev and QA teams for testing and improvement if needed', 'Ability to scope work and provide proper estimate', 'Familiarity with SDLC and agile methodologies and tools such as TFS, Git, SCRUM', 'Stay current with the latest in cognitive analytics and explore new tools and features if necessary', '2+ years of experience with strong python development skills', '1+ years in building python data engineering platforms for data science or data analytic groups', '1+ years of web development experience with strong java script skills', 'Strong relational and non-relational data base experience', 'ML Modeling is plus', 'Exhibit and practice courteous, ethical and professional behavior while interacting with both internal and external customers', 'Act in a collaborative, team-oriented environment focused on common goals to achieve mutually beneficial results', 'Be accountable and responsible for the accuracy and completeness of assigned work and results', 'Prioritize and manage work load and communicate issues clearly', 'Exhibit effective verbal and written communication skills', 'Comply with all laws, regulations and company policies', 'Travel when required']",2020-09-24 13:59:32
Data Engineer - AWS FinTech,Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['3+ years of experience as a Data Engineer or in a similar role', 'Experience with data modeling, data warehousing, and building ETL pipelines', 'Experience in SQL', 'Bachelor’s degree in CS or related technical field.', '5+ years of work experience with ETL, Data Modeling, and Data Architecture.', '3+ years experience using big data technologies (Parquet, Spark, Hadoop, Presto, EMR, etc.)', 'Excellent knowledge of SQL and Linux OS', 'Proficiency in at least one modern programming language such as Java, Scala, or Python', 'Excellent understanding of software development life cycle and/or agile development environment with emphasis on BI practices.', 'Design, implement, and support a platform providing secured access to large datasets.', 'Interface with tax, finance and accounting customers, gathering requirements and delivering complete BI solutions.', 'Model data and metadata to support ad-hoc and pre-built reporting.', 'Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.', 'Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.', 'Tune application and query performance using profiling tools and SQL.', 'Analyze and solve problems at their root, stepping back to understand the broader context.', 'Learn and understand a broad range of Amazon’s data resources and know when, how, and which to use and which not to use.', 'Keep up to date with advances in big data technologies and run pilots to design the data architecture to scale with the increased data volume using AWS.', 'Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for datasets.', 'Triage many possible courses of action in a high-ambiguity environment, making use of both quantitative analysis and business judgment.', 'Master’s degree in Information Systems or a related field.', 'Experience using business intelligence reporting tools (Tableau, Business Objects, Cognos, etc.)', 'Knowledge of data management fundamentals and data storage principles', 'Knowledge of distributed systems as it pertains to data storage and cloud computing', 'Strong problem-solving skills and ability to prioritize conflicting requirements.', 'Excellent written and verbal communication skills and ability to succinctly summarize key findings.', 'Experience working with AWS Big Data Technologies (EMR, Redshift, S3)', 'Strong organizational and multitasking skills with ability to balance multiple priorities.', 'Experience providing technical leadership and mentor other engineers for the best practices on the data engineering space.', 'An ability to work in a fast-paced environment where continuous innovation is occurring and ambiguity is the norm.']",2020-09-24 13:59:32
Junior Data Developer/Engineer,"CGI Group, Inc.",3.6 out of 5,"Arlington, VA 22201","['Demonstrate in-depth technical capabilities with the ability to support multiple work streams and drive assimilation of new techniques and solutions.', 'Apply advanced analytics and machine learning methodologies to large quantities of data to derive and present key actionable insights.', 'Engineer and support a dynamic technical stack using Microsoft, Oracle, and SAP technologies that interact with existing client applications.', 'Develop robust platforms with a microservice approach to permit easy scalability and dynamic application.', 'Integrate enterprise platforms with specialized applications for reconciliation and recording purposes', 'Evaluate data quality using SQL and data analysis techniques that improve client-reporting capabilities.', 'Follow technology trends within the Big Data road map and inform clients how this technology will benefit the future development platform.', 'Participate in team problem solving efforts and offer ideas to solve client issues.', 'An interim Secret clearance is required to begin working onsite with our client, and a Secret clearance must be maintained throughout the project duration. Due to the nature of the government contract requirements and/or clearance requirements, US citizenship is required.', ""Bachelor's degree or master's degree in Computer Science, Mathematics or STEM related discipline."", '1+ Years of Experience developing data solutions using relational database management systems such as Oracle, SQL Server, Redshift, SAP HANA, etc.', '1+ Years of Experience using Python, PowerShell, Perl or other scripting languages to extract and manipulate data.', '1+ Years of Experience in creating complex SQL queries, stored procedures, functions, data structures and strong analytical problem solving skills.', 'Experience working with messy data, building data pipelines and automation activities.', 'Experience working in an Agile based environment.', 'Strong technical and troubleshooting techniques.', 'Perl', 'SQL', 'Python', 'RDBMS Concepts', 'PowerShell']",2020-09-24 13:59:32
Data Engineer,Crowdskout,N/A,Utah,"['Create highly scalable and robust data solutions for use by our products and clients', 'Design, build, and maintain multiple performant data pipelines & ETL / ELT flows against massive datasets', 'Ensure data accuracy and reliability', 'Strong SQL experience (any flavor)', 'Experience building large scale streaming and batch data pipelines (e.g. Python, Java)', 'Experience building out data warehouse and/or data lake infrastructure', 'Experience with data modeling and physical database design', 'Experience using Big Data technologies (e.g. Spark, Presto, Kafka)', 'Experience with SQL & NoSQL databases (e.g. MySQL, MongoDB)', 'AWS data stack (e.g. Kinesis, Glue, RDS, Athena, Redshift etc.)', 'Software development using PHP', 'Graph database experience', 'Workflow management engine experience', 'Knowledge of data security best practices (e.g. data encryption, tokenization, masking)']",2020-09-24 13:59:32
Business Analyst,Vermeer Corporation,3.5 out of 5,United States,[],2020-09-24 13:59:32
"Sr DevOps Engineer ( AWS ) data driven, IPO path, 100% remote",Relentless Talent,N/A,"Pittsburgh, PA","['401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Vision insurance', '8 hour shift', 'AWS: 1 year (Preferred)', 'DevOps: 5 years (Preferred)', ""Bachelor's (Preferred)"", 'Fully Remote']",2020-09-24 13:59:32
Data Engineer,"YinzCam, Inc.",4 out of 5,"Pittsburgh, PA 15206","['Thinks nothing is impossible', 'Is a tinkerer and implementor of big-data systems', 'Has a knack for data visualization to derive insights', 'Is equally comfortable with database systems and machine-learning algorithms', 'Running analyses on terabytes of data that arise from digital assets', 'Applying machine-learning algorithms on data sets in order to cluster and segment them', 'Providing insights from the data, to understand user behavior, predict user behavior, identify anomalies, and identify patterns', 'Building, maintaining, and refining data dashboards', 'Driving new product development based on insights from the data', '2 years+ of machine-learning experience with giant data-sets', '2 years+ of experience in data visualization techniques and best practices', '2 years+ of experience in working with Hadoop, Hive, Spark, and other big-data platforms', '2 years+ of experience with SQL, relational databases, NoSQL databases, including Postgres and Cassandra', '2 years+ of experience with Google Analytics, Firebase', '2 years+ of experience with AWS cloud services, such as EC2, EMR, RDS, Redshift', '2 years+ of experience in Java/C++/Python programming', 'Expert programmer and tinkerer, comfortable around operating systems, cloud computing, network protocols', 'Willingness to work in a high energy, fast-paced environment', 'Strong desire to learn and grow career', 'Degree in Computer Science/Engineering, with a heavy focus on machine-learning, data science, data engineering.']",2020-09-24 13:59:32
Data Engineer,Warner Bros. Entertainment Group,4.2 out of 5,"Burbank, CA","['Develop and provide support for core data relationship, data ingest, data transformation services and search capabilities. Creates functional and technical specifications. Creates and executes against a plan to launch and maintain applications.', 'Review project objectives and determine best technology for implementation. Implement best practice standards for development, build and deployment automation.', 'Evaluate software products and vendors for WarnerMedia (WM) Technology and other divisions. Recommend action, develop and lead implementation of selected products/services.', 'Work with internal and external developers to ensure (WM) Technology code standards and best practices are performed for development of applications.', 'B.S. in Computer Science or equivalent experience.', 'AWS Developer Certification preferred.', 'AWS Database or Data Analytics Certification preferred.', '3+ years data engineering experience.', 'Demonstrated proficiency in data modeling and data structures.', 'Demonstrated experience implementing database technologies such as NoSQL, and Relational. Experience in graph databases a plus.', 'Demonstrated expertise and experience in ELK stack (elasticsearch, logstash, kibana).', 'Demonstrated expertise and experience in modern databases such as Mongo, Couchbase, Neptune, Neo4j, or equivalent. Experience in MarkLogic a plus.', 'Proficient in one or more modern query languages such as elasticsearch query DSL, cypher, gremlin, or graphql. xQuery preferred but not required.', 'Highly proficient in XML, JSON and YAML data exchange formats. Experience in XSDs and triple stores.', 'Proficient in API design and development, specifically REST APIs. Experience with Swagger 2.0 and AWS API gateway is highly preferred.', 'Demonstrated experience in data analytics tools such as Tableau, Kibana etc.', 'Experience in working with data streaming technologies such as Amazon Kinesis, Apache Kafka etc.', 'Experience in AWS at scale leveraging services such as elasticsearch, RDS, Redshift, Neptune and ec2.', 'Highly proficient in at least one modern programming language such python, java, or node.js. Bash experience preferred.', 'Demonstrated expertise and experience in deploying containerized application using Docker, Kubernetes or equivalent.', 'Experience with source code and knowledge repositories such as git, jira, or equivalent systems.', 'Proficient in a Linux environment.', 'Proficient in core DevOps principles.', 'Proficient in the SDLC in an agile environment.', 'Systems design and architecture.', 'Ability to work with outside vendors and clients under sometimes adverse circumstances and under time critical constraints.', 'Must be able communicate effectively and tactfully with all levels of personnel (in person, written, telephone).', 'Must be able to pay close attention to detail.', 'Must be able to handle multiple tasks in a fast-paced environment.', 'Must be able to organize and schedule work effectively.', 'Must be able to work flexible hours, including overtime, if and when necessary.', 'Must be able to respond to after-hours pager notifications to provide support for applications as necessary.']",2020-09-24 13:59:32
Senior Data Engineer,Nurx,2.8 out of 5,California,"['Create and maintain data pipelines and processes that fetch and store data in an efficient and easy to access manner.', 'Help build infrastructure to aggregate data from several sources and make it readily available for analyses.', 'Optimize existing ETLs to make them resilient to data failures, and scale with size.', 'Take an active role in key strategic decision making and analytics across the company.', 'Help Nurx develop its ""Big Data"" strategy - particularly helping evolve our distributed computing and machine learning capacity growth.', 'Flex into other areas of the organizations to help drive data driven decision making. Assist the Product, Finance, and Engineering teams derive key insights as needed.', 'Engage with stakeholders to understand business problems and translate their questions into insights and easily digestible summaries.', 'Minimum of 4 years of experience in data[base] engineering, data science, or product engineering.', 'Experience with various AWS services.', 'Experience with database engineering, Postgres preferred.', 'Experience with containerization and building virtual environments.', 'Experience with Airflow or DBT', 'Experience with Data Collection via ETLs and an understanding of data warehouse organization.', 'Able to manipulate complex data structures in Python or other programmatic data focused languages.', 'Some understanding of statistical principles.', 'Ability to understand how data should be structured for analytical purposes.', 'Talented and collaborative team who will both support and challenge you.', 'Market competitive salary and equity.', 'Medical, dental, commuter, wellness, and engineering technology benefits.', '401(k) retirement plan.', 'Paid holiday, vacation, and sick leave.', 'Take what you need vacation (and we really mean it!).']",2020-09-24 13:59:32
Senior Data Engineer,Nurx,2.8 out of 5,California,"['Create and maintain data pipelines and processes that fetch and store data in an efficient and easy to access manner.', 'Help build infrastructure to aggregate data from several sources and make it readily available for analyses.', 'Optimize existing ETLs to make them resilient to data failures, and scale with size.', 'Take an active role in key strategic decision making and analytics across the company.', 'Help Nurx develop its ""Big Data"" strategy - particularly helping evolve our distributed computing and machine learning capacity growth.', 'Flex into other areas of the organizations to help drive data driven decision making. Assist the Product, Finance, and Engineering teams derive key insights as needed.', 'Engage with stakeholders to understand business problems and translate their questions into insights and easily digestible summaries.', 'Minimum of 4 years of experience in data[base] engineering, data science, or product engineering.', 'Experience with various AWS services.', 'Experience with database engineering, Postgres preferred.', 'Experience with containerization and building virtual environments.', 'Experience with Airflow or DBT', 'Experience with Data Collection via ETLs and an understanding of data warehouse organization.', 'Able to manipulate complex data structures in Python or other programmatic data focused languages.', 'Some understanding of statistical principles.', 'Ability to understand how data should be structured for analytical purposes.', 'Talented and collaborative team who will both support and challenge you.', 'Market competitive salary and equity.', 'Medical, dental, commuter, wellness, and engineering technology benefits.', '401(k) retirement plan.', 'Paid holiday, vacation, and sick leave.', 'Take what you need vacation (and we really mean it!).']",2020-09-24 14:00:12
Data Engineer,Steampunk,N/A,"McLean, VA 22102","['Profile and analyze source system data to determine data relationships, keys, conformed dimensions, and necessary transformations', 'Identify data quality issues', ""Ensure data structures are designed for flexibility to support clients' business needs"", 'Develop strategy and repeatable process for maintaining Enterprise Data Models', 'Design & test integrations to/from data modeling tools', 'Work with developers to create an API access layer for the data', 'Reverse engineer complex, new datasets, and map these new datasets to the existing model.', 'Provide documentation and instruction to data modelers and developers', 'Constantly interact with both ETL developers and end users data analysts to share knowledge, collect feedback, and provide additional implementation requirements.', 'Develop, maintain, and review data processes and architecture for both on-premise and cloud-based data systems', 'You will contribute to the growth of our Data Exploitation Practice.', 'Who wants to do something different......', 'US Citizen Only', 'Ability to hold a position of public trust with the US government.', '5+ years industry experience coding commercial software and a passion for solving complex problems.', '5+ years direct experience in Data Modeling and Data Solution Development', 'Experience with data modeling tools and their integrations', 'Experience developing processes to manage data model development, principles, and standards', 'Experience architecting data warehouses', 'Demonstrated and understanding customer requirements and prioritize for maximum customer / user experience.', 'Demonstrated on-the-job experience as a big data architect/engineer', 'Demonstrated on-the-job experience manipulating structured and unstructured data for analysis', 'Demonstrated on-the-job experience constructing complex queries to analyze results using databases or in a data processing development environment', 'Demonstrated on-the-job experience aggregating results and/or compiling information for reporting from multiple datasets', 'Demonstrated experience collaborating with staff, IT customers, and other technical and non-technical staff and contractors at all levels', 'Demonstrated experience translating product requirements into system solutions that take into account technical, schedule, cost, security, and policy constraints', 'Demonstrated experience working in an Agile environment', 'Demonstrated experience providing technical direction to project teams of developers and data scientists who build web-based interfaces, dashboards, and reports', 'Demonstrated experience working with data science tools technologies, particularly Python or SQL', 'Demonstrated experience with Solr, Elasticsearch, or similar tool', ""Bachelor's degree in computer science, information systems, engineering, business, or a scientific or technical discipline""]",2020-09-24 14:00:12
Content Specialist,Tesla,3.5 out of 5,"Fremont, CA","['Proactively manage content within the content management system and take ownership for quality and accuracy', 'Participate in the full web production lifecycle, including scoping out content requirements, production, testing and ongoing management/refinement', 'Support localization of global web content and quality of translations', 'Partner with software engineers, product managers, business stakeholders, UX designers and other teams to produce and publish compelling content', 'Ensure online content supports SEO goals, our brand standards, web style guidelines and legal and compliance requirements.', 'Incorporate learnings from analytics data into the development of content', 'Optimize meta-data and on page content based on priority keyword focus', 'Learn about our customers and our products, and take the initiative to identify and propose new content', '1-3 years experience in a similar content management/digital production role, ideally for a global website', 'Experience in a content management system', 'Superior proofreading and copy editing skills', 'Knowledge of basic HTML', 'Understanding of SEO principles and content optimization', 'Eye for detail, even under pressure', 'Ability to work in a fast-paced environment and go above and beyond to meet deadlines.']",2020-09-24 14:00:12
"Data Acquisition Engineer - Atlanta, GA",Nolan Transportation Group,3.3 out of 5,"Atlanta, GA","[""Data Acquisition Engineer must have a bachelor's degree Computer Science, or any other related quantitative field"", ""Five or more working years' experience with Big Data environments developing high end data platforms solutions a requirement"", 'Designing & building data architectures including the design & set-up of scalable (big) data lakes (full cloud or hybrid cloud), scheduled transformations & data governance', 'Understanding of distributed computing principles', 'Strong understanding of Data Architecture concepts in Big Data ecosystem', 'Strong understanding of Enterprise Architecture concepts in AWS/Azure ecosystem', 'Hands-on experience in Scala, Spark', 'Analyze complex business and technical problems related to the implementation of new technology and/or the customization of existing technologies', 'Partner with other technology teams to work with business executives and end users to conceptualize new application projects, recommend technologies and implementation strategies. Then architect/design for requirements of the project within financial and timeline guidelines', 'Understand the changing business needs of the organization/projects and recommend viable strategies for the future', 'Author and/or Review architecture/design and other technical documents ensuring high quality deliverables and systems development across tech stacks and applications team', 'Deep understanding of Data Bricks Eco system is highly desirable', 'Transportation, Brokerage, or Supply Chain experience a big plus', 'Must be a result-oriented individual, be a self-motivated and proactive needing minimal supervision, be a strategic and creative thinker, have an ability to handle multiple simultaneous projects, be highly organized able to prioritize and meet tight deadlines, have a keen eye for detail, have an ability to work comfortably in a group/collaborative setting, take accountability for business and team performance, have an ability to stay calm and composed in times of uncertainty and stress']",2020-09-24 14:00:12
Junior Research Engineer/Data Scientist,Technica Corporation,3.7 out of 5,"Dulles, VA 20166","['Support a team of Developers and Data Scientists working on a variety of research and development projects as well as customer projects', 'Research and analyze cutting edge algorithms and technologies with a focus on Natural Language Processing and data visualization techniques', 'Effectively communicate results of research and analysis with teammates and senior management in the form of essays, whitepapers, and Powerpoint presentations', 'Design, Develop and Deploy:', 'Automated analytic software, techniques, and algorithms', 'Data-driven analytics; event-driven analytics', 'Bachelor’s in Computer Science, Mathematics, or relevant technical field', 'Experience with web frameworks (React, Flask, NodeJS)', 'Experience with Python', 'Eligible to obtain a U.S. Secret clearance', 'Experience using Linux as a development operating system', 'Experience using Natural Language Processing techniques', 'Experience with Docker and Singularity container platforms', 'Experience with Machine Learning toolkits such as Tensorflow, Pytorch', 'Experience with data visualization']",2020-09-24 14:00:12
Data Technician (Full- or Part-Time),Thasos Group,N/A,"New York, NY 10003","['Qualifications:Detail-oriented personalityExcellent communication skillsProactive in improving existing methods/toolsResponsible and reliableTechnical Skills (highly preferred but not required):Python, JavaScript, HTMLPandas, PostgreSQLWeb scrapingWhy Thasos?Winner – “Best Alternative Data Provider, 2018” Inside Market DataWinner – “Best Overall Buy-Side Product, 2017” Waters TechnologyThasos is an alternative dataintelligence firm based in New York City. Founded in 2011, Thasos created their initial business model as part of the MIT Media Lab, a research lab at the Massachusetts Institute of Technology, to aggregate anonymized geolocation data from mobile phones to support financial investing. By converting real-time mobile phone location data into actionable information, the company aims to significantly improve transparency into businesses, markets, and economies worldwide.Flexible, part-time work schedule (students welcome)Company-sponsored lunch every ThursdayRegular company outings (happy hours, hikes)Compensation includes Competitive Salary + Benefits + EquityPositions are in Manhattan with an immediate start date.']",2020-09-24 14:00:12
Data Engineer,CommonStock,N/A,"San Francisco, CA 94111","['Apply AI/ML to our wildly-fascinating (valuable) data to predict price movements and generate alpha', 'Apply NLP to millions of messages and derive high-signal, actionable sentiment analysis of assets', 'Own the ETL pipeline for our Market Data and Broker services while optimizing queries', ""Set up and tune databases and validate data to ensure it's up to the minute"", 'Build sexy, interactive visualizations and dashboards to represent our proprietary data insights to users', 'Publish research based on the amazing trends you’ll find buried in our data (these will go viral across Bloomberg/WSJ/CNBC/r/dataisbeautiful)', 'Adapt ML algorithms and SQL dashboards to solve problems across several teams, such as product, operations, customer support, compliance, and security', 'Build statistical models to predict user behavior and drive business intelligence', 'Integrate multifaceted data streams such as rapidly changing market data, user data based on app activity, and brokerage operations data to perfect our processes and workflows', 'Combine knowledge of several research domains to power product and strategic decisions', 'Explore new ways to equip users with investing insights', 'Help improve information architecture behind the billions of market data calls we process, reducing latency and improving accuracy/integrity', '3+ years production data science experience', 'Intense technological know-how combined with insatiable curiosity, creativity, and user empathy', 'Preferably (not required) a graduate degree in a quantitative field such as mathematics, statistics, machine learning, computational statistics, NLP, artificial intelligence or similar fields', 'Strong collaborative mindset and experience working with external clients to translate their needs into effective engineering solutions', 'Solid understanding of statistical analysis and machine learning algorithms.', 'Excellent programming skills, including expert level familiarity with either Python or R programming languages', 'You spend your free time in r/dataisbeautiful and Kaggle', 'Exquisite SQL', 'Strong grasp of available data pipeline and machine learning technologies (Spark, Tensorflow, AirFlow, SageMaker etc. - experience with AWS ecosystem a plus)', 'Ability to lead technical architecture discussions and help drive technical decisions, as well as implement day-to-day changes', 'We’ve created an outrageously valuable data set that’s never existed before, we’re confident we can generate alpha. In order to reach our potential, we need to apply state-of-the-art machine learning and data science techniques towards natural language processing, security, anomaly detection, optimization, and time series forecasting.', 'We’re also a data-driven company: every product decision is backed by data. We can’t build a world-changing product without a world-class data scientist to provide insight and guidance.', 'PostgreSQL', 'Python + R', 'Metabase', 'AWS', 'IEX', 'Mixpanel', 'Datadog']",2020-09-24 14:00:12
"Staff Engineer, Data (Bank Charter)",SoFi,3.2 out of 5,"Seattle, WA","['Design and architect data structures in Data Warehouse', 'Build and modify data pipelines via Extract, Transform, Load (ETL) processes', 'Provision, optimize and maintain data feeds to external systems', 'Write SQL queries to validate quality and clean existing data', 'Build out automated checks and work within the team for data quality', 'Help analytics team and business users in querying and understanding the Data Warehouse', ""Bachelor's degree"", '6+ years industry experience', 'Experience writing SQL against different database platforms and advising best practices along the way', 'Demonstrated skills and experience in finding, investigating, and resolving data quality issues', 'Demonstrated skills and experience in building data feeds and business reports', 'Self-motivated', 'Ability to bring new ideas and promote process improvement', 'Experience with reporting systems such as Tableau', '3+ years of of Python', 'First-rate attention to detail', '1+ years of Kafka', 'Direct experience querying data lakes', 'Understanding of Data Warehouses and ETL', 'Ability to thrive in a fast-paced growing company', 'Ability to drive a project from inception to completion', 'Enthusiasm for solving challenging problems', 'Team attitude: a willingness to roll up your sleeves, work with others and get stuff done', 'Ability to work quickly and accurately under pressure', 'Competitive salary packages and bonuses', 'Comprehensive medical, dental, vision and life insurance benefits', 'Generous vacation and holidays', 'Paid parental leave for eligible employees', '401(k) and education on retirement planning', 'Tuition reimbursement on approved programs', 'Monthly contribution up to $200 to help you pay off your student loans', 'Great health & well-being benefits including: telehealth parental support, subsidized gym program', 'Employer paid lunch program (except for remote employees)', 'Fully stocked kitchen (snacks and drinks)']",2020-09-24 14:00:12
"Senior Staff Software Engineer, Data",Tinder,4.8 out of 5,"West Hollywood, CA 90069","['Guide and oversee the architecture, implementation, testing, and operations of core data services', 'Collaborate with Engineering, Product, and Analytics on the expansion of our data serving layer', 'Drive and coordinate cross-team/company-wide initiatives', 'Be the steward for promoting data engineering best practices, from data governance to data ingestion, data storage, and data serving', 'Influence the roadmap and development for the Data Engineering team', 'Mentor and guide junior engineers', 'Excellent knowledge of Computer Science fundamentals, with strong competencies in data structures, algorithms, software design, and coding', 'Hands on experience building and maintaining large scale analytics systems in production', 'Hands on experience building streaming pipelines leveraging technologies such as Apache Kafka, Apache Spark, and Flink', 'Strong Scala/Java skills and experience', 'Eagerness and humility to keep learning and growing, and a passion for providing mentorship', 'Able to apply long-term and high-level thinking and problem solving skills to complex problems', 'A BS, MS, or PhD in Computer Science or Engineering from a top school, but a wonderful project list is even better', 'Bonus points for strong machine learning or stats knowledge', 'The hustle of a startup with the impact of a global business', 'Tremendous opportunity to seek some of the industry’s most exciting problems', 'Working with an outstanding team of creative, fun and highly motivated people', 'Comprehensive health coverage, competitive salary, and 401(k) match']",2020-09-24 14:00:12
Data Engineer,Catalytic Data Science,N/A,South Carolina,"['Build & operate automated ETL pipelines that process terabytes of text data nightly', 'Develop service frontends around our various backend datastores (AWS Aurora MySQL, Elasticsearch, S3)', 'Perform technical analyses and requirements specification with our product team on data service integrations', 'Help customers bring their data to the platform', 'Python 3 or Java programming experience, preferably both', 'Day-to-day experience using AWS technologies such as Lambda, ECS Fargate, SQS, & SNS', 'Experience building and operating cloud-native data pipelines', 'Experience extracting, processing, storing, and querying of petabyte-scale datasets', 'Familiarity with building and using containers', 'Familiarity with event-based microservices', 'Prior experience with Elasticsearch (custom development and/or administration) is a huge plus', 'Prior work with text and natural-language processing', 'Knowledge of Graph databases', 'Focus on customer’s needs and our company’s goals, not just writing code', 'Iterate until customers love what you’ve built', 'Self-start and initiate', 'Self-organize', 'Strive to grow personally and professionally, beyond just expanding technical abilities', 'Love to experiment with new technology and share knowledge with the team']",2020-09-24 14:00:12
Cloud Engineer,THE TALENT STATE CONSULTANT,N/A,"Lake, IL","['AWS Certified Solutions Architect, AWS Certified Solutions Associate, AWS Certified Cloud Practitioner.', 'Certified Kubernetes Administrator (CKA), Certified Kubernetes Application Developer (CKAD).', 'Docker Certified Associate (DCA).', 'Bachelor’s Degree or equivalent education and typically 12 years of IT/Developer related experience.', 'Minimum 3 - 5 years of experience in designing, executing, and supporting services such as AWS (Azure experience a plus), Kubernetes and Docker.', 'Minimum 3-5 years of experience with CI/CD tooling and automation utilizing GIT, Jenkins, Ansible, Cloud Formation, Terraform or similar.', 'Minimum 3-5 years Linux OS experience (Windows a plus).', 'Proven implementation of creative technology solutions that advance the business.', 'Positive attitude and a strong commitment to delivering quality work.', 'Excellent knowledge of cloud computing technologies and current computing trends.', 'Has participated in the design, implementation, and migration of applications to a cloud environment.', 'Recent work experience health care/life science organization is a plus.', 'Experience in the systems development, implementation, and operations of a large-scale, enterprise systems.', 'Excellent interpersonal skills and well-developed verbal and written communication skills.', 'Must be able to effectively lead and facilitate meetings with customers and technical team members.', 'Must be deliverables focused and detail oriented.', 'Must exhibit exceptional teamwork skills.', 'Must have a strong customer focus.', 'AbbVie is looking for a highly motivated Cloud Kubernetes Engineer that will be responsible for the engineering, implementation, and operations of cloud services in a multi-cloud environment supporting scientific and R&D related activities.', 'The ideal candidate will have a solid understanding of AWS, Docker EE, Kubernetes (EKS) and ECS along with multiple automation toolsets and practices.', 'This candidate should have the experience and ability to collaborate with various business units to provide consultation and support on-premise hardware and cloud solutions with a focus on best practices and security.', 'This role will be expected to investigate and engineer new technologies focused on automation to enhance and secure both on-prem and cloud platforms fostering agility to the business.', 'Expertise and in-depth knowledge of Kubernetes, AWS EKS and AWS ECS (Docker EE a plus).', 'Develops process and standards for Kubernetes, AWS EKS and AWS ECS.', 'Collaborates with Enterprise Docker team to develop and understand process and standards.', 'Develops container deployment strategy in line with current deployment and automation toolsets (GIT, Jenkins, Ansible, CloudFormation, and Terraform).', 'Reviews architectural diagrams for proposed solutions and implements the standard cloud or on prem services based on compute, data, or security requirements.', 'Develops templates for automating Kubernetes, AWS EKS and AWS ECS related deployments.', 'A solid understanding of networking and core Internet protocols (e.g. TCP/IP, DNS, SMTP, HTTP, and distributed networks).', 'Collaborates with cross-functional teams to support the engineering and implementation of new cloud applications or solutions.', 'Assists development teams with proof of concept cloud services and implementations.', 'Collaborates with the architecture team on strategy.', 'Adheres to corporate standards regarding applicable corporate and divisional policies.', 'AWS (Azure experience a plus): 3 years (Preferred)', 'Kubernetes and Docker: 3 years (Preferred)', 'Linux OS experience (Windows a plus): 3 years (Preferred)', 'IT/Developer: 10 years (Preferred)', 'Temporarily due to COVID-19']",2020-09-24 14:00:12
Hardware Test Engineer,keywordsolutions,N/A,"Redmond, WA","['Minimum 1 year of image processing and/or image quality testing related working experience for consumer devices.', 'Knowledge of image quality metrics and test methods on noise, sharpness, distortion, color fidelity, 3A, etc. Understand how they relate to camera performance.', 'Good programming/scripting skills on C#, Python, Shell script and MATLAB.', 'Familiar with IMATEST, Skype and other standard camera test/analysis tools are a plus.', 'Good skills on data analysis and reporting. Good at writing test documentation including test plans, procedures, and reports.', 'Strong communication skills required, including the ability to clearly express technical concepts in verbal and written forms.', 'Temporarily due to COVID-19']",2020-09-24 14:00:12
Data Modeler,Archer Daniels Midland Company,3.7 out of 5,"Erlanger, KY","['Implement business and IT data requirements through new data strategies and designs across all data platforms (relational, dimensional, and NoSQL)', 'Work with solution teams and Data Architects to implement data strategies, build data flows, and develop logical/physical data models', 'Work with Data Architects to define and govern data modeling and design standards, tools, previous findings, and related development for enterprise data models.', 'Hands-on modeling, design, configuration, installation, performance tuning, and sandbox POC.', 'Work proactively and independently to address project requirements and articulate issues/challenges to reduce project delivery risks.', 'Build, maintain, optimize and update logical and physical data models along with corresponding metadata to support new and existing projects.', 'Develop standard methodologies for standard naming conventions and coding practices to maintain consistency of data models.', 'Recommend opportunities for reuse of data models in new environments.', 'Perform reverse engineering of physical data models from databases and SQL scripts.', 'Evaluate data models and physical databases for variances and discrepancies.', 'Validate business data objects for accuracy and completeness.', 'Analyze data-related system integration challenges and propose appropriate solutions.', 'Guide System Analysts, Engineers, Programmers and others on project limitations and capabilities, performance requirements and interfaces.', 'Evaluate modifications to existing data model and new application design and recommend efficiency gains or corrections when requiredSkills', 'Bachelor degree in computer/data science technical or related experience.', '5+ years of hands-on relational, dimensional, and/or analytic experience (using RDBMS, dimensional, NoSQL data platform technologies, and ETL and data ingestion protocols).', 'Experience with data warehouse, Data Lake and enterprise big data platforms in multi-data-center contexts required.', 'Experience with metadata management, data modeling, and related tools (Erwin or ER Studio or others) required.', 'Experience in team management, communication, and presentation.', 'Understanding of agile delivery methodology and experience working in scrum environment', 'Ability to understand and translate business needs into data vault and dimensional data models supporting long-term solutions.', 'Work with the Application Development team to implement appropriate data strategies.', 'This position offers a complete benefit package, including 401K/ESOP, pension, health, life, vision, and dental insurance. ADM requires the successful completion of a pre-employment drug screen and a background check.']",2020-09-24 14:00:12
Senior Data Engineer,HEB,4.3 out of 5,"Austin, TX 78702","['Work with HEB Digital teams to provide data solutions for ecommerce, supply chain, store operations, finance, and marketing reporting and analytics platforms', 'Contribute to existing data platforms and implement new technologies', 'Develop a deep understanding of HEB’s data and become a domain expert', 'Ensure data is distributed in a timely and accurate manner', 'Make data discoverable and accessible to business users', '4+ years of data engineering experience', 'Proficient with data technologies (e.g. Spark, Kinesis, Kafka, Airflow, Oracle, PostgreSQL, Redshift, Presto, etc.)', 'Experienced with designing and developing ETL data pipelines using tools such as Airflow, Nifi, or Kafka.', 'Strong understanding of SQL and data modeling', 'Understanding of Linux, Amazon Web Services (or other cloud platforms), Python, Docker, and Kubernetes', 'Experienced with common software engineering tools (e.g., Git, JIRA, Confluence, or similar)', ""Bachelor's degree in computer science or comparable field or equivalent experience"", 'A proven understanding and application of computer science fundamentals: data structures, algorithms, design patterns, and data modeling', 'A robust Benefits plan with coverage starting Day One', 'Dental, vision, life, and other insurance plans; flexible spending accounts; short term / long term disability coverage', 'Partner Care Team, for any time you have healthcare or coverage questions', 'Telehealth offers 24/7 access to board-certified doctors by phone', 'Partner Guidance allows free counselor visits', 'Funeral leave, jury duty, and military pay (subject to applicable law)', 'Maternal / paternal leave for new parents, including adoptions', '10% off H-E-B brand products in-store and online', 'Eligibility to participate in 401(k)', 'Opportunity to become a “Partner-Owner” after 12 months', 'H-E-B is one of the largest, independently owned food retailers in the nation, operating over 400 stores throughout Texas and Mexico, with annual sales generating over $25 billion', 'We hire talented people (109,000+ Partners), and give them autonomy to be creative in how they impact the business', 'We’re a Partner-driven company with a Bold Promise – Because People Matter', 'We embrace Diversity and Inclusion as core values, and support them with thriving company-wide programs', 'We’re a truly original Texas-based company that created the Spirit of Giving to help Texas communities every day', 'Once eligible, our Partners become Owners in the company. “Partner-owned” means our most important resources—People—drive the innovation, growth, and success that make H-E-B The Greatest Retailing Company']",2020-09-24 14:00:12
Data Engineer,Easton Diamond Sports,2.9 out of 5,"Exeter, NH","[""Bachelor's degree in Computer science or a related field (MBA a plus) with 3+ years of practical work experience or the equivalent combination of education and experience."", 'Comprehensive knowledge of database technologies including, but not limited to Google Cloud, AWS, SQL, Hadoop, SAP HANA, and Alteryx.', 'Hands-on experience developing platforms that translate big data into business insight.', 'Strong knowledge of data structures and operating systems.', 'Knowledge of database maintenance and administration techniques.', 'Experience with Machine Learning languages is a plus.', 'Desire to work in a high-paced environment.', 'Strong problem-solving skills and the ability to work independently.', 'Strong written and verbal communication skills.']",2020-09-24 14:00:12
Data Engineer,Easton Diamond Sports,N/A,"Exeter, NH","['Interviews on the spot', 'Tuesday, September 29, 20208:30 AM - 12:30 PM US/Central', ""Interviewing via webYou'll receive an email on how to connect."", '44 slots left', '', ""Senior Staff Data Engineer$160,000 - $180,000 / year, Full-timeResponsibilities:\xa0Individual Contributor (expected to be hands-on coder 50%-80% of the time)Lead the design and delivery of complex, cross-team systems built and deployed on AWSInterview top talent for Engineering's staffing needsMentor highly talented engineers within the org\xa0Required Skills:\xa012+ years of overall relevant Software Engineering experience7+ years of Data Engineering development experience including familiarity in multiple batch and streaming data processing technologies (Hadoop, Spark, Kafka, MapReduce, Hive, etc.)3+ years Architecting, Designing and Building large-scale, multi-use Big Data Systems on Public cloud hosting providersStrong communication skills (including influencing across multiple teams)Extensively worked in a range of database technologies including SQL and noSQL DB\xa0Nice to Have:\xa03+ years in AWS environmentEcommerce industry experience"", 'Individual Contributor (expected to be hands-on coder 50%-80% of the time)', 'Lead the design and delivery of complex, cross-team systems built and deployed on AWS', ""Interview top talent for Engineering's staffing needs"", 'Mentor highly talented engineers within the org', '12+ years of overall relevant Software Engineering experience', '7+ years of Data Engineering development experience including familiarity in multiple batch and streaming data processing technologies (Hadoop, Spark, Kafka, MapReduce, Hive, etc.)', '3+ years Architecting, Designing and Building large-scale, multi-use Big Data Systems on Public cloud hosting providers', 'Strong communication skills (including influencing across multiple teams)', 'Extensively worked in a range of database technologies including SQL and noSQL DB', '3+ years in AWS environment', 'Ecommerce industry experience', 'Senior Data Engineer$130,000 - $150,000 / year, Full-timeSkills and Experience:\xa03-5 years of experience with highly scalable distributed systems using open source toolsIn-depth knowledge of the software development lifecycleAn ability to demonstrate software engineering fundamentals such as OO design, unit testing, code reuse, code reviewsExtensive knowledge in different programming and scripting languages such as Java, C++, PHP, Ruby, Python, etc.Familiarity with one of more big data infrastructures such as Hbase, Hadoop, Kafka, Cassandra, or RDBMSData ETL and data modelingModern build tools such as Maven, Jenkins, Github', '3-5 years of experience with highly scalable distributed systems using open source tools', 'In-depth knowledge of the software development lifecycle', 'An ability to demonstrate software engineering fundamentals such as OO design, unit testing, code reuse, code reviews', 'Extensive knowledge in different programming and scripting languages such as Java, C++, PHP, Ruby, Python, etc.', 'Familiarity with one of more big data infrastructures such as Hbase, Hadoop, Kafka, Cassandra, or RDBMS', 'Data ETL and data modeling', 'Modern build tools such as Maven, Jenkins, Github', 'Interviews on the spot', 'Tuesday, September 29, 20208:30 AM - 12:30 PM US/Central', ""Interviewing via webYou'll receive an email on how to connect."", '44 slots left', 'United States+1', 'United Kingdom+44', '', 'Afghanistan (\u202bافغانستان\u202c\u200e)+93', 'Albania (Shqipëri)+355', 'Algeria (\u202bالجزائر\u202c\u200e)+213', 'American Samoa+1684', 'Andorra+376', 'Angola+244', 'Anguilla+1264', 'Antigua and Barbuda+1268', 'Argentina+54', 'Armenia (Հայաստան)+374', 'Aruba+297', 'Australia+61', 'Austria (Österreich)+43', 'Azerbaijan (Azərbaycan)+994', 'Bahamas+1242', 'Bahrain (\u202bالبحرين\u202c\u200e)+973', 'Bangladesh (বাংলাদেশ)+880', 'Barbados+1246', 'Belarus (Беларусь)+375', 'Belgium (België)+32', 'Belize+501', 'Benin (Bénin)+229', 'Bermuda+1441', 'Bhutan (འབྲུག)+975', 'Bolivia+591', 'Bosnia and Herzegovina (Босна и Херцеговина)+387', 'Botswana+267', 'Brazil (Brasil)+55', 'British Indian Ocean Territory+246', 'British Virgin Islands+1284', 'Brunei+673', 'Bulgaria (България)+359', 'Burkina Faso+226', 'Burundi (Uburundi)+257', 'Cambodia (កម្ពុជា)+855', 'Cameroon (Cameroun)+237', 'Canada+1', 'Cape Verde (Kabu Verdi)+238', 'Caribbean Netherlands+599', 'Cayman Islands+1345', 'Central African Republic (République centrafricaine)+236', 'Chad (Tchad)+235', 'Chile+56', 'China (中国)+86', 'Christmas Island+61', 'Cocos (Keeling) Islands+61', 'Colombia+57', 'Comoros (\u202bجزر القمر\u202c\u200e)+269', 'Congo (DRC) (Jamhuri ya Kidemokrasia ya Kongo)+243', 'Congo (Republic) (Congo-Brazzaville)+242', 'Cook Islands+682', 'Costa Rica+506', 'Côte d’Ivoire+225', 'Croatia (Hrvatska)+385', 'Cuba+53', 'Curaçao+599', 'Cyprus (Κύπρος)+357', 'Czech Republic (Česká republika)+420', 'Denmark (Danmark)+45', 'Djibouti+253', 'Dominica+1767', 'Dominican Republic (República Dominicana)+1', 'Ecuador+593', 'Egypt (\u202bمصر\u202c\u200e)+20', 'El Salvador+503', 'Equatorial Guinea (Guinea Ecuatorial)+240', 'Eritrea+291', 'Estonia (Eesti)+372', 'Ethiopia+251', 'Falkland Islands (Islas Malvinas)+500', 'Faroe Islands (Føroyar)+298', 'Fiji+679', 'Finland (Suomi)+358', 'France+33', 'French Guiana (Guyane française)+594', 'French Polynesia (Polynésie française)+689', 'Gabon+241', 'Gambia+220', 'Georgia (საქართველო)+995', 'Germany (Deutschland)+49', 'Ghana (Gaana)+233', 'Gibraltar+350', 'Greece (Ελλάδα)+30', 'Greenland (Kalaallit Nunaat)+299', 'Grenada+1473', 'Guadeloupe+590', 'Guam+1671', 'Guatemala+502', 'Guernsey+44', 'Guinea (Guinée)+224', 'Guinea-Bissau (Guiné Bissau)+245', 'Guyana+592', 'Haiti+509', 'Honduras+504', 'Hong Kong (香港)+852', 'Hungary (Magyarország)+36', 'Iceland (Ísland)+354', 'India (भारत)+91', 'Indonesia+62', 'Iran (\u202bایران\u202c\u200e)+98', 'Iraq (\u202bالعراق\u202c\u200e)+964', 'Ireland+353', 'Isle of Man+44', 'Israel (\u202bישראל\u202c\u200e)+972', 'Italy (Italia)+39', 'Jamaica+1', 'Japan (日本)+81', 'Jersey+44', 'Jordan (\u202bالأردن\u202c\u200e)+962', 'Kazakhstan (Казахстан)+7', 'Kenya+254', 'Kiribati+686', 'Kosovo+383', 'Kuwait (\u202bالكويت\u202c\u200e)+965', 'Kyrgyzstan (Кыргызстан)+996', 'Laos (ລາວ)+856', 'Latvia (Latvija)+371', 'Lebanon (\u202bلبنان\u202c\u200e)+961', 'Lesotho+266', 'Liberia+231', 'Libya (\u202bليبيا\u202c\u200e)+218', 'Liechtenstein+423', 'Lithuania (Lietuva)+370', 'Luxembourg+352', 'Macau (澳門)+853', 'Macedonia (FYROM) (Македонија)+389', 'Madagascar (Madagasikara)+261', 'Malawi+265', 'Malaysia+60', 'Maldives+960', 'Mali+223', 'Malta+356', 'Marshall Islands+692', 'Martinique+596', 'Mauritania (\u202bموريتانيا\u202c\u200e)+222', 'Mauritius (Moris)+230', 'Mayotte+262', 'Mexico (México)+52', 'Micronesia+691', 'Moldova (Republica Moldova)+373', 'Monaco+377', 'Mongolia (Монгол)+976', 'Montenegro (Crna Gora)+382', 'Montserrat+1664', 'Morocco (\u202bالمغرب\u202c\u200e)+212', 'Mozambique (Moçambique)+258', 'Myanmar (Burma) (မြန်မာ)+95', 'Namibia (Namibië)+264', 'Nauru+674', 'Nepal (नेपाल)+977', 'Netherlands (Nederland)+31', 'New Caledonia (Nouvelle-Calédonie)+687', 'New Zealand+64', 'Nicaragua+505', 'Niger (Nijar)+227', 'Nigeria+234', 'Niue+683', 'Norfolk Island+672', 'North Korea (조선 민주주의 인민 공화국)+850', 'Northern Mariana Islands+1670', 'Norway (Norge)+47', 'Oman (\u202bعُمان\u202c\u200e)+968', 'Pakistan (\u202bپاکستان\u202c\u200e)+92', 'Palau+680', 'Palestine (\u202bفلسطين\u202c\u200e)+970', 'Panama (Panamá)+507', 'Papua New Guinea+675', 'Paraguay+595', 'Peru (Perú)+51', 'Philippines+63', 'Poland (Polska)+48', 'Portugal+351', 'Puerto Rico+1', 'Qatar (\u202bقطر\u202c\u200e)+974', 'Réunion (La Réunion)+262', 'Romania (România)+40', 'Russia (Россия)+7', 'Rwanda+250', 'Saint Barthélemy+590', 'Saint Helena+290', 'Saint Kitts and Nevis+1869', 'Saint Lucia+1758', 'Saint Martin (Saint-Martin (partie française))+590', 'Saint Pierre and Miquelon (Saint-Pierre-et-Miquelon)+508', 'Saint Vincent and the Grenadines+1784', 'Samoa+685', 'San Marino+378', 'São Tomé and Príncipe (São Tomé e Príncipe)+239', 'Saudi Arabia (\u202bالمملكة العربية السعودية\u202c\u200e)+966', 'Senegal (Sénégal)+221', 'Serbia (Србија)+381', 'Seychelles+248', 'Sierra Leone+232', 'Singapore+65', 'Sint Maarten+1721', 'Slovakia (Slovensko)+421', 'Slovenia (Slovenija)+386', 'Solomon Islands+677', 'Somalia (Soomaaliya)+252', 'South Africa+27', 'South Korea (대한민국)+82', 'South Sudan (\u202bجنوب السودان\u202c\u200e)+211', 'Spain (España)+34', 'Sri Lanka (ශ්\u200dරී ලංකාව)+94', 'Sudan (\u202bالسودان\u202c\u200e)+249', 'Suriname+597', 'Svalbard and Jan Mayen+47', 'Swaziland+268', 'Sweden (Sverige)+46', 'Switzerland (Schweiz)+41', 'Syria (\u202bسوريا\u202c\u200e)+963', 'Taiwan (台灣)+886', 'Tajikistan+992', 'Tanzania+255', 'Thailand (ไทย)+66', 'Timor-Leste+670', 'Togo+228', 'Tokelau+690', 'Tonga+676', 'Trinidad and Tobago+1868', 'Tunisia (\u202bتونس\u202c\u200e)+216', 'Turkey (Türkiye)+90', 'Turkmenistan+993', 'Turks and Caicos Islands+1649', 'Tuvalu+688', 'U.S. Virgin Islands+1340', 'Uganda+256', 'Ukraine (Україна)+380', 'United Arab Emirates (\u202bالإمارات العربية المتحدة\u202c\u200e)+971', 'United Kingdom+44', 'United States+1', 'Uruguay+598', 'Uzbekistan (Oʻzbekiston)+998', 'Vanuatu+678', 'Vatican City (Città del Vaticano)+39', 'Venezuela+58', 'Vietnam (Việt Nam)+84', 'Wallis and Futuna (Wallis-et-Futuna)+681', 'Western Sahara (\u202bالصحراء الغربية\u202c\u200e)+212', 'Yemen (\u202bاليمن\u202c\u200e)+967', 'Zambia+260', 'Zimbabwe+263', 'Åland Islands+358']",2020-09-24 14:00:59
SQL/Data Engineer,Enquire Solutions,3.3 out of 5,"Greenwood Village, CO 80111","['Create, modify, and implement stored procedures', 'Create and update tables, views, and functions', 'Monitor and run SSIS packages', 'Translate client business requirements into technical CRM requirements', 'Data mapping of client legacy system to Enquire CRM', 'Communicate directly with clients to identify areas for data cleansing and transformation', 'Works closely with client to debug/fix data issues during and post-implementation', 'Handle multiple implementations at any given time while working with set deadlines', 'Bachelor’s in Computer Science or a related field', '3-5 years experience with SQL, SSIS, and ETL development', '1+ years data warehousing experience', 'Proficient with MS Office suite', 'Team-oriented and highly motivated. Demonstrates a high level of cooperation with others.', 'Excellent problem-solving skills with the ability to communicate issues and provide resolutions in an easy to understand manner with clients and technical team members.', 'Highly organized and able to work under pressure to complete tight deadlines.', 'Agile SDLC experience preferred', 'Ability to represent Enquire in a positive and professional manner', 'Must live in Colorado']",2020-09-24 14:00:59
Data Center Engineer,General Dynamics Information Technology,3.8 out of 5,"Falls Church, VA 22042","['Supply expert knowledge in the move or fit-out of a new classified data center instance', 'Have extensive knowledge of the requirements for establishing and maintaining a SCIF approved data center instance', 'Be able to manage the project from requirements gathering through to final authorization of the center to operate', 'Have experience with redundancy and load balancing across multiple data center locations', 'Design, build, maintain, monitor, and support infrastructure environments and data center facilities', 'Act as technical liaison between the IT Infrastructure team and Business owner to provide insight into upcoming implementations and strategies including validation of ongoing solutions supportability.', 'Work across teams to ensure IT system upgrades, deployments and maintenance are conducted with minimal impact to the operation.', 'Continuously monitor and evaluate IT Infrastructure security, providing ongoing recommendations and reporting any issues when appropriate.', 'Participate in design, implementation and execution of backup and disaster recovery.', 'Define, implement, and monitor solutions and tools that automate and alert on systems and network performance and issues', 'Plan, develop, organize, write, edit and keep current documentation including project plans, project proposals, technical operation documentation, procedure documentation, network diagrams, data flow diagrams, technical support documentation, and scope of work documentation.', 'Complete risk management tasks for areas of responsibility or as assigned including but not limited to: required risk assessments are completed and revisited at required intervals; all vendor management due diligence, risk assessments, monitoring and other documentation is completed for new and existing technology vendors as required.']",2020-09-24 14:00:59
Data Engineer - Bigdata,Olsten Staffing,3.9 out of 5,"Sunnyvale, CA","['Pay:', 'From $60.00 per hour', 'Experience:Hive, 2 years (Required)Spark, 2 years (Required)Java / Python, 4 years (Required)Bigdata, 9 years (Required)Hadoop, 7 years (Required)', 'Monday to Friday', 'Hive: 2 years (Required)', 'Spark: 2 years (Required)', 'Java / Python: 4 years (Required)', 'Bigdata: 9 years (Required)', 'Hadoop: 7 years (Required)', 'Temporarily due to COVID-19']",2020-09-24 14:00:59
"Applications Engineer, University Graduate, 2021",Google,4.3 out of 5,"Austin, TX","[""Master's degree in Information Technology/Systems or related technical field or equivalent practical experience."", 'Coursework and/or experience developing business applications end-to-end, including front-end, data storage and application integration.', 'Programming experience in Java and scripting (e.g., Perl, Shell, Python, XML).', 'Knowledge of SQL, relational database concepts and Unix/Linux.', 'Understanding of software development life cycle, SAP, and/or Salesforce technologies.', 'Understanding of information management, data modeling, system integration, development methodologies (including unit testing), web technologies.', 'Communication skills and proven ability to work effectively with all organizational levels.', 'Ability to start a full-time role in 2021.', 'Develop and deploy applications that support and change fundamental assumptions of how IT works.', 'Partner with internal teams to define and implement solutions that improve internal business processes.', 'Work closely with analysts to translate business requirements into technical solutions.', 'Build internal solutions, with custom front-ends (web, mobile) and back-end services that automate business processes. Maintain highest levels of development practices including: technical design, solution development, systems configuration, test documentation/execution, issue identification and resolution, writing clean, modular, and self-sustaining code.', 'Integrate third party products into internal systems as well as support and upgrade implemented systems.']",2020-09-24 14:00:59
Data Scientist,Ushur,N/A,United States,[],2020-09-24 14:00:59
Senior Interface Engineer,Bridgecr LLC,N/A,Remote,"['Bi-directional, cross-platform communication and management of data between disparate systems.', 'Quickly break down complex problems into potential solutions, knowns, unknowns, in order to get solid resolutions.', 'A proven record of creating sweeping improvements in stability, performance and scalability across major business-critical systems.', 'Multiplies the effectiveness of other engineers by facilitating cross-team and intradepartmental team work.', 'Ability to pick up new technology quickly and adapt in a growth environment.', 'Deliver software on-time, in scope, and make accurate estimates.', 'Demonstrable, progressive experience as an SSE for seven or more years.', 'Developing enterprise software. Specifically, extensive experience creating readable and testable code.', 'Capable of debugging the most challenging of problems the team encounters.', 'Experience working in a team environment using agile sprint methodologies and tools including Jira, Git, and Slack.', 'Proven understanding of architectural design patterns and the proper use cases associated with each.', 'Experience integrating/consuming RESTful APIs.', 'Healthcare domain knowledge', 'Integration platform as a service', 'HL7 v 2.x, CCDA, FHIR, REST, X12']",2020-09-24 14:00:59
"Data Engineer, Senior",Booz Allen Hamilton,3.9 out of 5,"Herndon, VA","['5+ years of experience with Extraction, Transaction, and Loading (ETL) processes, Relational Database Management Systems (RDBMS), and non-SQL data stores, storage configuration, search, query, and extraction', 'Experience with designing, creating, and implementing indexes to speed retrieval of massive data', 'Experience with gathering analyst requirements and creating, organizing, and using data stores and use indexes', 'Experience with creating and using data documents', 'Experience with optimizing queries and retrieving data', 'Experience in integrating predictive models with application code to support analysis', 'Ability to obtain a security clearance', 'BA or BS degree or MA or MS degree and 3 years of experience in data science', 'Knowledge of Intelligence Community or DHS systems and tools', 'Possession of excellent oral and written communication skills', 'Possession of excellent interpersonal skills']",2020-09-24 14:00:59
Data Engineer,VidMob,4 out of 5,"Pittsfield, MA 01201","['VidMob is proud to offer comprehensive health plans paid for by the company, enhanced Maternity/Paternity Programs and unlimited vacation plans.', 'We also provide employees with access to 401K plans, healthy food and snacks, and pre-taxed transit.', 'Competitive salary and equity (based on experience).', 'Benefits:', 'Health Care Plan (Medical, Dental & Vision)', 'Unlimited Paid Time Off (Vacation, Sick & Public Holidays)', 'Family Leave (Maternity, Paternity)', 'Training & Development', 'Stock Option Plan', '401k Plan', 'Work with data insights teams to define and extract data sets for use in analysis and machine learning', 'Work with software engineering and data science teams to design, build, and manage our application DB, machine learning components, and our data infrastructure', 'Maintain, extend, and automate reporting infrastructure', 'Manage the design and architecture of our data warehouse', 'Create software tools to automate and manage ETL processes and dependencies', 'B.S. in computer science or equivalent experience', 'Advanced working knowledge of SQL and relational databases, MySQL preferred', 'Understanding of statistics and data modeling methodologies', 'Experience collaborating with Data Scientists and Data Analysts', 'Ability to create fast solutions to problems introduced in a changing environment with iteration towards optimal solutions', 'Experience with data-related AWS services such as RDS, Redshift, and Kinesis', 'Experience with programming or scripting language, preferably Python, Java, or Scala', 'Health Care Plan (Medical, Dental & Vision)', 'Unlimited Paid Time Off (Vacation, Sick & Public Holidays)', 'Family Leave (Maternity, Paternity)', 'Training & Development', 'Stock Option Plan', '401k Plan']",2020-09-24 14:00:59
Data Engineer – Geospatial,KoBold Metals,N/A,Remote,"['Design aspects of the TerraShed™ data system to ingest, store, and quickly process and access a wide variety of geoscience data', 'Integrate diverse and messy geophysical, geochemical, geologic, and geographic data from around the world into a well-structured proprietary data system', 'Create tools for ingesting unstructured datasets and extracting key features', 'Develop methods and tools to enable data scientists and geoscientists to rapidly view and interrogate both model results and underlying data', 'Proficiency in Python', 'Proficiency in Postgres/PostGIS', 'Familiarity with open-source libraries for manipulating (e.g., GDAL, ogr), visualizing (e.g., leaflet), and serving (e.g., WMS) geospatial data', 'Familiarity with desktop software used for geospatial visualization and analysis and experience integrating these tools with other data systems, e.g., through custom plugins', 'Familiarity with how geologists use 2D and 3D geospatial data, including both analyses based on 2D GIS projects as well as 3D modeling', 'Experience with setting up and deploying systems on AWS', 'Excited to work on a wide range of problems, and to take on a wide range of responsibilities, learning new tech tools whenever needed', 'Highly intellectually curious and eager to learn from technical experts who aren’t software people', 'Keen not just to build products, but to figure out what product to build to best achieve the business objectives of the company', 'Highly self-motivated and autonomous, able to effectively structure one’s own work, make realistic time estimates, and communicate well as one progresses', 'Comfortable with a fast-changing work environment', 'Careful to get the details right', 'A bachelor’s degree or higher in geoscience, other physical sciences, engineering, computer science, or mathematics', 'Experience with Flask or similar web frameworks']",2020-09-24 14:00:59
Data Engineer,"Marsh & McLennan Companies, Inc.",3.7 out of 5,"New York, NY","['Work in a diverse and inclusive culture as part of a global CIO organization', 'A fast pace, demanding and collaborative environment with exposure to the senior most leaders in the Technology organization', 'Career Growth – performance is rewarded with new opportunities', 'Impact – Opportunity to work on exciting projects as part of a program that is on the executive committee agenda', 'Benefits – competitive salaries and comprehensive benefits and programs including: health and welfare, tuition assistance, 401K, employee assistance program, domestic partnership benefits, career mobility, employee network groups, volunteer opportunities, and other programs', 'Specializes in one or more of the following areas: Server, Network (voice/data), messaging/collaboration, mainframe, Architecture, Storage/backup, Applied Engineering and/or Application engineering.', 'Designs, develops, implements, and analysis of Technical product/systems.', 'Creates, manages and maintains strategy, standards, roadmaps and new technologies.', 'Provides advanced design and engineering functions for one or more of the following skillset areas: Server, Network (voice/data), Messaging/Collaboration, Mainframe, Implementation, Architecture, Storage/Backup, and/or Application design.', 'Recommends alterations to developments and designs; improving quality of products/procedures', 'Manages Engineering Support staff in one or more of the following areas: standards, projects, level III support issues, designs and overall IT Engineering for Infrastructure/Technology.', 'Trains, leads, mentors, Engineers and Managers.', 'Creates, manages, maintains departmental policies, processes and procedures; relating to standards, projects and cross functional interoperability.', 'Prepares and tracks budgets, project/staffing plans.', 'Understands/communicates, Strategic/Global Initiatives and Infrastructures.', 'Consultants to aid in the development of solutions; Works closely with the Project Management Office and stakeholders to provide guidance/ advice concerning infrastructure issues', 'Identifies opportunities and recommends solutions for improving service efficiency and effectiveness.', 'Provides levels II/III support for Hardware and Operating System issues.', 'Documents Operational procedures; hand-off to the Operations Group.', 'Understands/communicates, Strategic/Global Initiatives and Infrastructures.', 'Solid expertise in setting up pipelines to ingest streaming, batch data from diverse sources, and perform data virtualization and/or ETL processes to make the data more usable, both with on-promise technologies and cloud-based solution providers', 'Proficiency in a programming language, such as Python, Java, SQL query engines Apache Spark, Rest APIs and the Hadoop ecosystem', 'Experience with data buffering such as with Apache Kafka, data stores such as any SQL or NoSQL,', 'Solid understanding of physical data base/structure modeling and implementations', 'Expert use and understanding of SQL', 'Solid understanding of data virtualization tools such as Dremio, data catalogues such as INFA EDC, Alation, ETL tools and BI tools such as Power BI and Tableau', 'Workflow tools for Orchestration/Automation/Pipelining', 'Solid logical Data Modelling for OLAP solutions – for Data Lakes, Data Marts and Data Warehouses', 'Experience with Dremio', 'Experience with quality review processes', 'Experience with data profilingData Visualization with Tableau or Power BI']",2020-09-24 14:00:59
Software Engineer - Entry Level,Jet Propulsion Laboratory,4.3 out of 5,"Pasadena, CA 91109","['Cybersecurity Engineer', 'Data Scientist', 'Data Visualization Developer', 'Electrical Ground Support Equipment Software Engineer', 'Engineering Applications Software Engineer', 'Flight Software Engineer', 'Scientific Application & Data Interaction Engineer', 'Scientific Applications Software Engineer', 'Software Systems Architect', 'Software Systems Engineer', 'Software Systems Engineer', 'User Interface Designer', 'User Interface Developer', ""Bachelor's, Master's, or PhD degree in Computer Science, Computer Engineering, Software Engineering, or related major."", 'Minimum of a 3.0/4.0 cumulative GPA.']",2020-09-24 14:00:59
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-09-24 14:00:59
Solutions Engineer,Parallel Domain,N/A,"San Francisco Bay Area, CA","['Prepare and deliver technical presentations tailored to our growing customer base', 'Collaborate with our sales and customer success teams to gather customer requirements through detailed technical discussions and scoping meetings', 'Deeply understand our prospects and customers to demonstrate how Parallel Domain can provide value for customer use cases; architect custom solutions when needed', 'Work closely with product team & internal engineering team to ensure new functionality is available for customer needs', 'Explore new product development areas driven by strategic understanding of customer landscape', '3+ years of customer-facing experience in technical sales for software products', '3+ years as either an application engineer or a developer of complex software for enterprise applications', 'Experience in machine-learning, AI, and/ or simulation products', 'Strong motivation to drive value for prospects & customers - and to provide an exceptional customer experience', 'Excellent communication skills, with an ability to explain complex technical products & excite customers about the technology', '(post-COVID) Ability to travel frequently to different customer locations to work onsite', 'Driven, proactive, organized, high level of professionalism, and strong cross-functional teaming skills', 'Passionate about autonomous systems & Parallel Domain solutions', 'Experience with geographic information systems, maps, or geospatial systems', 'Strong programming and 3D math skills', 'Experience in automotive OEMs', 'Deep software development expertise', 'Experience in the autonomous systems and/or computer vision industries, including but not limited to autonomous vehicles, delivery robots, drones, etc.']",2020-09-24 14:00:59
User Studies Operations Engineer,Apple,4.2 out of 5,"Santa Clara Valley, CA 95014","['Job', 'Company', 'Knowledge of engineering development lifecycle and ability to rapidly acquire familiarity with emergent technologies and software algorithms', 'Experienced in operations, readiness or project management (or equivalent)', 'Meets and exceeds goals through careful planning, risk mitigation, and exception event handling', 'Reduces risk by uncovering hidden problems and driving meaningful mitigation strategies', 'Works well under pressure in the face of unexpected events and is energized by challenges', 'Is a nimble problem solver, driving time-sensitive strategic changes based on a mixture of analysis, experience and collaboration with domain experts']",2020-09-24 14:00:59
"Data Engineer, Senior",Booz Allen Hamilton,3.9 out of 5,"Herndon, VA","['5+ years of experience with Extraction, Transaction, and Loading (ETL) processes, Relational Database Management Systems (RDBMS), and non-SQL data stores, storage configuration, search, query, and extraction', 'Experience with designing, creating, and implementing indexes to speed retrieval of massive data', 'Experience with gathering analyst requirements and creating, organizing, and using data stores and use indexes', 'Experience with creating and using data documents', 'Experience with optimizing queries and retrieving data', 'Experience in integrating predictive models with application code to support analysis', 'Ability to obtain a security clearance', 'BA or BS degree or MA or MS degree and 3 years of experience in data science', 'Knowledge of Intelligence Community or DHS systems and tools', 'Possession of excellent oral and written communication skills', 'Possession of excellent interpersonal skills']",2020-09-24 14:01:43
Data Engineer,VidMob,4 out of 5,"Pittsfield, MA 01201","['VidMob is proud to offer comprehensive health plans paid for by the company, enhanced Maternity/Paternity Programs and unlimited vacation plans.', 'We also provide employees with access to 401K plans, healthy food and snacks, and pre-taxed transit.', 'Competitive salary and equity (based on experience).', 'Benefits:', 'Health Care Plan (Medical, Dental & Vision)', 'Unlimited Paid Time Off (Vacation, Sick & Public Holidays)', 'Family Leave (Maternity, Paternity)', 'Training & Development', 'Stock Option Plan', '401k Plan', 'Work with data insights teams to define and extract data sets for use in analysis and machine learning', 'Work with software engineering and data science teams to design, build, and manage our application DB, machine learning components, and our data infrastructure', 'Maintain, extend, and automate reporting infrastructure', 'Manage the design and architecture of our data warehouse', 'Create software tools to automate and manage ETL processes and dependencies', 'B.S. in computer science or equivalent experience', 'Advanced working knowledge of SQL and relational databases, MySQL preferred', 'Understanding of statistics and data modeling methodologies', 'Experience collaborating with Data Scientists and Data Analysts', 'Ability to create fast solutions to problems introduced in a changing environment with iteration towards optimal solutions', 'Experience with data-related AWS services such as RDS, Redshift, and Kinesis', 'Experience with programming or scripting language, preferably Python, Java, or Scala', 'Health Care Plan (Medical, Dental & Vision)', 'Unlimited Paid Time Off (Vacation, Sick & Public Holidays)', 'Family Leave (Maternity, Paternity)', 'Training & Development', 'Stock Option Plan', '401k Plan']",2020-09-24 14:01:43
Data Engineer – Geospatial,KoBold Metals,N/A,Remote,"['Design aspects of the TerraShed™ data system to ingest, store, and quickly process and access a wide variety of geoscience data', 'Integrate diverse and messy geophysical, geochemical, geologic, and geographic data from around the world into a well-structured proprietary data system', 'Create tools for ingesting unstructured datasets and extracting key features', 'Develop methods and tools to enable data scientists and geoscientists to rapidly view and interrogate both model results and underlying data', 'Proficiency in Python', 'Proficiency in Postgres/PostGIS', 'Familiarity with open-source libraries for manipulating (e.g., GDAL, ogr), visualizing (e.g., leaflet), and serving (e.g., WMS) geospatial data', 'Familiarity with desktop software used for geospatial visualization and analysis and experience integrating these tools with other data systems, e.g., through custom plugins', 'Familiarity with how geologists use 2D and 3D geospatial data, including both analyses based on 2D GIS projects as well as 3D modeling', 'Experience with setting up and deploying systems on AWS', 'Excited to work on a wide range of problems, and to take on a wide range of responsibilities, learning new tech tools whenever needed', 'Highly intellectually curious and eager to learn from technical experts who aren’t software people', 'Keen not just to build products, but to figure out what product to build to best achieve the business objectives of the company', 'Highly self-motivated and autonomous, able to effectively structure one’s own work, make realistic time estimates, and communicate well as one progresses', 'Comfortable with a fast-changing work environment', 'Careful to get the details right', 'A bachelor’s degree or higher in geoscience, other physical sciences, engineering, computer science, or mathematics', 'Experience with Flask or similar web frameworks']",2020-09-24 14:01:43
Data Engineer,"Marsh & McLennan Companies, Inc.",3.7 out of 5,"New York, NY","['Work in a diverse and inclusive culture as part of a global CIO organization', 'A fast pace, demanding and collaborative environment with exposure to the senior most leaders in the Technology organization', 'Career Growth – performance is rewarded with new opportunities', 'Impact – Opportunity to work on exciting projects as part of a program that is on the executive committee agenda', 'Benefits – competitive salaries and comprehensive benefits and programs including: health and welfare, tuition assistance, 401K, employee assistance program, domestic partnership benefits, career mobility, employee network groups, volunteer opportunities, and other programs', 'Specializes in one or more of the following areas: Server, Network (voice/data), messaging/collaboration, mainframe, Architecture, Storage/backup, Applied Engineering and/or Application engineering.', 'Designs, develops, implements, and analysis of Technical product/systems.', 'Creates, manages and maintains strategy, standards, roadmaps and new technologies.', 'Provides advanced design and engineering functions for one or more of the following skillset areas: Server, Network (voice/data), Messaging/Collaboration, Mainframe, Implementation, Architecture, Storage/Backup, and/or Application design.', 'Recommends alterations to developments and designs; improving quality of products/procedures', 'Manages Engineering Support staff in one or more of the following areas: standards, projects, level III support issues, designs and overall IT Engineering for Infrastructure/Technology.', 'Trains, leads, mentors, Engineers and Managers.', 'Creates, manages, maintains departmental policies, processes and procedures; relating to standards, projects and cross functional interoperability.', 'Prepares and tracks budgets, project/staffing plans.', 'Understands/communicates, Strategic/Global Initiatives and Infrastructures.', 'Consultants to aid in the development of solutions; Works closely with the Project Management Office and stakeholders to provide guidance/ advice concerning infrastructure issues', 'Identifies opportunities and recommends solutions for improving service efficiency and effectiveness.', 'Provides levels II/III support for Hardware and Operating System issues.', 'Documents Operational procedures; hand-off to the Operations Group.', 'Understands/communicates, Strategic/Global Initiatives and Infrastructures.', 'Solid expertise in setting up pipelines to ingest streaming, batch data from diverse sources, and perform data virtualization and/or ETL processes to make the data more usable, both with on-promise technologies and cloud-based solution providers', 'Proficiency in a programming language, such as Python, Java, SQL query engines Apache Spark, Rest APIs and the Hadoop ecosystem', 'Experience with data buffering such as with Apache Kafka, data stores such as any SQL or NoSQL,', 'Solid understanding of physical data base/structure modeling and implementations', 'Expert use and understanding of SQL', 'Solid understanding of data virtualization tools such as Dremio, data catalogues such as INFA EDC, Alation, ETL tools and BI tools such as Power BI and Tableau', 'Workflow tools for Orchestration/Automation/Pipelining', 'Solid logical Data Modelling for OLAP solutions – for Data Lakes, Data Marts and Data Warehouses', 'Experience with Dremio', 'Experience with quality review processes', 'Experience with data profilingData Visualization with Tableau or Power BI']",2020-09-24 14:01:43
Software Engineer - Entry Level,Jet Propulsion Laboratory,4.3 out of 5,"Pasadena, CA 91109","['Cybersecurity Engineer', 'Data Scientist', 'Data Visualization Developer', 'Electrical Ground Support Equipment Software Engineer', 'Engineering Applications Software Engineer', 'Flight Software Engineer', 'Scientific Application & Data Interaction Engineer', 'Scientific Applications Software Engineer', 'Software Systems Architect', 'Software Systems Engineer', 'Software Systems Engineer', 'User Interface Designer', 'User Interface Developer', ""Bachelor's, Master's, or PhD degree in Computer Science, Computer Engineering, Software Engineering, or related major."", 'Minimum of a 3.0/4.0 cumulative GPA.']",2020-09-24 14:01:43
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-09-24 14:01:43
Solutions Engineer,Parallel Domain,N/A,"San Francisco Bay Area, CA","['Prepare and deliver technical presentations tailored to our growing customer base', 'Collaborate with our sales and customer success teams to gather customer requirements through detailed technical discussions and scoping meetings', 'Deeply understand our prospects and customers to demonstrate how Parallel Domain can provide value for customer use cases; architect custom solutions when needed', 'Work closely with product team & internal engineering team to ensure new functionality is available for customer needs', 'Explore new product development areas driven by strategic understanding of customer landscape', '3+ years of customer-facing experience in technical sales for software products', '3+ years as either an application engineer or a developer of complex software for enterprise applications', 'Experience in machine-learning, AI, and/ or simulation products', 'Strong motivation to drive value for prospects & customers - and to provide an exceptional customer experience', 'Excellent communication skills, with an ability to explain complex technical products & excite customers about the technology', '(post-COVID) Ability to travel frequently to different customer locations to work onsite', 'Driven, proactive, organized, high level of professionalism, and strong cross-functional teaming skills', 'Passionate about autonomous systems & Parallel Domain solutions', 'Experience with geographic information systems, maps, or geospatial systems', 'Strong programming and 3D math skills', 'Experience in automotive OEMs', 'Deep software development expertise', 'Experience in the autonomous systems and/or computer vision industries, including but not limited to autonomous vehicles, delivery robots, drones, etc.']",2020-09-24 14:01:43
User Studies Operations Engineer,Apple,4.2 out of 5,"Santa Clara Valley, CA 95014","['Job', 'Company', 'Knowledge of engineering development lifecycle and ability to rapidly acquire familiarity with emergent technologies and software algorithms', 'Experienced in operations, readiness or project management (or equivalent)', 'Meets and exceeds goals through careful planning, risk mitigation, and exception event handling', 'Reduces risk by uncovering hidden problems and driving meaningful mitigation strategies', 'Works well under pressure in the face of unexpected events and is energized by challenges', 'Is a nimble problem solver, driving time-sensitive strategic changes based on a mixture of analysis, experience and collaboration with domain experts']",2020-09-24 14:01:43
Software Engineer,Bridgecr LLC,N/A,Remote,[],2020-09-24 14:01:43
Front End Engineer,Data Bridge Consultants,4.5 out of 5,United States,"['REDUX', 'REACT', 'Type Script', 'Java Script', 'Scrum Agile environment', 'HTML', 'CSS', 'DOCKER', 'Kubernetes', 'Heavy Front End Experience']",2020-09-24 14:01:43
2021 Data Analyst Internship- Product and Technology,T-Mobile,3.8 out of 5,"Bellevue, WA","['Job', 'Company', 'At least 18 years of age', 'Legally authorized to work in the United States', 'High School Diploma or GED']",2020-09-24 14:01:43
Data Engineer,Facebook,4.2 out of 5,"Seattle, WA","['Apply proven expertise and build high-performance scalable data warehouses', 'Design, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)', 'Securely source external data from numerous partners', 'Intelligently design data models for optimal storage and retrieval', 'Deploy inclusive data quality checks to ensure high quality of data', 'Optimize existing pipelines and maintain of all domain-related data pipelines', 'Ownership of the end-to-end data engineering component of the solution', 'Collaboration with the Data Center SMEs, Data Scientists, and Program Managers', 'Support on-call shift as needed to support the team', 'Design and develop new systems in partnership with software engineers to enable quick and easy consumption of data', 'BS/MS in Computer Science or a related technical field', '7+ years of SQL (Oracle, Vertica, Hive, etc.) experience and relational databases experience (Oracle, MySQL)', '7+ years of experience in custom or structured (i.e. Informatica/Talend/Pentaho) ETL design, implementation and maintenance', '7+ years’ experience in data engineering, experience in applying DWH/ETL best practices', '7+ years of Java and/or Python development experience', '2+ years experience in LAMP and the Big Data stack environments (Hadoop, MapReduce, Hive)', '2+ years experience working with enterprise DE tools and experience learning in-house DE tools']",2020-09-24 14:01:43
Data Engineer,"Omnitech, Inc",3.7 out of 5,"Sioux Falls, SD","['Company matching on the 401k plan', 'Reimbursement for tuition and certification costs', 'A curious analytical mind with ability to understand business objectives, ask insightful questions, and be detailed in implementation', 'A track record of helping companies get value from data management and business intelligence', 'Diverse understanding of industry tools, software and techniques; especially Microsoft SQL Server platform and tools', 'A desire to mentor and be mentored', 'A history of working on multidisciplinary teams in a productive manner', 'Professional image and demeanor with the ability to present oneself in a consultative, confident, and yet humble manner', 'Strong T-SQL skills', 'SQL Server design and development experience', 'Understanding of data profiling techniques', 'Understanding of performance optimization, data warehousing, cube architecture', 'Understanding of common data extraction techniques across a diverse set of sources including structured and non-structured data', 'Experience with data cleansing and conforming techniques', 'Develop standards and best practices to ensure data standardization and consistency as required', 'Strong experience with dimensional modeling, star schema and Kimball Data Warehouse methodologies', 'Design and develop data warehousing solutions for clients across a variety of industries and business sizes utilizing Microsoft’s SQL', 'Perform the role of subject matter expert for Microsoft Business Intelligence technologies including SQL Server and Analysis Services', 'Knowledge of Multidimensional Expression (MDX) and Data Analysis Expressions (DAX) languages', 'Familiarity with managing dimensional attribute history through Slowly Changing Dimension (SCD) concepts', 'Working knowledge of ETL change detection solutions such as change data capture (CDC)', 'Experience with Big Data technology a plus', 'Understanding of SQL Server FastTrack and/or Parallel Data Warehouse', 'Familiarity with storage technologies (e.g. SAN, NAS, etc.) a plus', 'Translate business requirements and technical designs into well-developed solutions that meet client business goals', 'Ability to explain the pros and cons of architectural decisions', 'Evaluate and recommend new technologies as required', 'Design and implement technology best practices, guidelines and repeatable processes', 'Provide technical assistance and cross training to other team members and clients', 'Participate in the business intelligence community to promote the use of the Microsoft BI platform and general data warehousing best practices', 'Assist in pre-sales, scoping and requirements gathering process', 'Ability to work closely with other project team members such as sales analysts, project managers, and software engineers', '3 years Data experience', 'A Bachelor’s Degree in engineering, computer science, physics, mathematics, or similar analytical degree', 'T-SQL, SQL Server, SSIS, SSRS, SSAS', 'Desire for continuous learning and to pursue professional certifications', 'Proven ability to consult and mentor others', 'Excellent communication, presentation, and interpersonal skills, confident with customers', 'Detail oriented, well-organized and excellent ability to multi-task', 'Energetic, comfortable working in a fast-paced environment', 'Hard-working and motivated, able to take initiative and meet deadlines', 'Comfortable working in a team-based environment', 'A hands-on attitude in a friendly work environment', 'MSDN Premium and Azure licensing as Microsoft Gold Partner', 'Opportunities for formal and informal training on new technologies', 'Support for career and life goals and development', 'Free soda, coffee and other ingestible fuel to keep you going', 'On-site exercise room with equipment', 'Company matching on the 401k plan', 'Reimbursement for tuition and certification costs']",2020-09-24 14:01:43
Cost & Scheduling Engineer,"HEPCO, Inc.",N/A,"Hancocks Bridge, NJ 08038","['Must have financial background with experience in scheduling and costs', 'Not looking for full on Project Managers or Engineers', 'P6 is a plus; not requirement']",2020-09-24 14:01:43
Business Analyst,Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['Job', 'Company', ""Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering)"", '1+ years of relevant experience in one of the following areas: Business intelligence, Business analytics or Data engineering', '1+ years of experience in writing complex, highly-optimized SQL queries across large data sets. Demonstrated strength in data modeling, ETL development, and Data warehousing.', 'Experience with data Visualization Tools including Tableau, Quick sight and etc.', 'Interfacing with business customers, gathering requirements and developing complex analytics model and data-sets for deep dive', '', 'Identifying the data quality issues across the various platforms at Amazon', '', 'Extracting and combining data from various heterogeneous data sources', '', 'Partnering with other analysts and engineers to build analytical solutions to deliver on business goals', '', 'Propose and implement new business metrics for senior management reviews and work with the data engineer to design and develop data infrastructure to support these metrics for business growth', 'Experience in scripting language including R, Python and etc. Understand and have the knowledge to utilize various statistical models for insight analysis, trend prediction and etc.', 'Experience with AWS services including S3, Redshift, EMR and RDS']",2020-09-24 14:01:43
Data Engineer,FLEX IT,5 out of 5,"Portland, OR","['Design and implement data products and features in collaboration with product owners, data analysts, and business partners using Agile / Scrum methodology', 'Contribute to overall architecture, frameworks and patterns for processing and storing large data volumes', 'Translate product backlog items into engineering designs and logical units of work', 'Profile and analyze data for the purpose of designing scalable solutions', 'Define and apply appropriate data acquisition and consumption strategies for given technical scenarios', 'Design and implement distributed data processing pipelines using tools and languages prevalent in the big data ecosystem', 'Build utilities, user defined functions, libraries, and frameworks to better enable data flow patterns', 'Implement complex automated routines using workflow orchestration tools', 'Anticipate, identify and solve issues concerning data management to improve data quality', 'Build and incorporate automated unit tests and participate in integration testing efforts', 'Utilize and advance continuous integration and deployment frameworks', 'Troubleshoot data issues and perform root cause analysis', 'Work across teams to resolve operational & performance issues', 'MS/BS in Computer Science, or related technical discipline', '5+ years of experience in large-scale software development, 3+ years of big data experience', 'Strong programming experience, Python preferred', 'Extensive experience working with Hadoop and related processing frameworks such as Spark, Hive, etc.', 'Experience with messaging/streaming/complex event processing tooling and frameworks with an emphasis on Spark Streaming or Structured Streaming and Apache Nifi', 'Good understanding of file formats including JSON, Parquet, Avro, and others', 'Familiarity with data warehousing, dimensional modeling, and ETL development', 'Experience with RDBMS systems, SQL and SQL Analytical functions', 'Experience with workflow orchestration tools like Apache Airflow', 'Familiarity with data warehousing, dimensional modeling, and ETL development', 'Experience with performance and scalability tuning', 'Experience with Scala or Java', 'Experience working in a public cloud environment, particularly AWS, and with services like EMR, S3, Lambda, ElastiCache, DynamoDB, SNS, SQS, etc', 'Familiarity with cloud warehouse tools like Snowflake', 'Experience building RESTful API’s to enable data consumption', 'Familiarity with build tools such as Terraform or CloudFormation and automation tools such as Jenkins or Circle CI', 'Familiarity with practices like Continuous Development, Continuous Integration and Automated Testing', 'Experience in Agile/Scrum application development', 'Invites and screens diverse qualified candidates', 'Intuitive video platform with no attendee limit', 'One-on-One breakout sessions with recruiters', 'Monday to Friday']",2020-09-24 14:02:28
Sr Data Engineer,iLAP SYSTEMS INC,N/A,"St. Louis, MO","['Experience:Data Engineer, 7 years (Preferred)', 'Work authorization:United States (Preferred)', '8 Years of experience in Informatica Development and database (Min 4 years of experience in Teradata).', 'Good Knowledge on DWH concepts Ability to gather requirements and convert business requirements to technical requirements.', 'Prepare technical specifications documents.', 'Experience of developing ETL application using Informatica PowerCenter (development experience, not just support experience).', 'Involved in creating the mappings in order to extract the data from source to target using Informatica designer.', 'Evaluate all functional requirements and map documents and perform troubleshoot on all development processes', 'Documents all technical specifications and associate project deliverables.', 'Design all test cases to provide support to all systems and perform unit tests.', 'Should analysis the data and develop understand the ETL specifications.', 'Develop mappings if required Develop Informatica 9x & 10x mapping, session and workflow.', 'Involved in creating the sessions, command tasks, workflows using the workflow designer.', 'Good at working with transformations including complex transformations Involved in building AutoSys to schedule the ETL Workflows.', 'Familiar with Stored Procedures and implementing them in the ETL jobs of Informatica. Worked on the HLD and LLD document.', 'Very good at UNIX and LINUX shell scripting Strong Database Experience with strong knowledge of writing complex SQL scripts as well as SQL tuning.', 'Extensively worked with Informatica performance tuning involving source level, target level and map level bottlenecks.', 'Ability to meet deadlines and handle multiple tasks, decisive with strong leadership qualities, flexible in work schedules and possess good communication skills.', 'Team player, Motivated, able to grasp things quickly with analytical and problem solving skills.', 'Comprehensive technical, oral, written and communicational skills', 'Should have Strong Analytical and interpersonal skills with good written and verbal communication.', 'Data Engineer: 7 years (Preferred)', 'United States (Preferred)', 'What is your current visa status in the USA ?']",2020-09-24 14:02:28
Network Engineer (Contract),Encore Technologies,N/A,"Ocala, FL 34470","['Pay:', '$45.00 - $50.00 per hour', 'Experience:Network Engineering, 5 years (Required)Cisco Routers, 4 years (Required)Meraki Wireless, 2 years (Required)', 'Location:Ocala, FL 34470 (Required)', '5+ years of Network Engineering experience', '5+ years of Cisco experience', 'Hands-on experience with Meraki wirelss', 'Light VoIP experience', 'Reliable Transportation', '8 hour shift', 'Monday to Friday', 'Network Engineering: 5 years (Required)', 'Cisco Routers: 4 years (Required)', 'Meraki Wireless: 2 years (Required)', 'Ocala, FL 34470 (Required)', '3 - 4 months', 'No', 'No']",2020-09-24 14:02:28
Data Platform Engineer,Skyline Technologies,3.8 out of 5,Wisconsin,"['Create estimates or provide input to estimates', 'Provide role leadership, in the form of standards enforcement for the team', 'Develop and maintain effective and collaborative relationships', 'Perform any special duties as assigned by your leader', 'Troubleshoot performance and configuration-related data platform issues for different client environments', 'Deliver project-based objectives across multiple environments', 'Manage multiple priorities across multiple engagements', 'Communicate directly with client partners', 'Work independently as well as part of a team, depending on the engagement', 'Variety in your work with opportunities to expand your skillset', 'Life-work balance and flexible hours', 'Supportive leadership and team members', 'Continuing education and networking opportunities', 'Competitive benefits package', 'A fun, supportive work environment with team engagements and family-friendly events', '5+ years of SQL Server database administration experienceInstallation, upgrade, configuration and administration with relevant versions of SQL Server.SQL HA/DR solutions (backup, restores, recovery included)Troubleshooting data platform performance problems, query tuning and optimization. Effective knowledge of indexes, index management, and statistics.Data security principles and implementing security with SQL Server.Implementing operational automation using scripting, including PowerShell.', 'Ability to hold a consultative discussion to help solve client partner challenges.', 'Strong knowledge of industry trends in database technology', 'Hold SQL Server-specific certifications or credentials', 'Have familiarity with Data Analytics-specific technologies:SSAS, SSIS, SSRS, MDS, DQS, Power BIOptimizing Input/output including at a disk level.Windows clustering.Networking - Things like Active Directory, firewalls, DMZ & general troubleshooting.Debugging on the Windows platform']",2020-09-24 14:02:28
Data Engineer,Analytica,3.6 out of 5,"Washington, DC 20001","['Support customer utilization of large, complex, and disparate data sets and recommend solutions aligned to customer mission and task accomplishment', 'Perform analytical exploration and examination of data from multiple sources of data', 'Design and develop data ingestion frameworks leveraging open source tools with Python as well as data processing/transformation frameworks leveraging open source tools', 'Design and build data pipeline frameworks to automate high-volume and real-time data delivery for on-premises platforms', 'Design and implement data repositories', 'Design and develop data cleansing and data quality management processing', 'Ensure proper security and access control to analytics data', 'Support the development, integration, and visualization of data science/machine learning algorithms for testing and operational deployment', 'Contribute to determining programming approach, tools, and techniques that best meet the business requirements', 'Provide subject matter expertise in the analysis, preparation of specifications and plans for the development of data processes', 'Develop conceptual, logical and physical data models', 'Design and develop efficient ETL processes and automated jobs that ingest the data accurately and efficiently into SQL databases from Netezza, Oracle, SQL server environments', 'Design and develop optimal Oracle, Netezza, Hadoop and AWS objects including, but not limited to, tables, views, materialized views, files, indexes, constraints, user defined functions, SQL (Structured Query Language) code, stored procedures, packages and automated workflows. Perform performance tuning activities as needed to ensure efficiency of ODS jobs and data engineering procedures.', 'Identify, develop, and implement solutions to failed jobs and performance issues to ensure data availability, integrity and accuracy', 'Develop and maintain documentations such as data models, workflow, architecture and ER diagrams, data dictionaries, design documents, deployment instructions, maintenance documents, and test plans and results', 'Use version control tools available in the SEC such as Git, and GitLab for storing of code and documentations', 'Provide a process for copying relevant data sets from production to testing and development environments in accordance with current DERA architecture and framework requirements and standards', ""Minimum of a Master's degree in econometrics, finance, or related technical fields such as mathematics, engineering, operations research, statistics, computer science, or an MBA or MFE, and demonstrated experience of at least four (4) years in data analysis, statistical data analysis and reporting of research studies."", ""4+ years' experience in managing and integrating large datasets using a variety of software packages."", 'Experience with Python and SQL is required', 'Programming experience using one or more of the following: SAS, VBA, STATA, MATLAB, Mathematica, Perl, R, SPLUS, Python, or SQL.', 'Demonstrate experience with SQL-type and non-SQL type databases, knowledge and experience in a systems environment, such as MS Windows, Linux, and UNIX, that facilitates manipulation and processing of data is also required', 'Demonstrate experience using advanced analytic techniques such as modern econometric methods, machine learning, multivariate statistical analysis, clustering and segmentation, experimental design, optimization and text analytics', 'Experience working with large datasets using Dask, Spark, MapReduce, Hadoop, Hive or similar technologie', 'Familiar with a wide range of analytics techniques, such as statistics, machine learning, and natural language processing', '1+ year operational/regulatory financial analysis experience']",2020-09-24 14:02:28
Cloud Data Engineer,Agile,3.8 out of 5,"Alpharetta, GA 30005","['Reviewing existing processes via documentation and with D&A team to gain full understanding of as-is requirements', 'Porting of Hadoop Hive code to GCP BigQuery environment', 'Creatively designing and developing ways to make variants of the reports configurable', 'Designing, building and optimizing database table structure and ETL around reporting generation and configuration', 'Building a configuration management system for the process as a whole and for controlling the parameters of each report submitted for processing', 'Development of audit, exception tracing, and completion/failure notifications for report generation process', 'Automating the visualizations for each report based on parameters within the configuration', 'Working with other departments to coordinate data transfer process from customer to usage within report generation', '2+ years of experience with Google BigQuery', '3+ years of experience with Python', 'Experience building software systems within a highly security-focused corporate environment']",2020-09-24 14:02:28
Data Engineer,Progrexion,3.3 out of 5,"Salt Lake City, UT 84111","['Job', 'Company', 'Build and maintain ETL pipelines, data warehouse/Lake data architecture, data workflows and analytic/ML feature engineering.', 'Design and implement SSIS/Python packages that pull data from internal and external Web Services/APIs, SFTPs etc.', 'Perform complex database programming by writing SQL procedures on large-scale databases', 'Develop new database objects and/or review existing objects to improve storage efficiency and access', 'Troubleshoot production issues during and after business hours to ensure SLAs are properly met', 'Analyze and address query/job performance issues/resource bottlenecks', 'Act as an information resource/subject matter expert for assigned areas of responsibility', '5+ years of experience working with relational databases (prefer SQL Server)', '2+ years of experience working in a data engineering role, designing, developing, and shipping software', 'Bring your experience to a vibrant team through design review, code review and mentoring while helping the team build an inclusive culture where each individual can do their best work.', 'Experience developing database applications using stored procedures and functions', 'Experience delivering solutions in a scrum/two week iteration setting', 'Eager to learn and apply feedback constructively', 'Able to work independently with minimal oversight', 'Demonstrated ability to fail fast, regroup and improve', 'Strong written and oral communication skills', 'Experience working in a fast-paced, enterprise environment', 'Experience in BI projects converting business needs to data warehousing and reporting solutions', 'Excellent communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions', 'Excellent diagramming, Sprint project management and organizational skills', 'Strong programming abilities in Unix/Python3/C#', 'Experience in SalesForce and Snowflake data migration a big bonus']",2020-09-24 14:02:28
Crash Sensing Data Engineer,Tesla,3.5 out of 5,"Fremont, CA","['Construct and maintain a large database of fleet impact data compiling information from multiple sources and data types into useful outputs', 'Build and maintain an array of scripts (Python & MATLAB) for the database', 'Facilitate useful output from the database, including automation of simulation (working closely with the CAE team) enabling iterative restraint and interior design based on real world events', 'Review CAE simulation and field data using (MATLAB, LS-PrePost and /or METApost)', 'Assist in setup and execution of attribute identification from images (tagging)', 'Assist in categorization of impacts based on risk of injury', 'Analysis of post-crash test data (DIAdem /MATLAB), reviewing results against expectations and predictions', 'Design and complete studies of field data to assess restraint system performance', 'Assist in the design of impact detection systems for pedestrian and occupant protection', 'Assist in co-ordination and oversight of test execution for correlation and calibration purposes', 'Support future and research projects related to occupant safety', 'Bachelor’s degree in Mechanical or Biomechanical Engineering', 'Previous knowledge of automotive crashworthiness legislation and attributes of vehicle safety and crashworthiness is preferred', 'Engineering fundamentals in problem solving', 'Test data analysis tools e.g. (DIAdem, Python, MATLAB, Hyperworks, LS-PrePost and/or METApost)', 'Good understanding and experience of vehicle structure development for crashworthiness', 'The ability to articulate and present technical issues to audiences of either end of the spectrum regarding familiarity on crash safety and potential occupant injury.', 'Hands-on experience with vehicle crash tests, sled tests and anthropomorphic test devices', 'Experience with field data analysis for vehicle crashes', 'Excellent organization skills and self-motivation']",2020-09-24 14:02:28
"Software Engineer, Supply (Remote within US)",Apartment List,4.5 out of 5,"San Francisco, CA","['Build the import, curation, and management systems responsible for all listing data and the core revenue flow of Apartment List', 'Work in a small team of dedicated and excitable software engineers', 'Wrangle an ever-expanding network of microservices', 'Work with our world-class apartment sales team to build and launch new client-facing products', '2+ years of hands on software engineering experience', 'Experience writing RESTful services in object-oriented or functional programming languages', 'Experience with Ruby, Python or similar programming language', 'Strong understanding of computer science fundamentals', 'Mentorship and training to get you onboard quickly and to learn new development skills.', 'Encouraged to explore new technologies and to adopt them in our product development.', 'Empowered to participate the whole development cycle, and drive important product decisions.', 'Lots of cool team building events, team offsites, company ski trip, and an annual sales conference which is followed up with an epic closing party!']",2020-09-24 14:02:28
Data Engineer,"LotusFlare, Inc.",N/A,"Sunnyvale, CA 94043","['2+ years of Scala and/or Python development experience is necessary', '2+ years of SQL (Oracle, Vertica, Hive, etc) experience is required', '2+ years of experience in custom or structured (ie. Informatica/Talend/Pentaho) ETL design, implementation and maintenance', '2+ years or experience applying statistical data analysis to real-life problems', 'Experience working with either a Map Reduce or a MPP system on any size/scale', 'BS or MS degree in Computer Science or a related technical field', 'Previous experience with Data ingestion and IR (information retrieval) is highly desirable', 'Industry experience as a Data Engineer or related specialty']",2020-09-24 14:02:28
Senior Data Engineer,Dell Technologies,4 out of 5,Massachusetts,"['Deep-dive into business problems relating to our integrated operating plan, quota planning, and sales compensation efforts', 'Deign and maintain optimal data architecture for our data science products', 'Build, clean, and maintain data sets that feed our machine learning algorithms and discovery processes (based in PostgreSQL database)', 'Identify opportunities for process improvements (may results in automating, optimizing, or fully rebuilding workflows)', 'Work with the greater Decision Sciences team to help with data related issues and analysis needs', 'Self-learner who is driven to learn new methods and techniques to fulfill business needs', 'Creative thinker who is success-driven both individually and as a team leader/mentor', 'Detail-oriented with the ability to effectively prioritize tasks', 'Experience working in an Agile environment', 'Expertise in PostgreSQL (experience with GreenPlum a plus)', 'Expertise with Python, Java, or a similar object-oriented language', 'Proven success building and optimizing data workflows', 'Proven success architecting data pipelines', 'Proven success in scaling data solutions', 'Experience in root cause analysis', 'Prior experience partnering with IT a plus', 'Good written and oral communications skills', 'Strong project management and organizational skills', '3+ year(s) of experience (preferred) in a data engineering capacity, preferably on a data science or advanced analytics team', 'Bachelors or Masters (preferred) in Computer Science/Engineering or related field']",2020-09-24 14:02:28
Data Engineer I,GoGuardian,N/A,"El Segundo, CA 90245","['Develop new ETL processes to fulfill data needs of data science and other departments', 'Utilize expertise in data modeling, ETL architecture, and report design for department initiatives', 'Produce detailed documentation including data flow diagrams, logical diagrams, and physical diagrams as needed', 'Ensure the data collection pipeline and data analysis infrastructure meet the needs of the business', 'Acquire strong knowledge of data structures, analysis, replication and distributed/relational data & database mapping', 'Assist with code review process for purposes of learning, asking new questions and finding errors', 'Assist with development of new scripts, KPIs and dashboards', 'Bachelor’s degree or equivalent experience', '1 year (preferably 2-3 years) experience building/operating systems for data extraction, ingestion, and processing of large data sets as a Data Engineer or related specialty', 'Experience with modern data warehousing tools such as Redshift, Big Query, Snowflake, Azure Synapse', 'Hands on experience with SQL query language along with data warehouse design and maintenance', 'Proficiency in a modern data-centric coding language such as Python, Go, or Scala', 'Experience working with data orchestration tools such as Airflow, Luigi, AWS Step Functions', 'Strong attention to detail, analytical mindset, highly organized and an ability to work independently within the policies, processes, and procedures defined for the team', 'Strong interpersonal skills & desire to work in a fast paced startup atmosphere requiring constant learning', 'Strong technical aptitude and demonstrated ability to quickly evaluate and learn new technologies', 'Experience with infrastructure as code such as Terraform, Chef, Puppet, Cloud Formation', 'Experience with containerization tools such as Docker', 'Experience with a broad set of AWS tools (S3, EC2s, DynamoDB, Lambda, Cloudwatch, AWS data pipeline)', 'Opportunity to impact and revolutionize safe digital learning experiences for K-12 students', 'Partner with enthusiastic and talented colleagues who are compelled to do good in the world', 'Weekly yoga classes and guided aromatherapy meditation', 'Annual personal growth stipend for continued learning', 'Grow and scale with one of the fastest growing EdTech companies']",2020-09-24 14:02:28
Neuroimaging Data Analyst,University of Colorado Boulder,4.2 out of 5,"Boulder, CO 80309","['The midpoint of our salary range is $71,500.00, commensurate with experience.', 'The University of Colorado offers excellent benefits, including medical, dental, retirement, paid time off, tuition benefit and ECO Pass.', 'Facilitate data sharing and comparison within INC and across institutions.', 'Advise INC users regarding the implementation of a common data format and directory structure.', 'Perform quality assurance metrics on neuroimaging data.', 'Standardize and detail lab-specific code to enable sharing,', 'Assist with the integration of new pipelines.', 'Lead basic and sophisticated data analyses.', 'Find opportunities for improvements and anticipate future needs.', 'Actively develop skills to maintain knowledge of standard methodologies in neuroimaging analysis.', 'Problem solves lab-specific neuroimaging analysis issues.', 'Serve in an advisory capacity, consulting with users on data formatting, and analytic questions for extramural grants.', 'Anticipate INC client needs, and ensure they are advised of new tools and methods for neuroimaging.', 'Train INC users on standard neuroimaging tools and pipelines.', 'Lead seminars and tutorials on new analytical methods in neuroimaging.', 'Answer questions from research teams, referring to outside specialists as appropriate.', 'Ensure INC clients have the vital knowledge and resources to meet their scientific objectives.', 'M.A./M.S.(Psychology, Neuroscience, Computer Science, Statistics, Mathematics).', '2+ years of experience processing and analyzing structural and functional human neuroimaging data (task-based fMRI, resting-state fMRI, DTI).', 'Proficiency with Linux command line and bash scripts.', 'Expertise with one or more neuroimaging software packages (e.g., FSL, SPM, AFNI, and FreeSurfer).', 'Proficient in programming languages relevant to scripting neuroimaging analyses (Python, Matlab, R).', 'Mastery with preprocessing methods for functional and neuroanatomical data (e.g., fmriPrep, FSL preprocessing pipeline).', 'Demonstrable ability to work with individuals across a wide range of statistical and neuroimaging skillsets (e.g., individuals new to neuroimaging as well as those with substantial expertise).', 'Phenomenal communication, customer service, and teamwork skills.', 'Familiarity with public MRI-based neuroimaging data sets and software pipelines such as HCP.', 'Familiarity with Siemens scanner, DICOM formats.', 'Experience with cluster computing (e.g., Slurm, SGE).', 'Knowledge of the BIDS data format.', 'Ph.D. in a relevant field.', 'Understanding of fundamental and sophisticated statistical techniques relevant to neuroimaging (e.g., multi voxel pattern analysis).', 'Familiarity with Jupyter notebooks.', 'Familiarity with Python packages such as scikitlearn and nilearn.', 'Familiarity with/ability to provide support in large data applications (e.g., cloud computing such as Amazon Web Services).', 'A current resume.', 'A cover letter that specifically addresses how your background and experience align with the requirements, qualifications and responsibilities of the position.']",2020-09-24 14:02:28
Mechanical Engineer - Entry Level,Jet Propulsion Laboratory,4.3 out of 5,"Pasadena, CA 91109","['Design engineering and drafting', 'Design data management and control', 'Maintaining hardware standards, testing standards, and design processes for flight hardware', 'Computer aided engineering solutions for mechanical design and analysis', 'Materials analysis, characterization, and testing', 'Mechanical and electronic fabrication', 'Environmental testing', 'Spacecraft Mechanical Engineering', 'Propulsion, Thermal, & Materials Engineering', 'Payload & Small Spacecraft Mechanical Engineering', 'Mechanical Fabrication & Test', ""Bachelor's, Master's, or PhD degree in Mechanical Engineering or related major."", 'Minimum of a 3.0/4.0 cumulative GPA.']",2020-09-24 14:02:28
Data Center Production Operations Engineer,Facebook,4.2 out of 5,"Altoona, IA 50009","['Perform deep dives and analyze complex technical issues within the data center, ranging from automated tooling to hardware failures and network issues.', 'Work as a technical lead with cross functional teams on large scale data center projects and initiatives.', 'Provide cross data center support and identify potentially larger issues, displaying effective communication when something is identified.', 'Work with internal hardware teams and vendors to help resolve complex technical issues, maintain high hardware quality levels and influence future design to ensure ease of serviceability.', 'Understand/analyze issues and be able to update and develop scripts and smaller sets of software.', 'Use data to drive maximum server fleet up-time and utilization rates, by understanding hardware failure rates and SLAs to customers. Identify trends and systemic issues in the fleet and drive resolution.', 'Mentor team members to evaluate and identify better ways to resolve issues and define updates to tools and processes.', 'Provide guidance and mentor technical leads and the go-to technical resource for management.', 'Build cross functional relationships and have the ability to influence policies and procedures to improve global data center operations.', 'Participate in an on-call rotation.', 'BS, BA or BEng in technical field or commensurate experience.', '5+ years of infrastructure or related experience.', 'Knowledge of Linux and hardware systems support in an Internet operations environment.', 'Knowledge of the interdependencies of data center functions and technologies.', 'Experience managing multiple projects within the same time schedule.', 'Knowledge of enterprise level networking and storage equipment installs.', 'Knowledge of out-of-band/lights-out server communication methods, such as IPMI and serial console.', 'Time and project management experience.', 'Experience in modifying and developing in commonly used scripting or programming languages.', 'Proven communication skills.']",2020-09-24 14:02:28
Integrations Engineer,GitLab,3.6 out of 5,United States,[],2020-09-24 14:03:11
Data Engineer,"Prizelogic, LLC",3.5 out of 5,"Scottsdale, AZ 85258","['Provide technical expertise in the implementation of PrizeLogic’s SaaS Platform using Talend Studio 7.0+, Talend Cloud and Talend Remote Engines.', 'Use innovative problem solving and critical thinking approaches to trouble shoot challenging data centric obstacles.', 'Analyze business requirements and scope of data transformation tasks.', 'Maintain a high proficiency level with Cloud-based data pipeline architectures and on-prem and Cloud-based database system models.', 'Some travel may be required to customer sites.', '3+ years Enterprise Data Warehouse experience using Talend.', '2+ years working in Azure (AWS experience will qualify for the right candidate).', '2+ years processing data from a multitude of sources including on-prem, Cloud, internal and external to a single, standardized Cloud-based target using a variety of formats such as direct database connections, CSV and JSON files.', '2+ years delivering automated extracts to external clients using both traditional (SFTP, HTTPS) and modern (Object Storage, APIs) transfer mechanisms.', 'Candidate must be organized and analytical, adept at working in a team environment, able to adopt and implement a project schedule and able to handle multiple priorities in a fast-paced environment.', 'Snowflake – Candidates with Snowflake experience will be given preference.', 'Java – Enough to understand and / or create custom Talend components.', 'JavaScript – Enough to understand and / or create Snowflake UDFs and Stored Procedures.', 'MongoDB.', 'CI/CD workflows using Azure DevOps.', 'Experience with consumer recognition data and algorithms.']",2020-09-24 14:03:11
Software and Data Engineer Intern,ViaSat,3.8 out of 5,"Carlsbad, CA 92009","['Data analytics & cloud application engineering', 'System infrastructure development; scripting, automation, data visualization & dashboarding', 'Network function virtualization, orchestration', 'Virtualized networking and service chaining', 'Distributed enterprise software applications', 'Cybersecurity software & systems engineering', 'Web & mobile application engineering', ""Bachelor's degree in Computer Science, Computer Engineering, Electrical Engineering, Physics, Mathematics, and/or a related field"", 'Exposure or desire to work with Cloud Technology, Automation, Machine Learning, Big Data, Full-Stack, Embedded, Apps, or Front-End', 'Previous internship experience in software development and/or test related areas', 'Knowledge of TCP/IP network fundamentals', 'Previous experience coding in Go, Java, Python, JavaScript, Hadoop, Spark, SQL, Postrgres, and/or C/C++']",2020-09-24 14:03:11
Mid level Data Scientist,P3,3.7 out of 5,"Midland, MI","['Identify business problems, provide data driven solutions, and deliver data science applications which enhance data-driven decision making in our manufacturing plants.', 'Identify, acquire, and engineer feature data sets with potential to address customer needs.', 'Apply machine learning, statistical or mechanistic models and other computational approaches to extract insights from large datasets in manufacturing systems.', 'Develop, prototype, and implement software solutions with engineering and production teams.', 'Collaborate with scientists from manufacturing in solution/experiment design and analyses.', 'Conduct and communicate results of research on data science approaches to improve decisions, add value to services, extend or improve in-house models and algorithms, and contribute to the advancement of these ideas.', '2-5 years of relevant post-graduate work experience in data science highly preferred', 'Proven ability to independently formulate data science problems to solve business needs by asking right questions and deliver data science solutions by identifying necessary data sources, building predictive models, and producing actionable results.', 'In-depth fundamental knowledge and extensive experience in applying Machine Learning (e.g. decision trees, neural networks, SVM, unsupervised learning) methodologies', '5+ years of programming experience with at least one data querying and one scripting language (e.g. SQL, Python, R, C++, Scala)', 'Familiarity with Data Engineering concepts and tools (e.g. git, docker)', 'Experience in optimization methods to improve manufacturing efficiency', 'Experience applying core statistical methodologies (e.g. regression, mixed models, experimental design) in an industry setting', 'Experience in Deep Learning', 'Familiarity with cloud based systems.', 'Experience with Relational or NoSQL databases.']",2020-09-24 14:03:11
Data Engineer,GSK,4.2 out of 5,"Collegeville, PA 19426","['Partner with data teams to implement pipeline designs to support R&D strategy and conceptual data flows', 'Partner with the metadata leads to translate conceptual data models into physical database/tables optimized for data analytics in RDIP using established environments and tools', 'Assist the design, build, test and maintenance of data acquisition and processing pipelines including but not limited to the creation/maintenance of appropriate artifacts', 'Ensure the preservation of data integrity from source to target state including but not limited to the acquisition of appropriate metadata and the incorporation of appropriate QC checks into the pipelines', 'Support the use and growth of the Data Engineering DataOps environment, influence strategy and roadmap for the curation toolset, work with R&D and Tech to prioritize enhancements', 'Provide Tier 3 support for production pipelines', 'Support DCS and broader R&D in self-service/exploratory efforts', 'Influence vendor roadmaps, work with R&D and Tech to prioritize DataOps enhancements, and onboard these tools or enhancements', 'Ensure the quality consistency and availability of guidance documentation of end users of the tools to support high quality outputs', 'Extend current pipelines to support clinical biomarkers', 'Assess GxP readiness as it related to the upstream data pipelines and develop a plan for addressing any gaps', 'Provide Tier 3 support/administration of DNA Nexus bioinformatics system', 'This position requires a Computer Science, Bioinformatics, or related degree; 5+ years’ experience in data movement, data wrangling and delivery of data or analytics pipelines', 'Experience implementing and maintaining, data or analytic pipelines.', 'Experience with Big Data technologies, Cloud-based offerings (Microsoft Azure, GCP, AWS, etc), and corresponding tools.', 'Experience with open source software, bioinformatics tools and languages such as SQL, R, Perl, Python, Java, and ETL tools.', 'Experience with data movement and management in the Pharmaceutical industry or related scientific fields.', 'Experience with the core components of the Hadoop stack including HDFS and Apache Spark, ideally a Cloudera based stack', 'Background and experience in LIMS systems, Next Generation Sequencing (NGS) workflows, Cloud computing and HPC systems.', 'Understanding of diverse ‘omic data types including RNA-Seq, DNA-Seq, Chip-Seq, WES, WGS, ATAC-seq, microbiome, proteomic, metabolomic data etc. from different sources.', 'Familiarity with data mining, machine learning and artificial intelligence techniques', 'Proven ability to contribute to development projects.', 'Strong interpersonal skills and effective communication of complex concepts to stake holders with wide range of expertise.', 'Operating at pace and agile decision-making – using evidence and applying judgement to balance pace, rigour and risk.', 'Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.', 'Continuously looking for opportunities to learn, build skills and share learning.', 'Sustaining energy and well-being.', 'Building strong relationships and collaboration, honest and open conversations.', 'Budgeting and cost-consciousness', 'LI-GSK']",2020-09-24 14:03:11
Data Analyst,Missing Link Communications,N/A,"Lorton, VA 22079","['Assist the client with introducing new capabilities related to data analytics, data ingest and data processing.', 'Work with other Data Scientists, System Engineers, and Software Developers.', 'Design, develop, implement and maintain data ingest solutions.', 'Design, develop, implement and maintain tools/applications/solutions that provide the capability to export data to external systems.', 'Evaluate in-house designed and developed, Commercial off the Shelf (COTS) / Government Off The Shelf (GOTS) and open source analytic tools and technologies.', 'Bachelor’s degree from a nationally accredited college/university', '3+ years of data analysis experience to include working with data analytical tools', 'Experience with maintaining data applications and solutions', 'Experience with data implementation', 'Ability to obtain a Public Trust Clearance']",2020-09-24 14:03:11
Data Engineer,DigitalOcean,4 out of 5,New York State,"['Develop and implement metrics and dimensions for powering analytical use cases across the company, incorporating a wide variety of data sources across the company at varying levels of complexity and scale', 'Focus on data quality of the data environment and data products being delivered to the business, and effectively communicate to internal user base regarding production status', 'Interface closely with data infrastructure, engineering and technical operations teams to ensure correctness and soundness of metrics built in the data environment and availability of data product services', 'Pioneer initiatives around data quality, integrity, security and governance', 'Work closely with data stakeholders across the company, both technical and non-technical, to understand evolving needs as more complex data models are introduced for reporting and data science', ""Bachelor's degree in Computer Science, Math, Statistics, Economics, or other quantitative field; or equivalent experience."", 'Experience in custom ETL design, implementation and maintenance', 'Track record of developing in complex data environments and intelligence platforms for business users', 'Demonstrable ability to relate high-level business requirements to technical ETL and data infrastructure needs, including underlying data models and scripts', 'History of proactively identifying forward-looking data engineering strategies, utilizing appropriate technologies, and implementing at scale', 'Extensive hands-on experience with schema design and dimensional data modeling', 'Experience interacting with key stakeholders in different fields, interpreting challenges and opportunities into actionable engineering strategies', 'Experience with analytics databases like Snowflake, Redshift, or BigQuery.', 'Advanced SQL and relational database knowledge (MySQL, PostgreSQL) in addition to warehousing and dimension modeling', 'Experience scripting in Go or Python or a similar scripting language.', 'Effective communication and interpersonal skills', 'Experience implementing dimensional modeling in a configuration tool like dbt or LookML a plus', 'Experience designing and building dashboards in BI tools like Looker, Tableau, or PowerBI a plus.', 'Experience with job schedulers (Airflow, Luigi, Azkaban, etc.) a plus', 'We value development. You will work with some of the smartest and most interesting people in the industry. We are a high-performance organization that is always challenging ourselves to continuously grow. We maintain a growth mindset in everything we do and invest deeply in employee development through formalized mentorship, LinkedIn Learning tracks, and other internal programs. We also provide all employees with reimbursement for relevant conferences, training, and education.', 'We care about your physical, financial and mental well-being. We offer competitive health, dental, and vision benefits for employees and their dependents, a monthly gym reimbursement to support your physical health, and a commute or internet allowance to make your trips to your office or your desk easier. We offer generous parental leave with transition time built-in upon return to work. We offer competitive compensation and a 401k plan with up to a 4% employer match.', ""We support our remote employee experience. While we have great office spaces in NYC, Cambridge and Palo Alto, we're very distributed—we use a number of communication tools to connect across the company—and all remote employees have the opportunity to visit our offices and meet their teams face-to-face at team offsites. We also have an annual company offsite, Shark Week, to get quality in-person time with the entire company at least once a year. We also allow employees to outfit their workstations to meet their needs—whether remote or in office."", 'We value diversity and inclusivity. We are an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.']",2020-09-24 14:03:11
Junior Data Scientist Intern,Sony Interactive Entertainment PlayStation,3.7 out of 5,"Aliso Viejo, CA","[""Pursuing a Bachelor's or Master's degree in Data Science/Computer Science (or related technical field), and/or within 1 year of their post-graduation date"", 'Experience in supervised and unsupervised machine learning algorithms as well as knowledge of common ML frameworks', 'Programming skills with Python or another programming language', 'Expertise in extracting data from multiple data sources using SQL', 'Good knowledge of statistics and probability', 'Excellent communication skills and passionate about learning new tools and developing products', 'Creative and fearless when tackling difficult problems', 'Comfortable with ambiguity and can demonstrate flexibility']",2020-09-24 14:03:11
Data Scientist,Amazon Advertising LLC,3.6 out of 5,"Seattle, WA","[""Bachelor's Degree"", '3+ years of experience with data scripting languages (e.g SQL, Python, R etc.) or statistical/mathematical software (e.g. R, SAS, or Matlab)', '2 years working as a Data Scientist', 'Partnering with economists and senior team members to drive science and implement technical solutions using machine learning and econometrics', 'Collaborate with Data Engineers to help build data systems and metrics that continually improve data quality', 'Develop science-driven algorithms that yield robust recommendations along an advertiser’s lifecycle', 'Contribute to building a scalable experimental framework that help stakeholders make data-driven informed decisions', 'Communicate verbally and in writing to senior leaders with various levels of technical knowledge, educating them about your approach, as well as sharing insights and recommendations', 'Master’s or PhD degree in Statistics, Applied Math, Economics, Computer Science, Machine Learning or a related quantitative field with at least 2 years of working experience as a Data Scientist', 'Experience using AWS technologies such as Redshift, S3, EMR and data pipelines and scaling models into production', 'Experienced in Machine Learning', 'Experience working with econometric models on causal impact questions', 'Experience in designing and analyzing large scale experiments']",2020-09-24 14:03:11
Business Intelligence Engineer,eClerx LLC,3.7 out of 5,"Austin, TX 78727","['Apply your experience and expertise in data engineering, problem solving, storytelling and the ability to look beyond the numbers and develop deep understanding of how our recommendations affects business objectives', 'Document, assess, influence and synthesize business requirements to develop, enable and advance data engineering & data infrastructure capabilities', 'Design future-state architectures of their data platforms enabling analytical intelligence and then play a role to implement a roadmap to reach that state', 'Work with business partners in cross functional teams to assist with data-related technical issues and support their data infrastructure needs', 'Collaborate with the eClerx development teams to create data tools for analytics and data sciences', 'Most importantly, a successful candidate will be a team player and collaborator within the eClerx community', '3-5 years of professional experience in data management, data engineering, visualization, data warehousing or relevant consulting experience for an enterprise scale company', 'Collect requirements and inputs from client stakeholders to define objectives and processes. Define interdependencies across multiple organizations, understand risks and develop mitigation plans and data models', 'Hands-on SQL knowledge and experience working with relational databases, query authoring (SQL) as well as familiarity with a variety of relational databases', 'Know-how of processes for monitoring, measuring, and reporting of data quality', 'Successfully develop and take ownership of conceptual and logical architecture designs for Business Intelligence systems', 'Experience with visualization platforms like Power BI (preferred) and/or Tableau', 'Experience in establishing and successfully implementing Data Governance programs is a plus', 'Collaborate with multiple stakeholders and participate in meetings to define/identify business requirements and data mapping sessions to understand business needs', 'MS in Information Systems or related advanced degree or Bachelor’s degree with relevant experience desired', 'Client-facing experience in managing analytical projects and teams', 'Successful history of manipulating, processing and extracting value from large disconnected datasets', 'Hands-on experience in SQL development is required. Teradata, NoSQL, Hadoop, Spark and R/Python experience is a plus', 'Experience in using various reporting or BI tools to create analytical dashboards that depict critical KPI’s for business needs. Power BI experience is a plus.', 'Understanding of data manipulation technologies & data platforms (based on either prepackaged ETL tools and/or custom programming).', 'Excellent communications skills, both written and spoken, as well as being able to present complex technical concepts to a non-technical audience', 'Strong project management and organizational skills', 'Demonstrate strong interpersonal skills and a comfort interacting with clients from the C-suite to managers to technical specialists', 'Be comfortable working autonomously or with broad guidelines; this role will often be working independently at client offices', 'Ideal candidate will possess strong business acumen and has been in a consulting role previously', 'Creative focuses on large scale post production up to cutting edge CGI; we provide creative production services to support all ATL & BTL creative assets managed through our FLUiiD4 marketing workflow solution', 'Commerce & Campaigns focuses on our clients’ omni-channel digital operations, including web operations, conversion rate optimization, site merchandising & eCommerce operations, campaign operations, and system re-platforming', 'Analytics, Insights & Reporting focuses on the full spectrum of data analysis from web and social analytics to more advanced predictive analytics and big data all underpinned by a strong business intelligence and visualization team', 'Data Management focuses on all facets of data acquisition, integration, normalization, and quality across all data sets (customer, product, supplier, partner, sales, transactional, etc.), as well as Master Data Management and data governance/stewardship']",2020-09-24 14:03:11
Data Analyst,3kaya Technologies LLC,N/A,"Sunnyvale, CA 94089","['only w2', 'Must be local to California', 'Any visa will work', 'Initially remote and onsite post COVID-19', 'End client is an American molecular diagnostics company', 'Location - Sunnyvale, CA', 'Must have - Python , ETL , SQL , PowerBI , Modeling/ML', 'Monday to Friday', 'ETL (Extract Transform Load): 2 years (Required)', 'SQL: 3 years (Required)', 'Python: 3 years (Required)', 'BioTech: 2 years (Required)', 'What is your visa status / work authorization and can you work on w2 ?', 'Temporarily due to COVID-19']",2020-09-24 14:03:11
Engineer I,"Bio-Rad Laboratories, Inc.",3.7 out of 5,"Redmond, WA 98052","['Adapts instrumentation and software systems settings to meet systems requirements, market andcustomer needs. Works alone with supervision on low complexity projects; may assist other personnel or workwith supervision on moderately complex projects, or machinery.', 'Develops protocols and executes performance qualification testing on various instruments and systems. Work involves various types of research, integration activities, investigations, analysis, and interpretation of data.', 'Edits technical documentation and internal/training support materials for instrumentation.', 'Works with Marketing, and Technical/ Product Support and Regulatory/Quality Assurance to definerequirements, recommend modifications, assess risk and verify performance.', 'Prepares and finalizes ECR/ECO packages to support new product launches']",2020-09-24 14:03:11
Senior HPC Engineer,Hexagon Manufacturing Intelligence,3.6 out of 5,"Orange County, CA","['Develop, maintain, and enhance parallel numerical algorithms used in MSC’s products', 'Research and develop innovative parallel methods and implementations for computational linear algebra', 'Review method proposals from fellow group members', 'Research and implement scalable, stable computational solutions including necessary data structures', 'Work with other teams to verify implementation, develop examples, and document features', 'Participate in technical conferences including User Meetings and/or write journal research papers', 'Senior candidates will be expected to mentor and guide junior team members', 'Bachelors in mathematics, computer science, or engineering with expertise in linear algebra both theoretical and computational. Graduate degree preferred', 'Experience with parallel method development and implementation exploiting both shared and distributed memory computing architectures, as well as compute accelerators such as GPUs', 'In-depth knowledge of computational linear algebraic methods as well as theory and demonstrated an ability to understand real world applications. Familiarity with the finite element method is a plus.', 'Ability to design and implement algorithms/data structures for computational linear algebra', 'Ability to program in C/C++ and Fortran. Demonstrated knowledge of MPI, OpenMP, CUDA, OpenCL, and Python. Experience in PERL and Shell programming is a plus', 'The ideal candidates have worked on parallel computational linear algebra software and integrated it with large-scale commercial applications, preferably in the context of finite element method solver packages.']",2020-09-24 14:03:11
Crude Oil and Natural Gas Well-Log Analyst,NATURAL-GAS-OIL,N/A,United States,"['Lead and participate in new drillings and rework older wells to increase production. Advanced knowledge in studies including data analysis will be required.', 'Study and propose various alternatives to develop the formations that each well is in the most effective way.', 'Evaluate and present the best techniques, tools and technologies to yield the highest production out of every well.', 'Act as a focal point and a go-to expert on well-log issues.', 'Must be able to show areas of knowledge in more then just one field. Please state what areas you have worked in and what formations.']",2020-09-24 14:03:11
Recycling Technologies Engineer,ICG Inc.,N/A,"San Jose, CA 95126","['Knowledge of material life cycles, from raw material extraction to end-of-life options, with a particular focus on materials used in consumer electronics and industrial manufacturing', 'Knowledge of manufacturing processes and technologies used in consumer electronics', 'Knowledge of mineral and metal extraction, production, refining and recycling processes, including new, emerging technologies in hydrometallurgy, pyrometallurgy, and biometallurgy', 'Experience developing and utilizing mineral and metallurgical process models of extraction, processing, and recycling to guide decision making in a data-driven manner; e.g. HSC Sim, Metsim', 'Knowledge of material flow analysis (MFA) and life cycle assessment (LCA) methods and techniques', 'Understanding of Circular Economy concepts and familiarity with common metrics used to discuss the Circular Economy', 'Comfortable with developing assumptions, working and making decisions with limited and imperfect data, and quantifying and identifying sources of uncertainty', 'Self-motivated, enthusiastic, and detail-oriented', 'Excellent at written and verbal communication', 'Experienced managing, organizing and maintaining large datasets', 'Experienced with spreadsheets, process modeling software, and data manipulation', 'Comfortable presenting to and working with both technical and non-technical teams', 'Day shift', 'www.icg-sj.com', 'Temporarily due to COVID-19']",2020-09-24 14:03:11
Senior HPC Engineer,Hexagon Manufacturing Intelligence,3.6 out of 5,"Orange County, CA","['Develop, maintain, and enhance parallel numerical algorithms used in MSC’s products', 'Research and develop innovative parallel methods and implementations for computational linear algebra', 'Review method proposals from fellow group members', 'Research and implement scalable, stable computational solutions including necessary data structures', 'Work with other teams to verify implementation, develop examples, and document features', 'Participate in technical conferences including User Meetings and/or write journal research papers', 'Senior candidates will be expected to mentor and guide junior team members', 'Bachelors in mathematics, computer science, or engineering with expertise in linear algebra both theoretical and computational. Graduate degree preferred', 'Experience with parallel method development and implementation exploiting both shared and distributed memory computing architectures, as well as compute accelerators such as GPUs', 'In-depth knowledge of computational linear algebraic methods as well as theory and demonstrated an ability to understand real world applications. Familiarity with the finite element method is a plus.', 'Ability to design and implement algorithms/data structures for computational linear algebra', 'Ability to program in C/C++ and Fortran. Demonstrated knowledge of MPI, OpenMP, CUDA, OpenCL, and Python. Experience in PERL and Shell programming is a plus', 'The ideal candidates have worked on parallel computational linear algebra software and integrated it with large-scale commercial applications, preferably in the context of finite element method solver packages.']",2020-09-24 14:03:54
Crude Oil and Natural Gas Well-Log Analyst,NATURAL-GAS-OIL,N/A,United States,"['Lead and participate in new drillings and rework older wells to increase production. Advanced knowledge in studies including data analysis will be required.', 'Study and propose various alternatives to develop the formations that each well is in the most effective way.', 'Evaluate and present the best techniques, tools and technologies to yield the highest production out of every well.', 'Act as a focal point and a go-to expert on well-log issues.', 'Must be able to show areas of knowledge in more then just one field. Please state what areas you have worked in and what formations.']",2020-09-24 14:03:54
Recycling Technologies Engineer,ICG Inc.,N/A,"San Jose, CA 95126","['Knowledge of material life cycles, from raw material extraction to end-of-life options, with a particular focus on materials used in consumer electronics and industrial manufacturing', 'Knowledge of manufacturing processes and technologies used in consumer electronics', 'Knowledge of mineral and metal extraction, production, refining and recycling processes, including new, emerging technologies in hydrometallurgy, pyrometallurgy, and biometallurgy', 'Experience developing and utilizing mineral and metallurgical process models of extraction, processing, and recycling to guide decision making in a data-driven manner; e.g. HSC Sim, Metsim', 'Knowledge of material flow analysis (MFA) and life cycle assessment (LCA) methods and techniques', 'Understanding of Circular Economy concepts and familiarity with common metrics used to discuss the Circular Economy', 'Comfortable with developing assumptions, working and making decisions with limited and imperfect data, and quantifying and identifying sources of uncertainty', 'Self-motivated, enthusiastic, and detail-oriented', 'Excellent at written and verbal communication', 'Experienced managing, organizing and maintaining large datasets', 'Experienced with spreadsheets, process modeling software, and data manipulation', 'Comfortable presenting to and working with both technical and non-technical teams', 'Day shift', 'www.icg-sj.com', 'Temporarily due to COVID-19']",2020-09-24 14:03:54
Data Engineer - Product Analytics,Stitch Fix,3.2 out of 5,"San Francisco, CA","['Job', 'Company', 'Senior IC position on the data engineering team, within our Algorithms organization, working with a team that focuses on our Product data infrastructure', 'You will build and own large additions to our data engineering framework, contributing to a code framework that centralizes ETL logic and definitions', 'You will help to define, build and maintain a clear, concise data model, especially focused on scalable product analytics infrastructure', 'You will build scalable data engineering solutions & frameworks to solve business and data problems', 'You will be involved in the day-to-day operations of the team, including maintaining and improving our current tools & scripts and supporting full-stack data scientists', 'You will have autonomy to help shape the future of data engineering at Stitch Fix by bringing your ideas on improving and automating what we do and how we do it', 'Work with different teams of data scientists, engineers and business partners on how to solve data and business problems in a scalable way', 'Be part of a team which has high visibility across the organization', ""Contribute ideas and direct the team's investment to impactful directions"", 'Contribute to a culture of technical collaboration and scalable development', 'Experience in building out scalable data models and data engineering capabilities, specifically around product analytics infrastructure', '3+ years of independent project experience with significant contributions.', 'Exceptional coding and design skills in Python and SQL', 'Experience in working autonomously and taking ownership of projects.', 'Ability to think globally, devising and building solutions to meet many needs rather than completing individual projects or tasks', 'Strong prioritization skills with business impact in mind', 'Familiarity with using Spark to access an S3 data warehouse', 'Strong cross functional communication skills that help simplify and move complex problems forward with business partners', 'We are a group of bright, kind and goal oriented people. You can be your authentic self here, and are empowered to encourage others to do the same!', 'We are a successful, fast-growing company at the forefront of tech and fashion, redefining retail for the next generation', 'We are a technologically and data-driven business', 'We are committed to our clients and connected through our vision of ""Transforming the way people find what they love""', 'We love solving problems, thinking creatively and trying new things', 'We believe in autonomy & taking initiative', 'We are challenged, developed and have meaningful impact', ""We take what we do seriously. We don't take ourselves seriously"", 'We have a smart, experienced leadership team that wants to do it right & is open to new ideas', 'We offer competitive compensation packages and comprehensive health benefits', 'You will be proud to say that you work for Stitch Fix and will know that the work you do brings joy to our clients every day']",2020-09-24 14:03:54
Data Engineer - Data Modeling - Mount Sinai COVID Informatics Center,Mount Sinai,3.9 out of 5,"New York, NY","['Job', 'Company', 'curate valuable datasets in the Consult Repository, which includes ingestion, documentation', 'develop requirements with informaticists and clinicians to communicate with the engineering team, and rest of MSCIC', 'gain a wide understanding of the many systems throughout the MSHS', 'ingest data from a wide range of data platforms, formats, and sources', 'work with data coming in multiple formats (eg. structured, imaging, genetic)', 'impact patient care by ensuring data is immediately consumable and translatable by both clinicians and informaticists', 'clinical data experience', 'data warehousing modeling practices (eg. dimensional/star schema, federated models, high normal form modeling)', 'working with highly sensitive and regulated Protected Health Information (PHI), and navigating related regulations/rules', 'deep understanding of ETL/ELT practices', 'experience in formal QA/QC environments', 'deep understanding of SQL for RDBMS', 'written production software in compiled languages (Java, Scala, Haskell, Go).', 'written production software in interpreted languages (Python, Ruby, Perl, or PHP)', 'code repository platforms such as Git, Subversion, Mercurial, etc.', 'cloud infrastructure administration in Azure, AWS, or Google Cloud', 'SysAdmin experience in Linux environments', 'Hadoop, Spark, or similar big data environments']",2020-09-24 14:03:54
DATA ANALYST - REMOTE,DATEC,3.9 out of 5,"Towson, MD","['EMAIL ID ?', 'Yes']",2020-09-24 14:03:54
"Engineer, Quality 2",Triumph Group,3.2 out of 5,"Redmond, WA 98053",[],2020-09-24 14:03:54
Data Engineer,Lineage Logistics,3.2 out of 5,"Novi, MI 48377","['Job', 'Company', 'Assist with the creation, modification, and tuning of queries against enterprise data assets including a Cloudera-based data lake and a RDBMS-based operational data store', 'Support the automation of data quality checks and seek to investigate and resolve related issues by debugging all aspects of the data pipeline and correcting problematic data', 'Ensure key data assets are accurate, comprehensive, and available', 'Validate changes to data pipelines including supporting the code promotion flow from non-production to production environments', 'Review the work of data wrangling and ETL resources to ensure accuracy, completeness, and performance', 'Document data assets to facilitate ongoing development, end user reporting, etc.', 'Collaborate with others to solve complex problems and resolve technological disagreements with informed, rational, practical solutions', 'Mentor and provide guidance especially to other technical resources', 'Bachelor’s Degree in Computer Science, Software Engineering, or IT Management and/or 6+ years of relevant work experience', '4+ years of direct data management experience including at least 2 years spent implementing and supporting data pipelines', 'Demonstrable knowledge of common database, data lake, and business intelligence technologies - e.g. PostgreSQL, Cloudera, and Jaspersoft', 'Thorough knowledge of data technologies and techniques', 'Ability to handle multiple assignments/projects simultaneously', 'Excellent verbal and written communication skills including the ability to explain technical concepts to business leaders', 'Prior software development experience', 'Knowledge of supply chain concepts and associated technologies including WMS, TMS, YMS, and related system']",2020-09-24 14:03:54
Data Engineer,"Vizient, Inc.",3.7 out of 5,"Irving, TX 75062","['Design, develop, enhance, code, test, deliver and debug data processing software independently using Apache Spark.', 'Participate in data architecture design sessions at product level.', 'Craft and maintain complex stored procedures using PL/SQL.', 'Promote data quality, research anomalies, and solve problems.', 'Maintain the data model for the aptitude marketplace OLTP.', 'Relevant degree in computer science is preferred.', '3 or more years’ relevant experience is required.', 'Working experience with Big Data tools and technologies (Hadoop, Spark, etc.) required.', 'Experience with Oracle Application Express (APEX); along with knowledge of SQL and PL/SQL is required.', 'Understanding of data warehousing & ET is preferred.', 'Comfortable working closely with business stakeholders, software engineers, data analysts, and quality assurance preferred.']",2020-09-24 14:03:54
Quality Engineer,SMW Manufacturing,3.5 out of 5,"Oxford, MS 38655","['Experience:Quality Engineer, 10 years (Preferred)', 'Education:High school or equivalent (Preferred)', 'Location:Oxford, MS 38655 (Preferred)', 'Responsible for Quality System Maintenance.', 'Root cause analysis and implementation of corrective action for process related concerns.', 'Assist Quality manager in establishing, implementing and maintaining the quality management system.', 'Responsible for continual improvement activities to enhance the quality system, such as 5S, Kaizen lean methods, etc.', 'Develop training to build quality awareness.', 'Experience in Measurement Systems: calipers, micrometers, optical comparator, Wenzel CMM (Open DMIS) using CAD generated models', 'Gage calibration: calipers, micrometers, jo-blocks, height stands, gage masters, thread gages, attributes gages', 'Experience with SPC, APQP, PFD, PFEMA, PCP and PPAP', 'Interface with Engineering and Operations to ensure transfer to Production of new products are in accordance with approved specifications.', 'Support the Quality Technicians to ensure that products and processes comply with the relevant requirements of the quality management system.', 'Conduct audits, including closing out audit findings, creating audits finding reports and determine proper corrective and preventative actions.', 'Create and maintain company quality documentation, such as quality manuals, quality procedures, etc.', 'Continuously improving QA receiving inspection process and procedures.', 'Ensure timely resolution of supplier failure, corrective actions and preventative actions.', 'Manage suppliers’ performance and conduct audits.', 'Preparation of QA reports.', 'Other research or related activities as deemed necessary', 'Comply with all safety requirements and proper use of PPE', 'Shall adhere to all safety, health and environmental procedures, policies and practices, such as; utilizing personal protective equipment and proper attire in keeping with safety standards.', 'High School Diploma or equivalency required', 'Bachelor’s degree in Engineering preferred but not required', 'Certification by American Society of Quality preferred but not required', 'The ability to travel from plant to plant if requested', 'At least 10 years’ experience as a Quality Engineer, or similar, in an ISO certified environment.', 'Ability to work in a fast-paced environment', 'Proven ability to work well in a team environment and excellent work history.', 'Attention to detail with emphasis on accuracy and quality', 'Ability to resolve technical issues and critical problems', 'Experience with Document Control and MRB systems', 'Demonstrated proficiency utilizing metrology/ inspection tools; experience with calibration systems required', 'Ability to read and understand blueprints and statistical information', 'Ability to prioritize work to balance multiple projects and deadlines', 'Excellent verbal, listening and written communication skills', 'Proficient in Microsoft Outlook, Excel and PowerPoint as well as current technology software familiarity.', 'Proactive, positive attitude, safety and environmental focused.', 'Ability to regularly stand or work for long periods of time.', 'Ability to regularly lift/or move up to ten (10) pounds, frequently lift and/or move up to twenty-five (25) pounds, and occasionally lift up to fifty (50) pounds.', 'Occasional walking throughout the day', 'Follow all company policies and procedures as well as all local, state, and federal laws concerning employment to include, but not limited to: I-9 information, EEOC, Civil Rights, and ADA.', 'The company does not tolerate sexual or other unlawful discriminatory actions, gestures, harassment, or statements. Any of these behaviors are subject to personnel action up to and including immediate termination and should be reported to management immediately.', 'Maintain confidentiality of company records and information at all times.', 'Maintain a professional image.', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Retirement plan', 'Vision insurance', '8 hour shift', 'Day shift', 'Monday to Friday', 'Quality Engineer: 10 years (Preferred)', 'High school or equivalent (Preferred)', 'Oxford, MS 38655 (Preferred)', 'Dependable -- more reliable than spontaneous', 'People-oriented -- enjoys interacting with people and working on group projects', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Achievement-oriented -- enjoys taking on challenges, even if they might fail', 'Autonomous/Independent -- enjoys working with little direction', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'High stress tolerance -- thrives in a high-pressure environment', 'Waiting period may apply', 'No']",2020-09-24 14:03:54
"Data Engineer, Intern",Qorvo,3.7 out of 5,"Greensboro, NC 27409","['Computer science, engineering, or other quantitative degree, or equivalent coursework and/or work experience.', 'Experience with or completed course work related to cloud-based data storage solutions.', 'Experience with or completed coursework related to data pipeline automation.', 'Familiarity with mathematical and statistical software tools and programming/scripting languages.', 'Strong process driven problem-solving skills.', 'Use SQL, Python / Pandas, Apache Spark and other data manipulation tools to develop, construct, test, and maintain databases and big data processing systems in support of analytics and applications.', 'Unify data from disparate sources while assessing and improving data quality and usability.', 'Prepare data for use in diagnostic, predictive, and prescriptive modeling.', 'Collaborate with BI users, applications developers, and data scientists to establish and refine data requirements.', 'Implement data movement and transformations in the context of an automated data pipeline.', 'Support pipeline operations.', 'Assist data scientists in feature engineering and model deployment', 'Excellent Communication skills', 'Effective collaborative skills', 'Innovative', 'Curious', 'Driven']",2020-09-24 14:03:54
Data Engineer (Remote),Cloudbeds,N/A,"Detroit, MI 48127","['Code ETL data transformations in PySpark/Spark.', 'Design and manage processing pipelines via AWS Glue and/or EMR clusters.', 'Manage ingestion and replication via DBMS from cloud MySQL databases.', 'Process external sources like Salesforce via Appflow or kaggle datasets.', 'Manage AWS Athena views and endpoints for consumption.', 'Creation, modification, and maintenance of data infrastructure (Redshift [with Spectrum], S3 Parquet data, DBMS, Notebooks, etc.)', 'Implement logging and debugging approaches in a standardized fashion.', 'Collaborate with Business Intelligence, Analytics, and Infrastructure teams on a daily basis.', 'Develop a framework for future extensions through standardized modern workflows.', 'Bachelor’s degree in computer science or related field, or equivalent experience.', '3+ years experience as a Data Engineer.', '2+ years experience working with Amazon Web Services.', 'Expert knowledge and experience developing efficient ETL data pipelines having multiple sources using PySpark/Spark and DataFrames.', 'Strong knowledge and experience developing workflows with AWS Glue, EMR, Redshift, Athena, and LakeFormation.', 'Strong knowledge of modern data lake, data warehousing, and ETL/ELT concepts.', 'Strong knowledge of how to compose and implement structural data models.', 'Experience molding fresh environments into efficient mature data platforms.', 'Experience with performance optimization for processing and storage via data partitioning and indexing techniques.', 'Ability to take a consultative approach to data strategy.', 'Ability to work in an Agile Scrum environment.', 'Ability to thrive in a fast-paced environment.', 'Ability to work remotely and manage your own time in an international team.', 'Exceptional written and verbal communication in English.', 'Best Startup Employers in 2020 | Forbes', 'Best Places to Work | HotelTechReport (2018, 2019, 2020)', 'Deloitte’s North America Technology Fast 500 (2019)', 'Inc. 500 Fastest Growing Companies (2018 & 2019)', 'Inc. Best Places to Work (2017 & 2018)', 'Best Places to Work | Inc Magazine (2017 & 2018)', 'Start-Ups to Watch in 2018 | Forbes', 'Connect MIP Award (Technology)']",2020-09-24 14:03:54
Data Center Design Engineer,Digital Realty,3.5 out of 5,United States,"['S./B.S. College degree related to technology, electrical or mechanical.', 'Minimum 2 years’ experience in telecommunications environment.', 'Minimum of 2 years of engineering and planning experience.', 'Must be detail oriented with excellent communications, interpersonal and oral/written presentation skills.', 'Advanced skills with ACAD.', 'Proficiency with Microsoft Office Suite (Visio, PowerPoint, Word, Outlook, Explorer) and/or equivalents.', 'Proven organizational ability, attention to details and strong analytical skills.', 'Must be a self-starter, proactive, flexible, and able to work within deadlines.', 'Must be able to work on multiple tasks/projects.', 'Experience working in a Data Center or Colocation environment.', 'Work in central office environment with hands-on experience.', 'Manage assignments of new customer racks, cabinets, cages, panels and conduits.', 'Create in ACAD Implementation Package and SOW documentation for installations of ladder rack, fiber raceway, cable ties, power and grounding.', 'Create Project Bill of Materials (BOM) for all installation projects.', 'Create Work Orders to instruct facility technicians on task to be performed and to track installation projects and sub-Contractor’s work.', 'Update facility floor plans using ACAD and DCIM software.', 'Update connectivity and cable tie records using DCIM software.', 'Update records of customers’ power circuits using company DCIM software.', 'Assist sales engineers with facility capacity inquiries regarding space, power and connectivity.', 'Perform audits as required at DLR sites.']",2020-09-24 14:03:54
Data Governance Reporting Engineer,Regions Bank,3.6 out of 5,"Birmingham, AL","['Measures and monitors data quality, designs, and executes remediation plans, maintains, and supports applicable data management standards', 'Implements and supports data quality requirements as designed by the Data Owner, including the business rules and movement controls', 'Performs user acceptance testing (with applicable consumers) and reviews results with Data Owner for approval', 'Reviews data quality issues, perform analysis, recommend fixes, and/or report timely any breaches of thresholds to Data Owners, Data Consumers, and escalate as needed to Enterprise Data Management (EDM)', 'Manages and resolves or remediates data issues identified by Data Owners and Data Consumers', 'Manages, executes and tracks data quality remediation plans in coordination with all stakeholders', 'Tracks and reports data quality statistics for data quality for stewarded application(s), warehouse or mart (including developing evidence of compliance with Data standards)', 'Collects and updates business metadata and references data for the data they are assigned', 'Translates business rules into data quality rules and produces data controls (in conjunction with the Data Stewards)', 'Ensures data for all Critical Data Elements (CDEs) is provisioned in an appropriate authoritative source (in conjunction with Data Stewards)', 'Supports applications and platforms to enable effective sharing of data from authoritative data sources', 'Develops and maintains dashboards related to Data Governance', 'Provides training and data assistance as needed', 'Bachelors degree in Business Management, Information Systems, or related field and three (3) years of Business Analysis, Systems Analysis, or related experience', 'Or a high school diploma/GED and seven (7) years of Business Analysis, Systems Analysis, or related experience', 'Master’s degree in Business, Science, or related field', 'Ability to review and analyze data, and identify and resolve problems', 'Solid written, verbal, and analytical skills', 'Capacity for day-to-day, hands-on execution', 'Ability to translate business needs into technical solutions', 'Basic project management skills', 'Strong research and problem determination and solution skills', 'Proven skills in data analysis – including queries to calculate data quality', 'Knowledge and understanding of the applicable tools and practices used in data governance including query and data profiling techniques', 'Understanding of data architecture practices', 'Familiarity with data quality issues and ETL processes', 'Typically work across many data assets and is an operations or technology person who is responsible for a Data Asset as it flows through systems', 'Identify and implement leading edge technology solutions to drive adoption and efficacy of the data governance program across the enterprise.', 'Build/enhance the framework for data quality assessment across different business units.', 'Build and manage processes and tools to support data issue management', 'Designing, developing and maintaining business intelligence solutions like dashboards', 'Presenting information through reports and visualization', 'Create and manage BI and analytics solutions that turn data into knowledge', 'Demonstrate Proven experience as a BI Developer or Data Scientist', 'PowerBI / Tableau / Arcadia experience strongly preferred', 'Experience with data visualization and data modeling', 'Experience with SQL stored procedures, functions, views and triggers', 'Effectively analyze data via multiple sources and communicate conclusions and insights from analysis through a variety of reports, charts, and visualizations', 'Ability to write detailed technical specifications and documentation']",2020-09-24 14:03:54
Data Engineer,Homie,4 out of 5,"South Jordan, UT 84095","['Disruption: Real Estate is ready for improvement; time to change it! Come build with us', 'Loyalty: To our customers, to your teammates, and Homie to its employees', 'Work Life Balance: We want you to have a life outside of Homie', 'Humility: We all have more to learn', 'Develop and maintain data pipelines including solutions for data collection, management, and usage.', 'Maintain and improve our data and platform', 'Develop and implement solutions for data quality validation.', 'Partner with engineers, data team members, product managers, and business stakeholders to understand business and technical requirements, plan and execute projects, and communicate status, risks, and issues.', 'Perform root cause analysis of system and data issues and develop solutions when necessary.', ""Bachelor's degree in Computer Science or Information Systems."", '5 years of experience in data engineering.', 'Proficient in SQL, Python, Hadoop, Spark, and Azure Analytics stack.', 'Experience with ETL data pipelining concept.', 'Experience working in software engineering, and can demonstrate best practices for project management, quality control, and product development.', 'Machine Learning experience', 'Experience with Docker and Kubernetes.', 'Experience building APIs and services using REST.']",2020-09-24 14:03:54
Big Data Engineer (Locals Only),SSI - Software Specialists,N/A,"Pittsburgh, PA","['Develop scalable streaming solutions based on Apache Spark and Apache Kafka using Scala and Java', 'Design, architect, optimize, and refactor code to maximize performance', 'Write comprehensive automated unit tests', 'Inform and encourage the technical growth of the team', 'Support existing programs and modules from both debugging and enhancement perspectives', 'Participate in code reviews and extensive unit testing', 'Write technical documents as part of established methodology', 'Write functional and technical specification documents and collaborate with systems analysts and product owner to ensure solutions align with business objectives', 'Work closely with Q/A team and internal users', 'Requires a four-year degree in Computer Science/Information Technology, Computer/Electrical Engineering or related discipline', 'At least five years of experience in systems analysis and programming, addressing unique issues of architecture and data management', 'Experience to work at the highest technical level of all phases of systems analysis and programming activity across the full scope of software development cycle', 'Experience with Spark, Scala or similar functional programming language', 'Experience with Hadoop data stores and formats like Hive, HBase, and Parquet', 'REST-based Web service development experience', 'Experience with the JVM', 'Experience with SQL and RDBMS technologies', 'Experience building scalable solutions', 'Experience with automated unit testing', 'Strong written and verbal communication skills', 'Ability to work both independently and as part of a team']",2020-09-24 14:04:35
Data Engineer,Dolls Kill,2.6 out of 5,"San Francisco Bay Area, CA","['Develop automated data pipelines for the extraction, preparation, and ingestion of data', 'Work with APIs and setup Webhooks to ingest live data from various partner applications', 'Ensure data quality and consistency; play an active role in establishing data governance around company KPIs', 'Create and maintain technical documentation', 'Work closely with analytics team to design, build & test end-to-end solutions', 'BS in Computer Science, Information Systems, Mathematics or a related field', '2+ years experience creating and maintaining automated data pipelines and ETLs', 'Experience working with large data sets', 'Experience with AWS', 'Ability to quickly learn new technologies and business processes', 'Strong analytical skills to determine effective approaches to business questions', 'Experience working with BI reporting tools such as Looker, Tableau or Microstrategy', 'Advanced level of proficiency in SQL development']",2020-09-24 14:04:35
Senior Data Engineer,Redfin,3.3 out of 5,"Seattle, WA","['Design data warehouse solutions using dimensional methodologies to support ETL processes and data analytics applications', 'Develop, implement and tune ETL processes', 'Write and tune SQL including database queries, ddl and dml', 'Create code that meets design specifications, follows standards, and is easy to maintain', 'Own features that you develop end to end. Work with end users on requirements gathering, develop and test your code, implement new processes in production, then maintain and support them over time', 'Drive our data platform and help evolve our technology stack and development best practices', 'Develop and unit test assigned features to meet product requirements', 'Work with Analytics and Digital Marketing teams to provide them the data they need to make efficient decisions', 'Support and maintain dev/test/prod environments to meet business delivery specifications and needs', 'Assist with adhoc report generation and data analysis for customers', 'Be part of weekly on call rotation', 'Expert level SQL skills', '7-10 years experience in database technologies (i.e., Postgres, MySQL ,SQL Server, Oracle, RedShift etc.)', 'Minimum 5 years of experience in Data Warehousing', 'Experience creating and maintaining automated data pipelines', 'Working knowledge of dimensional modeling techniques', 'Working knowledge of data quality approaches and techniques', 'Experience with Redshift is highly desired', 'Experience with AWS tools (S3/Redshift/DynamoDB/IAM) is highly desired', 'Architectural insight on where to store data and modeling experience to recommend how it should be structured to make it accessible, performant, and resilient to change', 'An entrepreneurial spirit, a drive to ship quickly, and familiarity with agile software development practices', 'The ability to deal with ambiguity, communicate well with partner teams - both technical and non technical, and a strong empathy for the customer experience', 'Experience working with Linux is a plus', 'Programming language experience (Python, Java, etc) is a plus', 'API development experience is a plus', 'The ability to work within an Agile/Scrum development process']",2020-09-24 14:04:35
Data Platform Engineer,Pantheon,N/A,"Minneapolis, MN 55401","['Unlimited vacation', 'Maternity and paternity leave', 'Monthly gym and book allowance', 'Fully loaded kitchen and daily catered lunches (HQ, NY, MN)', 'Discounts on custom bicycles (the founders of Pantheon also founded Mission Bicycle)', 'Create an automated, state of the art, data platform for various job types and sizes', 'Help stabilize a standard deployment pattern that will enable us to grow our data platform service capabilities for the company', 'Close collaboration with the wider engineering team to both deliver platform improvements and provide subject-matter-expertise for other technology initiatives', 'Continuous improvements to our standard of engineering excellence by implementing best practices for coding, testing, deploying and communication', 'Knowledge of large-scale platforms and the design of scalable, robust services in the real world, especially for data transfers and manipulations (both streaming and batch)', 'Experience with a variety of data store types, tech stacks, and the tradeoffs between them.', 'Experience with scripting the creation of dynamic platform infrastructures hosted by one or more cloud providers such as Google or AWS.', 'Desire to work on a new project and participate in the design and documentation activities related to the creation of new infrastructure.', 'Strong experience in Python', 'Automating infrastructure with kubernetes', 'Scheduling ETLs using Airflow', 'Exposure to frameworks such as Django', 'Experience working on new “greenfield” projects', 'Experience supporting data scientists and analysts through PaaS', 'Fantastic work environment powered by an amazing team', 'Unlimited vacation', 'Dog-friendly office (HQ)', 'Maternity and paternity leave', 'Monthly gym and book allowance', 'Fully loaded kitchen and daily catered lunches (HQ, NY, MN)', 'Discounts on custom bicycles (the founders of Pantheon also founded Mission Bicycle)', 'Pantheon recently closed its Series D funding ($40m)', 'Pantheon is one of America’s Best Workplaces of 2019', 'Pantheon earns Top 10 Ranking in “Best Software Awards” by G2 Crowd', 'Pantheon actively sponsors programs like the Grace Hopper Celebration (GHC 19)']",2020-09-24 14:04:35
Java / Selenium QA Engineer (Automated),HealthLabs.com,4.3 out of 5,Remote,"['9 Paid Holidays', 'Maternity and Paternity Leave', '10 Paid Vacation Days Beginning Your First Year of Service', 'Company issued Macbook Pro, 4K HD Monitor, Dock Station and Jabra Headset', '9 Paid Holidays', 'Maternity and Paternity Leave', '10 Paid Vacation Days Beginning Your First Year of Service', 'Relaxed ""Tech-Focused"" Environment (flexible schedules, no dress code)', 'Tourist visits to Houston, Texas for company-wide outings and events', 'Selenium IDE testing background', 'Excellent interpersonal, consultative and communication skills, including exceptional English written communication', '2+ years of automation experience in scripting and running automated test', 'Experience working closely with a development team', 'Ability to work in a fast-paced, quickly changing environment', 'Strong analytical skills such as cause and effect analyses', 'Ability to understand and articulate how changes in technology impact customer experience', 'Ability to follow instructions, work independently, or function in a team as needed', 'Strong knowledge of QA processes and concepts including test case preparation and automated testing methodologies', 'Java development Experienced', 'Selenium API experience', 'Experience working with Cucumber', 'Experience executing testing and deploying with continuous integration (CI) on Linux', 'Familiar with software design patterns', 'Mobile QA experience with Android applications Experience with Selendroid, Selenium, Appium, and Docker', 'Experience with cross-browser testing', 'Develop and maintain automated tests via automated tools and frameworks', 'Design test plans, scenarios, scripts, or procedures', 'Monitor automated test runs, review the findings and record the results', 'Ensure automated tests resulting in high-quality software and few defects when product deployed to production', 'Evaluate problems identified in testing and work with product development engineers to isolate issues by collecting and analyzing detailed process steps, log files, and data input', 'Develop a deep understanding of available testing tools, test strategies and best practices for automated testing', 'Lead the test effort and define a strategic testing approach']",2020-09-24 14:04:35
Data Engineer,"Integrated Technology Strategies, Inc.",N/A,"Allentown, PA","['Bachelor’s degree in engineering or a bachelor’s degree in technology from a recognized university', 'Candidate should have recent work experience with US-based customers', 'Minimum 10 years of relevant experience is required', '5+ years of experience working in data engineering or architecture role', 'Expertise in SQL and data analysis and experience with at least one programming language (Python/PySpark or Scala preferred)', 'Experience developing and maintaining data warehouses in big data solutions', 'Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space (preferred)', 'Database development experience using Hadoop or BigQuery and experience with a variety of relational, NoSQL, and cloud data lake technologies', 'Worked with BI tools such as Tableau, Power BI, Looker, Shiny', 'Conceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data.', 'Big Data Development experience using Hive, Impala, Spark and familiarity with Kafka (Preferred)', 'Familiarity with the Linux operating system (Preferred)', 'Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics']",2020-09-24 14:04:35
Data Engineer,"Epiq Systems, Inc.",3.2 out of 5,"Park, IN","['Create and maintain optimal data pipeline architecture', 'Assemble large, complex data sets that meet functional / non-functional business requirements', 'Identify, design, and implement internal process improvements: automation of manual processes, optimization of data delivery methods, re-design of infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics', 'Work with key stakeholders to strive for greater functionality in our data systems', 'Serve as a Subject Matter Expert (SME) regarding data architecture, as well as proper data collection and storage methods.', 'BE/B.Tech/MCA Computer Science or related discipline, or equivalent industry experience', '5+ years as a software developer and/or SQL developer designing and building software and database solutions using SQL Server 2008R2 or newerDemonstrated experience designing and developing medium to large-scale, mission-critical database solutions, to include the following strengths: Thorough understanding of Kimball/Inmon strategies, key performance indicators (KPI) Reports, and data mining structuresExpert data modeler and proficient with modeling toolsExtensive knowledge of data normalization concepts, Relational Database Management Systems, data warehouse systems, and star schemasExpertise with Index management: creation, maintenance, and tuning', 'Extensive experience in SQL Server Business Intelligence Development Studio(BIDs):Integration Services (SSIS)Extracting, Transforming, and Loading (ETL) data from MS Excel, flat files, or other sources to SQLReporting Services (SSRS)Creating simple and complex reports in SSRS, including matrix / pivot outputs, charts and graphs, Drill Through and Drill Down', 'Extensive experience with T-SQL, including but not limited to:TroubleshootingTriggersStored ProceduresFunctionsViewsPerformance tuning', 'Experience developing dashboards and other macro-level outputs using Power BI or similar business intelligence tools', 'Excellent communication skills; ability to express complex ideas in writing at appropriate level of detail for intended audience; fluent in English', 'Team player, willing to engage within and across the organization', 'Ability to support data needs of multiple initiatives, systems, and products concurrently in a fast-paced environment', 'Self-directed professional who seeks out opportunities and areas where improvements can be realized', 'Passionate about technology, automation, and eliminating human toil', 'Position requires no significant manual labor.', 'Position does require moderate standing, sitting, carrying and walking.', 'Position requires infrequent lifting, repetitive bending and/or moving.', 'Position requires close vision, distant vision, peripheral vision, and depth perception.', 'Position requires talking and listening to communications with clients and employees.']",2020-09-24 14:04:35
"Support Engineer, 2+ years exp. req.",Brightmetrics,N/A,"Petaluma, CA 94952","['Starting salary for this position is $60,000 - $70,000.', 'We pay 80% of your premiums for medical, dental, and vision insurance for you and your family.', 'You’re quickly eligible for a 401k plan administered for all employees.', '$60,000.00 - $70,000.00 per year', 'Benefits:', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Experience:Customer Service/Technical Support, 2 years (Required)Remote, 1 year (Required)', 'Respond to Support tickets. Some may be quick and simple, others may involve research and troubleshooting. You serve as their lifeline in getting the data they’re looking for. Be patient with them if they’re having a hard time describing what they’re looking for. Be thorough in your personalized response and use all available resources in your research if needed to ensure you’re providing accurate information. We want our customers to always feel welcome to reach out to us for help.', 'Identify bugs or feature requests. Occasionally a customer will request a feature we currently don’t have, or will point out a feature not working as expected. You’ll pass these along to the Product team for review.', 'Expand our Knowledge Base. We are constantly producing new or updating existing learning resources for our customers. These include Help Center articles, tutorial videos, and training.', '2+ years customer service experience supporting a SaaS based application', '1+ year remote experience', 'Zendesk experience (preferred, but not required)', 'Cover Pacific time zone business hours (Monday-Friday, 8 am - 5 pm)', 'Excellent customer relationship and communication skills; written and verbal', 'Excellent problem solving and listening skills with high-level attention to detail', 'Ability to prioritize, multi-task, and follow-up', 'Ability to see a problem through to resolution with high-level of accuracy', 'Ability to always be friendly and professional, even when customer expectations may seem unreasonable', 'Self-motivated, independent, critical thinker who works well with limited supervision and executes professionally', 'Ability to travel one week per quarter (when safe to do so) to our HQ office in Northern California. We use this time to connect with each other, engage in team-building activities, and collaborate in person.', 'Work anywhere. Really, we mean it. You can choose to work from our HQ office in Petaluma, CA or we will provide what’s needed for your home office.', 'Competitive Salary. Brightmetrics offers a very competitive salary. Starting salary for this position is $60,000 - $70,000.', 'Health Benefits. We pay 80% of your premiums for medical, dental, and vision insurance for you and your family.', 'Retirement Plan. You’re quickly eligible for a 401k plan administered for all employees. Even if you opt not to contribute, you will have a plan that Brightmetrics will contribute an amount equivalent to 3% of your pay into.', 'Vacation.  We offer unlimited paid time off. We know our employees work hard, and we believe it’s important for them to have time to relax and recharge when needed.', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Customer Service/Technical Support: 2 years (Required)', 'Remote: 1 year (Required)']",2020-09-24 14:04:35
Data Engineer,Vydia,N/A,"Holmdel, NJ 07733","['Ensuring the availability and timely delivery of data, company-wide', 'Modeling new data sets and crafting all new ELT workflows and pipelines', 'Lead the orchestration of the workflows and contribute strongly to infrastructure decisions', 'Improving on and monitoring of existing pipelines and oversight of our ELT workflow', 'Maintaining a single version of truth for our data and working with others to implement continuous integration (CI) data quality tests', 'Mentoring and guiding your junior colleagues and leading with vision, and with respect to the company’s data strategy', 'You are a Python pro and have regularly used AWS or Google Cloud Platform to manage data and move it between applications', 'Do you love APIs? When you encounter a new one, do you study it inside and out and learn every corner of it, as though you designed it yourself?', 'Working with deeply-nested, complex JSON is a fun day at the office for you.', 'You can articulate the merits and pitfalls of the different approaches in designing a pipeline.', 'You are passionate about data quality control and know how and where to anticipate potential errors.', 'Working “in the cloud” is not a point of distinction for you, it is a given.', 'You understand what it means to work at a tech startup. Hopefully, this is what excites you more than anything else about working here.', 'You intuitively know how to extract value and insights from data.', 'You love the idea of building the data scene in NJ and being a leader in this community.', 'You have orchestrated workflows using Airflow and are familiar with the challenges and how to overcome them.']",2020-09-24 14:04:35
Data Analytics Engineer,TechStyle Fashion Group,3.3 out of 5,"El Segundo, CA","['Design, build and maintain reporting structures for the media and web analytics teams (30%)', 'Design, build and maintain data integrations (10%)', 'Review data integrations from offshore team (20%)Review offshore team’s work and provide guidance and mentorshipHandle merge and deployment', 'Review code submitted by non-technical analysts (30%)Ensure processes are well-structured, organized well, efficient and ready for productionAct as mentor to less senior developers and analystsHandle merge and deployment', 'Production support (10%)Data integrationsReporting processes', 'Evaluate existing data and analytics pipelines with data engineering peers to ensure that analytics systems are performant', 'Collaborate with analysts and stakeholders in developing new data models and ETL design specifications based on analytics requirements (must be able to elicit and translate business requirements)', 'Proven ability to extend your scope into the Analytics domain and partner with that team to optimize the output of the Analytics function', 'Follow best practices for version control and centrali (this is covered in required skills)', 'Expert SQL skills, particularly in an analytics/reporting capacity. Significant experience creating and maintaining reporting processesAdvanced SQL skills requiredPrimary/foreign keys, indexes (when to use them)Joins and unionsTables and Views (How are they different? Pros and cons of using)Be able to describe differences between DML/DDL statementsWindow functionsScalar and aggregate functions', '2+ years of experience creating and managing data pipelines', '1 year experience with python or another scripting language', 'Strong command of git (1+ year)', 'Comfort working in linux-based python development', 'Traditional data warehousing (e.g. kimball)', 'Data engineering experience on cloud platforms (e.g. bigquery, redshift, snowflake, teradata, vertica)', 'Expertise in devops and CI/CD practices', 'Airflow infrastructure experience', 'Conversant in docker', 'Data Visualization tools: Tableau, SSRS, Looker etc.,', 'Experience working with large amounts of raw data (web logs, Click stream, data feeds)', 'Ability to create and interact with very large data processing pipelines, distributed data stores, and distributed file systems', 'E-commerce or retail or internet experience']",2020-09-24 14:04:35
Data and Analytics Practice Area Director,Slalom Consulting,3.7 out of 5,"Miami, FL","['Practice Building – Drive growth of the Slalom Miami Data & Analytics Practice with both our clients and partners through developing strategic solution offerings, driving thought leadership initiatives, and collaborating with other Slalom capability leads. Assemble best practices and develop case studies and other core deliverables to grow solution offerings.', 'Business Development – Relationship building with executive-level client stakeholders and expansion of Slalom’s client portfolio in the South Florida region. Guide business development activities, partnering with other Slalom leaders to grow new and existing client relationships.', 'Team & Individual Development – Lead by example to build a team of leaders and engineers and create a passionate, team-player environment. Provide technical thought leadership in the data science and data engineering spaces. Support recruiting, on-boarding of new employees, and the development of leaders.', 'Engagement Management – Deliver high-quality projects for Slalom clients while also providing engagement oversight, handling key project aspects such as engagement risk, project economics including planning and budgeting, deliverable content, and consensus for proposed solutions from top management levels at the client.', 'Partner Management – Build and maintain foundational relationships with relevant Data & Analytics partners such as AWS, GCP, Microsoft, Snowflake, and more', '12+ years of experience focused in Data & Analytics engagement–based consulting experience or equivalent industry experience', 'Expertise in data warehousing, cloud data platforms, data science platforms, data visualization tools, and other relevant data & analytics technology', 'Proven history of leveraging and growing existing client base, organic business development, and acquiring new customers.', 'Deep experience with managing and leading people, including mentoring and coaching skills', 'Expert business operations experience (e.g., invoicing, SOW, margins, utilization)', 'Outstanding verbal and written communication skills to audiences of all levels, including client-facing skills']",2020-09-24 14:04:35
Messaging Infrastructure Engineer,IBM,3.9 out of 5,United States,"['Management and supporting of messaging environments.', 'Proactive system analysis, monitoring and documentation', 'Understand MS Exchange messaging ecosystem security aspects, maintain and ensure systems are up to par with the security industry standards[RH1]', 'Operating, managing, processing, provisioning, and troubleshooting enterprise email, mobile, and collaboration services, in an environment with minimum 10,000 users, 50,000 or more preferred', 'Conducting account management', 'Managing roles and services, user permissions, e-mail queues, mobile messaging, and dynamic distribution groups', 'Troubleshooting issues with enterprise email', 'Coordinating restoration of email services', 'Resolving emergency incidents (e.g., restoring deleted messages and mailboxes)', 'Documenting incident resolutions and providing updates', '2+ years of experience installing, configuring and managing MS Exchange current supported versions, on premise environments, including Database, Mailbox Server roles/ services, and message routing.', 'LDAP and Directory Services AD DS expertise.', 'DNS and related technologies.', 'DLP.', 'Familiar with PowerShell.', 'Outlook 2016/2019, Outlook Mac 2016/2019.', 'Activesync, Mobile Email (Android, IOS).', 'SMTP, TLS.', 'Email Hygiene, Policy Management.', 'Knowledge of Agile methodology', 'Knowledge of Identity technologies; SSO, MFA', 'IBM Lotus Notes/Exchange integration experience']",2020-09-24 14:04:35
Data Engineer,Noetic Strategies Inc.,N/A,"Scott AFB, IL 62225","['Design new or integrate existing tool(s) to automatically ingest, sort, tag, and organize various data sources and types according to a schema, methodology, or ontology.', 'Prepare data for predictive and prescriptive modeling.', 'Provide expertise / assistance in identifying and integrating applicable technologies and/or methodologies from government or commercially available sources to address needs.', 'Translate intelligence production end state goals into machine ingestible code/tools.', 'Provide technical assistance in identifying and integrating appropriate technology solutions for data and knowledge management.', 'Develop new or refine existing databases to ingest, sort, tag, and organize various data sources and types (structured and unstructured) according to an ontology to enable wider integration and analysis.', 'Maintain working knowledge of AI and ML initiatives leveraging existing expertise to better meet customer needs.', 'Develop and build relationships with other data engineers developing similar tools and products.', 'Travel to and attend meetings, conferences, and symposiums as directed.', 'Brief leadership on new requirements to meet analytical needs and significant findings.', 'The best candidate will have a broad knowledge of current tools and technologies utilized in data engineering, able to advise management and work toward a end result without too much guidance or mentoring.', 'TS / SCI (poly will be required also)']",2020-09-24 14:04:35
SAP Data Pipeline Engineer,Highbrow LLC,N/A,"Renton, WA","['Responsible for building and supporting data replication pipelines for 10-15 SAP modules in ECC and SRM', 'Developer or administrator expertise in at least one of SAP ECC or SRM environments', 'Understanding of the FI, CO, MM, PP, WM, SD, and HR modules', 'Strong understanding of transaction and replication processes', 'Familiarity with operating in a cloud environment', 'Rigorous attention to detail and habit of taking ownership', 'Ability to take on an assignment and drive the task to closure independently']",2020-09-24 14:04:35
Lead Data Engineer,Proton,N/A,"Boston, MA",['Yes'],2020-09-24 14:04:35
Lead Data Engineer,Proton,N/A,"Boston, MA",['Yes'],2020-09-24 14:05:17
"Software Engineer, Data",Fathom Health,N/A,Remote,"['Develop data infrastructure to ingest, sanitize and normalize a broad range of medical data, such as electronics health records, journals, established medical ontologies, crowd-sourced labelling and other human inputs', 'Build performant and expressive interfaces to the data', 'Build infrastructure to help us not only scale up data ingest, but large-scale cloud-based machine learning', '3+ years of development experience in a company/production setting', 'Experience building data pipelines from disparate sources', 'Hands-on experience building and scaling up compute clusters', 'Excitement about learning how to build and support machine learning pipelines that scale not just computationally, but in ways that are flexible, iterative, and geared for collaboration', 'A solid understanding of databases and large-scale data processing frameworks like Hadoop or Spark. You’ve not only worked with a variety of technologies, but know how to pick the right tool for the job', 'A unique combination of creative and analytic skills capable of designing a system capable of pulling together, training, and testing dozens of data sources under a unified ontology', 'Developing systems to do or support machine learning, including experience working with NLP toolkits like Stanford CoreNLP, OpenNLP, and/or Python’s NLTK', 'Expertise with wrangling healthcare data and/or HIPAA', 'Experience with managing large-scale data labelling and acquisition, through tools such as through Amazon Turk or DeepDive']",2020-09-24 14:05:17
Data Engineer,BNY Mellon,3.5 out of 5,"Boston, MA","['Lead/contribute data engineering and/or data science projects to support IM firms', 'Use domain expertise to understand business requirements and design the right solution', 'Build or implement data pipelines, databases, visualizations, and other data tools (hands-on)', 'Contribute to team in a wide range of technical areas by instituting new practices and staying abreast of the latest technical developments', 'Take initiative to lead/contribute to overall team efforts in software development, data engineering, data science, and technical consulting', 'Work closely with other data engineers and data scientists to improve processes and enable faster insight-generation from complex datasets', 'BA/BS Degree (advanced degrees and/or CFAs are great too)', '5+ years general business experience preferred, especially in financial services, asset management, and/or management consulting or similar environments', '5+ years of data engineering, data architecture, data science, and/or software engineering experience', 'Excel proficiency', 'SQL proficiency', 'Python expertise', 'Experience with machine learning algorithms and techniques', 'Experience with modern data pipelines and/or data operating platforms (e.g. Dataiku, Alteryx, Spark)', 'Able to lead ad-hoc and structured product teams within an agile framework', 'Excellent interpersonal skills necessary to accomplish goals through others, including employees, peers, and other function/business areas of the company']",2020-09-24 14:05:17
Data Engineer,BNY Mellon,N/A,"Boston, MA","['Interviews on the spot', 'Tuesday, September 29, 20208:30 AM - 12:30 PM US/Central', ""Interviewing via webYou'll receive an email on how to connect."", '44 slots left', '', ""Senior Staff Data Engineer$160,000 - $180,000 / year, Full-timeResponsibilities:\xa0Individual Contributor (expected to be hands-on coder 50%-80% of the time)Lead the design and delivery of complex, cross-team systems built and deployed on AWSInterview top talent for Engineering's staffing needsMentor highly talented engineers within the org\xa0Required Skills:\xa012+ years of overall relevant Software Engineering experience7+ years of Data Engineering development experience including familiarity in multiple batch and streaming data processing technologies (Hadoop, Spark, Kafka, MapReduce, Hive, etc.)3+ years Architecting, Designing and Building large-scale, multi-use Big Data Systems on Public cloud hosting providersStrong communication skills (including influencing across multiple teams)Extensively worked in a range of database technologies including SQL and noSQL DB\xa0Nice to Have:\xa03+ years in AWS environmentEcommerce industry experience"", 'Individual Contributor (expected to be hands-on coder 50%-80% of the time)', 'Lead the design and delivery of complex, cross-team systems built and deployed on AWS', ""Interview top talent for Engineering's staffing needs"", 'Mentor highly talented engineers within the org', '12+ years of overall relevant Software Engineering experience', '7+ years of Data Engineering development experience including familiarity in multiple batch and streaming data processing technologies (Hadoop, Spark, Kafka, MapReduce, Hive, etc.)', '3+ years Architecting, Designing and Building large-scale, multi-use Big Data Systems on Public cloud hosting providers', 'Strong communication skills (including influencing across multiple teams)', 'Extensively worked in a range of database technologies including SQL and noSQL DB', '3+ years in AWS environment', 'Ecommerce industry experience', 'Senior Data Engineer$130,000 - $150,000 / year, Full-timeSkills and Experience:\xa03-5 years of experience with highly scalable distributed systems using open source toolsIn-depth knowledge of the software development lifecycleAn ability to demonstrate software engineering fundamentals such as OO design, unit testing, code reuse, code reviewsExtensive knowledge in different programming and scripting languages such as Java, C++, PHP, Ruby, Python, etc.Familiarity with one of more big data infrastructures such as Hbase, Hadoop, Kafka, Cassandra, or RDBMSData ETL and data modelingModern build tools such as Maven, Jenkins, Github', '3-5 years of experience with highly scalable distributed systems using open source tools', 'In-depth knowledge of the software development lifecycle', 'An ability to demonstrate software engineering fundamentals such as OO design, unit testing, code reuse, code reviews', 'Extensive knowledge in different programming and scripting languages such as Java, C++, PHP, Ruby, Python, etc.', 'Familiarity with one of more big data infrastructures such as Hbase, Hadoop, Kafka, Cassandra, or RDBMS', 'Data ETL and data modeling', 'Modern build tools such as Maven, Jenkins, Github', 'Interviews on the spot', 'Tuesday, September 29, 20208:30 AM - 12:30 PM US/Central', ""Interviewing via webYou'll receive an email on how to connect."", '44 slots left', 'United States+1', 'United Kingdom+44', '', 'Afghanistan (\u202bافغانستان\u202c\u200e)+93', 'Albania (Shqipëri)+355', 'Algeria (\u202bالجزائر\u202c\u200e)+213', 'American Samoa+1684', 'Andorra+376', 'Angola+244', 'Anguilla+1264', 'Antigua and Barbuda+1268', 'Argentina+54', 'Armenia (Հայաստան)+374', 'Aruba+297', 'Australia+61', 'Austria (Österreich)+43', 'Azerbaijan (Azərbaycan)+994', 'Bahamas+1242', 'Bahrain (\u202bالبحرين\u202c\u200e)+973', 'Bangladesh (বাংলাদেশ)+880', 'Barbados+1246', 'Belarus (Беларусь)+375', 'Belgium (België)+32', 'Belize+501', 'Benin (Bénin)+229', 'Bermuda+1441', 'Bhutan (འབྲུག)+975', 'Bolivia+591', 'Bosnia and Herzegovina (Босна и Херцеговина)+387', 'Botswana+267', 'Brazil (Brasil)+55', 'British Indian Ocean Territory+246', 'British Virgin Islands+1284', 'Brunei+673', 'Bulgaria (България)+359', 'Burkina Faso+226', 'Burundi (Uburundi)+257', 'Cambodia (កម្ពុជា)+855', 'Cameroon (Cameroun)+237', 'Canada+1', 'Cape Verde (Kabu Verdi)+238', 'Caribbean Netherlands+599', 'Cayman Islands+1345', 'Central African Republic (République centrafricaine)+236', 'Chad (Tchad)+235', 'Chile+56', 'China (中国)+86', 'Christmas Island+61', 'Cocos (Keeling) Islands+61', 'Colombia+57', 'Comoros (\u202bجزر القمر\u202c\u200e)+269', 'Congo (DRC) (Jamhuri ya Kidemokrasia ya Kongo)+243', 'Congo (Republic) (Congo-Brazzaville)+242', 'Cook Islands+682', 'Costa Rica+506', 'Côte d’Ivoire+225', 'Croatia (Hrvatska)+385', 'Cuba+53', 'Curaçao+599', 'Cyprus (Κύπρος)+357', 'Czech Republic (Česká republika)+420', 'Denmark (Danmark)+45', 'Djibouti+253', 'Dominica+1767', 'Dominican Republic (República Dominicana)+1', 'Ecuador+593', 'Egypt (\u202bمصر\u202c\u200e)+20', 'El Salvador+503', 'Equatorial Guinea (Guinea Ecuatorial)+240', 'Eritrea+291', 'Estonia (Eesti)+372', 'Ethiopia+251', 'Falkland Islands (Islas Malvinas)+500', 'Faroe Islands (Føroyar)+298', 'Fiji+679', 'Finland (Suomi)+358', 'France+33', 'French Guiana (Guyane française)+594', 'French Polynesia (Polynésie française)+689', 'Gabon+241', 'Gambia+220', 'Georgia (საქართველო)+995', 'Germany (Deutschland)+49', 'Ghana (Gaana)+233', 'Gibraltar+350', 'Greece (Ελλάδα)+30', 'Greenland (Kalaallit Nunaat)+299', 'Grenada+1473', 'Guadeloupe+590', 'Guam+1671', 'Guatemala+502', 'Guernsey+44', 'Guinea (Guinée)+224', 'Guinea-Bissau (Guiné Bissau)+245', 'Guyana+592', 'Haiti+509', 'Honduras+504', 'Hong Kong (香港)+852', 'Hungary (Magyarország)+36', 'Iceland (Ísland)+354', 'India (भारत)+91', 'Indonesia+62', 'Iran (\u202bایران\u202c\u200e)+98', 'Iraq (\u202bالعراق\u202c\u200e)+964', 'Ireland+353', 'Isle of Man+44', 'Israel (\u202bישראל\u202c\u200e)+972', 'Italy (Italia)+39', 'Jamaica+1', 'Japan (日本)+81', 'Jersey+44', 'Jordan (\u202bالأردن\u202c\u200e)+962', 'Kazakhstan (Казахстан)+7', 'Kenya+254', 'Kiribati+686', 'Kosovo+383', 'Kuwait (\u202bالكويت\u202c\u200e)+965', 'Kyrgyzstan (Кыргызстан)+996', 'Laos (ລາວ)+856', 'Latvia (Latvija)+371', 'Lebanon (\u202bلبنان\u202c\u200e)+961', 'Lesotho+266', 'Liberia+231', 'Libya (\u202bليبيا\u202c\u200e)+218', 'Liechtenstein+423', 'Lithuania (Lietuva)+370', 'Luxembourg+352', 'Macau (澳門)+853', 'Macedonia (FYROM) (Македонија)+389', 'Madagascar (Madagasikara)+261', 'Malawi+265', 'Malaysia+60', 'Maldives+960', 'Mali+223', 'Malta+356', 'Marshall Islands+692', 'Martinique+596', 'Mauritania (\u202bموريتانيا\u202c\u200e)+222', 'Mauritius (Moris)+230', 'Mayotte+262', 'Mexico (México)+52', 'Micronesia+691', 'Moldova (Republica Moldova)+373', 'Monaco+377', 'Mongolia (Монгол)+976', 'Montenegro (Crna Gora)+382', 'Montserrat+1664', 'Morocco (\u202bالمغرب\u202c\u200e)+212', 'Mozambique (Moçambique)+258', 'Myanmar (Burma) (မြန်မာ)+95', 'Namibia (Namibië)+264', 'Nauru+674', 'Nepal (नेपाल)+977', 'Netherlands (Nederland)+31', 'New Caledonia (Nouvelle-Calédonie)+687', 'New Zealand+64', 'Nicaragua+505', 'Niger (Nijar)+227', 'Nigeria+234', 'Niue+683', 'Norfolk Island+672', 'North Korea (조선 민주주의 인민 공화국)+850', 'Northern Mariana Islands+1670', 'Norway (Norge)+47', 'Oman (\u202bعُمان\u202c\u200e)+968', 'Pakistan (\u202bپاکستان\u202c\u200e)+92', 'Palau+680', 'Palestine (\u202bفلسطين\u202c\u200e)+970', 'Panama (Panamá)+507', 'Papua New Guinea+675', 'Paraguay+595', 'Peru (Perú)+51', 'Philippines+63', 'Poland (Polska)+48', 'Portugal+351', 'Puerto Rico+1', 'Qatar (\u202bقطر\u202c\u200e)+974', 'Réunion (La Réunion)+262', 'Romania (România)+40', 'Russia (Россия)+7', 'Rwanda+250', 'Saint Barthélemy+590', 'Saint Helena+290', 'Saint Kitts and Nevis+1869', 'Saint Lucia+1758', 'Saint Martin (Saint-Martin (partie française))+590', 'Saint Pierre and Miquelon (Saint-Pierre-et-Miquelon)+508', 'Saint Vincent and the Grenadines+1784', 'Samoa+685', 'San Marino+378', 'São Tomé and Príncipe (São Tomé e Príncipe)+239', 'Saudi Arabia (\u202bالمملكة العربية السعودية\u202c\u200e)+966', 'Senegal (Sénégal)+221', 'Serbia (Србија)+381', 'Seychelles+248', 'Sierra Leone+232', 'Singapore+65', 'Sint Maarten+1721', 'Slovakia (Slovensko)+421', 'Slovenia (Slovenija)+386', 'Solomon Islands+677', 'Somalia (Soomaaliya)+252', 'South Africa+27', 'South Korea (대한민국)+82', 'South Sudan (\u202bجنوب السودان\u202c\u200e)+211', 'Spain (España)+34', 'Sri Lanka (ශ්\u200dරී ලංකාව)+94', 'Sudan (\u202bالسودان\u202c\u200e)+249', 'Suriname+597', 'Svalbard and Jan Mayen+47', 'Swaziland+268', 'Sweden (Sverige)+46', 'Switzerland (Schweiz)+41', 'Syria (\u202bسوريا\u202c\u200e)+963', 'Taiwan (台灣)+886', 'Tajikistan+992', 'Tanzania+255', 'Thailand (ไทย)+66', 'Timor-Leste+670', 'Togo+228', 'Tokelau+690', 'Tonga+676', 'Trinidad and Tobago+1868', 'Tunisia (\u202bتونس\u202c\u200e)+216', 'Turkey (Türkiye)+90', 'Turkmenistan+993', 'Turks and Caicos Islands+1649', 'Tuvalu+688', 'U.S. Virgin Islands+1340', 'Uganda+256', 'Ukraine (Україна)+380', 'United Arab Emirates (\u202bالإمارات العربية المتحدة\u202c\u200e)+971', 'United Kingdom+44', 'United States+1', 'Uruguay+598', 'Uzbekistan (Oʻzbekiston)+998', 'Vanuatu+678', 'Vatican City (Città del Vaticano)+39', 'Venezuela+58', 'Vietnam (Việt Nam)+84', 'Wallis and Futuna (Wallis-et-Futuna)+681', 'Western Sahara (\u202bالصحراء الغربية\u202c\u200e)+212', 'Yemen (\u202bاليمن\u202c\u200e)+967', 'Zambia+260', 'Zimbabwe+263', 'Åland Islands+358']",2020-09-24 14:05:17
2021 Early Talent: Technology Rotational Associate (Infrastructure and SW Engineer),TIAA,3.7 out of 5,United States,"['Up to four professional experiences on a technology team', 'Unique networking opportunities and access to IT Senior Leadership', 'Ongoing personal and professional development opportunities', 'Weeks of intensive technical and behavioral based training utilizing technologies vital to the industry and organization', ""Currently pursuing a Bachelor’s or Master's degree"", 'Graduation date between December 2020 and June 2021', 'Minimum Overall GPA of 3.0 or better', 'Technical skills (e.g. programming, networking, etc.) and the intellectual curiosity to learn and acquire more in-depth expertise', ""Currently pursuing a Bachelor’s or Master's degree in Computer Science, Information Technology, Mathematics, Data Analytics, Data Science, Cyber-Security, Engineering and/or Operations Management, and any other STEM"", 'Internship experience is a plus', 'Leadership skills and a commitment to shared success (i.e. works well in teams)', 'Technical skills (AWS, Java, Angular, Networking, Mobile OS)', 'Strong verbal and written communication skills', 'Adapts and embraces change – especially in exciting and fast paced environments', 'High motivation', 'Self-starter', 'Desire to continuously learn', 'Demonstrated ability to prioritize tasks and deliver on commitment', 'Minimum of 2 years work, or academic experience in using Microsoft Office products or similar completive products (Word, PowerPoint, Excel, Outlook)']",2020-09-24 14:05:17
Data Solutions Engineer,Southeastern University,4.2 out of 5,"Lakeland, FL 33801",[],2020-09-24 14:05:17
Data Engineer- Remote,Trianz,3.4 out of 5,"Austin, TX 78728","['5+ years of SQL experience.', '3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, digdag.io, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M).', '3+ years’ experience with Data Modeling.', 'Experience analyzing data to discover opportunities and address gaps.', '5+ years’ experience in custom ETL design, implementation and maintenance.', 'Experience working with cloud or on-prem Big Data/MPP analytics platform(i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar).']",2020-09-24 14:05:17
Data Center Operations Engineer,Internap,3 out of 5,"Chandler, AZ 85224",[],2020-09-24 14:05:17
Data Science (Telematics) Intern,Terex Corporation,3.6 out of 5,"Redmond, WA 98052","['Partner with team members from global locations - more than 50 manufacturing locations worldwide.', 'Intern/Co-op opportunities can lead to full time careers', 'Work with the software, product management, product support, and engineering teams to identify areas for leveraging machine and company data to drive business solutions internally and for our customers', 'Create data visualizations', 'Understand Genie products and the data they produce', 'Develop custom data models and algorithms to apply to internal and external data sources', 'Provide insight and input into future Genie machine data projects', 'Develop the future Genie telematics analytics strategy', 'Work together to learn cross-functional processes and solve problems with IoT data', 'Pursuing a master’s degree in STEM or alternative degree combined with comparable experience', 'Experience using R, Python, or other software / language to manipulate and extract insights from data', 'Experience querying relational databases (MySQL, SQL Server, Etc.)', 'Familiarization with RShiny and other data visualization tools', 'Strong analytics and critical thinking skills', 'Willingness to learn Genie products and processes', 'Strong written and verbal communication skills for presenting complex concepts to senior managers', 'Experience / relevant coursework with a cloud computing environment such as AWS, Google Cloud Platform, or Microsoft Azure', 'Experience creating and deploying advanced machine learning and reliability algorithms', 'Desire to work with IoT data and product engineers in order to develop end-to-end data science solutions']",2020-09-24 14:05:17
Data Engineer,Deloitte,4 out of 5,"Lake Mary, FL","['Identify opportunities for efficiencies in work process and innovative approaches to completing scope of work', 'Conduct relevant research, data analysis, and create reports', 'Maintain responsibility for completion and accuracy of work products', 'Think creatively and collaborate with team members', 'Maintain database backup and recovery infrastructure', 'Ensure database integrity, stability, security and system availability', 'Collaborate with applications development team, network team and systems programmers', 'Assist developers with writing and tuning SQL and stored procedures', 'Bachelors Degree', '5+ relevant experience within data science or analysis', 'Experience with programming languages such as Python, R, and VBA', 'Experience with data visualization tools, such as Tableau, Qlik, PowerBI, d3.js and other web application technologies, or equivalent', 'Experience with SQL and NoSQL database technologies such as SQL Server, Oracle SQL', 'Proficiency with data extraction, transformation, and loading to support advanced analytics', 'Experience with a wide range of analytics techniques, such as statistics, machine learning, natural language processing, optimization, simulation, or closely related techniques', 'Familiarity with JSON and XML data formats', 'Performance tuning including queries, tables, index design, code redesign and system layout', 'Strategic road mapping of database environment (warehousing, infrastructure)', 'High-performing team player who believes that cross-functional teams are greater than the sum of its parts', 'Ability to maintain the required clearance for this role', 'Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future', 'Previous government consulting experience']",2020-09-24 14:05:17
"Computer Engineer, AST, Flight Data Systems",US National Aeronautics and Space Administration,4.4 out of 5,"Greenbelt, MD","['Serves as a subject-matter expert (SME) that demonstrates technical leadership in the development of critical electronics hardware for flight data systems for spacecraft, instruments, and payloads.', 'Provides expertise spanning design, verification, and analysis that covers digital and analog electronics and knowledge of key component technologies such as processors or programmable logic devices such as Field Programmable Gate Arrays (FPGA).', 'Explores and reports on new design or technology developments that are key to the organization and that help guide insertion efforts.', 'Serves as an SME on design review panels or unusual and complex troubleshooting efforts, conducts knowledge sharing, and improves the availability and widespread use of design resources (such as automated design tools).', 'Manages and performs design activities, as assigned, to continually maintain expertise in the state-of-the-art. Assignments span programs covering both flight project and technology development efforts.', 'Manages interdisciplinary teams in the aforementioned efforts and provides guidance to technical managers in meeting the requirements of these programs.', 'Serves as task manager in overseeing contractors who perform key support activities.', 'Serves as a key decision maker or stakeholder in a proactive role that pursues and promotes new technologies or implements emerging technologies for flight data systems applications.', 'Submits proposals to secure technology development funding from programs such as IRADs (Internal Research and Development), manages (including budgets and schedules), and reports outcomes in the execution of such development efforts.', 'Identifies, develops, and facilitates the transfer of technology developed from research and development or project work resulting from the accomplishment of assigned duties or responsibilities.', 'Identifies and/or leads the implementation of engineering process or procedure improvements or breakthroughs that benefits mission, program, or infrastructure objectives through improved performance, efficiency, budget, or schedule.', 'Serves as an SME consultant on a broad range of subjects, including initiatives, and proposals. Such consultation is provided to all levels of management at the Center.', 'Establishes liaisons with program or technology managers and work closely with their representatives to ensure that technical needs are met. Conducts trade studies, research, and/or analysis to establish and support findings.', 'Duties described above are at the full-performance level. Duties assigned at a lower grade level will be of more limited scope, performed with less independence and limited complexity; duties will be commensurate with the grade of selected employee.', 'Job family (Series)0854 Computer Engineering', ""RequirementsRequirementsConditions of EmploymentThis position is open to U.S. citizens, nationals or those who owe allegiance to the U.S.Position subject to pre-employment background investigation.A one-year probationary period may be required.QualificationsIn addition to the Basic Education Requirements, you must have one year of specialized experience equivalent to the next lower grade level, which has equipped you with the particular competencies needed to successfully perform the duties of the position described above.To qualify for the GS-13:Specialized experience equivalent to the next lower grade level (GS-12) includes performing duties such as; performing design, verification, and analysis of digital and analog electronics to include key component technologies such as processors or programmable logic devices such as FPGA.To qualify for the GS-14:Specialized experience equivalent to the next lower grade level (GS-13) includes performing duties such as; providing technical leadership in the development of critical electronics hardware for flight data systems for spacecraft, instruments, and payloads.Your resume must include a clear and detailed narrative description, in your own words, of how you meet the required specialized experience. Experience statements copied from a position description, vacancy announcement or other reference material constitutes plagiarism and may result in disqualification and losing consideration for the job.Please spell out all acronyms.EducationBasic Education Requirement: A bachelor's degree from an accredited college or university with major study in Aeronautical Engineering, Aeronautics, Aerospace Engineering, Architecture, Astronautical Engineering, Astronautics, Astronomy, Astrophysics, Biomedical Engineering, Ceramic Engineering, Ceramics, Chemical Engineering, Chemistry, Civil Engineering, Computer Engineering, Computer Science*, Life Science, Earth and Planetary Science, Electrical Engineering, Electronics Engineering, Geology, Geophysics, Industrial Engineering, Materials Engineering, Materials Science, Mathematics (Pure or Applied), Applied Mechanics, Engineering Mechanics, Mechanical Engineering, Metallurgical Engineering, Metallurgy, Meteorology, Nuclear Engineering, Nuclear Engineering Physics, Oceanography, Optical Engineering, Physics, Applied Physics, Engineering Physics, Space Science, Structural Engineering, Welding Engineering or other appropriate physical science or engineering field.Degrees in engineering technology are not considered to be qualifying for this position.Note: Curriculum must include 30 semester hours of course work in a combination of mathematics, statistics and computer science that provided in-depth knowledge of the following: (1) theoretical foundations and practical applications of computer science, including digital computer system architecture and system software organization, the representation and transformation of information structures and the theoretical models for such representations and transformations; and (2) essential mathematical and statistical techniques. Of the 30 semester hours, 15 must be in any combination of statistics and mathematics which includes differential and integral calculus.U.S. Engineering degrees must have been awarded from a college or university school of engineering with at least one curriculum accredited by the Engineering Accreditation Commission (EAC) of the Accreditation Board for Engineering and Technology (ABET). To find out if a degree meets this requirement, go to http://www.abet.org.Foreign Engineering degrees must be recognized by a Mutual Recognition Agreement (MRA), often known as accords These are non-governmental agreements among organizations that accredit academic degree programs. MRAs recognize the substantial equivalence of mature accreditation systems and programs accredited by signatory organizations within their jurisdictions. For a listing of Signatories, please visit, https://www.abet.org/global-presence/mutual-recognition-agreements/is-your-program-recognized/.Science and other related degrees must have been awarded from colleges or universities that are accredited by recognized accrediting organizations. For a list of schools that meet this criteria, go to http://ope.ed.gov/accreditation/.If you are using education completed in foreign colleges or universities to meet the qualification requirements, you must show that the education credentials have been evaluated by a private organization that specializes in interpretation of foreign education programs. These education credentials must be deemed equivalent to that gained in an accredited U.S. education program; or full credit has been given for the courses at a U.S. accredited college or university. For further information, visit: https://www2.ed.gov/about/offices/list/ous/international/usnei/us/edlite-visitus-forrecog.html.All degrees must have been received in the year of, or any year subsequent to the original date of accreditation.Official transcripts will be required at the time of selection to verify that you meet the educational requirement or substitution.Additional informationIf you have special priority selection rights under the Agency Career Transition Assistance Program (CTAP) or the Interagency Career Transition Assistance Program (ICTAP), you must:Indicate your eligibility when applying for a position. The USAJOBS resume asks you to identify your ICTAP eligibility; the NASA Supplemental Information asks you to identify your CTAP eligibility.Be well qualified for this position to receive consideration. See 'How You Will Be Evaluated' for NASA's definition of well qualified.Be prepared to submit proof that you meet the requirements for CTAP/ICTAP if you are selected for the position. This includes copies of your agency notice, most recent Performance Rating and most recent Notification of Personnel Action (SF-50) noting current position, grade level, and duty location.Identification of promotion potential in this position does not constitute a commitment or an obligation on the part of management to promote the employee. Promotion will depend upon administrative approval and the continuing need for an actual assignment and performance of higher level duties.As identical vacancies are identified, additional selections may be made.You must meet qualifications requirements by the closing date of this announcement.How You Will Be EvaluatedYou will be evaluated for this job based on how well you meet the qualifications above.This position is announced under Direct Hire authority. A Human Resources Specialist will review your resume to determine if you meet the qualifications and eligibility requirements as listed in 'Requirements'.CTAP and ICTAP candidates will be assessed using NASA STARS, an automated system that matches the competencies extracted from your resume to the competencies identified by the selecting official for the position. Based on the competencies you match, you are placed in one of three categories identified as 90, 80, or 70 point quality categories, which are defined as:90 pt. Category - Tentatively meets (until subsequent confirmation upon referral) the basic qualification requirements identified in the vacancy announcement and has experience in the same or similar job that has demonstrated superior proficiency in the primary requirements of the position.80 pt. Category - Tentatively meets (until subsequent confirmation upon referral) the basic qualification requirements identified in the vacancy announcement and demonstrates satisfactory proficiency in the primary requirements of the position.70 pt. Category - Fails to meet criteria described in the 80 pt. category.For the purpose of the CTAP and ICTAP, candidates rated in the top quality (90 pt.) category are considered well-qualified.Background checks and security clearanceSecurity clearanceNot RequiredDrug test requiredNo"", 'This position is open to U.S. citizens, nationals or those who owe allegiance to the U.S.', 'Position subject to pre-employment background investigation.', 'A one-year probationary period may be required.', 'Note: Curriculum must include 30 semester hours of course work in a combination of mathematics, statistics and computer science that provided in-depth knowledge of the following: (1) theoretical foundations and practical applications of computer science, including digital computer system architecture and system software organization, the representation and transformation of information structures and the theoretical models for such representations and transformations; and (2) essential mathematical and statistical techniques. Of the 30 semester hours, 15 must be in any combination of statistics and mathematics which includes differential and integral calculus.', ""Required DocumentsRequired DocumentsNASA's application process has been specifically developed to ensure that we only ask you for the information we absolutely need to evaluate your qualifications and eligibility. In order to apply for this position, you only need to submit your resume and answer the screening questions and supplemental information. No additional documentation is accepted at the time of application. (For example you need not submit narrative 'KSA' statements; they are not required and will not be evaluated.) In this way we allow you to focus on preparing a resume that best describes your background and abilities. For assistance in preparing your resume, consult the Applicant Guide. Nothing further is required until requested by the Human Resources Office. At that point, we may ask you to submit documentation to support statements made in your resume. For example, we may ask you to provide academic transcripts or proof of Federal employment status. If you fail to provide the required documents within the stated time period, we may withdraw a job offer and/or remove you from further consideration.If you are relying on your education to meet qualification requirements:Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education.Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating."", 'BenefitsBenefitsA career with the U.S. Government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Learn more about federal benefits.Review our benefitsEligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time, or intermittent. Contact the hiring agency for more information on the specific benefits offered.', 'The publicU.S. citizens, nationals or those who owe allegiance to the U.S.']",2020-09-24 14:05:17
Software Engineer,Alaska Airlines,3.9 out of 5,"Seattle, WA 98194",[],2020-09-24 14:05:17
Senior Data Engineer (Python)-Remote,SemanticBits LLC,4.2 out of 5,Remote,"['Competitive salary', 'Three weeks of PTO', 'Ten paid holiday days', 'Comprehensive health benefits (medical with HSA option, dental, and vision)', '401k retirement plan with matching benefit', '100% paid short-term and long-term disability', '100% paid life insurance', 'Flexible Spending Accounts (FSA)', 'Casual working environment', 'Python, Postgres, Redshift, Apache NiFi, Airflow, Express, AWS EMR, Looker, Mongo, general working with BI tools & AWS resources.', 'Strong knowledge of computer science fundamentals: object-oriented design and programming, data structures, algorithms, databases', 'Demonstrable experience engineering scalable data processing pipelines and clusters', 'Demonstrable expertise with Python and Spark and wrangling of various data formats - CSV, XML, JSON.', 'Experience with any of the following technologies is highly desirable: Postgres, Redshift, Apache NiFi, Airflow, Node.js, Express, AWS EMR, Looker, Mongo', ""Bachelor's degree required, strong preference for Computer Science field of study"", 'A minimum of 5 years of related professional experience', 'Experience with Agile methodology, using test-driven development.', 'Excellent command of written and spoken English', 'Self-driven problem solver', 'Candidate must reside in the United States', 'Flexible and willing to accept a change in priorities as necessary', 'Experience working in the healthcare industry with PHI/PII', 'Federal Government contracting work experience', 'Prior experience working remotely full-time', 'This position is to be performed remotely from an individual’s home office and involves sedentary work. Employees in this role can be expected to exert up to 10 pounds of force on occasion in order to lift, carry, push, pull or otherwise move standard electronic equipment. Employees are expected to make decisions in a timely manner and display emotional intelligence during occasional stressful situations.']",2020-09-24 14:05:17
Data Visualization Engineer,"Marsh & McLennan Companies, Inc.",3.7 out of 5,"Hoboken, NJ 07030","['Recognition – global career advancement opportunities', 'Visibility – work with HR leadership in support of our enterprise People strategy', 'Career Growth – excellent performance is recognized by career mobility', 'Developmental Opportunities – grow in a culture focused on training and coaching', 'Work/Life Balance – have flexibility in meeting your professional and personal commitments', 'Culture – work in a diverse culture and a global team', 'Benefits - competitive salaries and comprehensive benefits and programs including: health and welfare, tuition assistance, 401K, employee assistance program, domestic partnership benefits, career mobility, employee network groups, volunteer opportunities, and other programs', 'Partner with HR Leaders, HR Partners, data engineers and scientists to understand the potential value of HR data sets, the most relevant presentation of the data, and the interactions required to explore the meaning behind the data', 'Design visualizations and interactive user interfaces in Power BI/ Tableau or similar visualization technologies to present complex data in an easily digestible format', 'Understand and emphasis on visual best practices from choosing the best charts to the use of colors and formatting', 'Bring your passion for analyzing complex datasets and converting them into information, which drives people decisions', 'Work with data engineers to tackle technical challenges associated with building fast and interactive visualizations on large datasets', 'Maintain best in class infrastructure through evaluations and proof of concepts with cutting-edge of visualization technology and frameworks', 'Take on a number of new project initiatives as an individual contributor that have the potential to grow into more sizable engineering efforts in the future', 'BS in Engineering', 'Statistical background', '4 -5 years of data visualization Engineering experience', 'Passion about data analytics', 'Power BI/ Tableau or similar visualization technologies', 'Willingness to learn new technologies in evolving digital space', 'Genuine passion about data', 'Agnostic mindset and willingness to work with any future tool', 'HRIS experience']",2020-09-24 14:05:17
Data Engineer,Projas Technologies,N/A,"Cupertino, CA","['Pay:', '$50.00 - $61.00 per hour', 'Monday to Friday', 'Fully Remote']",2020-09-24 14:05:17
Industrial/Manufacturing Engineer,"Bear Archery, Inc. dba Escalade Sports",N/A,"Gainesville, FL 32608","['Plans utilization of facilities, equipment, materials, and personnel to improve efficiency of manufacturing and other operations.', 'Studies functional statements and project information to determine functions and responsibilities of workers and work units and to identify areas of duplication. Project Management.', 'Establishes work measurement programs and analyzes work samples to develop standards for labor utilization. Resolve questions relating to job utilization and performance.', 'Analyzes work force utilization, facility layout, and operational data, such as production costs, process flow charts, and production schedules, to determine efficient utilization of workers, equipment and materials.', 'Analyzes and recommends improvements to station and process ergonomics.', 'Works on studies relating to work method and establishes a format to be used in the development of standard data.', 'Recommends methods for improving worker efficiency and reducing waste of materials and utilities, such as restructuring job duties, reorganizing work flow, relocating work stations and equipment, and purchase of equipment.', 'Confers with management and engineering staff to implement plans and recommendations. Recommend methods for improving utilization of personnel, material, and utilities.', 'Analyze statistical data and product specifications to determine standards and establish quality and reliability objectives of finished product.', 'Develop manufacturing methods, labor utilization standards, and cost analysis systems to promote efficient staff and facility utilization. Process development and improvement,', 'Plan and establish sequence of operations to fabricate and assemble parts or products and to promote efficient utilization.', 'Apply statistical methods and perform mathematical calculations to determine manufacturing processes, staff requirements, and production standards.', 'Coordinate quality control objectives and activities to resolve production problems, maximize product reliability, and minimize cost.', 'Confer with vendors, staff, and management personnel regarding purchases, procedures, product specifications, manufacturing capabilities, and project status.', 'Draft and design layout of equipment, materials, and workspace to illustrate maximum efficiency using drafting tools and computer.', 'Review engineering specifications, orders, and related information to obtain knowledge of manufacturing methods, procedures, and activities.', 'Communicate with management and user personnel to develop production and design standards.', 'Designs Jigs, Fixtures and machinery.', 'Conducts and analyzes time studies.', 'Review orders, engineering specifications, production schedules and related information to get knowledge about the manufacturing activities, procedures and methods.', 'Formulate designs, sampling procedures and develop instructions and forms for evaluating, recording and reporting reliability, as well as, quality data.', '8 hour shift', 'Day shift', 'Monday to Friday', 'Industrial Engineering: 3 years (Required)', ""Bachelor's (Required)"", 'Gainesville, FL 32608 (Required)', 'United States (Required)', 'www.beararchery.com', 'Only full-time employees eligible', 'No']",2020-09-24 14:05:59
Data Engineer,Direct Agents,3.1 out of 5,"Culver City, CA 90232","['Create automated data systems using APIs, Selenium, web scrapers, etc.', 'Set up and maintain database ecosystems', 'Build advanced data models to provide granular and predictive insights', 'Develop AI systems to perform advanced operations based upon data inputs', 'Visualize data in an easily digestible format', 'Supplying internal teams with datasets to be used for strategic optimizations', 'Maintain data integrity and work with teams to troubleshoot discrepancies', 'Stay abreast of latest industry topics, trends, news, methodologies, and tools', ""Bachelor's or Master’s Degree in Mathematics/Computer Science/Engineering/Finance or related field"", 'Advanced Python skillset', 'Strong Statistical and/or Machine Learning background', 'Strong knowledge of database structures and SQL', 'Excellent quantitative skills and attention to detail', 'Experience using Power BI data visualization software is a plus', 'Highly motivated to identify and develop solutions to complex problems', 'Strong time management skills – ability to prioritize and meet deadlines', 'Diligent work ethic. Must be self-motivated and able to take the initiative to get the job done', 'Digital Marketing experience is preferred but definitely not required', 'Competitive pay & health benefits.', 'Weekly social, wellness, and team building events', 'Access to health benefits and many other perks like One Medical', 'An amazing values based company culture ripe with collaboration, encouragement and camaraderie', 'Monthly education and training in digital advertising', 'Access to the best in class marketing technology and methodology', 'Ability to innovate and make an impact with your ideas in real-time', 'A fast tracked path to growth based on what you put into the role and your passion for learning in the company']",2020-09-24 14:05:59
Sr. Data Engineer,Atom Tickets,N/A,"Santa Monica, CA 90404","['Create and maintain optimal data pipeline architecture.', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies.', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Experience building and optimizing data pipelines, architectures and data sets.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with unstructured datasets.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.', 'Strong project management and organizational skills.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a BS degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:', 'Experience with big data tools: Hadoop, Spark, Kafka etc.', 'Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.', 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.', 'Experience with AWS cloud services: EC2, EMR, RDS, Redshift', 'Experience with stream-processing systems: Storm, Spark-Streaming, etc.', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.']",2020-09-24 14:05:59
Data Engineer,Proactive MD,3.3 out of 5,"Mauldin, SC","['Competitive wages with opportunities for performance-based increases', 'A chance to be part of a truly innovative healthcare company that believe in putting the patient first.', 'Research and deploy innovative statistical and scientific techniques to Proactive MD datasets.', 'Apply machine learning and deep learning methods (e.g. regression, neural networks, etc.) to enhance Proactive MD’s predictive analytics capabilities.', 'Develop data models to improve analytic performance and unlock new data insights.', 'Build and maintain data pipelines for the extract, transformation, and load of clinical data, medical and pharmaceutical claims, and other key data feeds.', 'Deliver and present analyses to internal and external customers as required.', 'Perform other duties as assigned by EVP, Health Data Science and/or executive leadership.', 'Act as a champion for our ""patient promise"" and mission, vision, and values and partner across the company to drive a high-performance work environment.', 'Bachelor’s degree or higher from an institution recognized by the Council for Higher Education Accreditation, with relevant coursework in advanced statistical methods, computer science, and mathematics.', 'Experience using data science and machine learning packages (e.g. Tensorflow, pandas, Healthcare.ai)', 'Experience using SQL for data management and query. Experience building or maintaining data pipelines with Microsoft SQL Server / Azure preferred.', 'Excellent verbal and written communication skills.', 'Excellent interpersonal, negotiation, and conflict resolution skills.', 'Excellent time management skills with the proven ability to meet deadlines.', 'Strong analytical and problem-solving skills.', 'Expert proficiency with Microsoft applications, including intermediate-to-advanced Microsoft Excel and Microsoft Access skills.', 'Proficiency with advanced statistical analysis packages (e.g. SAS, SPSS, or R)']",2020-09-24 14:05:59
Staff Software Engineer,TrueAccord,3.6 out of 5,Remote,"['Leading the engineering efforts on our new Financial Services offering', 'Working with other teams to integrate Financial Services into existing products', 'Building the framework and methodologies needed to create an engineering team around Financial Services', 'Bringing a strong, opinionated technical mindset into the role', 'Paving the way for more team members, then hire them.', '5+ years of experience in Software Engineering', 'Experience creating successful products from scratch.', 'Worked closely with subject matter experts to bring simplified solutions to complex problems.', 'Jumped head first into a mature codebase to find the best solution to integrate new features before.', 'The ability to explain nuanced decisions with clarity, and the ability to help others make the same decisions for the future.']",2020-09-24 14:05:59
Data Engineer (AML/KYC/Sanctions/Fraud Detection Process),Grail Insights,N/A,"San Francisco, CA","['Client Interaction and ManagementUnderstanding the client objectives and managing client expectations on projectsIndependently work with client to scope and deliver on projects as a part of larger teamAs part of a larger team, align requirements on different work streams and tasks assigned by the client', 'Project ManagementMaking significant contributions to the design of the analytical approach and work planBeing responsible for smooth project operations – overall project quality and productivity of teams', '2-4 years of relevant experience as a Data Engineer in payments compliance process- AML/ KYC/ Sanctions/ Fraud detection.', 'Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage etc.) and experience with applications.', 'Knowledge of machine learning techniques (clustering, decision tree learning) is a plus', 'Proficiency in SQL, Python, Tableau', 'Prior experience in tuning Sanctions, AML and RR models is highly preferred', 'Experience in developing dashboards and metrics for payments compliance such as model effectiveness', 'Experience with building and tuning predictive models and system implementation', 'Any experience with Customer Risk Scoring, Customer Risk Rating is a plus', 'Graduate with an engineering degree (preferably Computer Science) or a degree in statistics/math with experience in coding or equivalent', 'Post Graduate with analytical pedigree (preferably Operations Research, Econometrics or MBA equivalent with analytical electives)']",2020-09-24 14:05:59
Data Engineer,Anne Lewis Strategies,N/A,"Washington, DC","['Building data-intensive applications to extract, transform, and load massive data sets from a variety of internal, external, and public data sources;', 'Assembling large and complex data sets that meet project needs;', 'Developing processes for data mining, data modeling, and data production;', 'Using an array of technological languages and tools to connect systems;', 'Working toward constantly improving data reliability and quality;', 'Collaborating with cross-functional teams to support their data infrastructure needs.', 'Experience with one or more key data analytics tools: (Pandas, PySpark)', 'Experience extracting data from public APIs;', 'Ability to build and optimize data pipelines, architectures, and data sets;', 'Experience managing big data resources through Amazon Web Services or another cloud provider;', 'Experience with SQL;', 'Attention to detail;', 'Intellectual curiosity to innovate on ways to solve data management issues;', 'Passion, energy, and excitement for progressive and philanthropic causes and all things digital.', '1-3 years of professional experience;', 'Experience building data-intensive applications that collect data from diverse sources in the service of creating high-performance algorithms and predictive models;', 'Experience deploying deep-learning models;', 'Experience managing data warehouses and/or data lakes;', 'Experience working with cross-functional teams in a dynamic environment.']",2020-09-24 14:05:59
Software Engineer,Dropbox,3.8 out of 5,"Nashville, TN","['You will partner with product managers, designers, and analysts to deeply understand the needs of our users and build a product that serves those needs', 'You will build infrastructure to handle metadata for hundreds of billions of files, hundreds of petabytes of user data, and millions of concurrent connections', 'You will write modular, secure, and well-tested code', 'You will design and build software capable of reaching millions of daily users in Python, React, and Go', 'You will ensure that our development environment is best in class by delivering improvements to internal tooling and direct partnership with our product platform teams', 'You will work closely with customer support to respond quickly to issues for our users and solve those in a permanent and scalable way', 'You will articulate a technical vision for a more enlightened way of working and work with multi-functional partners to deliver that vision', 'BS (or higher, e.g., MS, or PhD) in Computer Science or related technical field involving coding (e.g., physics or mathematics), or equivalent technical experience', '2+ years of work related industry experience', ""A desire to take Dropbox even further. If these large-scale projects resonate, we'd love to learn more about you and find out if we can work together"", '100% company paid individual medical, dental, & vision insurance coverage', '401k + company match', 'Market competitive total compensation package', 'Free Dropbox space for your friends and family', 'Wellness Reimbursement', 'Generous vacation policy', '10 company paid holidays', 'Volunteer time off', 'Company sponsored tech talks (technology and other relevant professional topics)']",2020-09-24 14:05:59
"Data Engineer, Battery Field Performance",Tesla,3.5 out of 5,"Palo Alto, CA","['Design high performance data aggregations in Spark to compute fleet metrics', 'Translate field results to changes in fleet metrics or models. Maintain version control and traceability for the individual models.', 'Schedule jobs in a reliable and traceable manner', 'BS/MS in Computer Science or a similar background with strong software engineering experience', 'Experience with Python, Spark', 'Experience with building high reliability pipelines', 'Experience with a production level scheduler like airflow or equivalent', 'Experience with front end technology like react is a plus']",2020-09-24 14:05:59
Data Center Operations Engineer,DTN,3.1 out of 5,"Omaha, NE 68114","['DTN is a global leader providing insights and analytics to our customers to feed, fuel, and protect the world. We help people make critical business decisions that impact the agriculture, oil and gas, trading, and weather industries.', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Employee discount', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Referral program', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Night shift', 'Windows: 2 years (Required)', 'Linux: 2 years (Required)', 'Associate (Required)', 'Overnight (Required)', 'Temporarily due to COVID-19']",2020-09-24 14:05:59
Data Engineer,Chenega Corporation,3.7 out of 5,"Springfield, VA","['SQL Server Integration Services (SSIS) including UI and custom code features.', 'Write or create stored procedures, SQL scripts, SSIS packages that can be used to:', 'Move data from source databases to target databases', 'Clean / Condition data', 'Convert or transform data', 'Reconcile and confirm converted data', 'Find data errors', 'Validate data to business rules', 'Ability to examine existing ETL scripts and track data back to source', 'SQL Server administration, tuning, and workbench.', 'Work with business experts to understand data and complete data mappings.', 'Focus on the development of extract, transform, and load (ETL) jobs currently using Microsoft SQL, Server, and SSIS.', 'The environment currently supports hundreds of related ETL jobs that move data between 30 different source systems and between multiple classifications.', 'Part of the challenge as a data engineer will be to find scalable and efficient coding solutions that plug into this extensible system in order to add more data to the Enterprise data store.', 'Other duties as assigned', 'Bachelor’s Degree in Statistics, Mathematics, Computer Science or another quantitative field', 'Equivalent years of experience in lieu of degree', '4 years of relevant experience with the following software / tools:', 'Experience with Microsoft SQL', 'Prior experience supporting IC/DoD', 'The existing data warehouse is built on Microsoft SQL hosted on Amazon Web Services (AWS), so experience developing solutions that scale well in these environments is a plus.', 'Active Top-Secret Clearance with ability to obtain SCI', 'Ability to work independently and yet be effective within a team setting', 'Must be capable of managing multiple efforts with time related constraints in a fast-paced contracting environment', 'Demonstrated ability to effectively communicate and collaborate with diverse internal and external stakeholder groups and individuals', 'Friendly presence, helpful attitude, good interpersonal skills, and ability to work well with others.', 'Excellent skills in Microsoft Word, Excel, and other Office applications', 'Proficient with Microsoft Office Applications, and experience working in a home office setting as well as the ability to train end users on frequently asked technical issues.', 'Ability to provide technical assistance and support over the phone; good phone skills, professional demeanor, previous customer service experience strongly desired.', 'While performing the duties of this Job, the employee is regularly required to sit and talk or hear. The employee is frequently required to walk; use hands to finger, handle, or feel and reach with hands and arms. The employee is occasionally required to stand; climb or balance and stoop, kneel, crouch, or crawl. The employee must occasionally lift and/or move up to 25 pounds. Specific vision abilities required by this job include close vision.', 'The employee will normally work in a temperature-controlled office environment, with frequent exposure to electronic office equipment.', 'During visits to areas of operations, may be exposed to extreme cold or hot weather conditions. Is occasionally exposed to fumes or airborne particles, toxic or caustic chemicals, and loud noise.']",2020-09-24 14:05:59
Data Operation Engineer,Intuitive,3.9 out of 5,"Raleigh, NC 27601","['Investigation, documentation and remediation of production data issues (job failures) , end user created incidents, enhancements and system management affecting enterprise data assets and systems within the supported ecosystem.', 'Collaboration with fellow Data Operations Engineers and Management in an onsite-offshore environment and participation in a 24X7 on call rotation.', 'Partner with Finance and Sales teams to understand their data and reporting requirements', 'Communication across several Intuitive business groups and end users.', 'Test, deploy and maintain data integrations, ETL processes, API’s and analytics solutions within our environment consisting of MS SQL Server, Snowflake, SAP, Salesforce, Cloud sources.', 'Providing analysis to managers on improvement opportunities for the business process by answering “Why” and “What if” questions', 'Creation of foundational analytics models that ensure the organizations clear and consistent data health and operation', 'Collaboration with management on ways to drive efficiencies and optimize value while effectively maintaining quality of services', 'Guides the business (quarterly/monthly) review process(s) while ensuring continuous improvement efforts through data and analysis', 'Closely partners with Enterprise Analytics Solution Architects and Sales franchise leads to create scalable and sustainable data solutions to be delivered in a repeatable manner', 'Three years Business Intelligence /Data Warehouse implementation experience with a Master’s Degree OR five years Business Intelligence/Data warehouse implementation experience with Bachelor’s degree.', '3+ years of experience in ETL development tools, preferably with knowledge of Snowflake, Python, Airflow, SAP Data Services, and Microsoft Integration Services (SSIS).', 'Minimum of one year of hands-on experience with building semantic-layer business intelligence solutions including metrics, dashboards and data visualization', 'Excellent SQL skills required for both troubleshooting, optimizing and to providing support of the Data warehouse/BI environment', 'Ideal candidate would have Python/R development experience as well as experience troubleshooting Machine Learning models.', 'Excellent written and verbal communication skills with the demonstrated ability to work across levels', 'Experience with and knowledge of SAP ecosystem or similar ERP ecosystems.', 'Experience with ticket management tools like ServiceNow or Jira.', 'Experience with code version control and collaboration platforms like GitHub.', 'Excellent understanding of Data Modeling and Data Warehouse implementation, management, and performance tuning.', 'Knowledge on reporting and visualization tools like Tableau', 'Strong experience with performance and scalability design and testing.', 'Experience creating test plans, testing and resolving data discrepancies', 'Strong sense of customer service for both internal and external customers.', 'Ability to manage multiple, conflicting, high priority requests.', 'Ability to venture into new functional/technology areas and learn on the fly.', 'Needs to have a strong interest in the healthcare area, specifically surgical and hospital space.', 'Experience with Cloud Analytics Platforms (MS Azure, AWS, Snowflake or GCP)']",2020-09-24 14:05:59
Data Center Infrastructure Space & Planning Engineer,CLS Bank International,2.8 out of 5,"Vienna, VA","['Effective skill exercising initiative and using good judgment to make sound decisions', 'Effective skill in producing desired results and achieving goals and objectives', 'Effective skill supporting a global 24/7, member/customer focused services operation', 'Effective verbal and written communication skills', 'Ability to work independently and as part of a team', 'Ability to document and apply policies, standards and procedures', 'Basic research, analytical, and problem solving skills', 'Working knowledge of data center electrical concept (power distribution, redundancy, and wiring)', 'Working knowledge of data center knowledge of data center building infrastructure (CRACS, GENS, and PDUs)', 'Working knowledge of IT/network equipment cabling (Installation and maintenance of the structured cabling system)', 'Working knowledge of rack & stacking of IT equipment (rack setup, layout, leveling and power strip setup, Ladder and Fiber Tray Construction)', 'Working knowledge of Nlyte', 'Clearly and concisely present findings and conclusions', 'Solid documentation and organizational skills', 'Comfortable working with all levels of employees; including senior management', 'Health insurance', 'Monday to Friday', 'One location', 'No: Not providing sponsorship for this job', 'No']",2020-09-24 14:05:59
Machine Learning Engineer,Ribbon Health,N/A,"New York, NY","['Passion and drive to simplify healthcare by building products that increase access to care and power every healthcare decision to be high-quality, cost-effective, and convenient', 'Commitment to Ribbon Health company values, working on an exceptional team, and building an exceptional company', 'Grit, hustle, desire, and a “get-it-done” attitude; strong comfort with a lean startup environment, where everyone is encouraged to participate in and contribute across all teams', 'Dedication to the creation of a diverse, equitable, and inclusive environment where teammates are celebrated for their unique perspectives and work together to simplify healthcare for all', 'You are proficient with SQL and have experience working with data at scale (e.g., Postgres, EMR, Spark, HBase, Presto, Postgres)', 'You feel comfortable owning ML workflows, such as automating the training of a predictive model, the deployment of that model at scale, etc', 'You have some experience designing, building, and/or managing scalable systems in the cloud (e.g., AWS, Google Cloud, Azure).', 'You have a track record of learning new technologies and languages on the job', 'Although you’ll initially work mostly in Python, you’ll help us continue to evaluate new technologies and find the best tools for the job at hand', 'Work closely with both business stakeholders and the machine learning team at Ribbon', 'Build and launch new models into production: You will work with the machine learning team to design, build, and launch new products and product features. This includes new APIs to extend the reach of our core technology', 'Build data infrastructure and work closely with data pipelines: You will develop infrastructure to support our ETL, analytics, and modeling workflows. Data engineering is a core part of what we do, so you have to love working closely with data!', ""Build and refine ML models: You will help create ML models that improve Ribbon's abilities to surface the most accurate healthcare data possible"", 'Evaluate third-party data sources: You will make decisions about what data is worth buying to augment the Ribbon data set']",2020-09-24 14:05:59
"Software Engineer, Data Platform (100% Remote)",Moveworks.ai,N/A,Remote,"['Work with various internal teams and customers to gather requirements and deliver data solutions to address those requirements', 'Model data and metadata to support analytics and reporting for different use cases', 'Design and implement a data platform to process large, complex data sets', 'Implement best practices around data integrity, validation, and documentation for data processing, reporting, and analysis', 'Optimize data processing pipelines and storage performance', 'Build the team of talented data engineers and coach them as the company grows', 'You have 4+ years of experience as a data engineer, ideally with a cloud-based SaaS company', 'Strong coding and design expertise', 'Familiarity with latest data processing and warehousing technologies is required', 'Hands on experience working with different teams for their data requirements', 'Experience with some data stores, such as Postgres, MySQL, HBase, etc.', 'BS or higher in Computer Science or a related field', 'Experience with large-scale machine learning pipelines is a plus']",2020-09-24 14:05:59
Flight Test Data Analyst/ Engineer (Entry Level) -- ELSYS,Georgia Tech Research Institute,4.2 out of 5,"Atlanta, GA 30318","['Support Flight Test Engineers in the development of flight scenarios to efficiently and effectively collect data necessary to determine system performance under test and operation', 'Interpret flight test plans and translate testing requirements into a comprehensive data analysis plan', 'Maintain flight test data sets and merge them with manual information gathering during the test process', 'Develop methodologies for how to assess system performance given digital data made available from the system', 'Develop and use software tools to support formatting and visualizing flight test data to answer system performance and operational measures', ""A Bachelor's degree in Aerospace, Computer, Electrical, or Mechanical Engineering, Computer Science, Physics, Mathematics, or related field is required."", 'Experience with Python, AutoCAD and/or SolidWorks', 'Experience as a co-op, intern, graduate research assistant, or student assistant researching telemetry, flight test data, aircraft data, and post-test data analysis', 'Experience with the development and publication of technical reports, data packages, test plans, and safety analysis plans']",2020-09-24 14:06:39
Early Career Chemical Engineer – DuPont Field Engineering Program & Direct Hire Opportunities,DuPont,4 out of 5,United States,"['Job', 'Company', 'Completing a Degree from an ABET accredited program in Chemical Engineering or Material Science & Engineering by Spring 2021.', '5 months minimum, 3 years maximum of paid engineering work experience in manufacturing or Research and Development in an industrial setting.OR', '2.5 months of paid academic Research and Development work plus 2.5 months of paid Co-Op/ Internship engineering experience in manufacturing or Research and Development in an industrial setting.', 'Legal right to work in the United States without restriction.', '3.0 or greater GPA (out of 4.0 scale) preferred', 'Willingness to provide 24x7 area support when required – Acting as the lead technology resource for their area of production involvement in day-to-day troubleshooting to assure safe, continuous operation is a minimum requirement.', '100% geographic flexibility to allow for best career development fit.', 'Commitment to complete a minimum of two assignments totaling 4.5 – 5 years.']",2020-09-24 14:06:39
Senior Petroleum Engineer,Killam,N/A,"Laredo, TX","[""Prepare AFE's and assist in economic justification for well work"", 'Track and meet goals related to LOE and production', 'Analyze and interpret well, field, and economic data and provide control measures', 'Review well data and provide the engineering prospective with charts, maps, schematics, etc.', 'Design, initiate, and coordinate well procedures for completion, workover, and well maintenance', 'Provide engineering perspective with drilling & completions, formation evaluation, wireline, cementing, reservoir stimulation, artificial lift, facilities & pipelining', 'Evaluate, recommend, and justify artificial lift', 'Provide at-site supervision and well control, and ensure safety is implemented', 'Interpret formation geology, well and field potential, and economics', 'Act as documenting liaison with State of Texas RRC Oil & Gas division', 'Research inactive wells to locate new potential', 'Design Plug and abandon procedures', 'Manage service companies and evaluate performance, pricing and contracts, and efficiency', 'Design enhanced oil and gas recovery and fluid disposal projects', 'Maintain leases in accordance with surface and mineral owners', 'BS in Petroleum engineering', 'Experience with field operations either through similar position or with oil field service company', '10+ years of experience within production engineering', 'Ability for advancement and over time taking on a leadership role', 'Must be able to be a team player and work with field hands, engineering managers, service companies, and executive team', 'Strong work ethic and drive', 'Problem solver and ability to solicit solutions from engineering and non-engineering (but experienced in running workovers rigs) staff in the field', 'Organziation skills, timely handling of paper work, and communication to all relevant parties in the organization is critical']",2020-09-24 14:06:39
Data Engineer,Verizon,3.9 out of 5,"Cary, NC 27513","['Job', 'Company', 'Gather requirements, assess gaps, and build roadmaps and architectures to help the analytics driven organization achieve its goals.', 'Work closely with Data Analysts to ensure data quality and availability for analytical modelling.', 'Explore suitable options and designs for specific analytical solutions.', 'Define extract, load, and transform (ELT) based on jointly defined requirements.', 'Identify gaps and implement solutions for data security, quality and automation of processes.', 'Support maintenance, bug fixes and performance analysis along data pipeline.', 'Bachelor’s degree or four or more years of work experience.', 'Four or more years of relevant work experience.', 'Experience using SQL (i.e., PL/SQL or T-SQL with RDBMSs like Teradata, MS SQL Server, Oracle, etc.)', 'Experience in data engineering, databases and data warehouses.', 'Strong experience with data engineering in Python.', 'Ability to travel occasionally', 'Master’s degree in Computer Science, Engineering, Statistics, IT, or related field.', 'Experience with Scala, Julia,R,Pythonor other machine learning programming language', 'Experience on Big Data platforms (i.e., Hadoop, Map/Reduce, Spark, HBase, CouchDB, Hive, etc.)', 'Strong analytical and problem-solving skills.', 'Experience working in a network operations center environment.', 'Experience as an open Source Contributor.']",2020-09-24 14:06:39
Data Engineer -Intern (0-1 Year Exp),Skoruz Technologies,4 out of 5,"Newark, CA 94560","['Health insurance', 'Monday to Friday', 'www.skoruz.com', 'https://www.facebook.com/skoruz/', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-09-24 14:06:39
Firmware Engineer - New College Graduate,NVIDIA,4.2 out of 5,Texas,"['Work closely with the architecture and different software design teams.', 'Implement new features in the core of Mellanox NIC firmware.', 'Develop verification tests for advanced features in a highly complex and sophisticated Firmware testing environment.', 'Gain a deep understanding of system debug, networking technology and stacks, as well as the HW/FW/SW relationship.', 'You will learn how a big software project is operated, maintained, qualified and released, and how Hardware and Firmware are developed.', 'Recent graduate with a BS in Computer Science/Engineering', 'Strong C/C++ and OOP capabilities.', 'Excellent understanding of data structures and algorithms fundamentals.', 'Scripting abilities (Python, Bash).', 'Strong analytical, debugging and problem solving skills.', 'Motivated and independent with strong interpersonal skills.', 'Knowledge of network protocols.', 'Prior verification experience.', 'Experience with Agile methods.', 'Real time programming, RTOS.', 'Knowledge in storage protocols.']",2020-09-24 14:06:39
Sr. Data warehouse Engineer,Infometry,N/A,United States,"['Hadoop Ecosystem of Tools (Spark, Hive, Pig, Oozie, Impala, MapReduce, etc)', 'Shell Scripting (Python, Perl, Bash, etc.)', 'MPP platforms (Vertica, Redshift, Teradata, Greenplum, etc.)', 'ETL tools (Kettle, Informatica, etc.)', 'Experience in Master data management', 'Business intelligence tools (Tableau, Qlikview, Looker, etc)', 'Database Performance concepts like indices, segmentation, projections, partitions', 'Experience working with business partners and engineers to gather, understand and bridge definitions and requirements', 'Troubleshooting']",2020-09-24 14:06:39
Stationary Engineer - Data Center,BCS Data Center Operations,N/A,"Pittsburgh, PA","['Competitive salary', 'Annual performance bonus', 'Pay:', '$0.00 per hour', '401(k)', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Referral Program', 'Tuition Reimbursement', 'Vision Insurance', 'Supplemental Pay:', 'Bi weekly or Twice monthly', 'Experience:Critical Data Center Systems, 2 years (Preferred)Critical Facilities Maintenance, 2 years (Preferred)Data Center-Specific, 2 years (Preferred)', 'Education:High school or equivalent (Preferred)', 'License:HVAC license (Preferred)Universal CFC Certificate (Preferred)Boiler Operator Certificate (Preferred)Electrical License (Preferred)Operating Engineers license (SMA) or equivalent (Preferred)', 'At the direction of supervisor, maintains, monitors, and performs preventive, predictive, and corrective maintenance on critical equipment, which may include the following: mechanical (including HVAC, computer room air conditioners, chillers, and plumbing) electrical (including UPS, DC battery systems, PDU, generators, transfer switches, and switchgear), cabling (including data and voice, broadband), fire detection and suppression, life safety, lighting, temperature control systems, building management systems, and digital systems (including fire alarm, duress, card access, CCTV). Also responsible for the operation and maintenance of non-critical equipment such as refrigeration, heat exchanger, HVAC, electrical, hot water systems. Monitors operation, adjusts, and maintains refrigeration, chilled water, and air conditioning equipment; boilers, and ventilating and hot water heaters; pumps, valves, piping and filters; other mechanical and electrical equipment; record readings and make adjustments where necessary to ensure proper operation of equipment.', 'Routinely performs all work in strict accordance with governing standard operating procedures, and maintenance work instructions.', 'Operates and monitors critical and non-critical system equipment and components. Oversees work efforts (including 3rd party contractors) for the safe and compliant operation, maintenance (corrective and preventive), and modification of critical equipment. Disables and enables fire alarm control panels and systems.', 'Install and repair plumbing/piping/tubing; wire single and three-phase motors (single & two speed); run conduit; pull wiring to machinery, motors, operating parts, etc.; install and rebuild pumps and motors; install and rebuild air compressors; heat exchangers; replace bearings in all types of motors; replace seals on pumps; install and repair piping, valves, filters, hot water systems, and associated controls; assist other mechanics and engineers with major repairs and maintenance of building and equipment. Install, repair, and maintain electrical controls, switching, and motor controls.', 'Receive and execute work orders for preventative and corrective maintenance on critical systems and building a physical structure. Consult with Data Center Engineer, Level 3 or Chief Engineer to order necessary materials to complete all maintenance and perform necessary work. Finalize work orders by completing necessary documentation in the computerized maintenance management system.', 'Respond immediately to emergency situations (fire, evacuation, equipment failure, etc.) and customer concerns.', 'As qualified, perform Building Management System Console operations.', 'Comply with departmental policy for the safe storage, usage, and disposal of hazardous materials. Maintain a clean and safe workplace.', 'Performs additional job duties as requested.', 'Flexibility, including the willingness and ability to readily respond to changing circumstances and expectations. Openness to new ideas and procedures.', 'Stress management/composure -- the ability to work, while maintaining composure and calm demeanor under pressure.', 'Strong customer service and client focus.', 'Excellent technical aptitude regarding the operation and maintenance of all critical mechanical, electrical and fire and life safety systems', 'The ability to be a part of a team and to work well in a collaborative, team-oriented environment', 'Strong planning skills', 'Problem analysis and problem resolution at both a strategic and functional level', 'Excellent oral and written communication skills', 'Solid work ethic and integrity', 'Lifting requirements are intermediate and may be required to occasionally lift, carry, push, pull, or otherwise move objects up to 50 pounds.', 'While performing the duties of this job, the employee is regularly required to frequently stand; walk; use hands, handle or feel, and reach with hands and arms.', 'This is a full-time position', 'Must be able to work varying shifts in a 24 x 7 x 365 environment', 'Limited travel may be required in this position.', 'High School diploma or GED equivalent', '2+ years’ experience in critical environment operations, maintenance, and/or engineering supporting critical facilities operations', 'Working knowledge of critical data center systems, including HVAC, standby emergency power, uninterruptible power supplies, and associated infrastructure', 'Universal CFC Certificate, Electrical License, HVAC license, Boiler Operator Certificate, etc., as agreed upon to perform duties', 'Operating Engineers license (SMA) or equivalent preferred', 'Valid driver’s license', 'Excellent technical aptitude regarding the operation and maintenance of all critical mechanical, electrical, fire, and life safety systems.', 'Must be willing to submit to a full criminal background check, results of which may or may not bar employment, in accordance with applicable state and federal laws.', 'Must be willing to submit to a drug screen, in which results will be interpreted and applied to an employment eligibility determination in accordance with applicable state and federal laws.', '401(k)', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Referral Program', 'Tuition Reimbursement', 'Vision Insurance', '12 Hour Shift', 'Bonus Pay', 'Critical Data Center Systems: 2 years (Preferred)', 'Critical Facilities Maintenance: 2 years (Preferred)', 'Data Center-Specific: 2 years (Preferred)', 'High school or equivalent (Preferred)', 'HVAC license (Preferred)', 'Universal CFC Certificate (Preferred)', 'Boiler Operator Certificate (Preferred)', 'Electrical License (Preferred)', 'Operating Engineers license (SMA) or equivalent (Preferred)', 'One location', 'Bi weekly or Twice monthly', 'A job for which military experienced candidates are encouraged to apply', 'https://www.bcsfmsolutions.com', 'No']",2020-09-24 14:06:39
Associate Sport Trader,Scientific Games,3.5 out of 5,"Las Vegas, NV 89118",[],2020-09-24 14:06:39
Database Engineer (Full-time),ProVantage Corporate Solutions,3.3 out of 5,"Raleigh, NC","['Someone who is self-motivated and able to thrive in a fast-paced, results-driven environment', 'Someone who is enthusiastic about the optimal performance of databases', 'Someone with proven expertise writing advances SQL queries and triggers, design and code complex stored procedures, and maintain/performance tune existing databases in mixed usage environment', 'Someone with product development experience in cloud and application services', 'Someone with experience in Machine Learning and Artificial Inelligence', 'Utilize MySQL to develop custom scripts to automate various database management processes, monitoring, and troubleshooting database performance', 'Monitor and troubleshoot database performance', 'Resolve various database issues, to include problems with data modeling, design, queries, security control, backup/restore, disaster recovery, and import/export data, as well as coordinate with data ingest efforts with regard to database operations', 'Audit database performance by performing advanced activities such as load testing and response time testing, and providing a report on these activities on an on-going basis so that overall system performance may be documented', 'Interface with customers, users, and developers, as needed to make certain the full picture, is accounted for', '3+ years’ experience with programming and database scripting including analysis, design, development, implementation, testing, maintenance, quality assurance, troubleshooting and/or upgrading of software systems', 'Extensive knowledge and experience in database programming tools and concepts such as SQL, PLSQL, Database triggers, and stored procedures', 'Skilled in creating technical documentation, configuration guides, and SOPs', 'Strong ability to create, update and maintain stored procedures', 'Ability to complete performance analysis and performance tuning of database code, SQL queries, and stored procedures', 'Working knowledge of agile lifecycle management tools such as JIRA', 'Exceptional communication, collaboration, influence and project management ability', 'Superior technical, analytical and decision-making skills', 'Previous experience in Product Management and Growth Manager is desirable', 'Bachelor’s degree in Engineering, Computer Science, or other related analytical, scientific, or technical discipline preferred', '40-60 hours per week', '0 to 10% travel (occasionally may need to have a high-level meeting with Clients at their place of business)', '3+ years experience in Machine Learning', 'Spirit of Excellence', 'Doing the Right Thing', 'We Before Me', 'Grace Through Generosity', 'Innovate to Elevate']",2020-09-24 14:06:39
Research Engineer,Bryant Associates,4.1 out of 5,"Silver Spring, MD","['Pay:', '$90,000.00 - $130,000.00 per year', 'Health insurance', 'Health insurance', '8 hour shift']",2020-09-24 14:06:39
Assoc Systems Engineer,"Savannah River Nuclear Solutions, LLC",4.1 out of 5,"Aiken, SC 29801","['Salary Range (annual)', '$52,272 - $85,848']",2020-09-24 14:06:39
Data Engineer,Endpoint Closing,N/A,"El Segundo, CA","['Competitive compensation, including a Long Term Incentive Plan', 'We offer great benefits - Health, Dental, Vision and 401K match', 'Build out and maintain our data warehouse (currently on Amazon Redshift)', 'Help maintain and support our data infrastructure', 'Provide guidance on data architecture for tables, indices, caching strategies, etc. to help improve performance', 'Collect data from various systems for analytics that will equip growth, product and executive teams with information they need to make decisions', 'Help build our integration with Salesforce to equip our business development team with key sales information to work more effectively.', 'Advise on user analytics implementations, sources and data management to help us better understand our user journey', 'Raise the bar on data quality', 'Experience building and maintaining data warehouses using tools such as Amazon RedShift, Snowflake, Hadoop, etc.', 'Experience designing and building ETL pipelines for a variety of sources', 'Experience working with a variety of APIs', 'Proficient in multiple database and programming languages', 'Knowledge of industry trends and best practices', 'Excellent communication and collaboration skills working with technical and non-technical stakeholders', 'Proven ability to work independently and drive results that move the needle', 'A solid understanding of information security best practices', 'Ability to derive technical projects and requirements based on high level business objectives', 'Responsibility, autonomy, and opportunities to advance your career as we grow', 'Your hard work, ownership, and self-sustainability will be greatly valued', 'Competitive compensation, including a Long Term Incentive Plan', 'We offer great benefits - Health, Dental, Vision and 401K match', 'Dog-friendly office, fully stocked snack bar and weekly catered lunches']",2020-09-24 14:06:39
Data Engineer,DataDog,3.4 out of 5,"Boston, MA","['Build distributed, high-volume data pipelines that power this core product', 'Do it with Spark, Luigi and other open-source technologies', 'Work all over the stack, moving fluidly between programming languages: Scala, Java, Python, Go, and more', 'Join a tightly knit team solving hard problems the right way', 'Own meaningful parts of our service, have an impact, grow with the company', 'You have a BS/MS/PhD in a scientific field or equivalent experience', 'You have built and operated data pipelines for real customers in production systems', 'You are fluent in several programming languages (JVM & otherwise)', 'You enjoy wrangling huge amounts of data and exploring new data sets', 'You value code simplicity and performance', 'You want to work in a fast, high growth startup environment that respects its engineers and customers', 'You are deeply familiar with Spark and/or Hadoop', 'In addition to data pipelines, you’re also quite good with Kubernetes and cloud technology', 'You’ve built applications that run on AWS', 'You’ve built your own data pipelines from scratch, know what goes wrong, and have ideas for how to fix it']",2020-09-24 14:06:39
Senior Data Engineer,The Home Depot,3.8 out of 5,"Atlanta, GA",[],2020-09-24 14:06:39
Data Engineer,Endpoint Closing,N/A,"El Segundo, CA","['Competitive compensation, including a Long Term Incentive Plan', 'We offer great benefits - Health, Dental, Vision and 401K match', 'Build out and maintain our data warehouse (currently on Amazon Redshift)', 'Help maintain and support our data infrastructure', 'Provide guidance on data architecture for tables, indices, caching strategies, etc. to help improve performance', 'Collect data from various systems for analytics that will equip growth, product and executive teams with information they need to make decisions', 'Help build our integration with Salesforce to equip our business development team with key sales information to work more effectively.', 'Advise on user analytics implementations, sources and data management to help us better understand our user journey', 'Raise the bar on data quality', 'Experience building and maintaining data warehouses using tools such as Amazon RedShift, Snowflake, Hadoop, etc.', 'Experience designing and building ETL pipelines for a variety of sources', 'Experience working with a variety of APIs', 'Proficient in multiple database and programming languages', 'Knowledge of industry trends and best practices', 'Excellent communication and collaboration skills working with technical and non-technical stakeholders', 'Proven ability to work independently and drive results that move the needle', 'A solid understanding of information security best practices', 'Ability to derive technical projects and requirements based on high level business objectives', 'Responsibility, autonomy, and opportunities to advance your career as we grow', 'Your hard work, ownership, and self-sustainability will be greatly valued', 'Competitive compensation, including a Long Term Incentive Plan', 'We offer great benefits - Health, Dental, Vision and 401K match', 'Dog-friendly office, fully stocked snack bar and weekly catered lunches']",2020-09-24 14:07:20
Data Engineer,DataDog,3.4 out of 5,"Boston, MA","['Build distributed, high-volume data pipelines that power this core product', 'Do it with Spark, Luigi and other open-source technologies', 'Work all over the stack, moving fluidly between programming languages: Scala, Java, Python, Go, and more', 'Join a tightly knit team solving hard problems the right way', 'Own meaningful parts of our service, have an impact, grow with the company', 'You have a BS/MS/PhD in a scientific field or equivalent experience', 'You have built and operated data pipelines for real customers in production systems', 'You are fluent in several programming languages (JVM & otherwise)', 'You enjoy wrangling huge amounts of data and exploring new data sets', 'You value code simplicity and performance', 'You want to work in a fast, high growth startup environment that respects its engineers and customers', 'You are deeply familiar with Spark and/or Hadoop', 'In addition to data pipelines, you’re also quite good with Kubernetes and cloud technology', 'You’ve built applications that run on AWS', 'You’ve built your own data pipelines from scratch, know what goes wrong, and have ideas for how to fix it']",2020-09-24 14:07:20
Senior Data Engineer,The Home Depot,3.8 out of 5,"Atlanta, GA",[],2020-09-24 14:07:20
Entry Level Associate Package Application Developer,IBM,3.9 out of 5,"Baton Rouge, LA 70802","['Assist clients in selection, implementation, and support of packages', 'Define, detail and scope the technical requirements into solution architecture and drive an independent project from an architectural stand point.', 'Design, develop and/or re-engineer application components, and integrate software packages, programs and reusable objects.', 'Get client-facing experience and industry knowledge', 'Leverage business knowledge to drive solutions for clients and their management', 'The IBM Client Innovation Center is an in-bound delivery model where we support our clients from our Baton Rouge center (aka: we work in a traditional IBM Agile office setting)', 'Some travel is expected, and all candidates must be willing and able to travel to meet our client needs across the U.S. Travel is typically related to knowledge transfer and training at the client site (Monday through Friday). You will be expected to travel approximately 50% of the time.', 'You must live in, or be willing to locate to, LOUISIANA. The work location is 100 North St, Baton Rouge, LA 70802. This is not a work from home position.', 'Our motto: Right Time, Right Place, Change the World', 'Check us out on YouTube: http://ibm.biz/BatonRougeCIC', 'Skill development: Helping our employees grow their foundational skills', ""Finding the dream job at IBM: Navigating our company with the potential for many careers by channeling an employee's strengths and career aspirations"", 'Diversity of people: Diversity of thought driving collective innovation', 'http://www.ibm.com/ibm/responsibility/initiatives.html', 'http://www.ibm.com/ibm/responsbility/corporateservicecorps', 'Basic programming proficiency and experience with Java, C# .NET, C++, Python, SQL, JavaScript and/or HTML', 'Basic understanding of SAP, Oracle, Microsoft Dynamics, Salesforce, Workday, and/or SharePoint (Configurations, Implementations, etc)', 'Ability to thrive in an ever changing, technology based consulting environment, using Agile Techniques', 'Ability to translate business requirements into technical solutions', '1 year exposure to ASP .NET, HTML, DHTML, XML, XSLT, JavaScript', '1 year exposure to SAP, Oracle, Microsoft Dynamics, Salesforce, Workday, and/or SharePoint (Configurations, Implementations, etc)', 'Knowledge of Enterprise Applications (EA) Implementation Methodology (ASAP, ACTIVATE), Development Methodologies (Agile, Waterfall) and Implementation Tools (Solution Manager, Worksoft, EnableNow, etc)', 'Advanced Microsoft Office Skills']",2020-09-24 14:07:20
Data Engineer,Renewable Energy Systems,3.6 out of 5,"Glasgow, OR","['Retrieving and homogenizing data from a wide range of operational renewable energy power plants, in particular solar farms and wind farms', 'Analyzing operational data from renewable energy power plants, including data from Condition Monitoring Systems', 'Providing flexible reporting solutions for internal and external clients', 'Creating engineering analysis tools used by specialists to detect and prevent faults', 'Using machine learning and artificial intelligence to automate the application of specialist knowledge', 'Evaluation of solar farm and wind farm SCADA systems to determine the best data extraction approach', 'Working together with the Product Owner and Software Developers to deliver new software products following the Scrum development methodology', 'Choosing the right technology, architecture and infrastructure for each product in consultation with other software developers and the Product Owner', 'Maintaining high operational performance; monitor and troubleshoot data feed outages or underperformance and implement countermeasures to prevent them in future', 'Demonstrating completed work at wrap up meetings', 'Following and contributing to team working agreement', 'Contributing to the strategic technical direction of the product', 'Delivering work which is applicable to wind, solar and storage assets in all markets', 'Supporting continuous improvement of team tools and practices', 'Modbus (in particular for solar farm inverters)', 'OPC', 'Web APIs', 'SQL databases', 'C#', 'Python', 'Docker', 'Cloud based application deployment (Azure or similar)', 'Continuous Integration Systems (including Jenkins and Azure DevOps)', 'Testing frameworks (including NUnit)', 'Version Control systems (in particular Github)', 'Solar farm SCADA systems', 'Wind farm SCADA systems', 'Scrum / Agile methodology', 'Continuous deployment', 'Ability to discuss and implement data transformations and numerical algorithms', 'Ability to understand users’ success criteria and design software to achieve their required outcomes', 'Ability to integrate with an existing international team', 'Degree in Computer Science, Science, Engineering or a technical discipline', 'Relevant experience working as a SCADA engineer, data engineer, data scientist or software developer']",2020-09-24 14:07:20
Math Algorithm Engineer,Intel,4.1 out of 5,"Hillsboro, OR 97124","['Numerical analysis or scientific software design', 'Development in C, Fortran or C++ languages.', 'Parallel programming technologies, such as OpenMP, TBB or MPI.', 'Linux, Windows or Mac OS development.', 'Mathematics/ numerical analysis preferably Fast Fourier Transforms or numerical sparse linear algebra.', 'Data structures/algorithms.', 'Computer architecture specific code optimizations.', 'Using mathematics software libraries.', 'Intel software development tools.']",2020-09-24 14:07:20
Sr. Big Data Engineer,SSI,3.7 out of 5,"Houston, TX 77060","['The Sr. Big Data Engineer manages the uninterrupted flow of information by designing and maintaining data pipelines to deliver data across our organization. S/he builds the automated data pipelines to ingest and prepare the data to meet the reporting and analytics needs of the organization. This includes building and maintaining the data structures and architectures for data ingestion, processing and deployment for large-scale, data-intensive applications. This individual must ensure that optimal ETL (Extract, Transformation, and Load) solutions are developed by applying best practices to the data modeling, code development and automation.', 'As part of an agile team, design, develop and maintain an optimal data pipeline architecture using both structured data sources and big data for both on-premise and cloud-based environments.', 'Develop and automate ETL code using scripting languages, ETL tools and job scheduling software to support all reporting and analytical data needs.', 'Design and build dimensional data models to support the data warehouse initiatives.', 'Assemble large, complex data sets that meet the analytical needs of the data scientist teams.', 'Assess new data sources to better understand availability and quality of data.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data pipeline performance, re-designing infrastructure for greater scalability and access to information.', 'Participate in requirements gathering sessions to distill technical requirements from business requests.', 'Collaborate with business partners to productionize, optimize, and scale enterprise analytics.', 'Collaborate with data architects and modelers on data store designs and best practices', 'Provide off-hours support for all developed data pipelines in an on-call rotation.', 'Bachelor s degree in Computer Science, Engineering, Information Science, Math or related discipline', 'Data engineering, data management or cloud certification is a plus', 'At least six (6) to eight (8) years of experience in in a data engineering role or related specialty with demonstrated ability in data modeling', 'At least two (2) years Data engineering experience on the Microsoft Azure, Amazon Web Services (AWS), or Snowflake', 'Experience using Extract, Transformation and Load (ETL) tools with Informatica (IICS) to build automated data pipelines', 'Experience with object-oriented/object function scripting languages: Python, Java, C++', 'Thorough understanding of relational, columnar and NoSQL database architectures and industry best practices for development', 'Understanding of dimensional data modeling for designing and building data warehouses', 'Excellent advanced SQL coding and performance tuning skills', 'Experience with big data tools: Hadoop, Spark, Kafka, etc.', 'Experience with parsing data formats such as XML/JSON and leveraging external APIs', 'Understanding of agile development methodologies', 'Ability to work in a team-oriented, collaborative environment; good interpersonal skills', 'Strong analytical and problem-solving skills; ability to weigh various suggested technical solutions against the original business needs and choose the most cost-effective solution', 'Keen attention to detail and ability to access impact of design changes prior to implementation', 'Self-driven, highly motivated and ability to learn quick', 'Ability to effectively prioritize and execute tasks in a high-pressure environment', 'Strong customer service orientation', 'Ability to present and explain technical information to diverse types of audiences in a way that establishes rapport and gains understanding', 'Work experience with geospatial data and spatial analytics is preferred']",2020-09-24 14:07:20
Research Engineer/Data Scientist,Technica Corporation,3.7 out of 5,"Dulles, VA","['401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Experience:Python, 1 year (Required)Natural Language Processing techniques, 1 year (Required)', ""Education:Bachelor's (Required)"", 'Security Clearance Required:Secret (Required)', 'Support a team of Developers and Data Scientists working on a variety of research and development projects as well as customer projects', 'Research and analyze cutting edge algorithms and technologies with a focus on Natural Language Processing and data visualization techniques', 'Effectively communicate results of research and analysis with teammates and senior management in the form of essays, whitepapers, and PowerPoint presentations', 'Design, Develop and Deploy:', 'Automated analytic software, techniques, and algorithms', 'Data-driven analytics; event-driven analytics', 'Bachelor’s in Computer Science, Mathematics, or relevant technical field', '1+ years’ experience using Natural Language Processing techniques', '1+ years’ experience with web frameworks (React, Flask, NodeJS)', '1+ years’ experience with Python', 'Active U.S. Secret clearance', 'Experience using Linux as a development operating system', 'Professional experience with Docker and Singularity container platforms', 'Professional experience with Machine Learning toolkits such as Tensorflow, Pytorch', 'Professional experience with customer facing data visualization', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'Python: 1 year (Required)', 'Natural Language Processing techniques: 1 year (Required)', ""Bachelor's (Required)"", 'Secret (Required)']",2020-09-24 14:07:20
Sr. Data Engineer,NYC Health + Hospitals,3.8 out of 5,"New York, NY 11201","['Reporting to the Data and Analytics Unit Director in the Data, Analytics and Product Development Team, the Senior Data Engineer within the Data and Analytics Unit will be responsible for designing, evaluating and testing data structures to support the work of the Data, Analytics and Product Development Team and its ability to inform the planning, reporting and development initiatives under the Test and Trace Corps. The Senior Data Engineer will also be responsible for:', 'Building and maintaining the internal data infrastructure to be used by data analytics staff and developing and ensuring standardization in data cleaning, programming and analyses across large, complex data sets', 'Structuring and transforming datasets for multiple complex use-cases, user stories and related requirements within the Data Analytics and Product Team and across the Test and Trace Corps organization', 'Auditing current data practices being employed by the Data, Analytics and Product Development Team and re-engineering tools for improved data flow', 'Building back-end data migration tools and infrastructure to support data analytics work', 'Performing in-depth investigation and analysis to identify and resolve complex processing problems associated with the systems, programs, and datasets utilized by the Test and Trace Corps organization', 'Recommending programs, practices, and standards to facilitate uniform application of electronic data methods, code versioning and review, ticket management', 'Supervising and overseeing the Data Engineer, providing assistance and insights on complex and difficult data sets and ensuring accuracy of work products.', 'Providing advice to front-end developers and field staff on overall data intake and integrations', 'Ability to work autonomously, think analytically, and anticipate data issues to solve before they arise', 'Excellent written and verbal communication skills, with the ability to explain data systems to non-technical teams', 'Strong quality control abilities and exceptional attention to detail', 'Ability to manage multiple complex projects at a time, prioritize, and execute on tight timelines', 'Expertise in Python or equivalent programming language for automation', 'Advanced knowledge of SQL', 'Experience with API interfacing in a data engineering and analytics environment', 'Varies', 'No']",2020-09-24 14:07:20
Data Engineer,Sarcos Robotics,3.3 out of 5,"Salt Lake City, UT 84108","['Design and build ETL and ELT pipelines', 'Securely move data to a data lake', 'Design, create, and improve tools to quickly process large volumes of data (terabytes)', 'Pitch in wherever needed to increase the likelihood of success', 'Innately possess accountability, fearless risk-taking, and measurable achievement', 'Able to work independently, with minimal supervision', 'Demonstrated creative and innovative solutions and problem-solving skills', 'Flexible and adaptable (willing to work on other technical problems as needed)', 'Insatiable curiosity for science, technology and understanding of how things work', 'Bachelor’s Degree in Computer Science, Computer Engineering, or equivalent industry experience', '2+ years experience as a Data Engineer, Data Scientist, Computer Scientist or similar title', 'Experience with Linux', 'Experience developing C++ & Python code', 'Practice using SQL and/or NoSQL databases', 'Skill in methodologies for storing and processing time-series data', 'Experience using Docker', 'Experience with Fog computing solutions', 'Previous usage of Parquet', 'Experience with EdgeX', 'Work is performed Monday through Friday with ability to work overtime and weekends.', 'This position can be worked remotely.', 'Safety awareness is absolutely essential at all times while in the work area.', 'Must be able to stand and sit for extended times.', 'Treat everyone on our team, regardless of seniority or role, the way they want to be treated', 'Trust my colleagues and believe that they have the best of intentions', 'Proactively communicate in a candid manner, with sufficient information to allow my colleagues to achieve their objectives', 'Be open minded and receptive to review, constructive feedback, and collaboration', 'Act with integrity by doing what is right for the company, my customers, my colleagues and myself', 'Demonstrate a positive can-do attitude coupled with the drive and determination to win, while holding myself accountable for both my success and the success of the company', 'Never criticize, disparage or malign colleagues behind their backs or in front of others', 'Not tolerate anyone in the company doing anything inconsistent with any of the above']",2020-09-24 14:07:20
Internship - Sales Engineer (Paid),Apergy,3 out of 5,"Odessa, TX","['Mechanical, Electrical or Petroleum engineering graduate', 'Ability to execute initiatives', 'Data analysis skills', 'Ability to actively engage and communicate with customers', 'Strong oral and written communication skills, including the ability to present and collaborate', 'Ability to make recommendations to further optimization', 'Organization and time management skills', 'Bachelor degree in Mechanical, Electrical or Petroleum Engineering from a 4-year accredited program', 'Willingness to relocate to Odessa, TX during internship', 'Willingness to remain in Odessa, TX if selected as a Sales Engineer Trainee']",2020-09-24 14:07:20
Senior Frontend Engineer,Monte Carlo,3.8 out of 5,Remote,"['Building analytics/ML experiences to delight customers', 'Owning major projects from inception to deployment, shipping at a rapid pace', 'Designing a simple yet flexible UX, and then iterating to improve itf React and Typescript,', '3+ years of experience delivering production-grade frontend code', 'Mastery of React and Typescript, and perhaps visualization frameworks', 'Experience building enterprise SaaS UIs', 'Sense of urgency, ownership mindset, and customer focus']",2020-09-24 14:07:20
Senior Business Intelligence Engineer,Blink Health,4.3 out of 5,"Kirkland, WA","['Partner with cross-functional teams to help improve decision making with data, including helping build a culture of data driven decision making.', 'Build single source of truth for every line of business', 'Create views and models in looker using LookML and Tableau', 'Build data pipelines using airflow and dbt', 'Conduct exploratory analysis to inform product strategy and evaluate recently released or existing products or features', 'Produce work that aids the decision-making process of the executive team', 'A bias for action in applying analytics to solve problems and a focus on identifying efficient solutions to complex issues.', 'A strong command of SQL and relational databases', 'Comfort with large, disparate datasets', 'Experience in Looker, Tableau or other similar BI tools', 'Clear communication skills to a wide and diverse audience, including Digital Marketers, Product Managers, a Financial Strategist, and a Data Engineer', 'An ability to prioritize disparate requests and communicate timelines and statuses to a broad audience', 'A growth mindset and deep intellectual curiosity', 'At least 7 years of professional experience with reporting responsibilities', 'An educated grasp of eCommerce and digital marketing', 'Financial reporting and/or pricing strategy experience', 'Distributed systems concepts and AWS']",2020-09-24 14:07:20
Data Center Engineer,Optiver US,3.8 out of 5,"Chicago, IL","['Installing and cabling switches, servers, and appliances in our onsite data center', 'Coordinating work at the remote colocations', 'Managing power and space including monitoring and capacity planning', 'Maintaining a consistent and clean cable management standards', 'Managing hardware inventory and troubleshooting hardware related issues', 'Coordinating colocations expansions and migrations', 'Shipping , receiving and transporting hardware between sites', 'Maintaining data center documentation', 'Attention to detail and strong documentation skills', 'Great communication skills', 'An understanding of change control processes', 'Ability to identify basic parts of network equipment – SFPs, line cards, chassis', 'Basic understanding of Networking concepts and troubleshooting steps', 'Jira familiarity', 'Basic understanding of Windows and Linux OS', 'Solid understanding of power management on the server rack level', 'Ability to identify server parts', 'Knowledge of structured cabling systems using cat 5, cat 6, multi-mode and single-mode fiber', 'Experience using cable testers', 'Ability to lift 75lbs', 'Reliable transportation and the ability to work second shift 10AM - 8PM Wednesday - Friday and Saturday 8AM - 6PM', 'Ability to occasionally travel to New Jersey colocations when COVID-19 restrictions are lifted', 'Legal authorization to work in the U.S. is required; we will not sponsor individuals for employment authorization for this job opening']",2020-09-24 14:07:20
Data Engineer,DVG Tech Solutions LLC,N/A,"Blue Ash, OH","['4 years of successful and applicable hands-on experience in the data development and principles including end-to-end design patterns', '4 years have proven track record of delivering large scale, high quality operational or analytical data systems', '4 years of successful and applicable experience building complex data solutions that have been successfully delivered to customers', 'Demonstrated written and oral communication skills', 'Experience in a minimum of two of the following technical disciplines: data warehousing, big data management, analytics development, data science, application programming interfaces (APIs), data integration, cloud, servers and storage, and database management', 'Experience building solutions using elastic architectures (preferably Microsoft Azure and Google Cloud Platform)', 'Direct experience with a variety of SQL, NoSQL, and Big Data Platforms.', 'Direct experience with data science solutions or platforms.', 'Data Engineers will be used in combination with Tiger Teams, Data Ingestion, and DMP architecture to quickly deliver', 'For DMP Tiger Teams, Data Engineers will be key in the creation of Ad Hoc Analytical solutions across Supply Chain, Human Resources, Digital, and Store Operations.', 'Leverage enterprise standards for data domains and data solutions, focusing on simplified integration and streamlined operational and analytical uses.', 'Ensure there is clarity between ongoing projects, escalating when necessary, including direct collaboration with 84.51.', 'Leveraging innovative new technologies and approaches to renovate, extend, and transform the existing core data assets, including SQL-based, NoSQL-based, and Cloud-based data platforms.', 'Define high-level migration plans to address the gaps between the current and future state.', 'Contribute to the development of cost/benefit analysis for leadership to shape the sound architectural decisions.', 'Analyze technology environments to detect critical deficiencies and recommend solutions for improvement.', 'Promote the reuse of data assets, including the management of the data catalog for reference.', 'Draft architectural diagrams, interface specifications, and other design documents.']",2020-09-24 14:07:20
Data Engineer,American Safety Council Inc,3.3 out of 5,"Orlando, FL 32801","['Help build a unified data platform', 'Utilize a variety of analytics/BI tools and methods', 'Design, model, develop and maintain data sets to support reporting analytics and exploratory analysis', 'Design and develop reporting systems that inform on key metrics, detect anomalies, and forecast future results', 'Flexibility to work with both SQL and NoSQL solutions', 'Work with a mixture of structured and unstructured data', 'Coordinate the efficiency, scalability, and stability of data collection, extraction, and storage processes', 'Design and build data lake solutions to handle large datasets, and provide a scalable infrastructure that can slice and dice data for BI reporting and ad-hoc analysis', 'Design data loading, staging, and ETL / ELT processes', 'Apply in-depth understanding of database tools & utilities, as well as highly developed SQL & database performance tuning skills', 'Design and build data lake solutions to handle large datasets', 'Identify opportunities to streamline and automate', 'Work with other Engineers to troubleshoot and optimize database performance in current and future implementations', 'Knowledge and understanding of reporting tooling to design and build solutions to meet customer needs', 'Five (5) or more years of experience as a Data Engineer, Database Engineer, Database Architect, Cloud Architect', 'Two (2) or more years of experience working with the Azure cloud environment (AWS/GCP a plus), preferably on data development', 'Two (2) or more years of experience building and optimizing ‘big data’ pipelines, architectures, and data sets', 'Advanced working SQL knowledge and experience working with relational databases, SQL query authoring & optimization, as well as working familiarity with a variety of databases', 'Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets', 'Strong analytical skills related to working with unstructured datasets', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement', 'Familiar with C# (dotnet framework and/or dotnet core)', 'Experience working with Microsoft Azure services such as Data Factory, Data Bricks, Cognitive APIs, Azure Machine Learning', 'Experience working with senior management, excellent client-facing skills', 'Bonus: familiar with accounting / financial reporting terms and data']",2020-09-24 14:08:06
Data Integration Developer (SQL/SAS),Compassion International,4.3 out of 5,"Colorado Springs, CO 80921","['Maintain a personal relationship with Jesus Christ.', ""Act as an advocate for children. Understand and advance Christ's mandate to protect children. Take active steps to help protect against neglect, abuse, and exploitation of children."", 'Uphold and engage in Compassion’s core Cultural Behaviors.', 'Develop a deep understanding of business goals, processes, systems, and data and how they work together.', 'Build and maintain BI data infrastructure (which includes ETLs, SAS macros, SQL views, and related documentation) to make data accessible, accurate, and efficient for other members of the Consumer Insights Team developing BI solutions such as reports, dashboards, and data science systems.', 'Uncover, analyze, document, and monitor issues affecting data quality.', 'Resolve data quality issues using multiple methods: through data loads to the source system of record; by partnering with IT to improve system logic, system integrations, input form validations, data replication, and performance issues; and by partnering with business training teams for end-user education; and by developing reports for business QA teams for manual correction.', 'Prepare data files to send to vendors for data enhancement services.', 'Prepare data files for bulk loading to the source system of record.', ""Bachelor's Degree in Management Information Systems, Computer Science, or related discipline"", 'Professional experience working in business intelligence or IT or in a role related to data integration, data engineering, or data stewardship.', 'Data wrangling using SAS, SQL, Pandas, R, or similar tools.', 'Advanced experience querying, writing SQL views, wrangling data, and executing DML against RDBMSs such as Netezza, Snowflake, Microsoft SQL Server (MSSQL), or MySQL.', 'Modern programming/scripting languages such as Python, C#, or Java preferred.', 'Relevant certification such as SAS Base Programming Specialist, IBM Certified Data Engineer, Google Professional Data Engineer, or Microsoft Azure Data Engineer.', 'The mission: Join a team that is motivated to release children from poverty in Jesus’ name.', 'Our benefits: Receive generous paid time off, 10% contribution to a 403(b) retirement fund on top of your salary, excellent health-care coverage, free short-term professional counseling, and more.', 'Spiritual growth: Participate in regular chapel services, prayer groups, and department devotionals.']",2020-09-24 14:08:06
Data Scientist Intern,Joby Aviation,N/A,"San Carlos, CA 94070","['Wrangle data from a multitude of formats and systems (TDMS, AVRO, PostgreSQL, AWS, etc).', 'Make sense of and “clean” data from a number of physical tests (the aircraft, reliability test equipment, subsystem tests, etc.)', 'Work closely with engineers to understand the test and clearly present on the results', 'Work with the data engineering team to develop and maintain efficient data pipelines', 'Develop tools to make processing and reporting on data as consistent and easy as possible', 'Leverage statistics, numerical fitting methods, and a fundamental knowledge of powertrain systems to draw conclusions', 'Pursuing a university degree in computer science, engineering, physics, or similar field.', 'Experience with python and data libraries (pandas, scipy, etc.)', 'Exposure to data system architectures in relation to how to store, fetch, and manipulate data (SQL, custom APIs, etc)', 'Experience with data visualization tools (matplotlib, bokeh, plotly, etc.)', 'Exposure to physical systems and an intuition around powertrain components and data', 'Excellent communication skills with a predication to good programming practices', 'Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, and', 'Experience with Spark or other big data tools is a big plus', 'Experience with machine learning techniques and methodologies']",2020-09-24 14:08:06
Data Engineer,DISH,3.3 out of 5,"Cheyenne, WY 82007","['Be a subject matter expert in data engineering designs and architecture.', 'Ensure that solutions adhere to defined standards and best practices and/or assist in the development of these standards and best practices.', 'Routinely research, analyze, test, retest, and troubleshoot complex problems.', 'Able to work in a fast-paced environment, under pressure, with strict deadlines, both as an individual contributor and team player.', 'Participate in knowledge transfer, documentation and information sharing while staying abreast of new technology/technical areas.', 'Other duties as assigned.', ""Bachelor's degree in Computer Science, Computer Engineering, or a related technical degree; four years related experience; or equivalent combination of education and experience"", '2 or more years experience in Big Data or data management systems', 'Expert in data extraction, transformation, and loading via a combination of Kafka, Spark, and Python', 'Expert in SQL-like query language and table design', 'Background in development and ability to code and debug code', 'Demonstrated experience building and managing a multi-tenant data infrastructure', 'Demonstrated experience in programming using one or more of the following: Java, C++, Perl, Python, or advanced Shell scripting.', 'Demonstrated experience with one or more of the following: NiFi, Flink, Impala, Hive, Athena, Redshift, BigTable, ElasticSearch, or Airflow', 'Experience in machine learning and statistical modeling', 'Experience running systems both in public cloud (e.g. AWS, Azure, GCP) as well as private data centers', 'Track record of practical problem solving, excellent communication, and documentation skills']",2020-09-24 14:08:06
"Business Intelligence Engineer, Trend Analytics",Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","[""Bachelor's degree in Computer Science, Engineering, Mathematics or related field."", '3+ years of experience with data scripting languages (e.g Python, R etc).', 'Experience with data visualization software such as Tableau, Amazon Quicksight.', 'Expert in SQL, ETL, data warehousing.', 'Design structured, multi-source data solutions to deliver the dashboards and reports that make data actionable.', 'Support economists, business analysts and internal customers by turning hypotheses into functional specifications and then executing delivery.', 'Drive the collection of new data and the refinement of existing data sources to continually improve data quality', 'Lead the technical lifecycle of data presentation from data sourcing to transforming into user-facing metrics.', 'Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation.', 'Advanced degree in computer science, mathematics, statistics, economics, or other quantitative field.', 'Experience working in very large data warehouse environments.', 'Excellent written and verbal skills to effectively communicate with business and technical teams, including defining business requirements and conveying key insights from complex analysis.', 'Comfortable communicating with technical and non-technical audiences.']",2020-09-24 14:08:06
"Engineering Manager ( React/Java ) - going IPO, 100% remote, data driven",Relentless Talent,N/A,"Pittsburgh, PA","['spring: 1 year (Preferred)', 'Java: 1 year (Preferred)', 'Fully Remote']",2020-09-24 14:08:06
Data Engineer,Regions Bank,3.6 out of 5,"Birmingham, AL","['Creates and maintain data pipelines', 'Assembles large data sets that meet business requirements', 'Use Sparks sequel (SQL) and workflow schedulers to develop feature engineering and scoring pipelines', 'Works closely with data scientists to ensure that feature engineering pipelines meet their needs', 'Provides guidance for writing Spark jobs to ensure that data science code is optimized for production', 'Uses and promotes Regions’ technology stack: BitBucket, Jira, Hadoop/Spark and Openshift/Kubernetes', 'Contributes to a collaborative, open developer environment', 'Receives instruction, guidance and direction from more senior level roles', ""Bachelor's degree in Mathematics, Physics, Statistics, Engineering or a quantitative related field"", 'Two (2) years experience using “big data” technologies as a Data Scientist, Data Engineer, Software Designer or a related field', 'Advanced working knowledge of SQL and relational databases', 'Experience performing root cause analysis on Spark jobs to identify areas for improvement', 'Experience with Airflow, Argo, Luigi, or similar orchestration tool', 'Experience with Containers and Kubernetes', 'Experience with DevOps principals and CI/CD', 'Experience with functional or object-oriented languages such as Python, C++, Rust, Scala', 'Experience with No-SQL databases such as HBase, Cassandra, or Redis.', 'Experience with streaming technologies such as Kafka, Flink, or Spark Streaming.', 'Identify and implement leading edge technology solutions to drive adoption and efficacy of the data governance program across the enterprise.', 'Work with Enterprise Architecture, Data Science, Risk Management and related technology teams to facilitate data usage while meeting data governance, Risk and Audit standards.', 'Present ideas/proposals for enhancing data management maturity and get buy-in from IT/business leads and executives across the enterprise.', 'Conduct data literacy and data awareness drives across the organization thru presentations, expos and meetings.']",2020-09-24 14:08:06
Senior Software Engineer - Data,Lob,N/A,California,"['Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.', 'Develop and maintain data infrastructure, libraries and services with software engineering best practices.', 'Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.', 'Build and curate data model expertise and uphold data quality and freshness.', 'Work closely with multi-functional teams to build and ship data-driven product features.', 'Coach and mentor fellow engineers.', 'Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.', 'Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.', 'Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.', 'Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.', 'Production experience with Spark, Python and SQL.', 'Experience with event-driven systems and time-series analysis a plus.', '5+ years of full-time, relevant industry experience.', 'Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)', ""Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media"", 'Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth', 'We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest', 'Health benefits for you and your dependent(s)', 'Flexible Spending Accounts', 'Open vacation policy', 'Commuter benefits', 'Wellness program', 'Paid parental leave', ""Ground floor opportunity as an early member of the Lob team; you'll directly shape the direction of our company"", 'Free lunch, dinner, and snacks', '401K']",2020-09-24 14:08:06
"Senior Software Engineer, Data",Pyze,N/A,"Redwood City, CA",[],2020-09-24 14:08:06
Senior Data Engineer - ETL/Data-Pipeline,Inffiniti Inc.,N/A,"Mountain View, CA","['Design and own data pipelines and integrations for streaming and batch data', 'Collect, clean and store large datasets which will be used for analytics, reporting and prediction', 'Implement best practices in security and data handling to maintain the privacy of users and partners', 'Help develop data products that drive company success by collaborating with the teams across the company', 'As part of a small, agile data-engineering team, you will have a tremendous opportunity to make a big impact for the company', 'Help accelerate data-engineering, data-science, business intelligence, reporting and analytics by evaluating, integrating and building new tools as needed', 'Help achieve a high-level of operational excellence in data-engineering', 'A desire to help people to use data effectively in a startup environment', 'Expertise in Spark/Storm/Flink/MapReduce/Impala/Hive', 'In-depth knowledge of AWS (including EMR, DMS, Athena, RDS, Aurora, Lambda, Redshift)', 'Expertise in stream data-processing (DMS/Flink/Spark/Kinesis/Kafka)', 'Advanced SQL skills and strong proficiency in the following programming languages: Python,', 'Demonstrated expertise in Object-Oriented/Functional programming including a solid grasp of common design patterns, idioms and design', 'Fluency in data structures, algorithms, distributed computing, storage systems, and various consistency models', 'Familiarity with Pandas, SciPy, Scikit-learn, Seaborn, SparkML packages/modules', 'Knowledge of multiple database technologies and their tradeoffs, and also how to make the best use of each type of database', 'Goal-oriented, with a passion for developing a world-class engineering culture', 'Willingness to learn and mentor in a collaborative team environment', 'BS/MS in Computer Science/Mathematics/Computer Engineering or related field, or equivalent experience', '4+ years in data-engineering or equivalent experience', '7+ years in software engineering or equivalent experience', 'Experience in relational, object, columnar, key-value and related database types', 'Experience in designing and maintaining at least one type of database', 'Experience in data-warehouse modernization, building data-marts, star/snowflake schema designs', 'Experience in data infrastructures, ETL/ELT pipelines, and BI/reporting/analytic tools', 'Experience in building production-grade data backup/restore and disaster recovery solutions', 'SparkML/Scikit-learn/TensorFlow experience', 'GraphX/TitanDB/neo4j/range++/graph-engine/orientdb experience', 'Delta Lake experience', 'Airflow/luigi/oozie/azkaban/pinball/chronos experience', 'Snowflake cloud data-warehouse experience', 'Hadoop MapReduce/Yarn/HDFS/Pig/Hive experience', 'Tableau/Periscope-Sisense/Domo/Looker/Superset experience', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Monday to Friday', 'One location', 'People-oriented -- enjoys interacting with people and working on group projects', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Autonomous/Independent -- enjoys working with little direction', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'High stress tolerance -- thrives in a high-pressure environment', 'Yes']",2020-09-24 14:08:06
Associate Engineer,Xactware,3.9 out of 5,"Littleton, CO","['Being part of and contributing to a large, dynamic and innovative community', 'Working with cutting-edge technology, and continuously developing new skills and capabilities', 'Focusing on our customers, their success, and the desire to serve them', 'Being responsible and assuming accountability for everything you touch', 'Enhance the capability and overall reputation of the Infrastructure and Support team, group, and division by offering exceptional customer service and technical ability to both internal and external customers', 'Successfully promote a continuous improvement mindset within operations, engineering, and development groups, that results in measurable efficiency, cost, and process improvement', 'Measurable contribution to the capabilities, security posture and optimization of company technologies', 'Positive feedback on the support received from business partners', 'Positive feedback from team members and leaders of the Verisk community', 'Ability to establish and maintain effective working relationships at all levels of the organization', 'A tangible desire and curiosity to seek out and learn new and innovative ways to manage and solve complex challenges', 'Strong communication skills (written & verbal) and a collaborative, team-oriented approach to work are a must, as is a comfort level working in a fast-paced, federated environment that embraces innovation and experimentation', 'Dependable and flexible with work hours, including nights and weekends as required', ""Prefer 2 years of related experience with a Bachelor's degree in Business or Marketing or related subject; No experience required with an advanced degree; Equivalent work experience"", 'Prefer experience designing, managing, and/or supporting enterprise infrastructure systems', 'Prefer experience with networking concepts (OSI network layers, TCP/IP)', 'Prefer experience with Microsoft Windows and Linux operating systems', 'Prefer experience working with public cloud products and services; AWS or Azure preferred', 'Familiarity with database platforms such as MSSQL, MySQL, and PostgreSQL', 'Desire to learn CI/CD tools and methodologies, system programming and scripting; Desire to develop a scripting/automation mindset', 'Desire to learn integration concepts with enterprise operations and security tools such as Okta, Splunk, SolarWinds, ServiceNow, Infoblox and Imperva', 'Developed customer service skills and experience interfacing with all levels of stakeholders', 'Experience creating technical documentation and using tools including Visio, Word, Excel, Outlook, and PowerPoint', 'No travel required']",2020-09-24 14:08:06
Module Process Engineer,Taiwan Semiconductor Manufacturing Company,3.9 out of 5,"Phoenix, AZ","['401(k)', 'Employee assistance program', 'Employee discount', 'Health insurance', 'Paid time off', 'Parental leave', 'Relocation assistance', 'Monday to Friday', 'Bonus pay', ""Bachelor's (Preferred)"", 'No']",2020-09-24 14:08:06
Data Engineer,FanThreeSixty,2.7 out of 5,"Kansas City, MO 64108","['Develop scalable pipelines to move and transform data between FanThreeSixty systems.', 'Maintain ownership of infrastructure associated with ETL processes.', 'Help guide the development of the data lake infrastructure', 'Strive to mitigate any data quality and accuracy issues and assist data consumers in developing a deeper understanding of the data.', 'Assist in the development of frameworks to integrate analytical output with the broader FanThreeSixty solution', 'Support client consulting engagements as needed.', 'Represent FanThreeSixty in a professional manner at all times.', 'Perform other related tasks as assigned.', 'Strong organizational, communications and interpersonal skills.', 'Ability to organize work effectively, conceptualize and prioritize objectives and exercise independent judgment based on an understanding of organizational policies and activities.', 'Exceptional strategic and analytical thinking skills.', 'Ability to query databases and perform statistical analysis.', 'Strong problem solving skills.', 'Collaboration skills.', 'Ability to confidently present information and analytics.', 'Works both independently and in a team environment to create business solutions.', 'Unrelenting desire to deliver high quality products.', 'Comfortable with cutting-edge technology.', 'Bachelor’s degree in mathematics, statistics, computer science or other related field required.', '3+ years of experience manipulating large datasets and using databases, as well as one (1) to three (3) years of experience with general purpose programming language.', 'Strong backend development skills using Python and Java in a professional environment.', 'Strong background in data engineering (ETL)', 'Experience with open source technologies include Spark, Airflow, Kafka, Elasticsearch, and Docker', 'An understanding of data lakes, data warehousing, and structuring data to address analytics use cases', 'Familiarity with basic principles of distributed computing and/or distributed databases.', 'Basic understanding of the Python data science ecosystem (pandas, scikit-learn, numpy)', 'Knowledge of one or more business/functional areas.', 'Familiar with traditional SQL and NoSQL databases.', 'Proficient in the Google Apps Suite.']",2020-09-24 14:08:06
Data Engineer,Pollen Inc,N/A,"Leawood, KS 66206","['Work closely with Software Engineers, Data Scientists, and Business Analysts to meet the company’s data storage, access, and analysis needs.', 'Collaborate with the Development and Operations teams to deploy and maintain clustered computing across multi-cloud environments.', 'Monitor, maintain, and enhance existing data structures to ensure reliability and data integrity.', 'Design and build large-scale, automated ingestions pipelines that integrate across multi-cloud platform and disparate data sources.', 'Evaluate cutting-edge technologies for integration into existing technology stack.', 'Bachelor’s degree in Computer Science or a related field.', '3 years of experience in the job offered or in a related position.', 'Demonstrated proficiency in data analysis and pattern identification.', 'Advanced proficiency with Big Data streaming and processing technologies.', 'Experience using technologies in the Hadoop Ecosystem and Linux/Unix operating systems.', 'Proficiency with a JVM language or experience coding within a functional programming paradigm.', 'Experience with cloud-hosted computing.', 'Experience using a version control system.', 'Strong demonstrated SQL and data modeling skills or experience.', 'Familiarity with Distributed Computing and Parallel Processing frameworks.', 'Familiarity with data science and machine learning concepts or methodologies.', 'Applicants must have the legal authority to work in the United States.']",2020-09-24 14:08:06
Data Engineer,Alltech Nutrition,3 out of 5,"Nicholasville, KY","['Provide expert recommendations to management on data platform technologies, approaches to business application integrations to the platform, and other design/architectural requirements.', 'Develop ETL / ELT jobs in Talend Studio, Talend Pipeline Designer, Microsoft SSIS and Azure Data Factory to move and integrate data from a wide range of data sources.', 'Work closely with data visualization developers and data science experts to refine data requirements', 'Choose and utilize optimal storage and data processing technologies for all data projects', 'Automate data cleansing and data quality processes', 'Setup security and data privacy controls to ensure all requirements for Alltech data are met', '5 years of experience building data integration software', 'Understanding of SQL relational databases and SQL queries', 'Solid grasp of Data Modeling, Data Structures and Algorithms', 'Programming experience, preferably in Java or Python', 'Experience using Microsoft Azure or Amazon Web Services (AWS)', 'Able to work in a fast-paced, multi-site location, team-oriented environment', 'Ability to communicate information to stakeholders at all levels in an effective and courteous manner', 'High level of attention to detail', 'Excellent oral and written communication skills', 'Strong work ethic and a make-it-happen attitude', 'Bachelor’s degree in Computer Science, Computer Information Systems, or equivalent', 'Experience with the following technologies:Data Integration platforms like Talend Studio, SSIS or InformaticaMicrosoft SQL Server including SQL Server Management Studio (SSMS)Database services such as Azure SQL, Azure Synapse, Redshift or Snowflake.Microsoft Common Data Model (CDM) architecturesMicrosoft Common Data Service (CDS) interfacesData Visualization platforms: Power BI, Tableau or TargitAzure and/or AWS cloud-based platforms and data toolsMicrosoft Dynamics 365 software tools', 'Experience with advanced data modeling', 'Understanding of Software Engineering principles', 'Knowledge of Data Warehouse and Data Lake architectures', 'Machine learning experience', 'Sponsorship for work visas is currently unavailable.']",2020-09-24 14:08:06
Associate Engineer,Xactware,3.9 out of 5,"Littleton, CO","['Being part of and contributing to a large, dynamic and innovative community', 'Working with cutting-edge technology, and continuously developing new skills and capabilities', 'Focusing on our customers, their success, and the desire to serve them', 'Being responsible and assuming accountability for everything you touch', 'Enhance the capability and overall reputation of the Infrastructure and Support team, group, and division by offering exceptional customer service and technical ability to both internal and external customers', 'Successfully promote a continuous improvement mindset within operations, engineering, and development groups, that results in measurable efficiency, cost, and process improvement', 'Measurable contribution to the capabilities, security posture and optimization of company technologies', 'Positive feedback on the support received from business partners', 'Positive feedback from team members and leaders of the Verisk community', 'Ability to establish and maintain effective working relationships at all levels of the organization', 'A tangible desire and curiosity to seek out and learn new and innovative ways to manage and solve complex challenges', 'Strong communication skills (written & verbal) and a collaborative, team-oriented approach to work are a must, as is a comfort level working in a fast-paced, federated environment that embraces innovation and experimentation', 'Dependable and flexible with work hours, including nights and weekends as required', ""Prefer 2 years of related experience with a Bachelor's degree in Business or Marketing or related subject; No experience required with an advanced degree; Equivalent work experience"", 'Prefer experience designing, managing, and/or supporting enterprise infrastructure systems', 'Prefer experience with networking concepts (OSI network layers, TCP/IP)', 'Prefer experience with Microsoft Windows and Linux operating systems', 'Prefer experience working with public cloud products and services; AWS or Azure preferred', 'Familiarity with database platforms such as MSSQL, MySQL, and PostgreSQL', 'Desire to learn CI/CD tools and methodologies, system programming and scripting; Desire to develop a scripting/automation mindset', 'Desire to learn integration concepts with enterprise operations and security tools such as Okta, Splunk, SolarWinds, ServiceNow, Infoblox and Imperva', 'Developed customer service skills and experience interfacing with all levels of stakeholders', 'Experience creating technical documentation and using tools including Visio, Word, Excel, Outlook, and PowerPoint', 'No travel required']",2020-09-24 14:08:48
Module Process Engineer,Taiwan Semiconductor Manufacturing Company,3.9 out of 5,"Phoenix, AZ","['401(k)', 'Employee assistance program', 'Employee discount', 'Health insurance', 'Paid time off', 'Parental leave', 'Supplemental Pay:', '401(k)', 'Employee assistance program', 'Employee discount', 'Health insurance', 'Paid time off', 'Parental leave', 'Relocation assistance', 'Monday to Friday', 'Bonus pay', ""Bachelor's (Preferred)"", 'No']",2020-09-24 14:08:48
Data Engineer,FanThreeSixty,2.7 out of 5,"Kansas City, MO 64108","['Develop scalable pipelines to move and transform data between FanThreeSixty systems.', 'Maintain ownership of infrastructure associated with ETL processes.', 'Help guide the development of the data lake infrastructure', 'Strive to mitigate any data quality and accuracy issues and assist data consumers in developing a deeper understanding of the data.', 'Assist in the development of frameworks to integrate analytical output with the broader FanThreeSixty solution', 'Support client consulting engagements as needed.', 'Represent FanThreeSixty in a professional manner at all times.', 'Perform other related tasks as assigned.', 'Strong organizational, communications and interpersonal skills.', 'Ability to organize work effectively, conceptualize and prioritize objectives and exercise independent judgment based on an understanding of organizational policies and activities.', 'Exceptional strategic and analytical thinking skills.', 'Ability to query databases and perform statistical analysis.', 'Strong problem solving skills.', 'Collaboration skills.', 'Ability to confidently present information and analytics.', 'Works both independently and in a team environment to create business solutions.', 'Unrelenting desire to deliver high quality products.', 'Comfortable with cutting-edge technology.', 'Bachelor’s degree in mathematics, statistics, computer science or other related field required.', '3+ years of experience manipulating large datasets and using databases, as well as one (1) to three (3) years of experience with general purpose programming language.', 'Strong backend development skills using Python and Java in a professional environment.', 'Strong background in data engineering (ETL)', 'Experience with open source technologies include Spark, Airflow, Kafka, Elasticsearch, and Docker', 'An understanding of data lakes, data warehousing, and structuring data to address analytics use cases', 'Familiarity with basic principles of distributed computing and/or distributed databases.', 'Basic understanding of the Python data science ecosystem (pandas, scikit-learn, numpy)', 'Knowledge of one or more business/functional areas.', 'Familiar with traditional SQL and NoSQL databases.', 'Proficient in the Google Apps Suite.']",2020-09-24 14:08:48
Data Engineer,Pollen Inc,N/A,"Leawood, KS 66206","['Work closely with Software Engineers, Data Scientists, and Business Analysts to meet the company’s data storage, access, and analysis needs.', 'Collaborate with the Development and Operations teams to deploy and maintain clustered computing across multi-cloud environments.', 'Monitor, maintain, and enhance existing data structures to ensure reliability and data integrity.', 'Design and build large-scale, automated ingestions pipelines that integrate across multi-cloud platform and disparate data sources.', 'Evaluate cutting-edge technologies for integration into existing technology stack.', 'Bachelor’s degree in Computer Science or a related field.', '3 years of experience in the job offered or in a related position.', 'Demonstrated proficiency in data analysis and pattern identification.', 'Advanced proficiency with Big Data streaming and processing technologies.', 'Experience using technologies in the Hadoop Ecosystem and Linux/Unix operating systems.', 'Proficiency with a JVM language or experience coding within a functional programming paradigm.', 'Experience with cloud-hosted computing.', 'Experience using a version control system.', 'Strong demonstrated SQL and data modeling skills or experience.', 'Familiarity with Distributed Computing and Parallel Processing frameworks.', 'Familiarity with data science and machine learning concepts or methodologies.', 'Applicants must have the legal authority to work in the United States.']",2020-09-24 14:08:48
Data Engineer,Alltech Nutrition,3 out of 5,"Nicholasville, KY","['Provide expert recommendations to management on data platform technologies, approaches to business application integrations to the platform, and other design/architectural requirements.', 'Develop ETL / ELT jobs in Talend Studio, Talend Pipeline Designer, Microsoft SSIS and Azure Data Factory to move and integrate data from a wide range of data sources.', 'Work closely with data visualization developers and data science experts to refine data requirements', 'Choose and utilize optimal storage and data processing technologies for all data projects', 'Automate data cleansing and data quality processes', 'Setup security and data privacy controls to ensure all requirements for Alltech data are met', '5 years of experience building data integration software', 'Understanding of SQL relational databases and SQL queries', 'Solid grasp of Data Modeling, Data Structures and Algorithms', 'Programming experience, preferably in Java or Python', 'Experience using Microsoft Azure or Amazon Web Services (AWS)', 'Able to work in a fast-paced, multi-site location, team-oriented environment', 'Ability to communicate information to stakeholders at all levels in an effective and courteous manner', 'High level of attention to detail', 'Excellent oral and written communication skills', 'Strong work ethic and a make-it-happen attitude', 'Bachelor’s degree in Computer Science, Computer Information Systems, or equivalent', 'Experience with the following technologies:Data Integration platforms like Talend Studio, SSIS or InformaticaMicrosoft SQL Server including SQL Server Management Studio (SSMS)Database services such as Azure SQL, Azure Synapse, Redshift or Snowflake.Microsoft Common Data Model (CDM) architecturesMicrosoft Common Data Service (CDS) interfacesData Visualization platforms: Power BI, Tableau or TargitAzure and/or AWS cloud-based platforms and data toolsMicrosoft Dynamics 365 software tools', 'Experience with advanced data modeling', 'Understanding of Software Engineering principles', 'Knowledge of Data Warehouse and Data Lake architectures', 'Machine learning experience', 'Sponsorship for work visas is currently unavailable.']",2020-09-24 14:08:48
Data / Signal Processing Engineer,"Applied Research Associates, Inc",4 out of 5,"Dayton, OH 45390","['Bachelor’s Degree in Mathematics, Physics, or Engineering or similar field with 2-4 years of relevant experience.', 'U.S. Citizenship is required.', 'Active DoD Secret or higher clearance.', 'Must be able to obtain and maintain a TS Clearance.', 'Strong understanding of MATLAB, IDL, and/or Python.', 'Strong understanding of signal processing for analog and digital systems such as digital filtering, detection and estimation theory, linear algebra and stochastic processes.', 'Strong familiarity with statistical analysis methods such as Sample Size Determination, Principal Components Analysis (PCA) and K-Means Clustering (K Clustering).', 'Strong understanding of image processing techniques.', 'Application of the scientific method to complex systems, including the ability to define and execute tests, reduce data, and perform statistical analysis.', 'Strong written and verbal communications skills.', 'Leadership, presentation, and collaboration skills.', 'Produce reports documenting methods and reasoning, choice of methods selected, and results with error analysis.', 'Document research through technical reports and papers.', 'Maintain a regular and predictable work schedule.', 'Interact appropriately with others in order to maintain a positive and productive work environment.', 'Ability to travel two or three times a year for several days each. Other trips required but much shorter duration. Travel on military and contractor aircraft maybe required. U.S. travel to remote sites to support test and demonstration events may be required.', 'Master’s Degree in Mathematics, Physics, or Engineering', 'Experience with SIMULINK or C++', 'Experience working in a Research and Development (R&D) environment', 'Experience developing and integrating signal and image processing techniques', '2 year(s): Software', '4 year(s): Hardware', '2 year(s): Systems Integration', 'Bachelor of Science or better in Electrical Engineering or related field', 'Bachelor of Science or better in Physics or related field', 'Bachelor of Science or better in Engineering or related field', 'Bachelor of Science or better in Computer Science or related field', 'Security Clear Secret', 'Team Player: Works well as a member of a group', 'Dedicated: Devoted to a task or purpose with loyalty or integrity', 'Functional Expert: Considered a thought leader on a subject', 'Leader: Inspires teammates to follow them', 'Ability to Make an Impact: Inspired to perform well by the ability to contribute to the success of a project or the organization', 'Flexibility: Inspired to perform well when granted the ability to set your own schedule and goals', 'Goal Completion: Inspired to perform well by the completion of tasks', 'Growth Opportunities: Inspired to perform well by the chance to take on more responsibility', 'Self-Starter: Inspired to perform without outside help']",2020-09-24 14:08:48
Data Engineer II,Ryder,3.4 out of 5,"Franklin, TN 37067",[],2020-09-24 14:08:48
Project Engineer II - Data Engineer,Ball Aerospace,3.8 out of 5,"Boulder, CO 80301","['Coordinates the technical and business-related activities (requirements & data model definition, sample data sets, mock data migration rounds, and data validation by selected end users) including cost, schedule and resource planning.', 'Generate schedule and resource plan for data cleanup activities.', 'Supports SIT, UAT, and production deployment from a migration resource and schedule perspective.', 'Track performance against cost and schedule as well as verifying the effort is meeting the technical specifications to include:', 'Ensures environments are available with proper access – working with IT', 'Guides decision making process holding people accountable', 'Be able to provide and communicate understanding of both the technical and programmatic aspects of a project to the project team as well as the internal customers.', 'Promote development of a strong data management team by participation in key aspects of the project and mentoring more junior team members. When delegating, establish clear expectations by providing well-defined tasks with clear entrance/exit criteria, due dates, and associated budgets.', 'Leads workshops on data identification, cleansing, and enrichment', 'Generate cost estimates for updates and additions to existing plans.', 'Identify, track, and address risks and opportunities, including helping target programs identify their specific data migration needs.', 'Develop detailed data management team schedules and manage/status team activities to meet delivery milestones.', 'Manage company-wide technical data priorities in relation to project specific technical and programmatic data priorities via alignment with the Enterprise Data Governance Board.', 'Demonstrate excellent interpersonal skills, strong written, communication, oral presentations skills, and ability to lead group discussions.', 'Provide timely feedback to team members about his/her performance. Seek opportunities to recognize outstanding performance via the Employee Recognition Process. Address poor performance appropriately.', 'Maintain a regular and predictable work schedule.', 'Establish and maintain effective working relationships within the department, the Strategic Business Units, Strategic Support Units and the Company. Interact appropriately with others in order to maintain a positive and productive work environment.', 'Perform other duties as necessary.', 'BS degree or higher in Engineering or a related technical field is required plus 12 or more years related experience.', 'Each higher-level degree, i.e. master’s degree or Ph.D., may substitute for two years of experience. Related technical experience may be considered in lieu of education. Degree must be from a university, college, or school which is accredited by an agency recognized by the US Secretary of Education, US Department of Education.', 'Experience in database development, ETL tools, scripting.', 'Understanding of data warehousing concepts.', 'Understands mock data migration cycles', 'Understands current state data model vs. future state data model to ensure data fidelity following data migrations', 'Understanding of/experience with DEV/OPS and utilizing Agile Methodology to execute large scale software projects.', 'Experience successfully identifying and deploying process/product improvements.', 'Demonstrated ability to develop project cost and schedule estimates and respective status reports', 'Attention to detail, self-motivation and go-getter attitude is required.', 'Demonstrated ability to achieve results by inspiring and connecting with the team and internal customers. Able to take a stand for what is right and demonstrate humility.', 'Demonstrated ability to manage the cost, schedule, and technical project baselines through risk and opportunity management. Able to monitor and manage the project baselines for internal and external changes.', 'Excellent written, verbal and presentation skills.', 'Work is performed in an office, laboratory, production floor, clean room, outdoors or remote research environment.', 'Travel and local commute between Ball campuses and other possible non-Ball locations may be required.']",2020-09-24 14:08:48
Campus: Data Scientist (2021 Start),Optiver US,3.8 out of 5,"Chicago, IL","['Quantitatively analyze trade and market data', 'Use a multitude of mathematical techniques to identify patterns in financial markets', 'Collaborate with Traders and Data Scientists to develop strategies based on identified patterns', 'Rigorously back-test prototyped trading strategies', '0-1 year of internship or research experience', ""Graduating with a Bachelor's degree in Statistics, Computer Science or STEM related field"", 'Proficiency with Python', 'Solid understanding of statistics', 'Experience with large data sets', 'The ability to think independently and work collaboratively with Traders and Developers', 'Legal authorization to work in the U.S. is required. We will not sponsor individuals for employment authorization for this job opening.']",2020-09-24 14:08:48
Data Engineer,GM Financial,3.7 out of 5,"Arlington, TX 76014","['Contribute to the evaluation, research, experimentation efforts with batch and streaming data engineering technologies in a lab to keep pace with industry innovation', 'Work with data engineering related groups to inform on and showcase capabilities of emerging technologies and to enable the adoption of these new technologies and associated techniques', 'Contribute to the definition and refinement of processes and procedures for the data engineering practice', 'Work closely with data scientists, data architects, ETL developers, other IT counterparts, and business partners to identify, capture, collect, and format data from the external sources, internal systems and the data warehouse to extract features of interest', 'Code, test, deploy, monitor, document and troubleshoot data engineering processing and associated automation', 'Perform other duties as assigned', 'Conform with all company policies and procedures', 'Experience with processing large data sets with Kafka, RabbitMQ, Flume, Hadoop, HBase, Cassandra and/or Spark or similar distributed system', 'Experience with NoSQL data stores such as MongoDB, Cassandra, HBase, Redis, Riak or other technologies that embed NoSQL with search such as MarkLogic or Lily Enterprise', 'Experience or familiarity with ETL and Business Intelligence technologies such as Informatica, DataStage, Ab Initio, Cognos, BusinessObjects or Oracle Business Intelligence', 'Ability to quickly prototype and perform critical analysis and use creative approaches for solving complex problems', 'Excellent written and verbal communication skills', 'High School Diploma or equivalent required', 'Bachelor’s Degree in related field or equivalent work experience preferred', '2-4 years of hands-on experience with SQL, data modeling, and relational databases such as Oracle, DB2 and Postgres required', 'Minimum of 1 year of experience with software engineering to include Java, Scala and Python required #LI-TS1']",2020-09-24 14:08:48
Healthcare Data Analyst (Engineer) I-Anesthesia,Boston Children's Hospital,4.1 out of 5,"Boston, MA 02115","['Communicating directly with clinicians to gather requirements throughout the project.', 'Supporting various research groups within the Anesthesia Department with their data needs:', 'Curating ad-hoc datasets/reports from Electronic Medical Record,', 'Building and supporting data warehouses,', 'Data wrangling/cleaning,', 'Data validation and documentation,', 'Statistical Analysis,', 'Visualization.', 'Taking part in internal infrastructure projects involving workflow orchestration, data warehousing, and visualization.', 'A bachelor’s degree in Computer Science or STEM field and 1+ years of work experience.', 'Experience with relational databases and SQL.', 'Proficiency in Python (pandas).', 'Experience designing and implementing ETL pipelines using Python.', 'Familiarity with building dynamic dashboards using tools such as Tableau or Microstrategy.', 'Proficiency in Statistical/Machine Learning', 'Experience with healthcare data', 'Familiarity with R', 'Familiarity with distributed frameworks for Big Data', 'LN']",2020-09-24 14:08:48
Active Directory Engineer,Simplex Info Systems Inc,N/A,"North Chicago, IL","['Quest Security Explorer (experience preferred but not required)', 'Quest Migration Manager (experience preferred but not required)', 'Windows Server Administration – Enterprise environment', 'Active Directory Security Groups – Subject Matter Expert', 'NTFS File Share permissions - Subject Matter Expert', 'Active Directory Migration project experience required', 'MS Excel – manage and convert large csv files to reports', 'Use AbbVie applications (MS Outlook, Jabber, MS Teams, WebEx)', 'Run Security Explorer NTFS exports and create reports using Excel', 'Use SE to grant and revoke File Share permissions', 'Prepare input files and perform user migrate / merge', 'Prepare input files and perform group migrations', 'Perform group sync or start / re-sync as appropriate', 'Run PowerShell scripts to create reports', 'Analyze report data', 'Monday to Friday', 'No']",2020-09-24 14:08:48
Data Engineer,Abacus Group LLC,3 out of 5,"Charlotte, NC 28277","['Robust benefits package: medical, dental, vision, disability, life insurance, 401k, and PTO', 'Performance bonus', 'Workplace perks such as healthy snacks, wellness program, and fun events', 'Design scalable data pipelines to be consumed by other development teams', 'Research new systems for integration by reading technical/API/database documentation', 'Develop data ingestion and integrations (REST, SOAP, SFTP, MQ, etc.) using C#/SQL/PowerShell', 'Create documentation and support procedures for new pipelines', 'Create tools and procedures for monitoring the health of all enterprise data feeds', 'Participate in architecture design and discussions', 'Provide logical and physical data design, and database modeling', 'Support the development and design of the internal data integration framework', 'Incorporate standards and best practices into engineering solutions', 'Solve complex data issues around data integration, unusable data elements, unstructured data sets, and other data processing incidents', 'Work with system owners to resolve source data issues and refine transformation rules', 'Be part of an Agile development team to collaborate and to help shape requirements', 'Manage code versions in source control and coordinate changes across team', 'Understand business process that both generate and consume the data', 'Perform data analysis in support of various department initiatives', 'Strong experience and proficiency with best practices for deploying data integration architectures used for data management (ETL)', 'Advanced knowledge of SQL, including tuning queries for performance', 'Experience with at least one scripting language (Python, PowerShell, etc.)', 'Intermediate/Advanced Excel skills (VBA, array functions, etc.)', 'Strong understanding of past practices for database structures and data modelling that are used for both transactional and reporting systems', 'Experience working with REST/SOAP APIs as data sources for integration', 'Experience maintaining enterprise data architecture and data flow documentation', 'Experience with at least one object oriented programming language (C#, Java, C++, etc.) preferred', 'Experience with enterprise reporting/BI tools (SSIS, MDX, SSAS, etc.) preferred', 'Experience defining and building REST/SOAP APIs preferred', 'Passionate about helping people', 'Curious about how things work', 'Enjoys collaboration with other professionals', 'Thinks critically and does not hesitate to provide critical feedback', '5+ years of experience in a Data Engineer or similar role', 'Experience managing 20+ interrelated enterprise data feeds', 'Expert knowledge of IT Infrastructure (Office 365, Duo, Active Directory, Azure, etc.)', 'Experience working with a diverse and geographically dispersed team', 'Ability to quickly adapt to changing business requirements', 'Actively strives for a work-life balance, and happiness', 'Exposure to diverse array of technologies', 'Part of a team of experienced technicians that aim to deliver exceptional service', 'Competitive compensation', 'Robust benefits package: medical, dental, vision, disability, life insurance, 401k, and PTO', 'Performance bonus', 'Opportunities to further technical education through online courses', 'Positive, friendly, supportive office environment', 'Workplace perks such as healthy snacks, wellness program, and fun events']",2020-09-24 14:08:48
Complaint Specialist,Philips,4 out of 5,Remote,"['Evaluate, investigate, track and complete complaints through effective and established complaint handling processes.', 'Ensure accurate documentation of evaluation and investigation results with the assigned complaint records.', 'Participate and collaborate objectively with team members to achieve consistent processes while identifying process improvements to drive efficiency and compliance.', 'Review information provided from the call center, field organization and customer feedback systems and provide evaluation as to whether these service events constitute complaints.', 'Identify product characteristics and/or failures that could lead to death or serious injury.', 'Coordinate with team members in obtaining any missing information.', 'Collaborate with a variety of diverse persons such as Engineers, Scientists, Clinical Specialists, Field Service Engineers, Professional Customers and Manufacturing personnel to facilitate the complaint investigation process globally.', 'Review each complaint and determine eligibility for adverse event reporting to worldwide regulatory agencies.', 'Other projects as assigned.', 'US work authorization is a precondition of employment. The company will not consider candidates who require sponsorship for a work-authorized visa.', '1+ year of post-market complaints experience in a medically regulated industry.', 'Bachelor’s degree in engineering, clinical sciences, related sciences, or relevant related experience- highly preferred', 'Proficiency using office tools such as Microsoft Office Suite and various other computer software applications.', 'Working knowledge of appropriate global medical device regulations, requirements, and standards such as ISO 13485 and ISO9001, and FDA QSR. Medical Device and or other regulated industry (Pharma, IVD,) preferred.', 'An organized, analytical thinker with exceptional attention to detail.', 'An excellent communicator, both written and verbal for coordinating with colleagues and regulatory authorities worldwide.', 'Able to exercise sound judgment within Philips using standard operating procedures and policies to determine appropriate action to achieve objectives.', 'Must be able to work under pressure to meet regulatory reporting time frames and company requirements.', 'Experience in TrackWise or similar system is preferable.']",2020-09-24 14:08:48
Big Data Hadoop Engineer,Resiliency LLC,N/A,"Pleasanton, CA","['4+ years of hands-on Development, Deployment and production Support experience in Big Data environment.', '4-5 years of programming experience in Java, Scala, Python, Solr, Hbase', 'Proficient in SQL and relational database design and methods for data retrieval.', 'Hands-on experience in Cloudera Distribution 6.x', ""Must have experience with Spring framework, Web Services and REST API's."", 'Project Experience in Query Processing Language (QPL) – a search engine independent technology for Advance Query Processing is highly desirable.', 'Supplier Personnel will make every effort to provide skills enhancement at a satisfactory rate and report any issues that may impede the progress of training and mentoring.', 'Supplier Personnel resources shall provide input to Contract Executive to develop training and mentoring plan to include specific skill sets, tasks, and training methodologies.', 'Supplier Personnel will be responsible to execute the training and mentoring plan(s) with designated Client employees and shall provide input to refine and further develop training and mentoring plans as training progresses.', 'Supplier Personnel shall meet and discuss progress of training to Client on a monthly basis.|', 'Client Contract Executive will be responsible to document a training plan on the “Mentoring & Skill Enhancement Planner” and to monitor progress of training and mentoring with the Client employee(s). The Mentoring & Skill Enhancement Tracker and Planner are provided as Attachment C to this SOW.', 'Project Experience in Query Processing Language (QPL) – a search engine independent technology for Advance QueryProcessing is highly desirable.', '4+ years of hands-on Development, Deployment and production Support experience in Big Data environment.', '4-5 years of programming experience in Java, Scala, Python.', 'Proficient in SQL and relational database design and methods for data retrieval.', 'Knowledge of NoSQL systems like HBase or Cassandra', 'Hands-on experience in Cloudera Distribution 6.x', 'Hands-on experience in creating, indexing Solr collections in Solr Cloud environment.', 'Hands-on experience building data pipelines using Hadoop components Sqoop, Hive, Solr, MR, Impala, Spark, Spark SQL.', 'Must have experience with developing Hive QL, UDF’s for analyzing semi structured/structured datasets.', ""Must have experience with Spring framework, Web Services and REST API's."", 'Hands-on experience ingesting and processing various file formats like Avro/Parquet/Sequence Files/Text Files etc.', 'Must have working experience in the data warehousing and Business Intelligence systems.', 'Expertise in Unix/Linux environment in writing scripts and schedule/execute jobs.', 'Successful track record of building automation scripts/code using Java, Bash, Python etc. and experience in production', 'Experience in building ML models using MLLib or any ML tools.', 'Hands-on experience working in Real-Time analytics like Spark/Kafka/Storm', 'Experience with Graph Databases like Neo4J, Tiger Graph, Orient DB', 'Agile development methodologies.']",2020-09-24 14:08:48
Complaint Specialist,Philips,4 out of 5,Remote,"['Job', 'Company', 'Evaluate, investigate, track and complete complaints through effective and established complaint handling processes.', 'Ensure accurate documentation of evaluation and investigation results with the assigned complaint records.', 'Participate and collaborate objectively with team members to achieve consistent processes while identifying process improvements to drive efficiency and compliance.', 'Review information provided from the call center, field organization and customer feedback systems and provide evaluation as to whether these service events constitute complaints.', 'Identify product characteristics and/or failures that could lead to death or serious injury.', 'Coordinate with team members in obtaining any missing information.', 'Collaborate with a variety of diverse persons such as Engineers, Scientists, Clinical Specialists, Field Service Engineers, Professional Customers and Manufacturing personnel to facilitate the complaint investigation process globally.', 'Review each complaint and determine eligibility for adverse event reporting to worldwide regulatory agencies.', 'Other projects as assigned.', 'US work authorization is a precondition of employment. The company will not consider candidates who require sponsorship for a work-authorized visa.', '1+ year of post-market complaints experience in a medically regulated industry.', 'Bachelor’s degree in engineering, clinical sciences, related sciences, or relevant related experience- highly preferred', 'Proficiency using office tools such as Microsoft Office Suite and various other computer software applications.', 'Working knowledge of appropriate global medical device regulations, requirements, and standards such as ISO 13485 and ISO9001, and FDA QSR. Medical Device and or other regulated industry (Pharma, IVD,) preferred.', 'An organized, analytical thinker with exceptional attention to detail.', 'An excellent communicator, both written and verbal for coordinating with colleagues and regulatory authorities worldwide.', 'Able to exercise sound judgment within Philips using standard operating procedures and policies to determine appropriate action to achieve objectives.', 'Must be able to work under pressure to meet regulatory reporting time frames and company requirements.', 'Experience in TrackWise or similar system is preferable.']",2020-09-24 14:09:28
Big Data Hadoop Engineer,Resiliency LLC,N/A,"Pleasanton, CA","['4+ years of hands-on Development, Deployment and production Support experience in Big Data environment.', '4-5 years of programming experience in Java, Scala, Python, Solr, Hbase', 'Proficient in SQL and relational database design and methods for data retrieval.', 'Hands-on experience in Cloudera Distribution 6.x', ""Must have experience with Spring framework, Web Services and REST API's."", 'Project Experience in Query Processing Language (QPL) – a search engine independent technology for Advance Query Processing is highly desirable.', 'Supplier Personnel will make every effort to provide skills enhancement at a satisfactory rate and report any issues that may impede the progress of training and mentoring.', 'Supplier Personnel resources shall provide input to Contract Executive to develop training and mentoring plan to include specific skill sets, tasks, and training methodologies.', 'Supplier Personnel will be responsible to execute the training and mentoring plan(s) with designated Client employees and shall provide input to refine and further develop training and mentoring plans as training progresses.', 'Supplier Personnel shall meet and discuss progress of training to Client on a monthly basis.|', 'Client Contract Executive will be responsible to document a training plan on the “Mentoring & Skill Enhancement Planner” and to monitor progress of training and mentoring with the Client employee(s). The Mentoring & Skill Enhancement Tracker and Planner are provided as Attachment C to this SOW.', 'Project Experience in Query Processing Language (QPL) – a search engine independent technology for Advance QueryProcessing is highly desirable.', '4+ years of hands-on Development, Deployment and production Support experience in Big Data environment.', '4-5 years of programming experience in Java, Scala, Python.', 'Proficient in SQL and relational database design and methods for data retrieval.', 'Knowledge of NoSQL systems like HBase or Cassandra', 'Hands-on experience in Cloudera Distribution 6.x', 'Hands-on experience in creating, indexing Solr collections in Solr Cloud environment.', 'Hands-on experience building data pipelines using Hadoop components Sqoop, Hive, Solr, MR, Impala, Spark, Spark SQL.', 'Must have experience with developing Hive QL, UDF’s for analyzing semi structured/structured datasets.', ""Must have experience with Spring framework, Web Services and REST API's."", 'Hands-on experience ingesting and processing various file formats like Avro/Parquet/Sequence Files/Text Files etc.', 'Must have working experience in the data warehousing and Business Intelligence systems.', 'Expertise in Unix/Linux environment in writing scripts and schedule/execute jobs.', 'Successful track record of building automation scripts/code using Java, Bash, Python etc. and experience in production', 'Experience in building ML models using MLLib or any ML tools.', 'Hands-on experience working in Real-Time analytics like Spark/Kafka/Storm', 'Experience with Graph Databases like Neo4J, Tiger Graph, Orient DB', 'Agile development methodologies.']",2020-09-24 14:09:28
Data Engineer with HL7 Experience,Data-Core Systems Inc,3.7 out of 5,"Philadelphia, PA 19103","['Experience:Python,Scala, 2 years (Required)AWS, SQL,data pipeline, 2 years (Required)BigData, 3 years (Required)HealthCare-HL7, 3 years (Required)Data Engineer , 8 years (Required)', 'Python,Scala: 2 years (Required)', 'AWS, SQL,data pipeline: 2 years (Required)', 'BigData: 3 years (Required)', 'HealthCare-HL7: 3 years (Required)', 'Data Engineer : 8 years (Required)', 'Yes']",2020-09-24 14:09:28
Data Engineer - Orion,id Software,4.5 out of 5,"Dallas, TX","['3+ years of experience in a data warehousing, data engineering, or data architect role', 'Experience with full life cycle development, architecture and implementation, of an enterprise data warehouse.', 'Experience working with AWS data technologies such as S3, Redshift Spectrum, Athena, Data Pipeline, Glue, EMR, RDS, and Kinesis', 'Expert level SQL skills', 'Data modeling experience for both transactional and data warehousing environments.', 'Experience working with a variety of data sources such as MySQL, Oracle, SQL Server, PostgreSQL, S3, HDFS, and MongoDB', 'Strong interpersonal skills and problem-solving ability', 'Build new and extend existing data structures to support real-time analytics for Orion services', 'Maintain large, multi-terabyte data warehouse which includes performance tuning and data retention/purge processes', 'Research and troubleshoot data quality issues, providing fixes and proposing both short- and long-term solutions', 'Prepare designs for database systems and recommend improvements for performance.', 'Maintain and develop various database scripts and tools to facilitate automation process', 'Provide support to all data warehouse initiatives.', 'Experience with infrastructure as code to support systems developed', 'Experience with Python and Linux shell scripting', 'Experience using source control systems (Git, Perforce, SVN, etc.)']",2020-09-24 14:09:28
"Junior Software Engineer, Front-End",CharterUP,N/A,"San Francisco, CA","['$70,000 base salary', 'Material equity award with standard vesting', 'Efficiently roll out technical features from concept to product', 'Collaborate with a team to develop our next generation travel platform', 'Develop tooling and processes to benefit and grow our team', ""Bachelor's degree in Computer Science, Computer Engineering, or similar STEM degree from a top-ranked institution"", 'Front-end proficiency in Vue, React, or Angular', 'Willingness to develop Back-end expertise in Java Spring Boot or Hibernate', 'Potential to quickly develop expertise in any part of our tech stack where you have limited experience', 'Candidate submits CharterUP online applicationResumes encouraged to be at most one page in length', 'Initial evaluationCandidate may be asked to submit a sample of their work or complete a quick hack', 'InterviewsCandidate to meet with various members of the dev team, including CTO, product leads, and senior engineersCandidate to meet with founder, head of recruiting, or other members of the executive team', 'TestingCoding exerciseGeneral aptitude assessment', 'OfferBackground and reference checks prior to formal offer', 'Customer FirstWe always think about how our decisions will impact our clients; earning and keeping customer trust is our top priorityWe are not afraid of short-term pain for long-term customer benefit', 'Create an Environment for Exceptional PeopleWe foster intellectual curiosityWe identify top performers, mentor them, and empower them to achieveEvery hire and promotion will have a higher standard', 'Everyone is an Entrepreneur / OwnerNo team member is defined by their function or job title; no job is beneath anyoneWe do more with less; we are scrappy and inventiveWe think long-term', 'Relentlessly High StandardsWe don’t accept “that’s how it’s always been done”; we constantly innovate and question established routines to improve processesWe actively push to be proved wrong and welcome different ideas; the best idea winsWe don’t compromise on quality', 'Clarity & SpeedWhen in doubt, we act; we can always change courseWe focus on the key drivers of a process that will deliver the most results', 'Mandate to Dissent & CommitWe are confident in expressing our opinions; it is our obligation to express our disagreementOnce we decide, we enthusiastically move together in the agreed upon direction']",2020-09-24 14:09:28
Data Science Contractor,CollegeVine,4 out of 5,Remote,"['A well-commented program (something like a Jupyter notebook is fine) that generates the ""natural"" clusters of our students. Ideally the weighting of individual features should be configurable. The output will be a clustering model we can use on new users.', 'A well-commented program (something like a Jupyter notebook is fine) that takes a clustering model and two sets of chancing parameters (A & B) as input. The program must output and visualize the delta between the A & B chancing parameters for each cluster.', 'A CSV containing the user data to be clustered.', 'A CSV containing the current chancing model parameters', 'Access to our internal documentation and APIs showing you how to apply our chancing algorithm to a set of user profiles and model parameters.']",2020-09-24 14:09:28
FEA Engineer - Application,Cooper Tire & Rubber Company,3.6 out of 5,"Findlay, OH","['You are responsible for building and maintaining the infrastructure of FEA modeling and engineering analysis, along with verification and validation of simulation models.', 'You will analyze nonlinear behavior which is difficult to be observed experimentally. And you will deliver and communicate your models and results within the Predictive Technology team as well as internal customers and multi-functional peers.', 'Based on analytical and numerical approaches, you will propose solutions and inform the design to meet product performance requirements in a fast-paced work environment.', 'You will participate in team brainstorming and new technology development.', 'You will develop new simulation tools and capabilities as needed.', 'Enthusiasm for creating high quality, affordable products.', 'Excellent verbal and written communication skills.', 'Rigorous knowledge of solid and structural mechanics.', 'Experience in static and dynamic finite element analysis.', 'Experience in model validation techniques.', 'Expertise in at least one of the following: Abaqus, Ansys, Nastran, LS-DYNA, COMSOL.', 'Scientific programming in at least two of the following: Python, Matlab, Fortran, C++, Julia.', 'Knowledge of managing high-performance computing systems.', 'Bachelor’s degree in Mechanical Engineering, Applied Mechanics, Engineering Physics, Aerospace Engineering, Civil Engineering, Biomechanics, or similar.', 'Experience in machine learning.', 'Experience in managing big data.', 'Experience in writing finite element solvers.', 'Experience in experimental material testing.', 'Experience in building and calibrating non-linear material models.', 'Knowledge of mechanics of laminated composite materials.', 'Knowledge of theory and practice of the finite element method applied to problems involving nonlinear solids, undergoing high strains, with contact and friction.', 'Master degree or Ph.D. in Mechanical Engineering, Applied Mechanics, Engineering Physics, Aerospace Engineering, Civil Engineering, Biomechanics, or similar.']",2020-09-24 14:09:28
Data Engineer,"Futuresoft IT, LLC",N/A,"Detroit, MI",[],2020-09-24 14:09:28
Mail & Production Print Services Engineer,Ricoh,3.4 out of 5,United States,"['Technical Domain Expertise -practical/direct expertise in one of our 8 Areas of Expertise: enterprise content management, application development, IT Projects & Services, advanced computing (including virtualization and/or mainframe/legacy), datacenter & cloud services, workstyle innovation and advanced mobility, or information data management, information sciences, information migration.', 'Preference will be to individuals that have a deep based technical or business expertise and are also deep in one or more specific industries like insurance, healthcare, banking & financial services, retail, manufacturing, energy, life sciences, etc.', 'Possesses excellent oral communication skills; speaks clearly and persuasively in positive or negative situations.', 'Possesses ability to solve practical problems and deal with a variety of concrete variables in situations where only limited standardization exists.', 'Possesses ability to interpret variety of instructions furnished in written/oral/diagram/schedule form.', 'Ability to read and comprehend written technical information.', 'Self-starter with excellent time management and organizational skills and requiring minimal direct supervision; is dependable, enthusiastic, entrepreneurial and self-motivated.', 'Possesses ability to work in fast paced and changing environment. Possesses excellent telephone skills in order to articulate a message via conference call.', 'Understands business implications of decisions; aligns work with strategic goals, is cost conscious. Exhibits sound and accurate judgment; supports and explains reasoning for decisions.', 'Team player who puts the effectiveness of the team and success of the company above all.', 'Effective strategist with experience researching and examining industry data, trends, issues, etc.; with an ability to interpret and analyze information and share best practices and advice with c-level executives.', 'Develops a strong rapport with senior leaders in multiple client environments.', ""This role will require strong subject matter expertise in a defined domain and will not function as a generalist. Collaborates across multiple function areas and departments within Ricoh in order to support the full breadth of Ricoh's (inclusive of mindSHIFT's) Premium services offerings."", 'Applies a consultative approach with decision makers and stakeholders.', 'Coordinate, facilitate and consult with various departments on information systems, communications, document capture and distribution technologies and other initiatives.', ""This position requires a minimum of a bachelor's degree in a related field, with an advanced degree preferred; 5- 10 years' related experience in business and technology; or an equivalent combination of education and/or experience."", 'Must have a minimum 5 years direct experience in at least 1 or more of the key domains including: organizational change management, business process management, shared services/capture center of excellence, supply chain & distribution, analytics & business intelligence, governance, risk, regulatory compliance, enterprise content management, application development, IT Projects & Services, advanced computing (including virtualization and/or mainframe/legacy), datacenter & cloud services, workstyle innovation and advanced mobility, or information data management, information sciences, information migration.', 'Requires six to ten years experience in the areas of business production printing, preferably leveraging InPlant/POD, workflow automation, variable data document production, output management, web-to-print, MIS systems and postal processing technologies', 'Must have strong presentation and deliverable skills.', 'Must be experienced in setting goals by defining and prioritizing specific and realistic objectives.', 'Must understand the buying cycles and methodologies associated with Strategic customers and be able to accurately forecast revenue and define solutions that deliver profitability.', 'Strong, proven experience exhibiting business analysis skills, project management skills, executive skills, technical skills, and a deep understanding of industry trends is required.', 'Expertise in researching industries, technologies, and customers to ensure the appropriate level of intelligence during sales engagements.', 'This position requires 75% plus travel.']",2020-09-24 14:09:28
"Manager, Big Data Engineer",KPMG,4 out of 5,"Las Vegas, NV 89169","['Job', 'Company', 'Rapidly architect, design, prototype, implement, and optimize cloud architectures, platforms and applications to tackle the needs for a variety of Fortune 1000 corporations and other major organizations; develop cloud platforms and applications using infrastructure as code methodologies to solve real world problems ensuring quality and compliance following best practices in the industry', 'Work in cross-disciplinary teams with KPMG industry professionals to understand client needs and be part of teams developing holistic operational solutions & applications contributing with the cloud infrastructure', 'Research, experiment, and utilize leading cloud methodologies and new tools for increased productivity, security, reliability and performance; provide proficient documentation and operating guidance for users of all levels', 'Develop skills in business requirement capture and translation, hypothesis-driven consulting, work stream and project management, and client relationship development; help promote the KPMG brand in the broader data analytics community', 'Help drive the process for pursuing innovations, target solutions, and extendable platforms for Lighthouse, KPMG, and clients; participate in developing and presenting thought leadership and help to ensure that the Lighthouse technology stack incorporates and is optimized for using specific technologies', 'A minimum of seven years of experience architecting and/or implementing conversational systems / chatbots with platforms such as IBM Watson, Google Dialogflow etc.', ""Bachelor's degree from an accredited college/university or Master's degree from an accredited college/university with minimum two years of experience; or a PhD in Computer Science, Computer Engineering, Engineering or related fields from an accredited college/university"", 'Experience in API Management with platforms such as IBM API Connect, Google Apigee etc.', 'Experience in enterprise integration with atleast one ESB such as IBM IIB, Boomi, MuleSoft etc.', 'Experience producing architecture work products incl experience with UML tools', 'Required: Architect or specialization certification in at least one of AWS / Azure / GCP.', 'Preferred: Experience with IVR/Telephony integration.', 'Good understanding and broad exposure to the AI capability landscape including semantic search, speech systems, information extraction etc.', 'Ability to travel up to eighty percent', 'Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future']",2020-09-24 14:09:28
Data Analyst,Cisco Systems,4.1 out of 5,"Research Triangle Park, NC",[],2020-09-24 14:09:28
Data Engineer,FCA,4 out of 5,"Southfield, MI 48033",[],2020-09-24 14:09:28
HR Coordinator,Dialpad,4.8 out of 5,"Austin, TX 78701","['Administer employee benefit programs, including health benefits, open enrollment, 401(k), perks and wellness', ""An apple a day keeps the doctor away - and it doesn't hurt that we offer 100% paid medical, dental, and vision plans for all employees."", 'Reimbursements', 'We offer a monthly stipend to help cover your cell phone, home internet, and even gym membership costs.', 'Own and administrator employee lifecycle processes including onboarding, offboarding, personnel changes, leaves of absences and compliance', 'Provide ongoing support to all employees globally', 'Administer employee benefit programs, including health benefits, open enrollment, 401(k), perks and wellness', 'Support and maintain data integrity in HR systems with a high level of accuracy', 'Support recruiting team with interview coordination', 'Manage and improve key HR tools, processes and workflows to keep our organization running smoothly', 'Support people programs involving employee experience, engagement, learning & development, performance management, recognition, and communication', 'Identify opportunities for improvement and assist with communication, implementation and change management of various programs and initiatives', 'A go-getter who can own a project with varying levels of instruction and run with it', 'Enthusiasm and willingness to be a team player', 'Ability to thrive in a fast-paced startup environment', 'Previous work experience in HR a plus', 'Strong attention to detail', 'Strong interpersonal skills with the ability to listen and empathize with others and anticipate, respond, and pivot to the needs of the employees and business', 'You are a problem solver, not a problem finder', 'You have a demonstrated ability to handle confidential information with total discretion', 'A sense of humor is a must :)']",2020-09-24 14:09:28
Data Azure Engineer,IST Inc.,N/A,"Dallas, TX","['Pay:', '$60.00 - $62.00 per year', 'Experience:core java, 3 years (Required)Azure, 2 years (Required)Databricks, 2 years (Required)', 'Monday to Friday', 'core java: 3 years (Required)', 'Azure: 2 years (Required)', 'Databricks: 2 years (Required)', '7 - 11 months', 'Temporarily due to COVID-19']",2020-09-24 14:09:28
Machine Learning Engineer,Triplebyte,5 out of 5,California,"['Competitive salary and stock options package', 'Open vacation policy', 'Employer paid health, vision and dental insurance', '401(k) plan with matching', 'Pre-tax commuter benefits', 'Psychometrics', 'Recommender systems', 'Time series analysis', 'Survival analysis', 'Bayesian inference', 'Probabilistic programming', ""Robust exploratory/experimental skills. We have a novel dataset of candidate profiles and interview outcomes from our candidate screening process and our hiring marketplace. You'll be responsible for designing and evaluating experiments to predict downstream outcomes."", 'Ability to implement models from research. Some of our best improvements in both speed and predictiveness has come from doing literature surveys and implementing novel techniques from research papers.', ""Engineering skills. This is a hybrid research/engineering role. You'll be responsible for productionizing your pipelines/models and integrating against our back-end services.""]",2020-09-24 14:09:28
Senior Data Engineer - Agent Compensation,Redfin,3.3 out of 5,"Seattle, WA","['Work with a cross-department team to review, define and implement the Redfin Agent Compensation System', 'Develop and maintain complex SQL that executes hundreds of custom business rules and outputs agent compensation data', 'Ensure 100% accuracy in everything you do - make sure that all code and processes are fully tested and verified before running in production', 'Develop, implement and tune ETL processes to support downstream applications', 'Create code that meets design specifications, follows standards and is easy to maintain', 'Develop and unit test assigned features to meet product requirements', 'Create a new architecture around agent compensation that will allow for configurable business rules and will scale to meet our growing employee base', 'Expert level SQL (7+ years experience)', 'Experience in database technologies (Postgres,RedShift etc.) (7+ years experience)', 'Programming language experience (Python, Java, etc) (1+ years experience)', 'Ability to communicate with both technical and non-technical users', 'Ability to function in a fast paced, constantly changing environment', 'Excellent written and verbal communication skills', 'PM skills such as planning, prioritization, requirements gathering and communication across teams', 'Working knowledge of data modeling and data quality techniques', 'Experience working with GIT/Docker/Jenkins is a plus', 'AWS experience is a plus']",2020-09-24 14:10:12
Junior Calibration Engineer,"MAHLE Powertrain, LLC.",3.6 out of 5,"Plymouth, MA",[],2020-09-24 14:10:12
Junior-Mid Data Scientist,TechSur Solutions,N/A,"Sterling, VA 20166",[],2020-09-24 14:10:12
DATA ENGINEER,Hyatt Corporate Office,N/A,"Chicago, IL","['Work closely with product managers, data scientists, engineering, and program management teams on strategies for data', 'Work with high volumes of data to efficiently process and expose for analysis', 'Ensure timely availability of usable data to all parts of the business that need it', 'Use state of the art technologies to acquire, ingest and transform big datasets', 'Support operational reporting and self-service data engineering work and our business intelligence suite', 'Work on the back-end of our platform, focused on building data pipelines that power data discovery, self-serve analytics and drive data product innovation', 'Stay up-to-date with high-potential new technologies', '2+ years of experience within the field of data engineering or related technical work including business intelligence, analytics', 'Experience and comfort solving problems in an ambiguous environment where there is constant change. Have the tenacity to thrive in a dynamic and fast-paced environment, inspire change, and collaborate with a variety of individuals and organizational partners', 'Experience designing and building scalable and robust data pipelines to enable data-driven decisions for the business', 'Exposure to Amazon AWS or another cloud provider', 'Experience with Business Intelligence tools such as Tableau, PowerBI and/or Looker', 'Familiarity with data warehousing platforms and data pipeline tools such as Redshift, Snowflake, SQL Server, etc.', 'Passionate about programming and learning new technologies; focused on helping yourself and the team improve skills', 'Effective problem solving and analytical skills. Ability to manage multiple projects and report simultaneously across different stakeholders', 'Rigorous attention to detail and accuracy', 'Aware of and motivated by driving business value', 'Experience with large scale enterprise applications using big data open-source solutions such as Hadoop, HBase, Spark, Kafka, and Elastic Search / Solr', ""Experience or knowledge of basic programming and DB's technologies (SQL, Python, Cassandra, MongoDB, Redis, Couchbase, Oracle, MySQL, Teradata)"", 'Bachelor’s degree in Engineering, Computer Science, Statistics, Economics, Mathematics, Finance, a related quantitative field', 'Advance CS degree is a plus knowledge and experience']",2020-09-24 14:10:12
Data Engineer,Seated,2.8 out of 5,"New York, NY 10011","['Work with product, engineering & business teams to deliver complex data analysis requests', 'Visualize datasets across multiple databases & warehouses using tools such as Tableau, D3, Looker, etc.', 'Build financial models & growth projections for new products and business initiatives', 'Build ETL pipelines for regular reporting on business and operational KPIs', 'Help business understand key trends by executing complex analysis via Tableau or ad-hoc SQL queries', 'Coordinate within cross-functional teams such as engineering, product, marketing, customer experience for various data analysis needs', 'Proactively build data and event-driven dashboard for real-time business operations and consumer insights', 'Bachelors in CS, Statistics, Economics or Engineering, Masters preferred', '3+ years of hands-on SQL experience', '2+ years of experience in using data visualization tools such as Tableau, Looker, PowerBI', '2+ years of experience in building financial models, growth projections & ETL data pipelines', 'experience either in R or Python and working with data warehousing solution such as AWS Redshift or Google BigQuery', 'Comprehensive Healthcare, Dental, and Vision', 'Generous 401(k) Matching', 'Stock options', 'Unlimited PTO', 'Pre-Tax Flexible healthcare spending account (FSA), Dependent Care FSA and Commuter Benefits', 'Paid Family Leave', '$100 monthly Seated allowance (dine on us)', 'Stocked fridges, coffee, soda, and lots of treats', 'Collaborative, dynamic work environment within a fast-paced, mission-driven company']",2020-09-24 14:10:12
SQL Developer/Data Engineer,ELLKAY LLC,2 out of 5,"Elmwood Park, NJ 07407","['Extract data from Client’s machines and restoring databases.', 'Identify data elements from various database as requested by client.', 'Working with Several Different Database Management Systems.', 'Be very proficient with SQL Server.', 'Strong SQL skills (SQL Server, Oracle, MySQL, Postgres etc.).', 'Experience in database design and structure, with an emphasis on scalability.', 'A strong desire to develop new and innovative ways to improve our data storage and processing.', 'Prepare and perform data analysis and transformations to align data to business rules.', 'Work with our clients Subject Matter Experts to obtain a greater understating of the business needs and goals.', 'Contribute to knowledge management activities and promote best practices for project execution.', 'Programming experience required in any object oriented programming languages like C#, Java etc.', 'Excellent SQL skills, with experience in building and interpreting complex queries.', 'A minimum 3 years of professional experience as SQL Developer or Data Engineer', 'A minimum 5 years of professional experience in information technology.', ""A minimum of bachelor's or higher in Computer Science, Information Systems, or equivalent degree or strong industry experience."", 'Healthcare Domain knowledge preferred.', 'Experience in HL7,CCDA preferred.']",2020-09-24 14:10:12
Google Data Engineer- Only W2 candidates No C2C,Amgenium,N/A,"Dallas, TX","['Monday to Friday', 'Temporarily due to COVID-19']",2020-09-24 14:10:12
Marketing Data Analyst,Electronic Arts,3.8 out of 5,"Redwood City, CA 94065",[],2020-09-24 14:10:12
"Data Transformation Engineer, Medical Diagnostics",Specific Diagnostics,N/A,"Mountain View, CA 94043","['Experience:relavent, 2 years (Required)', 'Work authorization:United States (Required)', 'Applying data transformation methods for processing high-volume, temporal high-dimensional data streams generated in real-time from our proprietary sensor technology.', 'The development of data-driven visualization tools for the explorative analysis of high-dimensional data.', 'The application and development of suitable pre-processing techniques to account for data errors and artifacts.', 'The development and validation of applications for a medical instrument built under the guidance of a senior manager experienced in the application development discipline (so you’ll be learning the valuable skill of integrating your work into applications for medical diagnostic devices).', 'Data pipeline and warehouse development and maintenance', ""Bachelor's degree in computer sciences, biomedical engineering, or related field and at least 2 years of interesting relevant experience."", 'Expert in Python & Pandas and proficient with Object Oriented Programming and test development.', 'Proficiency in SQL as well as NoSQL database technologies.', 'Comfortable with Linux and writing Bash scripts', 'Familiar with authoring on Tableau Desktop or Tableau Server', 'Full fluency (verbal and written) of the English language is a must.', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'On call', 'relavent: 2 years (Required)', 'United States (Required)', 'One location', 'Detail-oriented -- quality and precision-focused', 'Aggressive -- competitive and growth-oriented', 'Outcome-oriented -- results-focused with strong performance culture', 'https://www.specific-dx.com/', 'No']",2020-09-24 14:10:12
Language Data Researcher,Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['Master’s degree in a related field, such as Data Analytics, BI, Linguistics, or Computational Linguistics', '3+ years experience working with data analysis', 'Own data analyses for customer-facing features, including launch go/no-go metrics for new features and accuracy metrics for existing features.', 'Handle unique data analysis requests from a range of stakeholders, including quantitative and qualitative analyses to elevate customer experience with speech interfaces', 'Lead and evaluate changing dialog evaluation conventions, test tooling developments, and pilot processes to support expansion to new data areas', 'Continuously evaluate workflow tools and processes and offer solutions to ensure they are efficient, high quality, and scalable.', 'Provide day-to-day expert support for a large and growing team of data analysts.', 'Provide key support for ongoing and new data collection efforts.', 'Conduct research studies to understand speech and customer-Alexa interactions as needed', 'Proficiency in scripting, querying and/or analytics tools: Linux, R, SAS, or similar tool', 'Practical knowledge of data processing needs and trade-offs', 'Experience working with speech and/or language data', 'Fluency in a foreign language', 'Expertise in building ontologies, taxonomies, and semantic relation frameworks', 'Comfortable handling a high volume of work on a daily basis', 'Comfortable working in a fast paced, highly collaborative, dynamic work environment', 'Willingness to support several projects at one time, and to accept reprioritization as necessary', 'Strong attention to detail', 'Exceptional level of organization', 'Experience taking a lead role on large, fast-moving projects', 'Strong technical and analytical aptitude', 'Familiarity with the machine learning model lifecycle', 'PhD in a relevant field', 'Research and academic publication experience']",2020-09-24 14:10:12
Construction Project Coordinator,Amazon.com Services LLC,3.6 out of 5,Remote,"[""Bachelor's Degree"", '3+ years of experience in project, construction, or base building management', 'Provide administrative support for Regional Construction Managers on large-scale projects and daily tasks', 'Compile and organize project updates, details and schedules in a reportable format', 'Engage with key stakeholders, including Developers and General Contractors, for project support, project reporting and related tasks', 'Interact with internal stakeholders, customers and partners', 'Compile pertinent metric information and publish to program leadership on a weekly basis', 'Act as the central hub for managing changes affecting the different programs supported. This includes but not limited to attending NAFC change management meetings, staying connected to project activity in the field and communicating issues to the wider program network', 'Perform all responsibilities in a fast paced, constantly changing environment', 'Travel up to 20% domestically', 'Experience as a project engineer or manager in a construction management setting', 'Experience with working remotely in a virtual environment', 'Ability to work independently while maintaining all deadlines and critical date obligations', 'Effective time management and organization skills', 'Effective and professional communication skills', 'Demonstrated ability to establish processes, workflows, standard procedures', 'Self-starter that is able to identify opportunities and drive solutions']",2020-09-24 14:10:12
"Associate Engineer, Pathways Program",Northrop Grumman,4 out of 5,"Azusa, CA 91702","['Use and/or application of technical principles, theories, and concepts. Demonstrate the skill and ability to perform professional tasks.', 'Develop recommended solutions to technical problems as assigned.', 'Contribute to the completion of assigned technical tasks.', 'Construct, troubleshoot, calibrate, adjust, test, and maintain equipment, components, devices, or systems.', 'Work from engineering drawings and written or verbal instructions.', 'Operate related equipment; conduct tests and report data in prescribed format.', 'Prepare prescribed compounds and solutions.', 'Have contact with immediate supervisor, project leaders, and other professionals in the section or group.']",2020-09-24 14:10:12
Real Estate Engineer,"Schenker, Inc.",3.5 out of 5,"Miami, FL",[],2020-09-24 14:10:12
Senior Data Engineer,Dun & Bradstreet,3.7 out of 5,"Waltham, MA 02451","['A senior data engineer’s role involves the development of new applications for major projects to drive significant revenue and cost savings for Dun and Bradstreet. Senior data engineers are expected to delve into new, cutting-edge technologies to explore new markets and opportunities.', 'Senior data engineers are expected to react quickly to high-tech marketplace needs, rapidly developing and deploying new products in an agile work environment to best meet and exceed the expectations of our clients and potential prospects.', 'Senior data engineers are well respected by the engineering team, and grow the skills and confidence of those around them.', 'Develop new applications in a variety of programming languages', 'Take ownership of existing applications for further development/improvements', 'Work closely with related groups to ensure business continuity', 'Perform analysis on large datasets to make and implement recommendations for maximizing customer experience', 'Work as a member of one or more agile teams, using lean principles and SCRUM methodology', 'Bachelor’s degree (preferable in computer science, mathematics, data science, or a related field)', 'Experience with SQL and Linux (3-5 years)', 'Experience with application development (3-5 years), strong preference for candidates with Python experience.', 'Strong collaboration skills', 'Experience with hosted environments, AWS, Azure, or other cloud service providers preferred', 'Experience with Snowflake Data Warehouse systems']",2020-09-24 14:10:12
Data Analytics BI Engineer,Skyline Technologies,3.8 out of 5,Wisconsin,"['Variety in your work with opportunities to expand your skillset', 'Life-work balance and flexible hours', 'Supportive leadership and team members', 'Continuing education and networking opportunities', 'Competitive benefits package', 'A fun, supportive work environment with team engagements and family-friendly events', 'An Associate degree in Information Systems, Computer Science or other related technical discipline, plus minimum two years developing Business Intelligence solutions', 'Knowledge of databases', 'Experience working with relational databases, especially in Microsoft SQL Server', 'Knowledge of data modeling, ETL technologies (T-SQL, SSIS) and data warehouse design theory (Kimball data modeling)', 'Experience working with the Microsoft BI stack including developing solutions in Visual Studio using SSRS, SSIS and SSAS', 'Experience building Tabular and/or Multidimensional models using MS Visual Studio, SSDT, and/or BIDS or PowerPivot models using Excel', 'Experience building solutions in Power BI', 'Excellent analytical and problem-solving skills', 'Effective oral and written communication and organization skills', 'Ability to balance multiple projects while remaining focused on the needs of end users, clients and the Project Manager', 'Ability to work independently or as a member of a team of technical professionals', 'Proficient programming, algorithm, data structure, and object-oriented programming & methodology experience', 'Desire for continued education and certification as it relates to the position', 'Experience working with PowerPivot and/or Power Query', 'Experience with Big Data BI solutions such as Azure Data Lake, Microsoft APS, Azure SQL DW, etc.', 'Experience working with additional database types including Oracle, AS400, Hadoop', 'Experience in programming utilizing C#, VB.NET, ASP.NET or equivalent languages.', 'Microsoft Certifications such as: MCSE: Data Platform, MCSE: Business Intelligence, MCSA: SQL Server 2008/2012, MCTS: SQL Server 2008 - Implementation and Maintenance, MCTS: SQL Server 2008 - Business Intelligence Development and Maintenance, MCITP: Business Intelligence Developer 2008', 'Application development experience', 'Previous consulting experience', ""If you have more experience and/or qualifications beyond this, that's great, we have several levels available within our structure!""]",2020-09-24 14:10:12
Data Analytics BI Engineer,Skyline Technologies,N/A,Wisconsin,"['Interviews on the spot', 'Wednesday, September 30, 20209:00 AM - 1:00 PM US/Eastern', ""Interviewing via webYou'll receive an email on how to connect."", '97 slots left', '', 'Data EngineerFull-timeBachelor’s degree with a major in analytical (e.g., engineering, statistics, mathematics, information technology, etc.) or social science discipline is preferred.Must have at least 5-10 years of experience, preferably with a federal government customer.Must have at least 5-10 years of experience building data pipelines.Must have knowledge of standard data modeling tools (e.g., ERWin, ER Studio) and SQL.Must possess an\xa0active Secret clearance or higherExperience with business process engineering, change management, and/or systems engineering is desired.', 'Bachelor’s degree with a major in analytical (e.g., engineering, statistics, mathematics, information technology, etc.) or social science discipline is preferred.', 'Must have at least 5-10 years of experience, preferably with a federal government customer.', 'Must have at least 5-10 years of experience building data pipelines.', 'Must have knowledge of standard data modeling tools (e.g., ERWin, ER Studio) and SQL.', 'Must possess an\xa0active Secret clearance or higher', 'Experience with business process engineering, change management, and/or systems engineering is desired.', 'Data ScientistFull-timeActive Secret clearance or higherBachelor’s degree in data science, mathematics, statistics, economics, computer science, engineering, or a related business or quantitative disciplineExperience working with tools, including object-oriented programming (Python, Java), computational analysis tools (R, MATLAB), and associated data science libraries (scikit-learn)Experience creating meaningful data visualizations and interactive dashboards using platforms such as Tableau, Qlik, Power BI, RShiny, plotly, and d3.js\xa0to communicate findings and relate them back to how your insights create business impactWorking knowledge of databases and SQL; preferred qualifications include linking analytic and data visualization products to database connectionsAt least 5–10 years\xa0of experience in the field', 'Active Secret clearance or higher', 'Bachelor’s degree in data science, mathematics, statistics, economics, computer science, engineering, or a related business or quantitative discipline', 'Experience working with tools, including object-oriented programming (Python, Java), computational analysis tools (R, MATLAB), and associated data science libraries (scikit-learn)', 'Experience creating meaningful data visualizations and interactive dashboards using platforms such as Tableau, Qlik, Power BI, RShiny, plotly, and d3.js\xa0to communicate findings and relate them back to how your insights create business impact', 'Working knowledge of databases and SQL; preferred qualifications include linking analytic and data visualization products to database connections', 'At least 5–10 years\xa0of experience in the field', ""Software EngineerFull-time3+years of experience as a Full Stack DeveloperBachelor's Degree in Engineering, Computer Science, Math, Statistics or related fieldAdvanced knowledge in Java and J2EEExperience with Java frameworks Hibernate, Spring MVC, Spring Core, Spring Boot, Rest and SOAP, NoSQL, SQLExperience with AngularJS and mobile frameworks such as Cordova/Titanium, PhoneGap, Ionic, Apple Watch SDK, etc.Experience within a Linux and/or Windows environmentPrevious experience working on agile development projectsStrong critical thinking, decision making, troubleshooting and problem solving skills.Active Secret clearance.\xa0 Must be a US Citizen."", '3+years of experience as a Full Stack Developer', ""Bachelor's Degree in Engineering, Computer Science, Math, Statistics or related field"", 'Advanced knowledge in Java and J2EE', 'Experience with Java frameworks Hibernate, Spring MVC, Spring Core, Spring Boot, Rest and SOAP, NoSQL, SQL', 'Experience with AngularJS and mobile frameworks such as Cordova/Titanium, PhoneGap, Ionic, Apple Watch SDK, etc.', 'Experience within a Linux and/or Windows environment', 'Previous experience working on agile development projects', 'Strong critical thinking, decision making, troubleshooting and problem solving skills.', 'Active Secret clearance.\xa0 Must be a US Citizen.', ""Network EngineerFull-timeBachelor's Degree in Computer Science, Computer Engineering, Computer Information Systems, or equivalent years of experience10 to 15 years' experience leading and architecting infrastructure projects5 to 10 years’ experience in building dedicated circuits between data centersDemonstrated experience architecting and implementing virtual storage and data replicationDemonstrated expertise in fiber infrastructure, VMware virtual environment, and network architecturesExperience leading technological feasibility studies related to IT infrastructure related activitiesExperience in performing infrastructure enhancement planning and execution.Must possess and maintain a Secret Security Clearance"", ""Bachelor's Degree in Computer Science, Computer Engineering, Computer Information Systems, or equivalent years of experience"", ""10 to 15 years' experience leading and architecting infrastructure projects"", '5 to 10 years’ experience in building dedicated circuits between data centers', 'Demonstrated experience architecting and implementing virtual storage and data replication', 'Demonstrated expertise in fiber infrastructure, VMware virtual environment, and network architectures', 'Experience leading technological feasibility studies related to IT infrastructure related activities', 'Experience in performing infrastructure enhancement planning and execution.', 'Must possess and maintain a Secret Security Clearance', ""Information Security AnalystFull-time4+ or more years of work experience in IT Security and support or equivalent combination of transferrable experience and educationBachelor's degree in an IT related field or equivalent work experienceDeep knowledge and understanding of the various ways attacks are carried out against a system or network and how to effectively detect themExperience involving security auditsPossess advanced analytical skills and strong ability to maintain calmness and being diplomatic under highly stressful situationsGeneral API experienceExperience aiding teams in automating processes"", '4+ or more years of work experience in IT Security and support or equivalent combination of transferrable experience and education', ""Bachelor's degree in an IT related field or equivalent work experience"", 'Deep knowledge and understanding of the various ways attacks are carried out against a system or network and how to effectively detect them', 'Experience involving security audits', 'Possess advanced analytical skills and strong ability to maintain calmness and being diplomatic under highly stressful situations', 'General API experience', 'Experience aiding teams in automating processes', 'Interviews on the spot', 'Wednesday, September 30, 20209:00 AM - 1:00 PM US/Eastern', ""Interviewing via webYou'll receive an email on how to connect."", '97 slots left', 'United States+1', 'United Kingdom+44', '', 'Afghanistan (\u202bافغانستان\u202c\u200e)+93', 'Albania (Shqipëri)+355', 'Algeria (\u202bالجزائر\u202c\u200e)+213', 'American Samoa+1684', 'Andorra+376', 'Angola+244', 'Anguilla+1264', 'Antigua and Barbuda+1268', 'Argentina+54', 'Armenia (Հայաստան)+374', 'Aruba+297', 'Australia+61', 'Austria (Österreich)+43', 'Azerbaijan (Azərbaycan)+994', 'Bahamas+1242', 'Bahrain (\u202bالبحرين\u202c\u200e)+973', 'Bangladesh (বাংলাদেশ)+880', 'Barbados+1246', 'Belarus (Беларусь)+375', 'Belgium (België)+32', 'Belize+501', 'Benin (Bénin)+229', 'Bermuda+1441', 'Bhutan (འབྲུག)+975', 'Bolivia+591', 'Bosnia and Herzegovina (Босна и Херцеговина)+387', 'Botswana+267', 'Brazil (Brasil)+55', 'British Indian Ocean Territory+246', 'British Virgin Islands+1284', 'Brunei+673', 'Bulgaria (България)+359', 'Burkina Faso+226', 'Burundi (Uburundi)+257', 'Cambodia (កម្ពុជា)+855', 'Cameroon (Cameroun)+237', 'Canada+1', 'Cape Verde (Kabu Verdi)+238', 'Caribbean Netherlands+599', 'Cayman Islands+1345', 'Central African Republic (République centrafricaine)+236', 'Chad (Tchad)+235', 'Chile+56', 'China (中国)+86', 'Christmas Island+61', 'Cocos (Keeling) Islands+61', 'Colombia+57', 'Comoros (\u202bجزر القمر\u202c\u200e)+269', 'Congo (DRC) (Jamhuri ya Kidemokrasia ya Kongo)+243', 'Congo (Republic) (Congo-Brazzaville)+242', 'Cook Islands+682', 'Costa Rica+506', 'Côte d’Ivoire+225', 'Croatia (Hrvatska)+385', 'Cuba+53', 'Curaçao+599', 'Cyprus (Κύπρος)+357', 'Czech Republic (Česká republika)+420', 'Denmark (Danmark)+45', 'Djibouti+253', 'Dominica+1767', 'Dominican Republic (República Dominicana)+1', 'Ecuador+593', 'Egypt (\u202bمصر\u202c\u200e)+20', 'El Salvador+503', 'Equatorial Guinea (Guinea Ecuatorial)+240', 'Eritrea+291', 'Estonia (Eesti)+372', 'Ethiopia+251', 'Falkland Islands (Islas Malvinas)+500', 'Faroe Islands (Føroyar)+298', 'Fiji+679', 'Finland (Suomi)+358', 'France+33', 'French Guiana (Guyane française)+594', 'French Polynesia (Polynésie française)+689', 'Gabon+241', 'Gambia+220', 'Georgia (საქართველო)+995', 'Germany (Deutschland)+49', 'Ghana (Gaana)+233', 'Gibraltar+350', 'Greece (Ελλάδα)+30', 'Greenland (Kalaallit Nunaat)+299', 'Grenada+1473', 'Guadeloupe+590', 'Guam+1671', 'Guatemala+502', 'Guernsey+44', 'Guinea (Guinée)+224', 'Guinea-Bissau (Guiné Bissau)+245', 'Guyana+592', 'Haiti+509', 'Honduras+504', 'Hong Kong (香港)+852', 'Hungary (Magyarország)+36', 'Iceland (Ísland)+354', 'India (भारत)+91', 'Indonesia+62', 'Iran (\u202bایران\u202c\u200e)+98', 'Iraq (\u202bالعراق\u202c\u200e)+964', 'Ireland+353', 'Isle of Man+44', 'Israel (\u202bישראל\u202c\u200e)+972', 'Italy (Italia)+39', 'Jamaica+1', 'Japan (日本)+81', 'Jersey+44', 'Jordan (\u202bالأردن\u202c\u200e)+962', 'Kazakhstan (Казахстан)+7', 'Kenya+254', 'Kiribati+686', 'Kosovo+383', 'Kuwait (\u202bالكويت\u202c\u200e)+965', 'Kyrgyzstan (Кыргызстан)+996', 'Laos (ລາວ)+856', 'Latvia (Latvija)+371', 'Lebanon (\u202bلبنان\u202c\u200e)+961', 'Lesotho+266', 'Liberia+231', 'Libya (\u202bليبيا\u202c\u200e)+218', 'Liechtenstein+423', 'Lithuania (Lietuva)+370', 'Luxembourg+352', 'Macau (澳門)+853', 'Macedonia (FYROM) (Македонија)+389', 'Madagascar (Madagasikara)+261', 'Malawi+265', 'Malaysia+60', 'Maldives+960', 'Mali+223', 'Malta+356', 'Marshall Islands+692', 'Martinique+596', 'Mauritania (\u202bموريتانيا\u202c\u200e)+222', 'Mauritius (Moris)+230', 'Mayotte+262', 'Mexico (México)+52', 'Micronesia+691', 'Moldova (Republica Moldova)+373', 'Monaco+377', 'Mongolia (Монгол)+976', 'Montenegro (Crna Gora)+382', 'Montserrat+1664', 'Morocco (\u202bالمغرب\u202c\u200e)+212', 'Mozambique (Moçambique)+258', 'Myanmar (Burma) (မြန်မာ)+95', 'Namibia (Namibië)+264', 'Nauru+674', 'Nepal (नेपाल)+977', 'Netherlands (Nederland)+31', 'New Caledonia (Nouvelle-Calédonie)+687', 'New Zealand+64', 'Nicaragua+505', 'Niger (Nijar)+227', 'Nigeria+234', 'Niue+683', 'Norfolk Island+672', 'North Korea (조선 민주주의 인민 공화국)+850', 'Northern Mariana Islands+1670', 'Norway (Norge)+47', 'Oman (\u202bعُمان\u202c\u200e)+968', 'Pakistan (\u202bپاکستان\u202c\u200e)+92', 'Palau+680', 'Palestine (\u202bفلسطين\u202c\u200e)+970', 'Panama (Panamá)+507', 'Papua New Guinea+675', 'Paraguay+595', 'Peru (Perú)+51', 'Philippines+63', 'Poland (Polska)+48', 'Portugal+351', 'Puerto Rico+1', 'Qatar (\u202bقطر\u202c\u200e)+974', 'Réunion (La Réunion)+262', 'Romania (România)+40', 'Russia (Россия)+7', 'Rwanda+250', 'Saint Barthélemy+590', 'Saint Helena+290', 'Saint Kitts and Nevis+1869', 'Saint Lucia+1758', 'Saint Martin (Saint-Martin (partie française))+590', 'Saint Pierre and Miquelon (Saint-Pierre-et-Miquelon)+508', 'Saint Vincent and the Grenadines+1784', 'Samoa+685', 'San Marino+378', 'São Tomé and Príncipe (São Tomé e Príncipe)+239', 'Saudi Arabia (\u202bالمملكة العربية السعودية\u202c\u200e)+966', 'Senegal (Sénégal)+221', 'Serbia (Србија)+381', 'Seychelles+248', 'Sierra Leone+232', 'Singapore+65', 'Sint Maarten+1721', 'Slovakia (Slovensko)+421', 'Slovenia (Slovenija)+386', 'Solomon Islands+677', 'Somalia (Soomaaliya)+252', 'South Africa+27', 'South Korea (대한민국)+82', 'South Sudan (\u202bجنوب السودان\u202c\u200e)+211', 'Spain (España)+34', 'Sri Lanka (ශ්\u200dරී ලංකාව)+94', 'Sudan (\u202bالسودان\u202c\u200e)+249', 'Suriname+597', 'Svalbard and Jan Mayen+47', 'Swaziland+268', 'Sweden (Sverige)+46', 'Switzerland (Schweiz)+41', 'Syria (\u202bسوريا\u202c\u200e)+963', 'Taiwan (台灣)+886', 'Tajikistan+992', 'Tanzania+255', 'Thailand (ไทย)+66', 'Timor-Leste+670', 'Togo+228', 'Tokelau+690', 'Tonga+676', 'Trinidad and Tobago+1868', 'Tunisia (\u202bتونس\u202c\u200e)+216', 'Turkey (Türkiye)+90', 'Turkmenistan+993', 'Turks and Caicos Islands+1649', 'Tuvalu+688', 'U.S. Virgin Islands+1340', 'Uganda+256', 'Ukraine (Україна)+380', 'United Arab Emirates (\u202bالإمارات العربية المتحدة\u202c\u200e)+971', 'United Kingdom+44', 'United States+1', 'Uruguay+598', 'Uzbekistan (Oʻzbekiston)+998', 'Vanuatu+678', 'Vatican City (Città del Vaticano)+39', 'Venezuela+58', 'Vietnam (Việt Nam)+84', 'Wallis and Futuna (Wallis-et-Futuna)+681', 'Western Sahara (\u202bالصحراء الغربية\u202c\u200e)+212', 'Yemen (\u202bاليمن\u202c\u200e)+967', 'Zambia+260', 'Zimbabwe+263', 'Åland Islands+358']",2020-09-24 14:10:53
Data Warehouse Architect / Modeler,Verstand AI,N/A,United States,"['Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', 'Supplemental Pay:', 'Experience:Data Warehouse, 3 years (Required)Cloud Computing, 3 years (Preferred)Data Modeling, 3 years (Required)', ""Education:Bachelor's (Required)"", 'Design and oversee data discovery process and instantiate data infrastructure.', 'Design reporting facts and dimensions using data warehousing best practices.', 'Create physical and logical data models.', 'Document the data dictionary.', 'Provide direction and definition of data modeling strategy and delivery', 'Lead effort of delivering data modeling solutions and platforms.', 'Implement standards and best practices in support of the EIM vision and reference architecture.', 'Develop technical standards and specifications for database models, data security and data warehouse performance.', 'Develop and coordinate regional and global project efforts.', 'Serve as project leader on assigned projects: assign tasks to project team; explain work methods, and check work for completeness, timeliness and accuracy.', 'Modify, install and prepare technical documentation for data modeling tool sets.', 'Data auditing and evaluation experience', 'Proficiency with relational star-schema data model design', 'Experience in data modeling (dimensional and other techniques using modeling tools) along with transactional systems, data warehouses and data marts', 'Proficiency with design, conceptual, logical and physical data models', 'Maintain data dictionary and enterprise conceptual data models', 'Experience with modeling normalized and de-normalized data structures', 'Experience in developing and maintaining data mapping ETL/ELT needs and data lineage', 'BI semantic-layer modeling', 'Experience and knowledge of reporting platforms such as Microsoft Power BI, Tableau Looker, Data Studio, etc.', 'Excellent organizational, time management and communication skills.', 'Ability to communicate effectively with peers, management, business groups, contractors, consultants and vendors.', 'Ability to define and explain work methods.', 'Must maintain confidentiality of proprietary, financial and personal data.', 'Experience with cloud databases such as AWS RDS/Redshift, Microsoft Azure Cosmos DB/SQL Server, or Google Cloud Platform BigQuery (preferred).', '4 year Bachelor Degree in Information Systems or related field.', '5-7 years related experience and/or training, or equivalent combination of education and experience.', 'Experience leading project teams, directing work, developing requirements working with business.', 'Excellent written and verbal communication', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', 'Monday to Friday', 'Bonus pay', 'Data Warehouse: 3 years (Required)', 'Cloud Computing: 3 years (Preferred)', 'Data Modeling: 3 years (Required)', ""Bachelor's (Required)"", 'Fully Remote', 'Outcome-oriented -- results-focused with strong performance culture', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.verstand.ai', 'Only full-time employees eligible', 'Yes']",2020-09-24 14:10:53
Data Engineer - Junior Level,USAA,3.9 out of 5,"Lake Dallas, TX 75065",[],2020-09-24 14:10:53
Sales Applications Engineer,"Twin City Fan Companies, Ltd.",3.1 out of 5,"Plymouth, MN","['Assist representatives in standard and special applications. Make special or difficult fan selections as experience and knowledge allows.', 'Assist with large and/or special jobs', 'Select and price the most effective fans for the application based on specifications.', 'Follow up with customers or representatives on quotations. Work with the Engineering Department to interpret specifications and customer requirements. Review customer drawings and data.', 'Work with the Manufacturing and Quality Assurance Departments to properly move the job through the shop to meet customer satisfaction.', 'Assist the purchasing department to specify purchase of special equipment and accessories to meet customer specifications.', ""Gain technical knowledge of company products and competitors' products. Maintain adequate knowledge of buyouts."", 'Work with the Order Department and give them clear and accurate instructions on orders received.', 'Gain knowledge of competition, their price levels and new products.', 'Keep supervisors adequately informed on various jobs.', 'Assist Customer Service on problem areas.', 'Other duties as assigned.', 'Bachelor of Science in Engineering (Mechanical or Electrical)', '0-2 years of relevant experience', 'Effective communications and interpersonal skills', 'Able to work with minimum supervision and to make reasonable decisions', 'Proficient in the use of standard office software programs and equipment', 'Standard office environment', 'Ability to occasionally lift up to 20 pounds', 'Ability to occasionally climb, balance, stoop, kneel, reach', 'Ability to work extended hours sitting at a computer']",2020-09-24 14:10:53
Application Engineer,"CaptiveAire, Inc.",3.3 out of 5,"Saint George, UT","['Medical, dental and vision insurance', 'Disability & life insurance based upon election of medical insurance', 'Paid holidays, vacation, and sick days based upon tenure', '401k with employer match', 'Flexible spending account (FSA)', 'Salary:', 'Competitive base salary with monthly bonus based on productivity and profits.', 'Supplemental Pay:', 'Experience:HVAC, 1 year (Required)engineering, 2 years (Preferred)', ""Education:Bachelor's (Required)"", 'Responsible for working with internal sales staff along with internal Engineering team to help design sustainable mechanical ventilation and control strategies for a wide variety of commercial applications.', 'Must have strong communication skills, with the ability to discuss complex mechanical equipment and controls with a wide range of audiences, ranging from highly technical engineers down to non-technical owners.', 'Must be able to review and analyze remote monitoring data.', 'Must be a self-starter, able to handle long term tasks with little guidance.', 'Must be able to train in Raleigh, NC.', 'BS in Engineering- mechanical or electrical preferred', '2-3 yrs experience preferably with an MEP firm', 'Knowledge of HVAC/Ventilation systems preferred, DOAS a plus', 'Strong understanding of electrical schematics, psychrometrics experience preferred', 'Must be able to manipulate data to derive trends and useful facts using Excel or similar software.', 'Medical, dental and vision insurance', 'Disability & life insurance based upon election of medical insurance', 'Paid holidays, vacation, and sick days based upon tenure', '401k with employer match', 'Flexible spending account (FSA)', 'Monday to Friday', 'Bonus pay', 'HVAC: 1 year (Required)', 'engineering: 2 years (Preferred)', ""Bachelor's (Required)"", 'One location', 'No: Not providing sponsorship for this job', 'www.captiveaire.com', 'No']",2020-09-24 14:10:53
Cloud Data Engineer (Azure),Navy Federal Credit Union,4 out of 5,"Vienna, VA 22180","['$120,000 - $215,000', 'Best-in-Class Benefits!', '7% 401k match / Pension plan / Tuition reimbursement / Great insurance options)', 'FORTUNE 100 Best Companies to Work For®', 'Computerworld® Best Places to Work in IT', 'FORTUNE® Best Workplaces for Millennials', 'Forbes® America’s Best Employers', 'Provide Business Intelligence (BI) and Data Warehousing (DW) solutions and support by leveraging project standards and leading analytics platforms', 'Evaluate and define functional requirements for BI and DW solutions', 'Define and build data integration processes to be used across the organization', 'Build conceptual and logical data models for stakeholders and management', 'Analyze and validate data accuracy of report results', 'Work directly with management understand requirement; and propose and develop best business solution that enables effective decision-making, and drive business objectives', 'Prepares realistic project implementation plans which highlight major milestones and deliverables leveraging standard methods and work planning tools', 'Recognizes potential issues and risks during the analytics project implementation and can suggest realistic mitigation strategies', 'Coaches and mentors project team members in carrying out analytics project implementation activities', 'Leads the preparation of high quality project deliverables that are valued by the business and presents them in such a manner that they are easily understood by project stakeholders', 'Interpreting data presented in models, charts, and tables and transforming it into a format that is useful to the business and aids effective decision making', 'Use of statistical practices to analyze current and historical data to make predictions, identify risks, and opportunities enabling better decisions on planned/future events', 'The ability to understand the business problem and determine what aspects of it require optimization; articulate those aspects in a clear and concise manner', 'The ability to define and analyze models that predict the probability of an outcome', 'Offers improvements to the way in which analytics service the entire function', 'Communicating and owning the process in manipulating and merging large datasets', 'Ability to view and understand other project or functional areas in order to consolidate analytical needs and processes', 'Being a key point of contact between the data analyst/data scientist and the project/functional analytics leads', 'Perform other duties as assigned', ""Bachelor's degree in Information Systems, Computer Science, Engineering, or related field, or the equivalent combination of education, training and experience"", '5 years’ experience working in a cloud computing with Azure experience required', 'Experience with data migration to cloud based environment', 'Extensive 5 years of experience in providing data architecture solutions for Cloud applications', 'Knowledge of and the ability to perform basic statistical analysis such as measures of central tendency, normal distribution, variance, standard deviation, basic tests, correlation, and regression techniques', 'Experienced in the use of standard ETL tools and techniques', 'Experienced in sourcing, maintaining, and updating data', 'Understanding of data warehousing, data cleaning, data pipelines and other analytical techniques required for data usage', 'Demonstrates functional knowledge of data visualization tools such as Microsoft Power BI, Tableau', 'Has working knowledge of various data structures and the ability to manipulate data within visualization tools', 'Ability to manipulate raw data into effective visualization dashboards', 'Ability to communicate end to end data outcomes visually', 'Demonstrates a deep understanding of multiple database concepts', 'Has a working knowledge of various data structures and the ability to extract data from various data sources (such as Cognos, Informatica)', 'Understands the concepts and application of data mapping and building requirements', 'Optimal understanding of SQL', 'Graduate education in Information Systems, Computer Science, Engineering, or related field', 'Knowledge of Navy Federal Credit Union instructions, standards, and procedures']",2020-09-24 14:10:53
Cloud Data Engineer (Azure),Navy Federal Credit Union,N/A,"Vienna, VA 22180","['Interviews on the spot', 'Wednesday, September 30, 20202:00 PM - 4:00 PM US/Pacific', ""Interviewing via webYou'll receive an email on how to connect."", '128 slots left', '', 'Bioinformatics EngineerFull-time', 'Tampa, Tampa, FL 33601 US', 'St. Petersburg, St. Petersburg, FL 33701 US', 'Clearwater, Clearwater, FL 33755 US', 'Interviews on the spot', 'Wednesday, September 30, 20202:00 PM - 4:00 PM US/Pacific', ""Interviewing via webYou'll receive an email on how to connect."", '128 slots left', 'United States+1', 'United Kingdom+44', '', 'Afghanistan (\u202bافغانستان\u202c\u200e)+93', 'Albania (Shqipëri)+355', 'Algeria (\u202bالجزائر\u202c\u200e)+213', 'American Samoa+1684', 'Andorra+376', 'Angola+244', 'Anguilla+1264', 'Antigua and Barbuda+1268', 'Argentina+54', 'Armenia (Հայաստան)+374', 'Aruba+297', 'Australia+61', 'Austria (Österreich)+43', 'Azerbaijan (Azərbaycan)+994', 'Bahamas+1242', 'Bahrain (\u202bالبحرين\u202c\u200e)+973', 'Bangladesh (বাংলাদেশ)+880', 'Barbados+1246', 'Belarus (Беларусь)+375', 'Belgium (België)+32', 'Belize+501', 'Benin (Bénin)+229', 'Bermuda+1441', 'Bhutan (འབྲུག)+975', 'Bolivia+591', 'Bosnia and Herzegovina (Босна и Херцеговина)+387', 'Botswana+267', 'Brazil (Brasil)+55', 'British Indian Ocean Territory+246', 'British Virgin Islands+1284', 'Brunei+673', 'Bulgaria (България)+359', 'Burkina Faso+226', 'Burundi (Uburundi)+257', 'Cambodia (កម្ពុជា)+855', 'Cameroon (Cameroun)+237', 'Canada+1', 'Cape Verde (Kabu Verdi)+238', 'Caribbean Netherlands+599', 'Cayman Islands+1345', 'Central African Republic (République centrafricaine)+236', 'Chad (Tchad)+235', 'Chile+56', 'China (中国)+86', 'Christmas Island+61', 'Cocos (Keeling) Islands+61', 'Colombia+57', 'Comoros (\u202bجزر القمر\u202c\u200e)+269', 'Congo (DRC) (Jamhuri ya Kidemokrasia ya Kongo)+243', 'Congo (Republic) (Congo-Brazzaville)+242', 'Cook Islands+682', 'Costa Rica+506', 'Côte d’Ivoire+225', 'Croatia (Hrvatska)+385', 'Cuba+53', 'Curaçao+599', 'Cyprus (Κύπρος)+357', 'Czech Republic (Česká republika)+420', 'Denmark (Danmark)+45', 'Djibouti+253', 'Dominica+1767', 'Dominican Republic (República Dominicana)+1', 'Ecuador+593', 'Egypt (\u202bمصر\u202c\u200e)+20', 'El Salvador+503', 'Equatorial Guinea (Guinea Ecuatorial)+240', 'Eritrea+291', 'Estonia (Eesti)+372', 'Ethiopia+251', 'Falkland Islands (Islas Malvinas)+500', 'Faroe Islands (Føroyar)+298', 'Fiji+679', 'Finland (Suomi)+358', 'France+33', 'French Guiana (Guyane française)+594', 'French Polynesia (Polynésie française)+689', 'Gabon+241', 'Gambia+220', 'Georgia (საქართველო)+995', 'Germany (Deutschland)+49', 'Ghana (Gaana)+233', 'Gibraltar+350', 'Greece (Ελλάδα)+30', 'Greenland (Kalaallit Nunaat)+299', 'Grenada+1473', 'Guadeloupe+590', 'Guam+1671', 'Guatemala+502', 'Guernsey+44', 'Guinea (Guinée)+224', 'Guinea-Bissau (Guiné Bissau)+245', 'Guyana+592', 'Haiti+509', 'Honduras+504', 'Hong Kong (香港)+852', 'Hungary (Magyarország)+36', 'Iceland (Ísland)+354', 'India (भारत)+91', 'Indonesia+62', 'Iran (\u202bایران\u202c\u200e)+98', 'Iraq (\u202bالعراق\u202c\u200e)+964', 'Ireland+353', 'Isle of Man+44', 'Israel (\u202bישראל\u202c\u200e)+972', 'Italy (Italia)+39', 'Jamaica+1', 'Japan (日本)+81', 'Jersey+44', 'Jordan (\u202bالأردن\u202c\u200e)+962', 'Kazakhstan (Казахстан)+7', 'Kenya+254', 'Kiribati+686', 'Kosovo+383', 'Kuwait (\u202bالكويت\u202c\u200e)+965', 'Kyrgyzstan (Кыргызстан)+996', 'Laos (ລາວ)+856', 'Latvia (Latvija)+371', 'Lebanon (\u202bلبنان\u202c\u200e)+961', 'Lesotho+266', 'Liberia+231', 'Libya (\u202bليبيا\u202c\u200e)+218', 'Liechtenstein+423', 'Lithuania (Lietuva)+370', 'Luxembourg+352', 'Macau (澳門)+853', 'Macedonia (FYROM) (Македонија)+389', 'Madagascar (Madagasikara)+261', 'Malawi+265', 'Malaysia+60', 'Maldives+960', 'Mali+223', 'Malta+356', 'Marshall Islands+692', 'Martinique+596', 'Mauritania (\u202bموريتانيا\u202c\u200e)+222', 'Mauritius (Moris)+230', 'Mayotte+262', 'Mexico (México)+52', 'Micronesia+691', 'Moldova (Republica Moldova)+373', 'Monaco+377', 'Mongolia (Монгол)+976', 'Montenegro (Crna Gora)+382', 'Montserrat+1664', 'Morocco (\u202bالمغرب\u202c\u200e)+212', 'Mozambique (Moçambique)+258', 'Myanmar (Burma) (မြန်မာ)+95', 'Namibia (Namibië)+264', 'Nauru+674', 'Nepal (नेपाल)+977', 'Netherlands (Nederland)+31', 'New Caledonia (Nouvelle-Calédonie)+687', 'New Zealand+64', 'Nicaragua+505', 'Niger (Nijar)+227', 'Nigeria+234', 'Niue+683', 'Norfolk Island+672', 'North Korea (조선 민주주의 인민 공화국)+850', 'Northern Mariana Islands+1670', 'Norway (Norge)+47', 'Oman (\u202bعُمان\u202c\u200e)+968', 'Pakistan (\u202bپاکستان\u202c\u200e)+92', 'Palau+680', 'Palestine (\u202bفلسطين\u202c\u200e)+970', 'Panama (Panamá)+507', 'Papua New Guinea+675', 'Paraguay+595', 'Peru (Perú)+51', 'Philippines+63', 'Poland (Polska)+48', 'Portugal+351', 'Puerto Rico+1', 'Qatar (\u202bقطر\u202c\u200e)+974', 'Réunion (La Réunion)+262', 'Romania (România)+40', 'Russia (Россия)+7', 'Rwanda+250', 'Saint Barthélemy+590', 'Saint Helena+290', 'Saint Kitts and Nevis+1869', 'Saint Lucia+1758', 'Saint Martin (Saint-Martin (partie française))+590', 'Saint Pierre and Miquelon (Saint-Pierre-et-Miquelon)+508', 'Saint Vincent and the Grenadines+1784', 'Samoa+685', 'San Marino+378', 'São Tomé and Príncipe (São Tomé e Príncipe)+239', 'Saudi Arabia (\u202bالمملكة العربية السعودية\u202c\u200e)+966', 'Senegal (Sénégal)+221', 'Serbia (Србија)+381', 'Seychelles+248', 'Sierra Leone+232', 'Singapore+65', 'Sint Maarten+1721', 'Slovakia (Slovensko)+421', 'Slovenia (Slovenija)+386', 'Solomon Islands+677', 'Somalia (Soomaaliya)+252', 'South Africa+27', 'South Korea (대한민국)+82', 'South Sudan (\u202bجنوب السودان\u202c\u200e)+211', 'Spain (España)+34', 'Sri Lanka (ශ්\u200dරී ලංකාව)+94', 'Sudan (\u202bالسودان\u202c\u200e)+249', 'Suriname+597', 'Svalbard and Jan Mayen+47', 'Swaziland+268', 'Sweden (Sverige)+46', 'Switzerland (Schweiz)+41', 'Syria (\u202bسوريا\u202c\u200e)+963', 'Taiwan (台灣)+886', 'Tajikistan+992', 'Tanzania+255', 'Thailand (ไทย)+66', 'Timor-Leste+670', 'Togo+228', 'Tokelau+690', 'Tonga+676', 'Trinidad and Tobago+1868', 'Tunisia (\u202bتونس\u202c\u200e)+216', 'Turkey (Türkiye)+90', 'Turkmenistan+993', 'Turks and Caicos Islands+1649', 'Tuvalu+688', 'U.S. Virgin Islands+1340', 'Uganda+256', 'Ukraine (Україна)+380', 'United Arab Emirates (\u202bالإمارات العربية المتحدة\u202c\u200e)+971', 'United Kingdom+44', 'United States+1', 'Uruguay+598', 'Uzbekistan (Oʻzbekiston)+998', 'Vanuatu+678', 'Vatican City (Città del Vaticano)+39', 'Venezuela+58', 'Vietnam (Việt Nam)+84', 'Wallis and Futuna (Wallis-et-Futuna)+681', 'Western Sahara (\u202bالصحراء الغربية\u202c\u200e)+212', 'Yemen (\u202bاليمن\u202c\u200e)+967', 'Zambia+260', 'Zimbabwe+263', 'Åland Islands+358']",2020-09-24 14:10:53
Associate Quality Engineer,Boehringer Ingelheim,4.1 out of 5,"Fremont, CA 94555","['Participate in small size validation (Equipment) projects:Participate with risk assessments for new systems and changes to existing systemsWrite simple validation plans, protocols and reports', 'Owning Quality Systems Records:Create, own, and manage life cycle of minor deviations, corrective actions and change controls for GMP equipment, facilities and automation systemsOperate within the relevant quality computer systems (ex. SAP, TrackWise) ensuring implementation in line with quality and timeliness objectivesWorking closely with Engineering, Quality, Process Development, Validation, and Manufacturing to investigate and resolve deviations including leading investigation teams in order to determine root cause, product impact, and appropriates corrective and preventive actions', 'Preparing material for internal and external regulatory and customer auditors', 'Participate in generating quality system metrics for the E&T department', 'Bachelors Degree from an accredited institution in Engineering with one (1) year of relevant cGMP biopharmaceutical manufacturing environment experience, or Masters Degree from an accredited institution in Engineering', 'Working knowledge of GMP guidelines, ICH Q7, Q8, Q9, Q10 and other international regulatory requirements', 'Excellent technical writing and verbal communication skills', 'Ability to work as part of a high performing team and collaborate effectively with staff at all levels.', 'Must have well-developed interpersonal skills with the ability to establish highly functional relationships with diverse personalities both within and outside the company.', 'Demonstrated ability to manage multiple activities while maintaining a high level of organization', 'Preferred experienced in Microsoft Office Suite', 'Knowledge of Microsoft Excel', 'Good knowledge and skills in biopharmaceutical and process engineering', 'Participation on technical projects with an interdisciplinary project team from planning to realization and start up', 'Understanding of validation concepts for biopharmaceutical manufacturing process, instrumentation and utility equipment.', 'Must be legally authorized to work in the United States without restriction.', 'Must be willing to take a drug test and post-offer physical (if required)', 'Must be 18 years of age or older']",2020-09-24 14:10:53
Sr. Data Engineer,MasterClass,N/A,"San Francisco, CA","['Proactively drive the execution of our data engineering, business intelligence, and data warehouse roadmap', 'Understand and translate business needs into data models to support long-term, scalable, and reliable solutions', 'Create logical and physical data models using best practices to ensure high data quality and reduced redundancy', 'Drive data quality across the organization; develop best practices for standard naming conventions and coding practices to ensure consistency of data models and tracking', ""Define and manage SLA's for data sets and processes running in production"", 'Continuously improve our data infrastructure and stay ahead of technology', 'Design a system for data backup in case of system failure', 'Build strong cross-functional partnerships with Data Scientists, Analysts, Product Managers and Software Engineers to understand data needs and deliver on those needs', '4+ years of experience in Data Engineering and Data Warehousing', ""Bachelor's degree in a quantitative field, e.g. Computer Science, Math, Physics"", 'Experience scaling data environments with distributed/RT systems and self-serve visualization environments', 'Advanced proficiency with SQL, Perl, Python, Postgres, REST/GraphQL', 'Experience designing and implementing cloud based and SaaS data warehouse (e.g. WS, Hadoop, NoSQL) and developing ETL/ELT pipelines', 'Experience integrating and building data platform in support of BI, Analytics, Data Science, and real-time applications', 'Strong communication skills, with the ability to initiate and drive projects proactively and accurately', 'Work full-time in our San Francisco office']",2020-09-24 14:10:53
Data Science Engineer,Nomi Health,N/A,"Austin, TX 73301","['Contribute to the development of the ML capabilities for the Nomi Health', 'Develop and implement data models to guide business decisions', 'Mapping data sources, including descriptions of the business meaning of the data, its uses, its quality, the applications that maintain it and the database technology in which it is stored. Documentation of a data source must describe the semantics of the data so that the occasional subtle differences in meaning are understood.', 'Documenting interfaces and data movement by recording how mapped data is moved around the virtual enterprise. This includes the frequency of movement, the source and destination of each step, how the data is transformed as it moves, and any aggregation or calculations.', 'Designing the movement of data through the enterprise, including sources of data and how the data is moved around in order to be improved.', 'Defining integrative views of data to draw together data from across the enterprise. Some views will use a database of extracted data and others will bring together data in near real time, considering data currency, availability, response times and data volumes. Designing canonical data views to limit technical debt as data flows from point-to-point transformation.', 'Defining technical standards and guidelines. Assess and document when and how to use the architected producers and consumers, the technologies to be used for various purposes, and models of selected entities, objects and processes. The guidelines should encourage reuse of existing data stores, as well as address issues of security, timeliness and quality.', 'Investigate and participate in emerging technologies and new release Proofs of Concept (PoCs).', 'Leveraging existing [core] data assets.', 'Managing related metadata to include business descriptions of the data, details of any calculations or summaries, descriptions of the sources of the data, and indications of data quality and currency.', 'Communicating the data architecture across the enterprise.', 'Ensuring a focus on data quality by working effectively with data stewards so they can understand data semantics and identify opportunities for improving data quality.', ""Bachelor's degree in Computer Science, Computer Engineering or relevant field."", 'A minimum of 2-3 years experience in a similar role.', 'Must have AWS or Azure experience. (Snowflake, Databricks, S3 desirable)', 'Must have ELT/ETL experience (Talend, MDM, other ETL/ELT tools)', 'Must have coding experience (python, JAVA, R),', 'Familiarity of system concepts and tools within an enterprise architecture framework.', 'Knowledge of various modern data formats, tools, and methodologies. (Infomatics desirable)', 'Excellent organizational and analytical abilities.', 'Outstanding problem solver.', 'Good written and verbal communication skills.']",2020-09-24 14:10:53
Senior Data Engineer,Pinwheel,4.5 out of 5,"New York, NY","['Work with business leaders and engineering leads to define KPIs and success metrics.', 'Model our data in LookerML and create analytics dashboards.', 'Work with the engineering team to define a data dictionary for analytics tracking calls from our different micro-services.', 'Architect and implement data pipelines for ETL processes into our AWS Redshift warehouse.', 'Leverage a variety of cloud technologies such as S3, SQS, and Lambda to efficiently and reliably deliver data from a variety of sources to our customers.', 'Write complex SQL queries to analyze data.', 'Perform more in depth exploratory data analysis using Jupyter notebooks and python libraries as pandas, numpy, matplotplib, seaborn, and scikit-learn.']",2020-09-24 14:10:53
Data Engineer,"CSAA Insurance Group, a AAA Insurer",3.3 out of 5,"Glendale, AZ 85308","['We offer a competitive total compensation package including base salary, both annual and long-term lucrative performance bonuses, benefits, and 401(k) Company match with additional discretionary contribution potential.', 'Comprehensive health care plans, including medical, dental, vision, and tax-deferred spending accounts.', 'Employee assistance, healthy pregnancy and wellness programs.', 'Paid time off, plus nine paid holidays and 24 hours of volunteer time off.', '401(k) plus company matching up to 6% and a cash balance pension program.', 'Paid training, tuition reimbursement, self-service training and career development opportunities.', 'Impact - Do you like reinventing data products and deliver new capabilities to organization to better understand customer and provide better services. Be part of modern data team who is innovating the way data can be leveraged to generate new insights.', 'Recognition. We offer a competitive total compensation package including base salary, both annual and long-term lucrative performance bonuses, benefits, and 401(k) Company match with additional discretionary contribution potential.', 'Lifestyle. We do honorable work, and we practice our values: respect, integrity, teamwork, and service.', 'Contribute to collaborative, multi-disciplinary project team efforts in an agile environment', 'Design and develop next generation data and analytics platform based on latest technology stack', 'Design and build data pipelines that transform data into usable formats', 'Evaluate and conduct POC on new technologies for fitment in next generation data platform ecosystem', 'Assist in the development and support of data products. Develop automated processes for data mining, modeling, and enrichment', 'Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy', 'Experience with database and data warehouse services in Snowflake, EC2, S3 and experience with SQL and NoSQL databases', 'Experience as a backend engineer or data engineer with experience in programming languages like Python, Spark, Java, SQL/Hive', 'Experience working within a multidisciplinary, agile team format', 'Excellent in communicating clearly to technical and non-technical audiences', 'Master’s Degree in Computer Science or related field', 'Solid analytical and problem-solving skills; ability to think strategically.', 'Ability to adapt quickly to changing priorities, assignments, and roles.', 'Ability to communicate your ideas and solutions in simple language to your team', 'Comprehensive health care plans, including medical, dental, vision, and tax-deferred spending accounts.', 'Employee assistance, healthy pregnancy and wellness programs.', 'Paid time off, plus nine paid holidays and 24 hours of volunteer time off.', '401(k) plus company matching up to 6% and a cash balance pension program.', 'Paid training, tuition reimbursement, self-service training and career development opportunities.']",2020-09-24 14:10:53
Data Presentation Engineer,Spreetail,2.7 out of 5,"Lincoln, NE","['Up to 5% of yearly salary; based upon company and team', 'performanceCompany Bonus:', 'Up to 5% of yearly salary; based upon company and team performance', 'Health Insurance:', 'Spreetail will pay for your full premium and half for spouse/family', 'plansDental Insurance:', 'Spreetail will pay half of the dental coverage for you/spouse/family', 'plans401k: Spreetail partners with ForUsAll to provide the opportunity to invest in your future with pre-tax and post-tax plan options', 'Paid Time Off: untracked time off', 'Wedding Week:', 'Enjoy an additional 5 paid days off before or after your wedding', 'Gym Membership:', 'After 2 years of employment, Spreetail will give you $5,000 when you', 'buy a home', 'Spreetail will match your donation dollar for dollar, up to $250 a', ""year and up to $1,000 if you've been here for 5 yearsCommunity Involvement:"", 'Enjoy a 20% discount on the products we sell', 'Actively give and receive feedback to drive team success.', 'Maintain a positive attitude, so your teammates and business stakeholders look forward to working with you.', 'Have a high attention to detail and focus on the quality of the data and your applications.', 'Seek feedback on current tools and assist in building the data product road map.', '2+ years of experience building business dashboards and reports.', 'Experienced building Mobile Reports.', 'Experienced building Power BI Apps.', '2+ years of experience with data presentation tools (Power BI, Tableau, QlikView, etc.)', 'Knowledgeable about SQL.', 'Quick to learn and adapt to new technologies.', 'Able to analyze and tell a story with data.', 'Experienced with data modeling and data warehousing.', 'Unit Appreciation Rights: Up to 5% of yearly salary; based upon company and team', 'Company Bonus: Up to 5% of yearly salary; based upon company and team performance', 'Health Insurance: Spreetail will pay for your full premium and half for spouse/family', 'Dental Insurance: Spreetail will pay half of the dental coverage for you/spouse/family', '401k: Spreetail partners with ForUsAll to provide the opportunity to invest in your future with pre-tax and post-tax plan options', 'Paid Time Off: untracked time off', 'Wedding Week: Enjoy an additional 5 paid days off before or after your wedding', 'Gym Membership: Spreetail will pay for half of your membership to a specified gym', 'Creating a Home: After 2 years of employment, Spreetail will give you $5,000 when you', 'Year 3 Vacation: After 3 years of employment, you will be eligible for an all-inclusive', 'Year 5 Sabbatical: After 5 years of employment, you will be eligible for a 2-week paid', 'Donation Matching: Spreetail will match your donation dollar for dollar, up to $250 a', 'Community Involvement: Spreetail encourages employees to take time off for volunteer', 'Product Discount: Enjoy a 20% discount on the products we sell']",2020-09-24 14:10:53
Data Engineer,Excella,4.4 out of 5,"Arlington, VA 22201","['Developing and managing data processes to ensure that data is available and usable', 'Creation and automation of data pipelines and platforms', 'Managing and monitoring data quality via automated testing frameworks (Data Driven Testing, TDD, etc.)', 'Working closely with Architects, Data Scientists, and DevOps to design, build, test, deliver, and maintain sustainable and highly scalable data solutions', 'Researching data acquisition and evaluating suitability', 'Integration of data management solutions into client environment', 'Actively managing risks to data and ensuring there is a data recovery plan', 'Building data repositories such as: data warehouses, data lakes, and operational data stores, etc.', '3+ years relevant professional work experience.', 'Experience and expertise in the following:', 'Project experience using the Scrum or Kanban framework.', 'Professionalism; to include written and oral communication – the ability to communicate collaboratively in front of a whiteboard. An ability to understand your audience and adjust your communication style to fit', 'Aptitude and desire for learning new technologies.', 'Technically savvy, entrepreneurial spirit who thrives in environments that reward self-initiative and resourcefulness.', ""You'll work with great people who love what they do: our team includes published authors, certified trainers, and internationally renowned speakers."", 'We have a ""bring your own device"" workplace and will share the cost of a new computer of your choice - Mac or PC. It\'s up to you.', ""We'll invest in your career by providing 3 days of paid professional development every year, including travel and registration fees to attend classes and conferences, in addition to tuition assistance for degrees and certifications."", 'Starting day one, every employee is bonus eligible and receives 17 days of paid vacation.', 'You can bike, drive, or metro to work - our commute reimbursement plan has you covered.', ""You'll have fun! We hold monthly social events all year long, including a summer event for you and your family.""]",2020-09-24 14:10:53
Junior Internal Software Engineer - Full-Stack Development,HackerU,4.8 out of 5,Florida,"['Meet with internal stakeholders to gather project requirements and identify workflow pain points that could be solved with software', 'Work with part-time volunteers across various teams to define clear and measurable project requirements and user stories', 'Develop strategies to improve organizational efficiency in the short-term while working towards the longer-term goals of a sustainable internal information architecture', 'Write and maintain quality software', 'Develop documentation and presentations which communicate the objectives of developed software and tools, to earn team buy-in and adoption', 'Identify opportunities for improved efficiency or visibility through software integrations as you work with different teams on a variety of otherwise disconnected internal tools', 'Work with curriculum teams to review and revise curriculum content for full stack and data science programs', 'Experience with full stack application development', 'Experience with declarative UI models, such as HTML', 'Experience programming with JavaScript', 'Experience with PHP, Python, NodeJS, and React is a plus', 'Able to plan projects with an Agile mentality', 'Able to design software and normalized data schemas', 'Willing to meet the challenge of working in a fast growing hi-tech company', 'Can effectively manage a variety of complex initiatives in varying environments and cultures', 'Ability to multitask and prioritize competing deadlines and projects', 'Highly motivated and determined to reach target-driven goals', 'Excellent command of the English language, in both written and verbal communications', 'Behavioral elements such as adaptability, resilience, resourcefulness, enthusiastic and meticulous are highly preferred']",2020-09-24 14:10:53
Business Intelligence Engineer,OneSignal,N/A,"San Mateo, CA","['Help query data from our systems to build reports and analysis to derive actionable insight for the sales team, customer success, marketing, support, product', 'Run SQL queries for teams to better acquire and retain customers, develop marketing strategies, bill our customers, as well as inform related product decisions', 'Develop in depth reports and dashboards for individual groups across the organization', 'Help evaluate and develop and build automated tracking of KPIs across the business as well', 'Create automated cohort analysis and revenue bridges to monitor acquisition, expansion, and churn and other Saas metrics', 'Evaluate ways to increase the efficiency of internal data flows and centralize sources of truth including generating a universal customer ID that can span across the organization', 'Build a tool that will allow people across the company to have access to data that will scale with the company growth', 'Connect SaaS tool data into a data warehouse. This could include data from Salesforce, NetSuite, Recurly, and backend entitlement data', 'Assist in architecting and designing a scalable data warehouse that can be connected to a business intelligence tool.', 'Connect SaaS tool data into a data warehouse. This could include data from Salesforce, NetSuite, Recurly, and backend entitlement data', 'Evaluate ways to increase the efficiency of internal data flows and centralize sources of truth', 'Minimum of 2+ years of experience', 'Skilled at querying relational databases (SQL) and ability to create ETL pipelines', 'Proficiency with programming languages such as Python, Ruby, Java, etc.', 'In-depth experience with business intelligence and analytics tools', 'Strong critical thinking skills and attention to detail', 'Knowledge of database systems such as Postgresql, Hadoop, Hive, Spark, Kafka, etc', 'Experience working at a SaaS company is helpful']",2020-09-24 14:10:53
Big Data Engineer (DW/ETL),Intuit,4.2 out of 5,"San Diego, CA 92101","['BS or MS in Computer Science or related field or equivalent work experience', '3+ years of core development experience', 'Skilled in developing Software for Java (Spring & Springboot), Scala for spark streaming & spark applications, or other JVM based languages.', 'Working Knowledge of XML, JavaScript, JSON, YML and Linux', 'Advanced experience with scripting language – Python or Shell is a must have', 'Strong knowledge of software development methodologies and practices', 'Experience working in Agile development teams; working knowledge of Agile (Scrum) development methodologies', 'Experience with Amazon web services: EC2, S3, and EMR (Elastic Map Reduce) or equivalent cloud computing approaches', 'Strong expertise in Data Warehousing and analytic architecture', 'Experience working with large data volumes', 'Experience in HTML5, CSS, and other Web technologies a plus.', 'Experience with low-latency NoSQL datastores (such as DynamoDB, HBase, Cassandra, MongoDB) is a plus', 'Experience with building stream-processing applications using Spark Streaming, Kinesis, etc. is a plus', 'Exposure to unit testing frameworks', 'Hands on experience with Hadoop stack of technologies – Hive, Pig, pig-udf', 'Ability to research and integrate 3rd party solutions', 'Evolving a mature code base into new technologies', 'Experience creating and consuming SOAP based or JSON/REST web services and communicating with systems.', 'Experience developing web services', '70-85% hands-on development in all phases of the software life cycle.', 'Rapidly fix bugs and solve problems', 'Conduct design and code reviews', 'Defect remediation', 'Technical design specification', 'Automated unit tests', 'Estimates and sequence of individual activities as inputs to project plans', 'Analyzes and synthesizes a variety of inputs to create software and services.', 'Identify dependencies as inputs to project plans', 'Collaborates effectively with peer engineers and architects to solve complex problems spanning their respective areas to deliver end-to-end quality in our technology and customer experience.', 'Influences and communicates effectively with non-technical audiences including senior product and business management.', 'Designing/developing ETL jobs across multiple big data platforms and tools including S3, EMR, Hive, Vertica']",2020-09-24 14:10:53
Aircraft Systems Engineer 1,Garmin,3.8 out of 5,"Salem, OR","['Our 401K retirement plan provides 5% of pay base contribution plus a match of 75 cents for every dollar you contribute to a maximum of 10% of your compensation.', 'The employee stock purchase plan allows for shares to be bought at a 15% discount.', 'Contributing to aircraft certification projects, including project planning, reporting project status, and contributing to a project team to achieve aircraft certification', 'Working with product development teams for new products, developing technical data in support of aircraft installation, and resolving technical issues', 'Providing reliable solutions to a wide range of difficult avionics engineering problems using sound problem-solving techniques', 'Creating certification data including installation data, test plans and reports, and compliance reports', 'Understanding design and/or certification constraints and working effectively with product development teams to complete complex, new, or significant projects', 'Excellent academics (cumulative GPA greater than or equal to 3.0 as a general rule).', 'Demonstrated strong and effective verbal, written, and interpersonal communication skills.', 'Aviation knowledge through prior experience as a pilot or maintenance technician.']",2020-09-24 14:11:39
Data Scientist,Noah,N/A,"San Francisco, CA 94110","['Competitive salary, 401k, and equity in a company that is growing rapidly', 'Comprehensive health, vision, and dental insurance, FSA', 'Paid time off', 'Ongoing training and development', 'Translating business priorities and requirements to data science deliverables', 'Working with data scientists, data engineers, and software engineers to develop and support the internal tools used for pricing, underwriting, marketing, product & operations support.', 'Design, develop and maintain business dashboards to track KPIs across marketing, operations and product linked activities.', 'Develop and maintain a suite of portfolio analytics and metrics utilized for reporting to internal and external stakeholders', 'Developing methods to analyze risk of the US housing market in a systematic and objective manner', ""Identifying, sourcing and managing the data required to build Noah's risk and pricing models"", ""Contributing to developing the core algorithms and analytical models for Noah's products"", ""Creating frameworks for back-testing Noah's proprietary models"", 'Degree in Computer Science, Math, Physics, Engineering, Statistics, Economics or other technical field', '3 years of data science/analytics experience', 'Experience with analytic and visualization tools such as Mode Analytics, Looker etc.', 'Experience with: data collection, filtering, and cleaning techniques, statistical techniques and concepts (regression, properties of distributions, hypothesis testing), and SQL and relational databases like Postgres', 'Development experience, preferably in Python', 'Ability to organize and present complex data to technical and non-technical audiences', 'Team player with high integrity', 'Experience working at an early stage startup', 'Open to feedback with an ongoing desire to improve', 'Understanding of financial concepts such as risk, volatility, IRR', 'A high degree of self awareness', 'Exposure to: A/B testing, statistical models and their interpretability, mortgage and home price models', 'Working knowledge of backend software development, including RESTful APIs and database', 'A collaborative mindset, and eagerness to partner with engineering, product, and business development teams', 'Competitive salary, 401k, and equity in a company that is growing rapidly', 'Comprehensive health, vision, and dental insurance, FSA', 'Paid time off', 'Ongoing training and development']",2020-09-24 14:11:39
Data Engineer II,Hy-Vee,3.7 out of 5,"West Des Moines, IA","['Designs, creates and maintains code and jobs for ETL processes', 'Monitors ETL pipelines and their systems for uptime and performance', 'Ensures new and existing code meets company standards for readability, testability, automation, documentation and performance', 'Assists in the design and implementation of new data stores', 'Assists developers in optimizing database code for performance.', 'Maintains and writes Python modules as needed.', 'Provides database enhancements to existing applications', 'Reviews and designs data integration for new applications.', 'Provide after hours on-call support on a rotational basis', ""Bachelor's Degree from an accredited college or university in a quantitative field required"", '5+ years of experience as a Database Engineer or similar experience', 'Knowledge of at least one of the following database platforms: SQL Server, Oracle, PostgreSQL or NoSQL (e.g. Mongo)', 'Knowledge of database monitoring tools', 'Experience designing and implementing snowflake, star and relational data models.', 'Knowledge of ETL/ELT tools (e.g. SSIS, Informatica, Airflow) and best practices', 'Ability to independently troubleshoot issues, think critically, and clearly communicate findings/recommendations', ""Experience ingesting data via API's"", 'Production experience supporting or developing for databases, especially RBDMS (e.g. SQL Server, Oracle, PostgreSQL).', 'Experience working in Windows and Linux OSes', 'Experience building cloud-native applications (kubernetes, docker, swarm, etc.)', 'Experience developing software, especially using CI/CD', 'Experience with event-driven architectures (e.g. Kafka, Google Pub/Sub, Azure Event Hub, etc.)', ""Experience creating API's to provide access to data"", 'Experience with streaming analytics (e.g. Spark, Google Dataflow, Azure Streaming Analytics, etc.)', 'Knowledge of design and general database automation', 'Knowledge of cloud databases (e.g. Azure Synapse, Google BigQuery, Snowflake, etc.)']",2020-09-24 14:11:39
Data Engineer - Orion,id Software,4.5 out of 5,"Dallas, TX","['3+ years of experience in a data warehousing, data engineering, or data architect role', 'Experience with full life cycle development, architecture and implementation, of an enterprise data warehouse.', 'Experience working with AWS data technologies such as S3, Redshift Spectrum, Athena, Data Pipeline, Glue, EMR, RDS, and Kinesis', 'Expert level SQL skills', 'Data modeling experience for both transactional and data warehousing environments.', 'Experience working with a variety of data sources such as MySQL, Oracle, SQL Server, PostgreSQL, S3, HDFS, and MongoDB', 'Strong interpersonal skills and problem-solving ability', 'Build new and extend existing data structures to support real-time analytics for Orion services', 'Maintain large, multi-terabyte data warehouse which includes performance tuning and data retention/purge processes', 'Research and troubleshoot data quality issues, providing fixes and proposing both short- and long-term solutions', 'Prepare designs for database systems and recommend improvements for performance.', 'Maintain and develop various database scripts and tools to facilitate automation process', 'Provide support to all data warehouse initiatives.', 'Experience with infrastructure as code to support systems developed', 'Experience with Python and Linux shell scripting', 'Experience using source control systems (Git, Perforce, SVN, etc.)']",2020-09-24 14:11:39
Data Engineer with HL7 Experience,Data-Core Systems Inc,3.7 out of 5,"Philadelphia, PA 19103","['Python,Scala: 2 years (Required)', 'AWS, SQL,data pipeline: 2 years (Required)', 'BigData: 3 years (Required)', 'HealthCare-HL7: 3 years (Required)', 'Data Engineer : 8 years (Required)', 'Yes']",2020-09-24 14:11:39
Onsite Engineer,HealthSpaces,N/A,"Columbus, OH 43212","['mindset over knowledge', 'the way you think over years of experience', 'culture over compensation', 'eagerness to learn over what you know', 'collaboration over departmental hierarchies', 'freedom to explore new technologies over existing tools and methods', 'Creative – you find unique ways to solve difficult problems and challenge the status quo', 'Self-managing - you take full ownership of driving tasks to completion, and helping those around you in doing the same', 'Collaborative – you recognize that working as a team yields more effective results than working alone; do you value your workplace culture and your co-workers experiences over chasing compensation; do you challenge others and set high goals for yourself and the people around them; do you want to spread your knowledge and insights to those around you in order to make them better.', 'Results driven – you focus on projects that deliver value to the end user; do you chase the ability to cause change and disrupt industries; are you the type to find solutions to major problems', 'Business savvy – you understand your clients and deliver solutions that cater to their needs', 'Cross disciplinary – you have skills that span across disciplines and are comfortable playing different roles in more than just one area', 'Continuous learner – you seek out ways to constantly develop your skills and invest in learning every single week', 'Agile – you pivot easily within a constantly changing environment and are comfortable with a high degree of change', 'Risk taker – you see failure as part of the learning process and do it time and again; are you the type to not hold back on whenever you have an idea; are you not scared to try something new, and will do your best in collecting data and analytics to make sure that your ideas are foolproof', 'Individual contributor – you wait for directives from management and work individually to accomplish goals', 'Specialist - you specialize in a specific discipline in order to gain an ever- deeper understanding and contribute your key expertise in that area', 'Traditional – you thrive within structured corporate organizations where roles and titles are clearly defined, and where you can climb the corporate ladder', 'Management – you’ve established yourself as a manager within a hierarchy and are responsible for following and enforcing traditional HR practices', 'Passive – you prefer to leave the good ideas to others and focus instead on implementing them', 'Conservative – you stick with what has worked in the past, you are uncomfortable challenging the status quo, and generally avoid taking risks and trying new approaches', 'Linear – you are most comfortable working in a traditional project plan/gantt chart environment', 'Install/maintain servers, network, and storage devices.', 'To pickup configuration and maintenance of generic applications.', 'Good analytical and problem solving skills', 'Up-to-date technical knowledge', 'Good interpersonal and customer care skills', 'Strong computer skills', 'Ability to troubleshoot and diagnose problems', 'Ability to communicate effectively to help customers fix their issues and feel satisfied with the experience', 'Logical thinker', 'Competitive salary', 'Additional employee benefits and perks', 'Tech Stipend', 'One-of-a-kind culture', 'Multiple locations']",2020-09-24 14:11:39
Data Engineer- Seattle Event,Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['5+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics.', '5+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.', '2+ years of experience in scripting languages like Python etc.', 'Demonstrated strength in data modeling, ETL development, and Data warehousing. Data Warehousing', 'Experience with Redshift', 'Experience with AWS services including S3, Redshift, EMR and RDS.', 'Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)', 'Experience in working and delivering end-to-end projects independently.', 'Lead architecture design and implementation of next generation BI solution.', 'Build robust and scalable data integration (ETL) pipelines using SQL, EMR, Python and Spark.', ""Mentor and develop other DE's and BIE's."", 'Build and deliver high quality data architecture to support business analyst, data scientists, and customer reporting needs.', 'Interface with other technology teams to extract, transform, and load data from a wide variety of data sources.', 'Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers', 'Experience providing technical leadership and mentoring other engineers for best practices on data engineering', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations']",2020-09-24 14:11:39
Data Engineer,NEHII,N/A,"Omaha, NE","['Design, develop, maintain and unit test stored procedures, scripts and ETL systems for products features', 'Responsible for expanding and optimizing our data and data pipelines as well as for data flow and data collection for cross functional teams', 'Responsible for producing exemplary quality & scalable code and delivering features on-time', 'Design for operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions', 'Follow development cycle procedures to maintain code base and build artifacts', 'Create and maintain technical documentation', 'Understand business needs and translate into data solutions for the clinical, population health, research and analytics teams.', 'B.S. or Masters in Informatics, Computer Science, Statistics, or a related discipline', 'Understanding of API ecosystems and experiences with designing, developing, and deploying RESTful API.', 'Expertise in several of the following: Python, R, SQL, git, and Hadoop/Spark in a distributed Unix environment, AWS', 'Ability to design and implement complex data management systems', 'Experience with biomedical standards and terminologies for metadata management and data integration.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring as well as working familiarity with a variety of databases and file format', 'Experience with HL7 is preferred', 'Understanding of Kafka/Rabbit MQ', 'Experience with message queuing, stream processing is a plus', 'Experience performing root cause analysis on internal and external data and processes', 'Development experience with MySQL, Redshift, MSSQL Server', 'Strong industry experience in programming languages such as Python, C# or Java, with the ability to pick up new languages and technologies quickly; understanding of cloud and distributed systems principles and experience with large-scale, big data method', 'At least 2 years of experience working with healthcare data and data processing, specifically medical, pharmacy and claims data', 'Experience with Agile development and Scrum', 'Hours are generally Monday-Friday, 8:00 AM-5:00 PM, but may vary as necessary with possible extended working hours.', 'Ability to work on a computer for extended periods of time.', 'Ability to stand or sit for extended periods of time.', 'Light work requiring exertion up to 20 pounds of force occasionally, and/or up to 10 pounds of force frequently, and/or a negligible amount of force constantly to move objects.', 'Ability to work in the La Vista, NE office with reliable and predictable attendance.']",2020-09-24 14:11:39
Real Estate Engineer,"Schenker, Inc.",3.5 out of 5,"Miami, FL",[],2020-09-24 14:11:39
Senior Data Engineer (Python)-Remote,SemanticBits LLC,4.2 out of 5,Remote,"['Competitive salary', 'Three weeks of PTO', 'Ten paid holiday days', 'Comprehensive health benefits (medical with HSA option, dental, and vision)', '401k retirement plan with matching benefit', '100% paid short-term and long-term disability', '100% paid life insurance', 'Flexible Spending Accounts (FSA)', 'Casual working environment', 'Python, Postgres, Redshift, Apache NiFi, Airflow, Express, AWS EMR, Looker, Mongo, general working with BI tools & AWS resources.', 'Strong knowledge of computer science fundamentals: object-oriented design and programming, data structures, algorithms, databases', 'Demonstrable experience engineering scalable data processing pipelines and clusters', 'Demonstrable expertise with Python and Spark and wrangling of various data formats - CSV, XML, JSON.', 'Experience with any of the following technologies is highly desirable: Postgres, Redshift, Apache NiFi, Airflow, Node.js, Express, AWS EMR, Looker, Mongo', ""Bachelor's degree required, strong preference for Computer Science field of study"", 'A minimum of 5 years of related professional experience', 'Experience with Agile methodology, using test-driven development.', 'Excellent command of written and spoken English', 'Self-driven problem solver', 'Candidate must reside in the United States', 'Flexible and willing to accept a change in priorities as necessary', 'Experience working in the healthcare industry with PHI/PII', 'Federal Government contracting work experience', 'Prior experience working remotely full-time', 'This position is to be performed remotely from an individual’s home office and involves sedentary work. Employees in this role can be expected to exert up to 10 pounds of force on occasion in order to lift, carry, push, pull or otherwise move standard electronic equipment. Employees are expected to make decisions in a timely manner and display emotional intelligence during occasional stressful situations.']",2020-09-24 14:11:39
Machine Learning Engineer,Silverfin,N/A,Remote,"['You’re experienced in applying machine learning, from proof of concept to a production system. You’re able to both get your hands dirty building models, and integrating what you’ve built into a production system. While our core application is built in Ruby on Rails, it’s probably not well-suited for machine learning projects, and you can suggest a more applicable language based on the project. We’re guessing Python.', 'You’re up for mentoring coworkers and can give in-depth, productive feedback during reviews. While you appreciate the small stuff, you recognize bikeshedding and can avoid its pitfalls.', 'You’re able to take initiative and push projects forward without being micromanaged.', 'You can code with reason and can justify the important decisions you made during development.', 'You can communicate clearly in English, both written and verbally.', 'You recognize and can apply engineering best practices when relevant. This includes the usual like version control, testing, and refactoring; but you also appreciate hygienic code, good naming, explicitness and readability over cleverness, etc. You’re willing to be flexible and pick-up other practices that the team decides on but you might not agree with.', ""You're aware of the trade-offs involved in proper engineering and can make balanced business decisions, keeping in mind all the stakeholders of the project."", 'The opportunity to build unique projects based on a significant amount of data, on top of a solid product-oriented foundation', 'Actual, proper work-life balance', 'Choose your own working hours and work 100% remotely', 'Personal growth training and opportunities', 'The possibility to grow the team and become a teamlead', 'Join a distributed remote-first engineering team with 25 colleagues in 14 different countries', 'A refreshing work environment with professional, friendly and welcoming colleagues', 'A €1000 yearly budget for conferences, courses, workshops or other expenses that will improve your skills', 'You have successfully taken a significant machine learning project from concept to production', 'At least 2 years of full-time experience with machine learning projects', 'Your work hours have some overlap with EU business hours (we require your local timezone to be within CET +/- 3h)', 'Experience as a remote worker in a fully remote team', 'Experience in Fintech', 'Accounting knowledge', 'Read about how our regular development interviewing process looks like (the machine learning engineer job is a bit different, but this should give you some idea)', 'Or email us with any questions on engineering-recruitment@silverfin.com']",2020-09-24 14:11:39
Data Engineer,Initiate Government Solutions,5 out of 5,"Rockville, MD","['Initiate Government Solutions offers competitive compensation and a strong benefits package including comprehensive medical, dental and vision care, matching 401K, paid time off, flexible spending accounts, life insurance, disability coverage, and other benefits that help provide financial protection for you and your family.', 'Initiate Government Solutions participates in the Electronic Employment Verification Program.', 'Designing and implementing data ingestion and data transformation processes using software tools', 'Modifying current batch-oriented data exchanges to interactive, on-demand or near real-time data exchanges', 'Enhancing data exchanges in response to changes in source information systems', 'Automating scheduled data exchanges', 'Integrating data from multiple sources by identifying or creating linkages and transforming data into compatible structures or encoding', 'Measuring data consistency and conformance to business rules', 'Designing and implementing transformations to data structure and representation in order to facilitate analysis', 'Designing and implementing data access controls to limit or filter data in accordance with defined policies', 'Advising personnel on the proven or recommended practices for SAP Smart Data Integration and other capabilities of the SAP HANA data platform', 'Analyzing the data structures in the Data Warehouse and designing and implementing database objects to facilitate analysis, improve efficiency or responsiveness, or aggregate or mask data for use by a broader audience', 'Minimum BA/BS in related field or equivalent with at least 5 or more years of experience working with large scale IT projects, preferably at the Federal level as a Data Engineer', 'Experience working with batch-oriented processes using Informatica PowerCenter workflows and scripted loads of delimited files', 'Proficiency with SAP HANA in Cloud Service environment', 'Impeccable attention to detail, strong organizational skills, and ability to multi-task under pressure', 'Excellent written and communication skills', 'Ability to obtain and maintain an HHS Public Trust', 'Current HHS Public Trust', 'Working experience supporting machine learning and natural language processing capabilities in SAP HANA', 'Prior experience supporting Data Warehouse focused on Human Resources data']",2020-09-24 14:11:39
"Engineer, Quality 2",Triumph Group,3.2 out of 5,"Redmond, WA 98053",[],2020-09-24 14:11:39
Data Engineer,Constellation Digital Partners,5 out of 5,"Raleigh, NC","['Leveraging expert-level domain experience in technologies and tools to integrate the Constellation platform with external data sources, especially credit union core processing systems.', 'Developing and executing data transformation processes to migrate credit union member data from existing mobile and online providers to the Constellation platform.', 'Contributing to the overall architecture of the platform, platform integration capabilities, and data.', 'Collaborating with internal and external stakeholders to design, develop, and launch data-oriented capabilities and services.', 'Engaging in aspects of release cycles, such as requirements review, work estimation, design, implementation, testing, and review.', 'Proficiency with data manipulation languages, understanding of data modeling principles, and an', 'An ability to work on multiple assignments, prioritize, and resolve issues in a timely manner in an evolving environment.', 'An innate desire to find the root cause of technical issues, while balancing business needs to identify, support, and solve customer needs.', 'A demonstrated ability to work well with people across multiple technical disciplines.', 'A “can do” positive attitude coupled with a strong respect for others and a results-oriented work style', 'Comfort working effectively with internal and external technology resources as well as credit union staff.', 'Availability to work weekends and the occasional late night or early morning.', 'Strong interpersonal skills, able to collaborate as part of a small team in a fast-paced environment.', 'Strong communication skills (oral, presentation, and written).', 'Adherence to organizational policies, procedures, standards, and controls as well as compliance with all federal and state laws and regulations.', 'Three to five years of related data engineering/data management experience.', ""A Bachelor's degree in Computer Science, Engineering, or equivalent work experience."", 'Demonstrated expertise in enterprise ETL processes.', 'A track record of success using various database and data manipulation tools.', 'Experience with object oriented, relational, and NoSQL databases.', 'Success defining and integrating with multiple forms of APIs to integrate platforms and systems.', 'Experience or certification in cloud-based architecture and services (AWS, Azure, etc.) is beneficial.', 'Exposure to Agile development methodology.', 'Knowledge of financial services data constructs,related practices and terminology.']",2020-09-24 14:11:39
"Systems Engineer, Tool Development and Data Scientist",LOCKHEED MARTIN CORPORATION,4 out of 5,"Sunnyvale, CA 94089","['QuickCost Database gathers SAP and Cobra cost information and integrates it with schedule, mass properties, PHSL, and MEL and other data to create a comprehensive cost and technical look at program data. This information is then carefully mapped to Standard WBS, NRE/RE, SV, and other attributes in order to enable cross-program comparison of cost information at the box level that is used to create future estimates. Our data must remain relevant and auditable/traceable in order to maximize value back to the business. Our QuickCost data enables the SEA team to provide the business with realistic cost estimates (RCE’s), which not only increases the probability of program win, but also reduces estimating costs by over 80% compared with traditional bottoms-up estimating methods.', 'Our Cost Estimating and Forecasting tools and techniques utilize our QuickCost Database to build credible, realistic estimates to aid in executive decisions for future program captures. Out tools rely on cost driving algorithms with supporting statistical analytics to maintain credibility with our customers and internal leadership. These tools continue to evolve and knowledge of solving platforms with easy to use interfaces for results is key.', 'Our Rapid Affordability and CAIV Exploration (RACE) decision analysis application is utilized at all LM Business Areas throughout the Corporation. The opportunity includes enhancing the tool’s ability to be installed and distributed to user base in both classified and unclassified environments, feature enhancements, integration to the Model Based environment, interfacing with visualization software, cyber security, and tool life cycle management. The software maintainer would have significant input in future version enhancements based on user-base required needs.', 'Updating existing and creating new forecasting tools and models to support estimating, affordability, life cycle cost, parametric analysis, and proposal development for total systems', 'Effectively supporting frequent contacts with internal personnel at different levels so excellent communications skills, both verbal and written, are important; submitting weekly activity reports', 'Having initiative, perseverance, and asking questions to senior engineers and leaders', 'Acting as liaison between Systems Engineering; Finance; Assembly, Test & Launch Operations (ATLO); Business Development and Program Management', 'Providing briefings to colleagues, senior staff, engineering and Directors', 'Being detail oriented and enjoying analyzing detailed data', ""Bachelor's degree in Math, Operations Research, Engineering, or related field"", 'Knowledge of Microsoft Excel and PowerPoint', 'Strong team collaboration and leadership skills', 'MySQL/relational database development', 'Advanced Microsoft Excel modeling expertise or aptitude', 'Knowledge of financial systems, financial analysis, regression, etc.', 'Business Intelligence toolset aptitude (Tableau, Domino, Power BI, etc.)', 'Application/Analytical development (R or Python, data mining, GUI front-end development, etc.)', 'Experience working on a Space or Military program', 'Master’s Degree in Systems Engineering or Engineering Management', 'Ability to communicate technically oriented material to broader team', 'Familiarity with proposal development and/or government acquisition process', 'Object oriented database development experience', 'Ability to navigate, extract and use LM financial data (SAP, Cobra, EVMS systems, etc.)', 'Ability to develop models that collect big data from legacy systems and generate value-added products with strategic business value', 'Experience in any of the following: Visual Studio / VB.net framework, Visual Basic for Applications, Gitlab, Microsoft Excel, Microsoft Excel Add-ins, Tableau, Power BI, software management, or software algorithm development', 'Strong team collaboration and leadership skills']",2020-09-24 14:11:39
Data Engineer,Tista Science and Technology Corporation,3.7 out of 5,"Rockville, MD 20854","['As the data expert on the project, collect, analyze, and interpret data in order to improve data quality, make effective business decisions, and determine areas of error that require data improvement', 'Conduct complex data analysis and report on results', 'Explore ways to enhance data quality and reliability', 'Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it', 'Collaborate with business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making', 'Perform data analysis required to troubleshoot data related issues and assist in the resolution of data issues', 'Work closely with a team of frontend and backend engineers, product managers, and business analysts', 'Work closely with engineering teams to support development of data architecture', 'Experience with or knowledge of agile software development methodologies', 'Excellent problem solving and troubleshooting skills', 'Process oriented with great documentation skills', 'Excellent oral and written communication skills with a keen sense of customer service', 'Bachelor of Science (B.S.) in Mathematics, Economics, Computer Science, Information Management or Statistics', 'Minimum of five (5) years proven work experience as a data analyst on complex data systems', 'A minimum of five (5) years of technical experience in dimensional and ER data models, and database design development', 'Minimum of four (4) years of Python or Java development experience', 'Advanced knowledge of SQL required', 'Experience designing, building, and maintaining data processing systems', 'Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy', 'Experience writing queries, reports, and presentations of findings geared to Business Owners and to non-technical personnel', 'A background in Medicare and Medicaid data analysis is preferred']",2020-09-24 14:12:22
Data Governance Administrator,Fayetteville Public Works Commission,4.3 out of 5,"Fayetteville, NC 28301","['Job', 'Company', '$70,618.28 - $88,272.86 per year', 'Benefits:', '401(k)', 'Dental Insurance', 'Disability Insurance', 'Employee Assistance Program', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Professional Development Assistance', 'Retirement Plan', 'Tuition Reimbursement', 'Vision Insurance', 'Experience:data governance, 5 years (Preferred)', ""Education:Bachelor's (Preferred)"", 'Work authorization:United States (Required)', '401(k)', 'Dental Insurance', 'Disability Insurance', 'Employee Assistance Program', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Professional Development Assistance', 'Retirement Plan', 'Tuition Reimbursement', 'Vision Insurance', 'Day shift', 'Monday to Friday', 'data governance: 5 years (Preferred)', ""Bachelor's (Preferred)"", 'United States (Required)', 'www.faypwc.com', 'https://www.facebook.com/faypwc', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-09-24 14:12:22
Test Engineer II,HighPoint,3.3 out of 5,Remote,"['Experience with DevOps techniques, principals, and culture and the tools and techniques used to sup Knowledge of IT Testing processes and best practices.', 'Ability to build and manage customer, vendor, and internal team relationships.', 'Ability to effectively manage multiple project timelines.', 'Regular and reliable attendance as determined by the manager is required.', 'Ability to work within deadlines and schedules.', 'Assist in defining test strategies, creating test plans, and communicating test workflows to the Contact center Data team.', 'Collaborate with Lead Tester to determine work capacity, set test schedules and milestones, and organize support for testing workflows.', 'Execute test plans on reporting and analytic tools and systems to ensure accuracy of output.', 'Review test cases to determine business needs and requirements for system or application enhancements will meet client expectations.', ""Bachelor's degree"", '5 years related experience and/or training; or equivalent combination of education and experience.', '8 years of additional relevant experience may be substituted for education']",2020-09-24 14:12:22
Junior-Mid Data Scientist,TechSur Solutions,N/A,"Sterling, VA 20166",[],2020-09-24 14:12:22
Big Data Engineer,ScienceSoft USA Corporation,N/A,"McKinney, TX 75070","['Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities;', 'Implementing ETL process;', 'Monitoring performance and advising any necessary infrastructure changes;', 'Defining data retention policies.']",2020-09-24 14:12:22
Early Career Mechanical Engineer – DuPont Field Engineering Program & Direct Hire Opportunities,DuPont,4 out of 5,United States,"['Job', 'Company', 'Completing a Degree from an ABET accredited program in Mechanical Engineering by Spring 2021.', '5 months minimum, 3 years maximum of paid engineering work experience in manufacturing or Research and Development in an industrial setting.OR', '2.5 months of paid academic Research and Development work plus 2.5 months of paid Co-Op/ Internship engineering experience in manufacturing or Research and Development in an industrial setting.', 'Legal right to work in the United States without restriction.', '3.0 or greater GPA (out of 4.0 scale) preferred', 'Willingness to provide 24x7 area support when required – Acting as the lead technology resource for their area of production involvement in day-to-day troubleshooting to assure safe, continuous operation is a minimum requirement.', '100% geographic flexibility to allow for best career development fit.', 'Commitment to complete a minimum of two assignments totaling 4.5 – 5 years.']",2020-09-24 14:12:22
"Manager, Big Data Engineer",KPMG,4 out of 5,"Las Vegas, NV 89169","['Job', 'Company', 'Rapidly architect, design, prototype, implement, and optimize cloud architectures, platforms and applications to tackle the needs for a variety of Fortune 1000 corporations and other major organizations; develop cloud platforms and applications using infrastructure as code methodologies to solve real world problems ensuring quality and compliance following best practices in the industry', 'Work in cross-disciplinary teams with KPMG industry professionals to understand client needs and be part of teams developing holistic operational solutions & applications contributing with the cloud infrastructure', 'Research, experiment, and utilize leading cloud methodologies and new tools for increased productivity, security, reliability and performance; provide proficient documentation and operating guidance for users of all levels', 'Develop skills in business requirement capture and translation, hypothesis-driven consulting, work stream and project management, and client relationship development; help promote the KPMG brand in the broader data analytics community', 'Help drive the process for pursuing innovations, target solutions, and extendable platforms for Lighthouse, KPMG, and clients; participate in developing and presenting thought leadership and help to ensure that the Lighthouse technology stack incorporates and is optimized for using specific technologies', 'A minimum of seven years of experience architecting and/or implementing conversational systems / chatbots with platforms such as IBM Watson, Google Dialogflow etc.', ""Bachelor's degree from an accredited college/university or Master's degree from an accredited college/university with minimum two years of experience; or a PhD in Computer Science, Computer Engineering, Engineering or related fields from an accredited college/university"", 'Experience in API Management with platforms such as IBM API Connect, Google Apigee etc.', 'Experience in enterprise integration with atleast one ESB such as IBM IIB, Boomi, MuleSoft etc.', 'Experience producing architecture work products incl experience with UML tools', 'Required: Architect or specialization certification in at least one of AWS / Azure / GCP.', 'Preferred: Experience with IVR/Telephony integration.', 'Good understanding and broad exposure to the AI capability landscape including semantic search, speech systems, information extraction etc.', 'Ability to travel up to eighty percent', 'Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future']",2020-09-24 14:12:22
Consultant - Data Engineer,Insygnum,N/A,"Chicago, IL","['You will receive competitive salary, benefits, and stock options', 'You will be working on hard, interesting problems', 'You will help shape the culture of the company as we grow', 'You will have the opportunity to apply your skills in a meaningful way and have a real-world impact', 'Help design an architecture for federated data stores and data fusion', 'Help design methods for storing data in a way that facilitates extremely fast data parsing and management', 'Implement ""glue code"" that connects middle tier components with backend components', 'Implement data management and analytics code utilizing data architecture (e.g. map reduce)', 'Collaborate with machine learning folks to determine how to analyze various data sets and set up methods for querying data stores', 'Collaborate with data architects to understand the applications we integrate with and the data they produce', 'Review requirements for new approaches to big data storage and analytics', 'Design methods for caching, paging, and integrating real-time data with historical data stores', 'Development knowledge for integrating components and contributing to core code base - Java preferred', 'Solid understanding of database and data warehousing technologies', 'Knowledge of SQL as well as NoSQL queries, syntax, and technologies', 'Knowledge of big data requirements, applications, and technologies such as Hadoop', 'Knowledge of ETL methods and approaches including triggers, named views, temporary tables, etc.', 'Linux expertise', 'Java is strongly preferred (e.g. for working with map reduce) but not ultimately a requirement if you excel in other areas', 'Strong SQL skills are highly desirable', 'OLAP experience', 'Experience with ETL tools like Informatica, Boomi, Pentaho, AbIntio, Datastage, etc.,']",2020-09-24 14:12:22
Data Engineer,KORTX,N/A,"Berkley, MI","['Employer Covered Medical, Vision & Dental Insurance Effective Day 1 of Employment', '401k Match', 'Monthly Health and Wellness Reimbursement', 'Cell Phone Reimbursement', 'Open Vacation Policy', 'Proven experience with Java/C#/C++/Python', 'Experience data workflow products (Luigi, Apache Airflow, AWS Pipeline)', 'Strong understanding of stream and batch processing solutions', 'Data warehouse experience (Snowflake, Redshift, etc.) and strong SQL background', 'Experience with NOSQL databases (e.g. Elasticsearch, DynamoDB, etc.)', 'Strong AWS background (EC2, ECS, CloudWatch, Kinesis, Lambda)', 'History of working on fast-paced teams or in startup environments', 'Required: 3 – 5 years of hands-on experience developing solutions from design to implementation', 'Accessing and storing raw data in a way that allows for clean aggregation and fast queries in real time', 'Consulting with potential & existing clients in a way that allows for an effective and competitive data strategy', 'Design and implement data solutions that are both cost effective as well as accessible while planning for scalability and privacy compliance', 'Attractive Annual Salary', 'Employer Covered Medical, Vision & Dental Insurance Effective Day 1 of Employment', '401k Match', 'Monthly Health and Wellness Reimbursement', 'Cell Phone Reimbursement', 'Open Vacation Policy', 'Flexible Hours', 'Great Place to Work Certified', 'Ranked on Inc. Magazine’s 2019 and 2020 Fastest Growing Companies Lists', 'No Outside Recruiters Please']",2020-09-24 14:12:22
Entry Level OCS (Catenary) Engineer,AECOM,3.7 out of 5,"Philadelphia, PA 19133",[],2020-09-24 14:12:22
Data Engineer,Jobvite,3.9 out of 5,"Indianapolis, IN 46204","['Translate business requirements into technical specifications.', 'Participate in all design reviews and requirement sessions, as required.', 'Understand database design, programming concepts, data modeling, and framework management.', 'Communicate ideas to both technical and non-technical people in all levels of the organization.', 'Create or update technical documentation for transition to support teams, including data flows and transformations.', 'Design, develop, and test data pipeline solutions and automate data loading processes.', 'Develop and implement an efficient migration process to move data pipeline objects from development to test and production environments.', 'Analyze data requirements, complex source data, and application data models, and determine the best methods for integrating data to support internal and external analytical needs.', 'Design and implement data models to support reporting, dashboarding, and integration needs.', 'Develop automated data audit, testing, and validation processes.', 'Stay up to date on ever evolving technologies and processes for managing data pipelines', '5+ years of data and/or software engineering experience.', 'Expert SQL skills and database ETL/ELT', 'Development experience with Java, Ruby, Python', 'Experience with public cloud solutioning (i.e., AWS, Azure, GCP).', 'Developing streaming data flows (i.e., w/ Kafka, Beam, AWS SQS, Spark Streaming)', 'Experience leading development efforts - gathering requirements, analyzing solutions, and executing', 'Additional Experience needed:Designing and developing complex data flows.Creating data models based on complex business entities.Large scale, complex data migration efforts.Loading data from internal / external APIs.Public cloud analytical database solutions (i.e., Snowflake, Redshift).Shell scripting.', 'Excellent Analytical skills and Flexibility/Adaptability when working as a team.', 'Preferred Experience:Experience with Machine Learning.Experience with BI and Reporting Tools (i.e., Looker, Tableau, PowerBI, Qlik).Experience in delivering solutions based on Agile principlesExperience with Kubernetes / containers', 'This role can also be remote based anywhere in the United States']",2020-09-24 14:12:22
Industrial Engineer- Flexible Location,UNITED PARCEL SERVICE,3.8 out of 5,"Blacksburg, VA","['Job', 'Company', 'Develop process improvement and layout changes to increase productivity and profitability.', 'Perform operational observation and process documentation.', 'Create, analyze and apply original work measurement.', 'Monitor and develop productivity standards for functional areas based on work measurement.', 'Develop operational volume forecasts and present staffing plans to the IE team.', 'Interact with cross-functional teams to resolve operational problems.', 'Identify exceptions, formulate recommendations, and implement process improvements.', 'Provide steady flow of information to management, customers, internal personnel, and direct reports as committed.', 'Conduct cost benefit analysis on projects requiring capital expenses and document validation of findings.', 'Knowledge of Industrial Engineering and or Engineering related discipline', 'Effective statistical analysis skills', 'Effective research and communication skills', 'Effective with written and oral communications']",2020-09-24 14:12:22
Onsite Engineer,HealthSpaces,N/A,"Columbus, OH 43212","['mindset over knowledge', 'the way you think over years of experience', 'culture over compensation', 'eagerness to learn over what you know', 'collaboration over departmental hierarchies', 'freedom to explore new technologies over existing tools and methods', 'Creative – you find unique ways to solve difficult problems and challenge the status quo', 'Self-managing - you take full ownership of driving tasks to completion, and helping those around you in doing the same', 'Collaborative – you recognize that working as a team yields more effective results than working alone; do you value your workplace culture and your co-workers experiences over chasing compensation; do you challenge others and set high goals for yourself and the people around them; do you want to spread your knowledge and insights to those around you in order to make them better.', 'Results driven – you focus on projects that deliver value to the end user; do you chase the ability to cause change and disrupt industries; are you the type to find solutions to major problems', 'Business savvy – you understand your clients and deliver solutions that cater to their needs', 'Cross disciplinary – you have skills that span across disciplines and are comfortable playing different roles in more than just one area', 'Continuous learner – you seek out ways to constantly develop your skills and invest in learning every single week', 'Agile – you pivot easily within a constantly changing environment and are comfortable with a high degree of change', 'Risk taker – you see failure as part of the learning process and do it time and again; are you the type to not hold back on whenever you have an idea; are you not scared to try something new, and will do your best in collecting data and analytics to make sure that your ideas are foolproof', 'Individual contributor – you wait for directives from management and work individually to accomplish goals', 'Specialist - you specialize in a specific discipline in order to gain an ever- deeper understanding and contribute your key expertise in that area', 'Traditional – you thrive within structured corporate organizations where roles and titles are clearly defined, and where you can climb the corporate ladder', 'Management – you’ve established yourself as a manager within a hierarchy and are responsible for following and enforcing traditional HR practices', 'Passive – you prefer to leave the good ideas to others and focus instead on implementing them', 'Conservative – you stick with what has worked in the past, you are uncomfortable challenging the status quo, and generally avoid taking risks and trying new approaches', 'Linear – you are most comfortable working in a traditional project plan/gantt chart environment', 'Install/maintain servers, network, and storage devices.', 'To pickup configuration and maintenance of generic applications.', 'Good analytical and problem solving skills', 'Up-to-date technical knowledge', 'Good interpersonal and customer care skills', 'Strong computer skills', 'Ability to troubleshoot and diagnose problems', 'Ability to communicate effectively to help customers fix their issues and feel satisfied with the experience', 'Logical thinker', 'Competitive salary', 'Additional employee benefits and perks', 'Tech Stipend', 'One-of-a-kind culture', 'Multiple locations']",2020-09-24 14:12:22
Java/Data Engineer,Systems Personnel,4.7 out of 5,"Buffalo, NY","['Java', 'Spring (Spring Boot, Spring Cloud Data Flow)', 'SQL Experience – strong Relational Database knowledge', 'Web services creations']",2020-09-24 14:12:22
Equipment Breakdown Risk Engineer,Liberty Mutual Insurance,3.6 out of 5,"Juneau, AK 99801","['Job', 'Company', 'Perform jurisdictional inspections on boilers and pressure vessels within assigned territory and report findings to the authority having jurisdiction and other interested parties. Support underwriters with risk assessment account reviews and serve as a technical resource to field claim adjusters', ""Conduct extensive research and data collection which helps to identify customer's source of risk, loss and costs. Compiles facts from on-site visits and various reports and databases to assess existing processes/practices, determine severity/frequency of problems, and identify needs. Assesses and benchmarks customers performance against internal and industry standards."", ""Interpret and analyze data to determine best course of action and/or solution that satisfies customer's risk service's needs. Utilize advanced software applications to help find innovative and cost-effective solutions to customers risk service's needs. Conduct cost-benefit analysis to determine how and when a recommended improvement at customers' facility/operation will pay off. Investigate cause and effect relationships."", 'Prepare technical reports which reports and evaluates data.', 'Organize data into a format which can easily be presented to customer. Prepare and present reports which outline action plan for improved practices and/or changing workforce cultures/behaviors.', ""Maintain effective partnerships with customers. Learn about customer's business in order to identify risk management objectives and needs. Ensure accurate and concise communication and mutual understanding with customers. Keep customers informed of status of services, support material available and outside resources relevant to identify customers' safety concerns."", 'Participate in training and development of customers. Oversee implementation of program(s). Provides technical support to assist with implementation of recommendations/actions plans. Counsel customers regarding technical issues.', 'Actively pursues professional development efforts to better meet customer expectations.', 'May actively participate in acquiring new business by following up on leads and presenting proposals to potential customers.', 'National Board Commission required.', 'Knowledge, skills and experience in boiler and pressure vessel inspections, service planning and delivery, risk assessment, risk analysis, solutions management and progress measurement. Fully effective interpersonal, writing and other communication skills required to develop and maintain relationships with customers, peers, and industry contacts.', ""Bachelor's degree or equivalent with coursework in mathematics and engineering or related area, plus a minimum of 3 years of directly related consulting experience. Demonstrated ability to retrieve and enter information using various proprietary software applications and create/modify documents and spreadsheets using Microsoft Office suite."", 'Ability to work closely with Claims and Underwriting.', 'Position requires regular travel.']",2020-09-24 14:12:22
Data Engineer - Threat Analysis,Ursus,N/A,"Menlo Park, CA 94025","['We are looking for engineers with extensive experience investigating and analyzing online abuse, and actively implementing countermeasures.', 'Our focus on data analysis and machine learning as well as our knowledge of the robust infrastructure of our back-end systems allows us to collaborate seamlessly with engineering, data science, and operations teams to build tools and techniques necessary to enforce content quality at scale.', 'Integrity Science Engineers have the opportunity to work on many of the most challenging, complicated, and high-visibility integrity risks the company faces.', 'The potential for impact with this work is substantial, as outcomes could affect the billions of people who use our products.', ""Successful candidates for this team have a bias toward action and enjoy finding patterns amid chaos, making quick decisions, and aren't afraid of being wrong."", 'The perfect candidate will have a background in a quantitative or technical field, will have experience working with large data sets, and will have in-depth experience in data-driven decision making.', 'You are scrappy, focused on results, a self-starter, and have demonstrated success in using analytics to reduce abuse and negative user experiences across the platform.', 'Identify and investigate online bad actors', 'Work closely with others to identify sources of abusive behavior and take countermeasures to stop abuse', 'Lead technical investigations from start-to-finish and effectively communicate actionable results to different audience types', 'Manage multiple projects at once while prioritizing time based on team priorities', '2+ years experience doing quantitative analysis', 'BA/BS in Computer Science, Math/Finance, Physics, Applied Economics, Statistics or other technical field.', 'Experience investigating and acting on high-impact threats and online threat actors', 'Experience with relational databases and SQL', 'Experience thinking critically and qualifying assessments with solid communications skills', 'Experience coding in at least one of the following: PHP, Python, Haskell, or Java.', 'Advanced degrees in Computer Science, Math/Finance, Physics, Applied Economics, Statistics or other technical field.', 'Experience prioritizing and executing with minimal direction or oversight', 'Experience working across the broader integrity/security/Trust & Safety community', 'Experience in adversarial space like fraud and spam.', 'Proven track record of managing and executing on short term and long term projects', 'Development experience in Haskell.', 'Familiarity with cross-platform integrity threats', 'Demonstrated understanding of security and integrity risks']",2020-09-24 14:13:03
Data Engineer,Sierra Nevada Corporation,3.7 out of 5,"Herndon, VA 20171","['Create, configure, implement, document and maintain ingestion, enrichment and analytic pipelines using distributed big data platform', 'Extend base platform functionality by adding new ingestion and analytic sources', 'Identify, evaluate and implement big data tools and frameworks required to provide requested capabilities', 'Experience with NoSQL database Elasticsearch.', 'Experience with data pipeline tool NiFi.', 'Experience with NoSQL databases in general, like Elasticsearch and MongoDB.', 'Experience with big data tools like Hadoop, Spark, Kafka.', 'Experience with data pipeline and workflow management tools like NiFi, Azkaban, Luigi, Airflow.', 'Experience with scripting languages like Python or Perl.', 'Requires a BA/BS in Related Field. Relevant work experience may substitute for required education.', 'The ability to obtain and maintain a Secret U.S. Security Clearance is required', 'Experience with AWS cloud services: EC2, EMR, RDS, Redshift', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala.', 'Experience with relational SQL databases like Postgres.', 'Experience with stream-processing systems: Storm, Spark-Streaming.']",2020-09-24 14:13:03
Data Engineer,Boston Children's Hospital,4.1 out of 5,United States,"['Strong background in distributed data processing and software engineering, can build high-quality, scalable data products.', 'Good knowledge of data architectures, databases, data modeling and data infrastructure ecosystem.', 'You love freedom and dislike being micromanaged. Given context, you’re capable of self-direction.', 'Motivated to explore new technologies and learn, and can do so without taking formal education.', 'Passionate about open source and interested in having your work widely used around the world.', 'Collaborate with partners to understand needs, model tables using data warehouse standard methodologies, and develop data pipelines to transform and load large healthcare datasets.', 'Develop automation and tooling to support distributed querying across federated cloud data repositories.', 'Manage the entire lifecycle of projects independently, including but not limited to, gathering requirements, communicating design decisions to cross-functional teams, and proactively seeking and incorporating user feedback.', 'Present your work at conferences and meetings and collaborate with developers from other organizations to create and improve open standards.', 'Bachelors or Masters in Computer Science or related technical discipline or equivalent industry experience.', 'BS and 5+ years of relevant work experience, MS and 4+ years of relevant work experience, or PhD and 3+ years of relevant work experience', 'Experience in big data technologies (eg. Spark, BigQuery, Redshift, Flink, Map/Reduce, HDFS, Pig, Hive, Presto, Airflow, Luigi, Kafka, Avro, Parquet)', 'Experience building data infrastructure in the cloud (eg. AWS, Google Cloud, Azure)', 'Practical experience with Python and SQL including ability to write, analyze, and debug SQL', 'Comfort working in a variety of tech stacks - a working knowledge of NodeJs and front-end development is a plus but not required', 'Experience with Jupyter notebooks (or similar) is a big plus', 'Ideal candidates will have a deep understanding of technical and functional designs for databases, reporting, and data mining areas.', 'Strong communication and collaboration skills', 'Sharing a link to your work on GitHub is a plus.', '401(k)', 'Dental insurance', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Tuition reimbursement', 'Vision insurance', 'Monday to Friday', 'Fully Remote', 'Yes']",2020-09-24 14:13:03
Software & Data Analytics Engineer,FacilityConneX,N/A,"Nashua, NH 03062","['Develop analytics within well-defined projects to address customer needs and opportunities.', 'Continuously contribute to improving and building out our analytics platform.', 'Assist in the build-out of our analytics library on our next generation Python based framework.', 'Work alongside software developers, software engineers, and partner subject matter experts, to translate algorithms into commercially viable products and services.', 'Work in technical teams in development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.', 'Share and discuss findings with team members and customer clients.', 'Provide quality documentation for both end users and internal teams.', 'Bachelor’s Degree in a “STEM” major (Science, Technology, Engineering, Mathematics)', 'At least 5 year’s full-time experience in applying data science software solutions.', 'Demonstrate strong proficiency using Python and associated data science packages (e.g. Pandas, NumPy, SciPy, Scikit-learn, Tensorflow)', 'Very solid experience working on daily basis with Linux-based operating systems', 'Demonstrated skill in the use of various database software tools (e.g. SQL, Redis, S3, Dynamo, OLAP)', 'Comfortable working in common programming languages / interfaces (e.g. JavaScript, Node JS, REST, GO)', 'Demonstrated skills in data cleaning, features engineering, model selection to best suit the application and data.', 'Demonstrated skill in the use of applied analytics and predictive analytics on streaming time- series data.', 'Familiar with CI/CD techniques associated with provisioning of analytics to production environments. E.g Docker, Kubernetes, GitHub Actions, other CI/CD and IaC technologies.', 'Solid experience with Docker containers and Kubernetes in collaboration with development team', 'Legal authorization to work in the U.S. is required. We will not sponsor individuals for employment visas at this time.', 'Must be willing to travel up to 10% if needed.', 'Strong passion for technology, a willingness to learn new skills and the ability to convert to new technologies', 'Self-motivated and self-directed, ability to translate technical direction into functional solutions', 'Ability to work effectively, managing multiple priorities', 'Proven ability to investigate complex issues and drive to completion', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Professional Development Assistance', 'Retirement Plan', 'Vision Insurance', '8 Hour Shift', 'Monday to Friday', 'Analytics: 5 years (Preferred)', 'Python: 5 years (Preferred)', ""Bachelor's (Required)"", 'Nashua, NH 03062 (Required)', 'Are you able to work without any visa sponsorship requirements or C2C arrangement?', 'One location', 'No', 'No: Not providing sponsorship for this job', 'Dependable -- more reliable than spontaneous', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Autonomous/Independent -- enjoys working with little direction', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'facilityconnex.com', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-09-24 14:13:03
Research Scientist,"APPLIED SCIENCES, INC",N/A,"Cedarville, OH 45314",['US Green Card (Required)'],2020-09-24 14:13:03
Facility Engineer (Data Center) - HVAC experience a must,Critical Ventures,N/A,"Piscataway, NJ","['Effectively oversee daily datacenter operations with respect to the facility and inventory', 'Ensure all infrastructure systems are operating within established tolerances, proactively maintained, and adequately serviced when necessary', 'Diagnose and troubleshoot electrical and mechanical systems as needed', 'Monitor the performance of and develop strong business relationship with vendors, carriers, and other outside agencies that interact with the data center', 'Provide support to NOC and networking team', 'Provide basic remote hands support', 'Occasionally perform maintenance or emergency work outside of regular business hours', '2+ years experience in servicing electrical and mechanical infrastructure of a building or a facility (ideally, a data center)', 'Understanding of computer networking and hardware concepts', 'Effective time management and communication skills', 'Strong analytical skills and attention to detail', 'May be required to lift up to 50 lbs.', 'Monday to Friday', 'Data Center: 2 years (Preferred)', 'Facilities Maintenance: 2 years (Preferred)', 'HVAC: 1 year (Required)', 'United States (Required)', 'Yes', 'Team-oriented -- cooperative and collaborative', 'No']",2020-09-24 14:13:03
Sr. Data Warehouse Engineer,"PRA Group, Inc.",N/A,"Norfolk, VA","['Design, develop and maintain optimal data pipeline architecture', 'Assemble large, complex data sets that meet business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'Work with stakeholders to assist with data-related technical issues and support their data needs.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Responsible for ensuring compliance with applicable laws, regulations and company policies across areas of organizational responsibility.', 'Bachelor’s degree in Computer Science or related quantitative disciplines.', '5+ years of experience in a Data Engineer role', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Strong project management and organizational skills.', '3+ years of experience in any ETL/ELT tool', 'Experience with big data tools: Hadoop, Spark, Kafka, etc is a Plus', 'Experience with relational SQL and NoSQL databases', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'ETL/ETL tool: 3 years (Preferred)', 'data engineer: 5 years (Preferred)', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Flexible schedule', 'Tuition reimbursement', 'Temporarily due to COVID-19']",2020-09-24 14:13:03
Transport Data Interconnect Engineer,ClientSolv Technologies,4 out of 5,"Littleton, CO","['Experience working with Internet Exchange Points (IPX) and Tier 1 telco hotels/data centers.', 'Define data interconnection requirements including APIs, transport interfaces and other interconnection.', 'Develop peering, IP transit and other interconnection requirements for the 5G network.', 'Manage data traffic flows and recommend network changes as traffic profiles change.', 'Define and later support the implementation of peering agreements and interconnection.', 'Understanding of traffic engineering, Internet access services and Ethernet services.', 'System architecture including reliability, security and redundancy requirements.', 'Working knowledge of various applicable standards and frameworks: IETF, MEF, etc.', 'Actively contribute to improvements and participate in innovation, lessons learned, and knowledge sharing activities.', 'Ability to define and manage performance with SLAs and KPIs.', 'Ensure that work meets all applicable engineering, financial, planning, and operational standards.', 'BS in a technical field or an equivalent combination of education and experience', '8 + years Internet / Telecommunications network experience', 'Working knowledge of DNS and BGP', 'Working knowledge of virtualization and software defined networking', 'Must have a strong understanding of O-RAN and other 5G architectures', 'Familiarity with optical networking and interfaces', 'Extensive work with data centers and familiarity with virtualized environments such as Amazon Web Services (AWS)', 'Analyzing new network requirements, deployments, augmentations, bandwidth upgrades and software upgrades', 'Ability to write detailed technical specifications', 'Ability to manage multiple commitments simultaneously', 'Excellent communication and follow-up skills', 'Proven ability to work independently and escalate issues appropriately', 'Ability to delivery in fast-paced high volume environment supporting aggressive targets', 'Monday to Friday', 'E911: 3 years (Preferred)', 'strong understanding of O-RAN and other 5G architectures: 3 years (Preferred)', 'Internet / Telecommunications networ : 7 years (Preferred)', 'Data Traffic : 5 years (Preferred)', 'Yes', 'No']",2020-09-24 14:13:03
Data Engineer,Brooksource,3.7 out of 5,"United, PA","['Job', 'Company', 'B.S. in Computer Science, Mathematics, Statistics or related field', 'Experience with Health Catalyst Data Platform', '5+ years of Data Development and Data Design', '3+ years in Healthcare analytics, with significant experience using payor claims data', '4+ years using SQL Server (SSIS, SSMS SSRS, MDM)', 'Write SQL queries, stored procedures, packages, functions, database triggers, and views', 'Create and develop automated ETL processes for data loading, report generation, data transfers, and quality control', 'Maintain robust QC processes to ensure data integrity', 'Utilize established and standard methodologies to QC data', 'Recommend and implement best practices for data management and governance', 'Help set technical direction and provide guidance to more junior data engineers', 'Solve technical problems, simple and complex, in a lean and efficient manner', 'Ensure data security implementations meet company requirements and standards', 'Health insurance', '8 hour shift', 'Monday to Friday', 'Health Catalyst: 1 year (Required)', 'Fully Remote']",2020-09-24 14:13:03
Data Engineer,Trianz,N/A,"Santa Clara, CA 95054","['Partner with leadership, engineers, program managers and data scientists to understand data needs.', 'Design, build and launch extremely efficient and reliable data pipelines to move data across a number of platforms including Data Warehouse, online caches and real-time systems.', 'Communicate, at scale, through multiple mediums: Presentations, dashboards, company-wide datasets, bots and more.', 'Educate your partners: Use your data and analytics experience to ‘see what’s missing’, identifying and addressing gaps in their existing logging and processes.', 'Leverage data and business principles to solve large scale web, mobile and data infrastructure problems.', 'Build data expertise and own data quality for your areas.', '5+ years of Python development experience.', '5+ years of SQL experience.', '3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, digdag.io, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M).', '3+ years experience with Data Modeling.', 'Experience analyzing data to discover opportunities and address gaps.', '5+ years experience in custom ETL design, implementation and maintenance.', 'Experience working with cloud or on-prem Big Data/MPP analytics platform(i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar).', 'Experience with more than one coding language.', 'Experience with designing and implementing real-time pipelines.', 'Experience with data quality and validation.', 'Experience with SQL performance tuning and E2E process optimization.', 'Experience with anomaly/outlier detection.', 'Experience with notebook-based Data Science workflow.', 'Experience with Airflow.', 'Experience querying massive datasets using Spark, Presto, Hive, Impala, etc.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Employee Assistance Program', 'Flexible Schedule', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Parental Leave', 'Professional Development Assistance', 'Referral Program', 'Relocation Assistance', 'Retirement Plan', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'www.trianz.com', 'Temporarily due to COVID-19']",2020-09-24 14:13:03
Solutions Engineer – Unstructured Data,Request Technology,N/A,"Chicago, IL",[],2020-09-24 14:13:03
Project Engineer,FORMA Construction Company,N/A,"Silverdale, WA",['GC project engineer: 5 years (Required)'],2020-09-24 14:13:03
Data Platform Engineer,FIS Global,3.5 out of 5,"Cincinnati, OH 45999","['Contribute to tooling and automation – enhancing productivity of end users and developers in the ecosystem', 'Proactively work to identify factors impacting the availability of critical endpoints and provide solutions', 'Explore public cloud technologies and extend the limits of existing infrastructure to solve unique scaling challenges.', 'Work closely with infrastructure, network, database, business intelligence and application teams to ensure standardization/optimizations of solutions deployed on big data platform.', 'Provide subject matter expertise on the capabilities and use of cluster components, big data technologies including but not limited data ingestion, data analysis, data governance, data management.', 'Develop tools and solutions to integrate, automate, and orchestrate cloud operational needs using Automation, AWS DevOps and Snowflake templates.', 'Define and bring in “Continuous Integration and Continuous deployment” standard methodologies', 'Continually acquire new data sources to develop an increasingly rich dataset', 'Fully own critical portions of data model. Collaborate with business partners to understand needs, model tables using data warehouse with DBT, and develop reliable data pipelines to ensure the timely delivery of high-quality data', 'Be a bridge between data engineering and the business, enabling insight that can empower better decision-making.', 'Design, build and launch extremely efficient and reliable data pipelines to move data across several platforms including Data Warehouse, Data Lakes', ""Minimum of 5+ years of related experience with bachelor’s degree or 4 years with master's degree"", '5+ years of Python development experience.', '5+ years’ experience in custom ETL design, implementation and maintenance.', 'Experienced in engineering data pipelines using big data technologies (Oracle Goldengate, Hive, Presto, Spark, etc...) on large scale data sets', 'Experienced in using Terraform, Ansible, Docker, EKS, Jenkins, Packer, DBT', 'Strong awareness of networking and internet protocols, including TCP/IP, DNS, SMTP, HTTP and distributed networks.', 'Serverless data collection pipeline using Kinesis, API Gateway, Lambda, S3, and SQS', 'In-depth knowledge of Snowflake architecture to create performance tuning and optimized data pipelines, query, and storage solutions.', 'The chance to work on some of the most challenging, relevant issues in financial services & technology', 'A fantastic range of benefits designed to help support your lifestyle and wellbeing', 'A multifaceted job with a high degree of responsibility and a broad spectrum of opportunities']",2020-09-24 14:13:03
Aerospace Engineer / Mechanical Engineer,Perspecta,3.3 out of 5,"King of Prussia, PA 19406","['Job', 'Company', 'Bachelor’s degree in engineering (aerospace, mechanical, electrical), physics, mathematics, computer science, image science or similar technical discipline', 'High degree of computer literacy with ability to rapidly learn complex applications and tools', 'Competence/experience in one or more of the following: Matlab, Python, Perl, Java, C++, SAS, or R', 'Strong analysis skills, with the ability to identify and accurately describe system issues', 'Ability to write and speak confidently, articulately, and clearly in order to participate in and brief at technical meetings', 'Ability to work independently and within a team environment']",2020-09-24 14:13:03
Data Visualization Engineer,Harnham,4.6 out of 5,"McLean, VA","['Put together data visualization customized designs, layouts, and implementation for various aviation clientele relating to crew members, black box data, etc.', 'Interact regularly with senior business stakeholders to understand what problems they are facing and how to create optimized visualization designs', 'Work closely with Data Science and Engineering teams to gather relevant, formatted and structured data to convert to accessible information', 'Act as the visualization expert for internal self-service of business units', 'You are an expert in presenting business critical insights to a large audience', 'You are commercially proficient in using D3.js for digital visualizations', 'You are capable of and professionally experienced with coming up with designs combining large volumes of relevant data across different businesses/departments', 'You are preferably coming out of a larger company pertaining to telecommunications, media, or similar insight-forward industries', '$140,000-$150,000 base annual salary', 'Medical, Dental, Vision Benefits', '401K', 'PTO/Vacation package', 'Collaborative, technology forward environment']",2020-09-24 14:13:03
Principal Engineer - Big Data,Indeed,4.3 out of 5,"Austin, TX 78731","['Other rewards may include quarterly bonuses, Long Term Incentives, an open Paid Time Off policy, and many region-specific benefits.', 'Austin Base Salary Range:', '172,000 - 218,000 USD per year', 'Consult with product teams across Indeed to advise on data platform and data integration best practices', 'Partner with data infrastructure and product teams on the development of prototypes, as well as designs for future integrations.', 'Analyze existing solutions and requirements, perform cost/benefit and scalability analysis, and make recommendations for platform consolidation', 'Collect feedback on current data infrastructure gaps and opportunities for improvement and bring back to Data Infrastructure leadership for prioritization.', 'Provide documentation, training, and consulting for data infrastructure users', 'Provide input and feedback to support continuous improvement in team processes', 'Drive projects and coordinate cross-team efforts in an independent and self-directed way', '10+ years in a Data Engineering or Data Platforms role', '10+ years coding experience (java or python preferred)', '8+ years hands on experience with AWS and big data technologies (Hadoop, Spark, Presto, Kafka, and similar)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of data lake fundamentals and building efficient data pipelines', 'Strong communication, collaboration, and multi-tasking abilities', 'Experience with Agile methodologies', 'View our bounty of perks: [1] http://indeedhi.re/IndeedBenefits']",2020-09-24 14:13:47
Mechanical Engineer,Confidential,N/A,"Grand Prairie, TX","['$60,000.00 - $70,000.00 per year', 'Benefits:', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Schedule:', 'Perform a full life-cycle product development (design, develop, test prototypes, manufacture and implement)', 'Design systems and components that meet needs and requirements', 'Produce outline designs', 'Conduct experiments methodically, analyse data and interpret results', 'Test and evaluate theoretical designs', 'Identify, formulate and produce effective solutions to emerging problems', 'Evaluate final product’s overall performance, reliability and safety', 'Alter and modify design to meet requirements and to eliminate malfunctions', 'Estimate budget and scope of project', 'Solicit observations from operators', 'Prepare product reports and documentation', 'Engage in lifelong learning and develop new theories or methods', 'Industrial experience: at least 7 years (Required)', 'Auto Cad : At least 7 years of familiarity with 2D or 3D engineering design and manufacturing tools (AutoCAD, ProE or other)', 'Solid understanding of core concepts including mechanics, kinematics, thermodynamics, materials science etc.', 'Creativity and analytical skills', 'Ability to communicate technical knowledge in a clear and understandable manner', 'Technical writing skills', 'Knowledge of QC procedures', 'BSc degree in Mechanical Engineering', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Monday to Friday', 'Industrial Mechanic: 5 years (Required)', ""Bachelor's (Required)"", 'Grand Prairie, TX (Required)', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Stable -- traditional, stable, strong processes', 'Team-oriented -- cooperative and collaborative', 'Waiting period may apply', 'No']",2020-09-24 14:13:47
Data Engineer – Consumer & Media Data,Procter & Gamble,4.2 out of 5,"Cincinnati, OH 45201",[],2020-09-24 14:13:47
Systems Engineer,Patrick Industries,3 out of 5,"Elkhart, IN 46516","['Patrick Industries offers a full suite of benefits to include Health, Dental, Vision, Life, Matching 401K, paid holidays, paid vacations, health club, and tuition assistance.', 'Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Employee discount', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Referral program', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', 'Maintains and creates technical documents and knowledge base information; documenting actions by completing forms, reports, logs, and records', 'Perform onsite visits to perform deployments, enhancements, and maintenance', 'Research, plan, install, configure, troubleshoot, maintain, and upgrade hardware and operating systems', 'Upgrades information systems by conferring with vendors and services; developing, testing, evaluating, and installing enhancements and new software', 'Monitoring the systems performance and undertake maintenance and upgrades as required.', 'Analyzes user requirements, procedures, and problems to automate or improve existing systems and review computer system capabilities, workflow, and scheduling limitations.', 'Provide staff and users with assistance solving computer related problems, such as malfunctions and program problems.', 'Expand or modify system to serve new purposes or improve workflow.', 'Analyze functional business applications and design specifications for functional activities.', 'Apply business process improvement practices to re-engineer methodologies and principles and business process modernization projects.', 'Apply, as appropriate, activity and data modeling, transaction flow analysis, internal control and risk analysis and modern business methods and performance measurement techniques.', 'Assist in establishing standards for information systems procedures.', 'Secures information systems by developing system access, monitoring, control, and evaluation as well as completing back-ups.', 'Works with business units to select, implement, and maintain systems relevant to the operations of the company', ""Protects organization's value by keeping information confidential"", 'The candidate must have at least 10 years of experience in a corporate environment with supporting systems', 'Industry certifications are a plus', 'MCSE/MCSD/MCSA', 'Storage Concepts', 'MS System Center', 'PowerShell', 'Active Directory', 'Microsoft Windows Server 2012r2/2016/2019 (certification is encouraged)', 'Microsoft Exchange (2016, 2019)', 'Microsoft Active Directory', 'VMware or Microsoft Hyper-V', 'SANs (EMC and HP preferred)', 'Experience with scripting a plus', 'Experience with Microsoft SQL', 'Linux administration a plus', 'Ability to communicate with all levels of an organization', 'Self-starter', 'Work effectively and independently on multiple complex activities and projects', 'Strong analytical skills are required as well as the ability to think creatively to find solutions for issues that arise', 'The ability to effectively multitask and handle multiple projects at the same time', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Employee discount', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Referral program', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', 'Day shift', 'Monday to Friday', 'systems engineer: 10 years (Required)', 'No']",2020-09-24 14:13:47
GBSD Engineer Mechanical,Northrop Grumman,4 out of 5,"Colorado Springs, CO 80925","['Medical, Dental & Vision coverage', '401k', 'Educational Assistance', 'Life Insurance', 'Employee Assistance Programs & Work/Life Solutions', 'Paid Time Off', 'Health & Wellness Resources', 'Research, develop, design, test, and document mechanical structures/components.', 'Maintain and improve existing mechanical, electromechanical components, equipment, and system designs for integration.', 'Apply sound mechanical engineering principles and techniques.', 'Plan, perform, and direct engineering activities to ensure the design, integration, and testing conform to mechanical design specifications and requirements.', 'Responsible for gathering, maintaining, formatting, compiling, and analyzing technical data, such as laboratory or material test results and engineering design changes.', 'Produce engineering documentation, reports, drawings, flow charts, block diagrams, and schematics.', 'Conduct tests and record data to assist with engineering evaluations or analysis.', 'Other duties upon request.', 'Medical, Dental & Vision coverage', '401k', 'Educational Assistance', 'Life Insurance', 'Employee Assistance Programs & Work/Life Solutions', 'Paid Time Off', 'Health & Wellness Resources', 'Employee Discounts']",2020-09-24 14:13:47
Design Engineer,BFX Fire Apparatus,N/A,"Fort Worth, TX 76118","['Pay:', '$50,000.00 - $70,000.00 per year', 'Health Insurance', 'Paid Time Off', 'Schedule:', 'Review customer drawings, specifications or instructions from team members, supervisors, engineering, customer service', 'Maintain required productivity and quality per departmental priorities and standards', 'Be able to troubleshoot and problem solve', 'Be able to read, interpret and understand technical drawings and geometric dimensions and tolerance callouts', 'Be computer literate and have ability to draw parts in CAD/CAM applications', 'Ability to read and interpret blueprints, drawings and quality specs.', 'Perform in process inspection to verify measurements and specifications.', 'Must perform work in a timely manner with respect to schedule and quality standards.', 'Ability to multi-task in a fast paced manufacturing environment and does so with minimal supervision.', 'We are looking for an experienced individual with a motivated “self-starter” attitude and the ability to perform well independently and as part of a team.', 'Successful candidates will typically have the following skill set:', 'Experience with Geometric dimensioning and tolerancing (GD&T);', 'Experience in AutoCad and SolidWorks and FEA analysis;', 'Capable user of MS Word and MS Excel', 'Minimum 3 years’ experience in using AutoCAD and Solid Works software or similar', 'Minimum 3 years’ experience in Engineering field', 'A bachelor’s degree in engineering strongly preferred', 'A basic understanding of mathematics and technical skills in computer aided drafting', 'Solid foundation of knowledge and experience with production and engineering', 'Health Insurance', 'Paid Time Off', '8 Hour Shift', 'Day shift', 'Monday to Friday', 'SolidWorks: 3 years (Required)', 'Engineering: 3 years (Required)', 'Basic Computer Skills: 3 years (Required)', ""Bachelor's (Preferred)"", 'United States (Required)', 'One location', 'www.bfxfire.com', 'No']",2020-09-24 14:13:47
Associate Software Engineer,Northrop Grumman,4 out of 5,"Roy, UT","['Conduct multidisciplinary research and collaborate with equipment designers and/or hardware engineers in the planning, design, development, and utilization of electronic data processing systems for product and commercial software.', 'Determine computer user needs.', 'Analyze system capabilities to resolve problems on program intent, output requirements, input data acquisition, programming techniques and controls.', 'Prepare operating instructions.', 'Design and develop compilers and assemblers, utility programs, and operating systems.', 'Ensures software standards are met.']",2020-09-24 14:13:47
Thermal Engineer (Cleared),SimuLogix,N/A,"Sterling, VA 20166","['Pay:', '$85.00 - $100.00 per hour', 'Analysis, design, or test nature.', 'Apply theoretical knowledge and engineering techniques to the solution of analytical engineering problems.', 'Select and/or modify proven methods, mathematical formulas, previous design and test information, handbook data or other available information related to the assignment.', 'Thermal analysis of avionics, structures and liquid propellants.', 'Perform heat transfer analysis of components and systems on the ground and in space.', 'Use classical heat transfer methods and software to predict temperatures and design thermal protection of spacecraft and missile systems on the ground and in flight', 'Learn and develop proficiency with thermal software (Sinda/Fluint, Thermal Desktop, TSS and Sinda G, and other specialized heat transfer codes)', 'Interpret, select, and apply NASA/DOD/military specifications and customer requirements to accomplish specific analyses', 'Support thermal Vacuum test planning, execution and model correlation', 'Produce engineering documentation and technical reports/analyses to support design, integration, and testing efforts', 'Candidate shall be responsible for gathering, compiling, and interpreting technical data such as flight data, test data, or material test reports', 'Candidate must be able to take direction and address issues using skills obtained in the field of Mechanical Engineering, or related thermal sciences, preferably as it relates to space and missile systems.', 'Other duties upon request', 'Candidate must have a minimum of four years of related experience.', 'TOP SECRET CLEARANCE REQUIRED', 'Strong thermal background with demonstrated work experience and knowledge as a thermal analyst and test engineer', 'Ability to read engineering drawings and specifications', 'Familiarity with thermodynamics, aerodynamics, compressible flow and fluid mechanics', 'Thermal Desktop, Sinda, TSS, and Matlab experience', 'Candidate should possess good written and verbal communication skills', 'Candidate must have basic problem solving skills and computer skills with standard word processing/spreadsheet experience', 'Candidate should be able to listen effectively, take direction, and possess initiative to accomplish assigned tasks and complete work in a timely fashion', 'TOP SECRET CLEARANCE REQURIED', 'Bachelor of Science degree in Mechanical or Aerospace Engineering is required.', 'Master of Science degree in Mechanical or Aerospace Engineering a plus', 'Monday to Friday', 'Spacecraft Thermal engineering: 5 years (Required)', 'Thermal Desktop/Sinda: 5 years (Required)', ""Bachelor's (Required)"", 'Top Secret Clearance (Required)', 'More than 1 year', 'Likely', 'www.simulogix.com', 'No']",2020-09-24 14:13:47
Project Engineer,FORMA Construction Company,N/A,"Gig Harbor, WA","['BENEFITSFORMA Construction Company has a comprehensive benefit package including, but not limited to: medical, dental, vision, vacation/sick/holiday pay, Employee Assistance Program, educational assistance, and 401K Program.', 'Pay:', '$60,000.00 - $90,000.00 per year', 'GC project engineer: 5 years (Required)']",2020-09-24 14:13:47
Data Engineer,Pitney Bowes,3.6 out of 5,"Austin, TX 73301","['Are passionate about client success.', 'Enjoy collaborating with others.', 'Strive to exceed expectations.', 'Move boldly in the quest for superior and best in market solutions.', 'Develop and maintain data pipelines in and out of data warehouse using combination of Python, Snaplogic, SQL Server, and Snowflake SnowSQL with a focus on performance, reliability, durability, data quality, security and SLA expectations.', 'Work with cloud streaming technologies, like Kinesis and Kafka', 'Analyze, design, build, test, implement and automate integration technology solutions', 'Approach tasks from DataOps point of view; automate data audit, validation and monitoring processes', 'Write SQL queries against MS SQL and Snowflake databases', 'Provide production support for Data Warehouse issues such data load problems, transformation translation problems', 'Ensure accurate and timely data availability to meet business SLA, especially around critical time periods', 'Document data pipelines and data warehouse processes and flows', 'Work closely with business analysts to understand requirements and develop solutions', 'Experience with Snowflake cloud-based data warehouse or any columnar database is a big plus', '3-5 years of experience with data streaming, ingest, ETL, and data warehousing technologies', '2+ years of experience with Cloud-computing services, such as Amazon Web Services', '1+ experience developing Python based code that reads/writes data into databases', '3-5 years of experience with working in a data engineering role', 'Strong understanding of various data formats such as CSV, XML, JSON, AVRO etc.', 'Provide the opportunity to grow and develop your career', 'Offer an inclusive environment that encourages diverse perspectives and ideas', 'Deliver challenging and unique opportunities to contribute to the success of a transforming organization', 'Offer comprehensive benefits globally (pbprojectliving.com)']",2020-09-24 14:13:47
Data Engineer,H&R Block,4.2 out of 5,"Kansas City, MO 64126","['Motivated by the idea of building something innovative, transformative, and impactful.', 'Committed to the idea that data can drive experiences and products that wow our business partners and clients', 'Obsessed with defying expectations and raising the bar', 'Driven by an innate sense of ownership for the products you create.', 'Design and deploy architecture, solutions, and software to capture, manage, store, and use structured and unstructured data from internal and external sources in both on-prem and cloud environments.', 'Deploy machine-learning models and other data-science products across the enterprise.', 'Navigate the balance between business needs, data governance best practices, and technical requirements.', 'Select or develop tools to cleanse, organize, and transform data and to maintain, defend, and update data structures and integrity on an automated basis.', 'Develop data products to facilitate self-service capabilities and assist the data teams to increase their efficiency and effectiveness.', 'Collaborate and communicate effectively within cross-functional teams that span internal Data Science & Analytics teams, IT, business groups, and executive stakeholders.', 'Be a positive force to cultivate a culture that is passionate about developing data tools as a business driver.', ""Bachelor's degree in a related field or the equivalent through a combination of education and related work experience."", '3 years Minimum related work experience', 'Use of Data Stage', 'Fluent in Java, Python, and a C based language', 'In-depth knowledge of Hadoop and bigdata technologies such as MapReduce, Hive, and Pig, NoSQL technologies, SQL technologies, and data warehousing solutions', 'Able to help partners articulate business requirements', 'Intermediate (practical application) Relationship building and conflict management skills', 'Oral, written and interpersonal communication skills']",2020-09-24 14:13:47
Staff Data Engineer,Burns & McDonnell,3.7 out of 5,"Kansas City, MO","['Design and deploy large scale data platforms and data warehouses and data lakes', 'Design and deploy ELT, ETL and data ingest tools and strategies', 'Works both as part of cross-functional teams, and sometimes stand-alone, to understand data infrastructure needs of projects and product.', 'Quickly ramp up on industry domains to interact within cross-functional teams and design pragmatic solutions', 'Configure and deploy analytics processing engines, data catalog and governance solutions', 'Participate in industry events outside of the office', 'Commitment to quality, reliability, customer satisfaction, and data security', 'All other duties as assigned', 'Bachelor’s degree in Computer Science, Engineering, Math, Statistics, Physics or related field from an accredited program required.', 'Minimum 4 years of related experience', 'Demonstrated experience designing and deploying data warehouse and data lakes', 'Demonstrated experience deploying data ingestion systems. An understanding of third-party products and strategies.', 'Demonstrated experience with public cloud providers.', 'Experience with relational systems, object stores and HDFS', 'An understanding of application of analytics processing engines', 'Experience with systems operations and management', 'Experience with Agile practices preferred', 'Software development skills; SQL, Python or similar', 'Ability to work with team members and clients to assess needs, provide assistance, and resolve problems.', 'Strong problem-solving and analytical skills.', 'Related consulting experience preferred.', 'Ability to present and explain technical concepts to business audiences.']",2020-09-24 14:13:47
NLP Engineer,RecordsOne LLC,N/A,United States,"['Pay:', '$90,000.00 - $120,000.00 per year', 'Benefits:', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'Supplemental Pay:', 'Maintaining, improving and scaling existing NLP code and infrastructure', 'Coordinating with middleware and front-end developers', 'Working with subject-matter experts to create internal tools and analytics, address customer issues, and design and develop new product functionality', 'Excellent writing and reading comprehension', 'Solid communication skills: willing and able to report on plans and progress, ask questions and admit mistakes', '3-5 years of professional Java experience, preferably including version control (Git), dependency management (Apache Maven), and test frameworks and methodology (TDD)', 'UN*X system administration, scripting, and troubleshooting savvy', 'Active interest in computational linguistics', 'Relationship builder with strong communication skills', 'Strong organizational skills and attention to detail', 'Critical analytical thinker with demonstrated success in problem-solving and execution', 'Ability to work collaboratively with internal and external stakeholders', 'Exceptional analytical and debugging skills', 'Excellent communication and documentation skills', 'Ability to help create and map business needs/application requirements to technical solutions', ""Associate or Bachelor's degree in Computer Science, Information Technology, System Administration, or a closely related field, or equivalent experience required"", 'Continuous deployment', 'AWS', 'Relational databases (MySQL, Postgres, SQLite)', 'UIMA (cTAKES) or other standoff-annotation frameworks', 'Web services (microservice architecture)', 'ML development and deployment (Python)', 'Data science tools and metrics', 'Ontologies (esp. UMLS, SNOMED)', 'Medical coding (ICD-10, CPT/HCPCS)', 'A publicly available portfolio (e.g. on GitHub)', 'A working standalone code sample, with comments and build/run instructions', 'A code test', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'Bonus pay', 'coding: 3 years (Required)', 'Natural language processing: 3 years (Preferred)', 'professional JAVA : 3 years (Required)', ""Bachelor's (Required)"", 'United States (Required)', 'Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', 'Fully Remote', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Team-oriented -- cooperative and collaborative', 'www.recordsone.com', 'Only full-time employees eligible']",2020-09-24 14:13:47
Backend Engineer (Mid Level),"ReStream Solutions, Inc.",N/A,"Austin, TX 78751","['401k Retirement Plan', 'Fantastic medical, dental, and vision insurance', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Mechanical Engineering and Design - We design and build all of our own process equipment', 'Hardware Engineering - We design and build all of our own hardware', 'Software Engineering - We manage our own cloud infrastructure, end-to-end, including UI/UX', 'Data Science and Machine Learning - We do all of the analytics and machine learning applications with our data', 'Operations - We provide the “boots on the ground” and resources to keep our equipment operating smoothly', 'Business Development - We are always exploring new ways to make our data more useful', 'Build systems and tools that can parse, clean, and aggregate time-series data', 'Work with front end engineers to identify needed API functionality for our web applications', 'Work with data science team to identify API functionality needed for data analytics', 'Build, test, and maintain core services (APIs) with REST endpoints using the Flask framework', 'Support the embedded systems group as needed', '2+ Years Experience Coding Professionally', 'Experience with a major web framework (e.g., Django, Flask, Symfony, etc)', 'Creative thinkers who can deliver simple, effective solutions with few “moving parts”', 'Willingness to handle back-end and front-end development of web applications', 'Fun-Loving, adventurous souls who don’t mind team events and happy hours', 'AWS', 'Python (Flask & Django)', 'Postgres', 'RabbitMQ', 'MongoDB', 'React', 'STEM Major (Engineering, Physics, Mathematics, etc)', 'Data Analytics with Python, including NumPy, SciPy, Pandas, and Jupyter Notebooks', 'Embedded system development experience', 'Familiarity with electrical, mechanical, fluid, or chemical processes', 'Experience in the Oil and Gas Industry', 'Bonus pool - When the company does well we all benefit', '401k Retirement Plan', 'Fantastic medical, dental, and vision insurance', 'Startup vibe with a casual environment - but we focus on maintaining a work/life balance!', 'Video games, happy hours, pot lucks….we like to have fun!', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'python: 2 years (Preferred)', 'Austin, TX 78751 (Required)', 'Temporarily due to COVID-19']",2020-09-24 14:13:47
Resident Quality Engineer,Confidential,N/A,"Bowling Green, KY","['Pay:', 'Up to $30.00 per hour', 'Monday to Friday', 'Weekends', 'One location', 'No']",2020-09-24 14:13:47
Data Engineer,Open Systems Technologies,4.1 out of 5,"Chicago, IL 60608","['Create and maintain optimal data pipeline architecture', 'Assemble large, complex data sets that meet functional / non-functional business requirements', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs', 'Keep our data separated and secure across national boundaries through multiple data centers and AWS regions', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader', 'Work with data and analytics experts to strive for greater functionality in our data systems', ""A Bachelor’s Degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field (Master's Preferred)"", '5+ years of experience in a Data Engineer role', 'Experience with health care datasets, clinical data, payer/claims data, SDOH data, etc.', 'Experience with big data tools: Hadoop, Spark, Kafka, etc. (Preferred)', 'Experience with relational SQL and NoSQL databases, including Postgres and Cassandra', 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.', 'Experience with AWS cloud services: EC2, EMR, RDS, Redshift', 'Experience with stream-processing systems: Storm, Spark-Streaming, etc.', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Strong problem-solving skills with strong attention to detail', 'Strong customer service skills and the ability to react diplomatically and patiently to internal and external customers', 'Excellent follow-up skills paired with the ability to multi-task and determine root causes', 'Strong written and verbal communication skills coupled with the ability to read, analyze and interpret technical procedures', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement', 'Strong analytic skills related to working with unstructured datasets', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management', 'A successful history of manipulating, processing and extracting value from large disconnected datasets', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores', 'Experience supporting and working with cross-functional teams in a dynamic environment', 'Dental insurance', 'Health insurance', 'Paid time off', 'Professional development assistance', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-09-24 14:14:29
Engineer with Link-16/Data Links,Sabre Systems,4 out of 5,"Patuxent River, MD 20670","[""Education:Bachelor's (Required)"", 'BS in a relevant Engineering /Science field.', '6 years of experience in a relevant Engineering /Science field.', 'Applies engineering principles to investigate, analyze, plan, design, develop, implement, test or evaluate military weapons systems.', 'Reviews and prepares engineering and technical analyses, reports, change proposals, and other technical documentation.', 'Applies engineering experience to perform functions such as system integration configuration management, quality assurance testing, or acquisition and resource management.', 'Analyzes, designs, develops, implements, tests or evaluates software, components, or system related to engineering or functional requirements of military weapons systems associated support systems, or management information systems.', 'Experience Integrating, planning, coordinating, and facilitating design, development, and implementation of aircraft data networks.', 'Knowledge of the implementation of Link-16 data networks, associated aircraft component hardware and software, and understanding data interoperability between network users.', 'Understanding and awareness of other viable aircraft data networks, to include Internet Protocol (IP) based systems, and their associated capabilities, limitations, or vulnerabilities.', 'Analyzes designs, develops, implements, tests, or evaluates software, components, or systems related to functional requirements of military data network systems, associated support systems.', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Professional development assistance', 'Referral program', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', ""Bachelor's (Required)""]",2020-09-24 14:14:29
Aircraft Structures and Composites Engineer - FAA MRO,Preferred Composite Services,N/A,"Miami, FL 33172","['Experience:Aircraft Structures, 5 years (Preferred)', 'License:Airframe & Powerplant License (Preferred)', 'Develops or assists in developing solutions to a variety of routine and standardized engineering or technical problems or assignments following established engineering protocols in the analysis and design of aircraft structures or special purpose applications on operational aircraft.', 'Reviews and interprets engineering documentation and product specifications to assist in determining repair scopes.', 'Confers with the Shop Manager and/or Lead Inspector to clarify or resolve problems. Creates the design and development of structural repairs for aircraft structural components. This includes producing in the production of computer aided drawings and engineering reports.', 'Provides technical authority to modify aircraft configurations, maintenance programs and associated Instructions for Continued Airworthiness (ICAs.)', 'Responsible for ensuring safe, compliant aircraft parts and reliable operations while maintaining competitive costs.', 'Oversees and provides the technical authority to repair and modify aircraft/components outside the OEM maintenance manuals and works with Structures DER for FAA 8110 approval.', 'Ensures all regulatory required actions are implemented to ensure compliance.', 'Directs engineering actions that improve PCS business.', 'Incorporates new systems and technologies justified by other divisions.', 'Drives continuous improvement to PCS operations.', 'Drives review, analysis and incorporation of service documents (SB, SL, etc.) to provide tangible operational or cost benefits.', 'Manages and improves costs of engineering expenses.', 'Understands the costs associated with engineering actions to provide desired results at minimum cost.', 'Works with the PCS structures team and technical staff to ensure quality, timeliness and effectiveness is achieved.', 'Prioritizes and coordinate work from multiple customer orders that supports aircraft configuration and maintenance requirements, i.e., Reliability, Publications, Planning, etc.', 'Primary focal for all technical issues related to the aircraft structures.', 'Embodies the PCS spirit and conduct oneself with Professionalism, Integrity, Resourcefulness, and Caring.', ""Strong working knowledge of aircraft systems and FAR's relating to engineering and maintenance activities required."", 'Knowledge and experience in all relevant regulatory requirements and industry practices is required.', 'Must be an expert in airline technical operations and conversant in structures.', 'Issue instructions and documents to economically support operations and return aircraft parts to service in a safe, airworthy, and timely manner.', 'Develop plans, instructions, and documents to comply with FARs, ADs, and SBs and to resolve non-mandatory in-service issues.', 'Liaise with manufacturers; maintenance representatives, repair & overhaul (MRO) facilities; outside engineering departments; regulatory personnel; and other outside agencies.', 'Review work of consultant, contract, and MRO Structures Engineers.', 'Evaluate Federal Aviation Regulations (FARs), Airworthiness Directives (ADs), Service Bulletins (SBs), Service Letters (SLs), and other notifications of in-service issues.', 'Develop and/or obtain approved data, acceptable data, and Alternate Methods of Compliance (AMOCs) for repairs, alterations, and modifications.', 'Evaluate reported Level 2 and Level 3 corrosion findings, develop corrective action plans, and submits plan in accordance with regulatory requirements.', 'Evaluate discrepancies that require mandatory reporting to the FAA and submit these reports to the FAA in accordance with regulatory requirements.', 'Develop product improvement modifications as dictated by reliability indicators.', 'Work with original equipment manufacturers on emerging issues to help ensure safety and airworthiness, but also minimize the economic impact.', 'Organize, develop and provide all necessary Structures Engineering documentation required to complete aircraft structures modifications and repairs within the allocated time schedule and budget allowance.', 'Implement the Repair Assessment Program (RAP).', 'Implement programs to comply with new FARs on Repairs, Alterations, and Modifications (RAMs) and other Aging Aircraft programs such as Widespread Fatigue Damage (WFD).', 'Initiate maintenance program changes and changes to maintenance documents.', 'Physical Requirements - While performing the duties of this job, the employee may be required to bend, squat, sit, stand, walk, crawl, work in tight spaces and handle objects. The employee is occasionally required to push/pull, stack, reach above shoulder level or carry light-weight materials.', '4-8 years Aircraft Structural Engineering', 'S. Engineering/Technical Engineering Degree preferred', 'Meets deadlines', 'Remembers & follows instructions', 'Meets daily attendance & punctuality standard', 'Work is thorough', 'Produces accurate, dependable work', 'Output is consistent', 'Complete attention to detail', 'Volume of work produced meets expectations', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Monday to Friday', 'Bonus pay', 'Aircraft Structures: 5 years (Preferred)', 'Airframe & Powerplant License (Preferred)', 'Are you an FAA DER?', 'No']",2020-09-24 14:14:29
Senior Data Engineer - 100% Remote,recruitAbility,N/A,"Austin, TX 78752","['At least 8 years experience designing and building data processing/ETL pipelines', 'At least 8 years experience in Python and Spark or similar technologies', 'At least 8 years experience with SQL and relational databases', 'At least 8 years experience parsing flat files', '8+ years of development experience', 'Prior track record in a hyper-growth, high-tech company', ""Bachelor's degree or equivalent practical experience"", 'Experience and interest in identifying security vulnerabilities in source code', 'Experience and interest in machine learning', 'Understanding of statistics and data analysis', 'Experience with a variety of programming languages and technologies (Java, Python, C++, C#, JavaScript, Go, Scala, etc.)', 'Experience with SQL and relational databases', 'Experience with Git, Mecurial, Maven, Gradle and other build and source code management tools', 'Experience with Google BigQuery, Compute Engine, and Cloud Storage', 'Experience with Docker and Kubernetes', 'Experience in static analysis', 'Experience with modern technology stacks', 'Experience with micro-services architectures', 'Experience with cloud platforms and SaaS solutions', 'Experience with agile/scrum development practices', 'Experience with test-driven development, continuous integration, continuous deployment', 'Excellent Compensation range in the $150k - $180k range depending on experience', 'Comprehensive benefits include 16 weeks of fully paid maternity and paternity leave, Ownership opportunity through an employee stock option plan, Health, dental, and vision insurance, 4% company 401K matching vested immediately', 'Be recognized, internally and publicly, for your contributions in a high profile position', 'Align your career trajectory with a hyper-growth company that is rapidly scaling', 'Be part of the initial team designing and building out the product', 'Join an industry with massive socio, economic, and political importance in the 21st century', 'Work alongside some of the best and the brightest minds in the security industry', 'Leave an indelible mark on a company where individual input has a real impact', 'Be recognized, internally and publicly, for your contributions in a high profile position', 'Align your career trajectory with a hyper-growth company that is on the move', ""Create a roadmap for our client's data acquisition and labeling efforts"", 'Create tools to find, ingest, organize, maintain, and label complex data sets for use in machine learning models', 'Work with data scientists to create and maintain data ontologies for security', 'Work with security engineers to identify and label vulnerabilities in source code repositories', ""Continually evolve the data engineering infrastructure and techniques to improve the client's ability to find security information"", 'Mentor junior data engineers and teach them how to use data engineering techniques to solve real world problems', 'Communicate complex concepts to team members', 'Creation and curation of source code datasets for the machine learning effort', 'Creation of data engineering pipelines to find and ingest source code', 'Creation of data engineering tools to help label and validate data']",2020-09-24 14:14:29
Process Engineer,MPP,2.8 out of 5,"Rockwood, TN 37854","['Experience:Powdered Metal, 3 years (Preferred)CNC / Machining, 3 years (Preferred)', 'Education:Associate (Required)', 'Location:Rockwood, TN (Required)', 'Work authorization:United States (Required)', '401(k)', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Employee discount', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Relocation assistance', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Powdered Metal: 3 years (Preferred)', 'CNC / Machining: 3 years (Preferred)', 'Associate (Required)', 'Rockwood, TN (Required)', 'United States (Required)', 'One location', 'Detail-oriented -- quality and precision-focused', 'Team-oriented -- cooperative and collaborative', 'https://www.mppinnovation.com/', 'Only full-time employees eligible', 'No']",2020-09-24 14:14:29
Corporate Quality Engineer,Union Tank Car Company (UTLX),3.3 out of 5,"Chicago, IL","['Experience:Quality Engineer, 4 years (Preferred)', ""Education:Bachelor's (Required)"", 'License:legally can work in US now & future without sponsorship (Required)', 'Work authorization:United States (Preferred)', 'Ensures that the Company Quality Assurance manual, procedures, work instructions and program meet all regulatory and customer requirements. Posts revisions and updates to the company webpage.', 'Interacts with customer service and engineering personnel in addition to customers and regulators to provide support and technical expertise on quality issues.', 'Monitors and reports non-conformances and OTMA (One Time Movement Approvals) data in an effort to drive continual improvement. Assists Production and Quality personnel to ensure specifications are adhered to and corrective/preventative actions are followed.', 'Assists and supports the repair facility network with AAR QA-7.1 submittals and responses as needed.', 'Manages internal audit functions of the quality department to ensure adherence to design and regulatory requirements. Assists with external regulatory audit functions and vendor audits as required. Initiates, tracks and conducts supplier/contractor audits and oversees the criteria which triggers such audits.', 'Ensures compliance to subcontractor activities and renewals for the repair facility network.', 'Reviews, summarizes, uploads and distributes the applicable AAR Circulars as they are published.', 'Participates in and actively supports quality projects, activities and Responsible Care initiatives to ensure that the company stays compliant and achieves its goals.', '401(k)', '401(k) matching', 'Dental insurance', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Relocation assistance', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Quality Engineer: 4 years (Preferred)', ""Bachelor's (Required)"", 'legally can work in US now & future without sponsorship (Required)', 'United States (Preferred)', 'One location', 'No']",2020-09-24 14:14:29
Resident Quality Engineer,Confidential,N/A,"Bowling Green, KY","['Monday to Friday', 'Weekends', 'One location', 'No']",2020-09-24 14:14:29
NOC Engineer,"USConnect Services Co., Inc.",N/A,"Livingston, TX 77351","['Provide technical support to the customer regarding network issues and end user equipment.', 'Provide one on one support for Service Network Technicians working in the field.', 'Monitor all voice, data, and transport networks.', 'Provision and configure', 'Identify, recommend and facilitate services upgrades to customers as warranted following inhouse processes.', 'Works with vendors to resolve hardware operating system issues; researches and tests possible solutions and implements solutions. Obtains quotes for new hardware for projects and upgrades', 'Upgrade systems for servers and networking equipment', 'Perform remote troubleshooting through diagnostic techniques and pertinent questions', 'Record events, problems, and their resolutions in logs', 'Test, debug, implement, and document programs. Assists in the modification of company products & internal systems to meet the needs of the end-user.', 'Conduct routine audits of hardware and software on workstations and servers to ensure compliance with established standards, policies, and configuration guidelines', 'Assist Senior IT personnel with the implementation of new service offerings', 'Participate in on-call support, scheduled weekend outages, and Disaster Recovery activities as required', 'The candidate should have intermediate networking skills including troubleshooting network problems, traffic monitoring, PC connectivity and debugging, virus/spyware removal, DNS, DHCP, networked printers, file shares, and some familiarity and experience using Cisco hardware and Genband/Taqua switches.', 'Other duties as assigned', 'Experience in transport and voice-switched services or IP/router managed Internet or related technology.', 'Experience in Microsoft Excel, Word, Access, Visio, and WAN/LAN technology is preferred.', 'Knowledge of telecommunications technology and/or previous telecommunications or Internet', 'Service Provider experience preferred.', 'Must have strong self-motivational skills as well as possess administration, coordination, and prioritization abilities.', 'Skill in operating various office equipment such as personal computer and telephone systems.', 'Skill in identifying and resolving subscriber problems.', 'Skill in oral and written communication.', 'Ability to communicate with customers, employees, and various business contacts in a professional and courteous manner.', 'Ability to organize and prioritize multiple work assignments in a fast-paced, changing environment is also necessary.', 'Ability to pay close attention to detail.', 'Knowledge of telephony equipment such as Calix, Genband, and Taqua is STRONGLY preferred.', 'Knowledge of Unified Communications systems and protocols, specifically BroadSoft BroadWorks is a plus.', 'Knowledge of Network Management tools (Solarwinds, Splunk)', 'B.S. or M.S. in Computer Science or related areas is preferred.', '401(k)', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Wellness Program', 'Life Insurance', 'Paid Time Off', 'Tuition Reimbursement', 'Vision Insurance', '8 hour shift', 'No']",2020-09-24 14:14:29
Firmware Engineer,MadgeTech,3.1 out of 5,"Warner, NH 03278","[""Education:Bachelor's (Required)"", 'Work authorization:United States (Required)', 'Design, write, debug and release embedded microcontroller firmware for new data loggers and sensors.', 'Integrate electronic hardware, firmware, and software into complete systems.', 'Identify root cause and resolve firmware issues in existing products', 'Ensure reliable operation of products under extreme conditions.', 'Work with a team of electrical, mechanical and software engineers to improve and support the product line.', 'Develop manufacturing test code and assist in transferring designs to manufacturing.', 'Effectively communicate progress and problems to management and other departments.', 'Participate in all phases of product life cycle from specification to testing.', 'Contribute innovative and efficient design techniques to allow rapid development of new product models and features.', 'Create and maintain documentation and procedures to ensure consistency and efficiency.', 'BS in Electrical Engineering, Computer Science or equivalent experience', 'Proficiency in C/C++ and assembly language programming for embedded applications.', 'Experience with Microchip PIC / ARM or similar microcontrollers', 'Experience with common communication protocols (SPI, I2C, RS232, USB)', 'Experience with sensors, transducers, analog to digital conversion, displays, power supplies and batteries', 'Ability to work both independently or on a team.', 'Must possess excellent interpersonal, verbal and written communications skills, detail-oriented, organization skills, problem solving and multi-tasking skills.', 'Must be authorized to work in the United States.', 'Communication technologies (ZigBee, Bluetooth, Wi-Fi, TCP/IP, 802.15.4, 802.11.x)', 'Graphical user interface (GUI) development', 'Digital signal processing and wireless design', 'Low Power design', 'Experience with software design tools for electrical schematics, simulation and PCB layout.', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Monday to Friday', ""Bachelor's (Required)"", 'United States (Required)', 'One location', 'No']",2020-09-24 14:14:29
"Manager, Data Management Engineering",Liberty Mutual Insurance,3.6 out of 5,"Dover, NH","['Create strong partnership with Product Owners and leadership for Data Management technologies ensuring effective data platform and tools management.', 'Provide servant leadership to a team of talented data professionals – scrum masters, administrators, engineers and technologists to motivate to work as “one data team” across the business and technology.', 'Serve as a key leader for our data transformation initiative from on-premise to cloud data technologies.', 'Build strong and measurable processes, tools and engineered data management solutions to support all data platforms – such as data warehouse, lakes, reporting / BI tools, data science, data catalog, data virtualization etc.', 'Devise metric-based Data Management tools or processes including protecting data as an asset (security, compliance, audit, etc.), data quality and governance, central monitoring of data jobs / processes, data cataloging etc.', 'Create an exciting technology team with a fun work environment and customer-focused culture with high standards of achievement.', 'Be an evangelist across Data and Analytics Engineering department for Agile practices, data quality and overall security, stable, reliable systems and engineering excellence.', 'Support and contribute to plans for retirement of data and application technical debt.', 'Lead Data and Analytics Engineering team on any enterprise initiatives such as data center migration, coordination of software/hardware upgrades.', 'Ensure aligned release management, CICD and test automation functions', 'Drive team to mature and scaled agile processes, consistent metrics and efficient processes', 'Ensure ITIL best practices are developed for and build collaborative relationships with IT technology peers in the area IT Operations and GRM US Engineering Enablement and Operations (EE&O) teams to ensure solutions alignment and partnership', 'Devise talent strategy for team – identifying resource gaps or inefficiencies, build hiring plan, promotions and performance managed are planned and consistent with needs and vision of department.', 'Define individual performance objectives and development plans and ensure alignment with project and department objectives.', 'Establish financial plan for department and manage to plan.', ""Bachelor's or master’s degree in technical or business discipline or related experience"", 'Proactive leadership skills with five (5) or more years people leadership experience.', 'Ten (10) or more years hands-on experience effectively managing data platforms, BI / reporting tools, integration / ETL tools and/or data management tools (e.g. Informatica, Teradata, Goldengate, Snaplogic, SAS, MicroStrategy, Power BI, Qlik Replicate).', 'Working knowledge of one or more Data Management tools (e.g. DQM, data governance, metadata management, data catalog or related tools).', 'Depth in vendor management, offshore teams and staffing expertise.', 'A “bar-raiser” mentality and are driven to motivate and lead teams to achieve great things.', 'Passion for operational efficiency, quantitative performance metrics and process orientation.', 'Depth of knowledge in operationalizing data governance and providing measurable DQM.', 'Working knowledge of project planning methodologies, IT standards and guidelines.', 'Customer passion, business focus and the ability to negotiate, facilitate and build consensus.', 'The ability to promote a team environment across a large set of separate agile teams and stakeholders.', 'Strong team management, financial / budget management, organizational, communication and presentation skills.', 'Cloud data platform or integration tools such as Snowflake or Snaplogic', 'Experience with Teradata, Informatica, Power BI, Tableau and/or MicroStrategy', 'Experience with Data Management tools such as Alation, Informatica (IDQ), Collibra etc.', 'Experience with ITSM tools such as Service Now, Remedy', 'Experience with AWS data lake technologies – S3, EMR, Athena, Glacier.', 'Experience with data virtualization technologies – Denodo', 'Six Sigma', 'ITIL Certification', 'Certifications in Agile development methodologies or PMP']",2020-09-24 14:14:29
Process Engineer,"Kobe Aluminum Automotive Products, LLC",2.9 out of 5,"Bowling Green, KY 42101","['Provide pre-task planning, technical expertise, guidance and leadership for foreman and process technicians in troubleshoot issues with the press equipment', 'Adhere to and reinforce safe working practices', 'Perform equipment/process failure root cause analyses', 'Perform predictive assessments and problem diagnosis', 'Ensure a common approach to solving machinery and or process problems, through the development of best practices.', 'Provide technical training to production team members to improve skill levels within the teams', 'Troubleshoot Process/Mechanical issues.', 'Work with cross functional teams (Forging, Tooling, and Maintenance) for engineering solutions', 'Implement continuous improvement projects', 'Create and maintain Standard Operation Procedures documentation', 'Maintain open lines of communication with plant leadership regarding status of equipment/process downtime, scrap, and project related activities', 'Project Champion to focus on scrap reduction and process improvements.', 'Industrial/Mechanical Engineering or Manufacturing Technologies Degree or equivalent training/experience', 'MS Office programs (Word and Excel)', 'Familiar with CAD/CAM programs is a plus', 'Hands-on experience in the automotive environment is a plus']",2020-09-24 14:14:29
Data Warehouse Engineer,"Bemis Associates, Inc.",3.6 out of 5,United States,"['Work authorization:United States (Required)', 'Data Warehouse', 'Proficiency in design, develop, test, and deploy of SQL Server ETL mappings for data movement between operational systems, ODSs, and Data Warehouses', 'Experience in designing/ building Azure cloud end-to-end data solutions (including ELT, Big Data, relational and non-relational data concepts)', 'Design, develop, test, and deploy data supply change solutions that best serve Business Intelligence analytics and reporting needs', 'Develop fundamental understanding of business function and related production systems', 'Develop and maintain proficiency in reporting, data mining, and analytic tools within the Microsoft Suite', 'Ensure designed systems are highly reliable, self-recovering, and require little or no supporting manpower', 'Consistently deliver according to commitments and project plan dates.', 'Lead design review discussion for technical and non-technical audiences.', 'Perform and/or lead necessary tuning of database and ETL systems and objects to ensure timing and performance goals are met', 'Collaborate with existing and prospective users to define Data Warehousing and Business Intelligence requirements.', 'Identify technical opportunities that offer potential to meet departmental / corporate goals.', 'Develop and document backup and recovery scenarios for databases and data warehouse solutions.', 'Database Administrator', 'Develop and document business rules and procedures to ensure the reliability, integrity, recoverability, and security of corporate data.', 'Develop and maintain database design.', 'Provide input to and assist with the development and maintenance of the corporate data model.', 'Sales and Operational Support', 'Assist with End-User support to ensure continuous access to data warehouse and BI solutions', 'Contribute to quarterly Budget and Forecast process with Demand Planning team', 'Other duties as assigned.', 'Bachelor’s Degree in Computer Science, Information Systems or related field preferred. Equivalent experience can substitute for education.', '7- 10 years of data warehouse experience', '5+ years of ETL experience', '1+ years of cloud data tools experience desired', 'Proficient relational database experience. The individual must have an excellent command of SQL.', 'Experience in Business Intelligence tools and architecture', 'Must have exposure to ERP systems and general concepts', 'Experience with ERP applications and modules. Dynamics Finance and Supply Chain or Dynamics AX preferred, but not required.', 'Experience with Dynamics CRM or equivalent CRM system', 'Strong communication and consulting skills with the ability to work directly with business partners and end users.', 'Experience with the software development lifecycle process; software quality assurance processes, source code control and change management required.', 'Ability to facilitate meetings attended by business partners, technical staff, and end users.', 'Ability to analyze a complex business problem and evaluate the impact of potential solutions from both a business and technical perspective is required.', 'Ability to present complex technical concepts in an appropriate manner that can be understood by technical staff and end users is required.', 'Ability to quickly understand, implement, and adapt to new technologies and development architecture.', 'Expertise with Microsoft Visual Studio', 'Expertise with Microsoft Azure cloud environment', 'Expertise with Microsoft SQL Server', 'Extensive knowledge of Microsoft Technology and Development Architecture', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Parental leave', 'Professional development assistance', 'Tuition reimbursement', 'Vision insurance', 'Monday to Friday', 'Bonus pay', 'United States (Required)', 'Fully Remote', 'No: Not providing sponsorship for this job', 'People-oriented -- enjoys interacting with people and working on group projects', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Autonomous/Independent -- enjoys working with little direction', 'www.bemisworldwide.com']",2020-09-24 14:14:29
Data Engineer,Brooksource,3.7 out of 5,"Indianapolis, IN 46240","['Experience:Database Development, 3 years (Preferred)ETL (Extract Transform Load), 3 years (Preferred)Python, 3 years (Preferred)', 'Development of jobs & pipelines from multiple production data sources into Data Lake environments', 'Engineers production ready solutions, inclusive of alerting and error handling', 'Works with Cloud based tools (Google GCP, Big Query, Dataproc, Composer, Steamsets, Looker, etc.) to deliver best-in-class cloud based data solutions', 'Works collaboratively with DBA team for operational execution and reliability of data solutions, both in Oracle and BigQuery', 'Assists in maintaining data governance through documentation of data solutions, through ERDs, Confluence documentation, or external tools', 'Engineer & model curated and keyed Data Warehouse solutions that meet business objectives that perform efficiently and effectively', 'Works in Agile product management method, managing tasks & objectives (user stories) through JIRA and providing updates to SCRUM master', 'Partners with Product Manager (PO) to understand business requirements across multiple functional areas; Store Operations, Merchandising, Supply Chain, Finance, Digital, Customer & Loyalty, Legal, & Data Science', 'Support current Data Warehouse ETL jobs, respond to tickets and inquiries from business partners when data quality issues occur', 'Other projects and duties as assigned', 'Bachelor’s degree (B.A.) in Information Systems or other related field from a four-year college or university, or equivalent combination of education and experience.', '2-4 years of proven work ability in data engineering, data analytics and process documentation required.', 'Must have experience with partnering with stakeholders of all levels of the organization to plan and solve problems.', 'Dental Insurance', 'Health Insurance', 'Vision Insurance', 'Database Development: 3 years (Preferred)', 'ETL (Extract Transform Load): 3 years (Preferred)', 'Python: 3 years (Preferred)', 'Yes', 'Store Discounts', 'One location', 'Monday to Friday', 'No weekends', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-09-24 14:14:29
Data Engineer Senior,USAA,3.9 out of 5,"Gilbert, AZ 85295",[],2020-09-24 14:14:29
Senior Data Engineer,"Tyler Technologies, Inc.",3.6 out of 5,"Troy, MI 48098","['Work and collaborate with a cross-functional team to define, document, and communicate the strategy and approach for building and maintaining complex data workflows.', 'Apply your technical skills, creativity, and problem-solving skills to design and implement efficient data migration, conversion, and integration pipelines.', 'Promote best practices, processes, and standards for effectively carrying out data engineering activities.', 'Design and build the test automation tooling necessary to validate and report the quality of all data workflows.', 'Coordinate effectively across local and remote team members.', 'Clearly communicate ideas between Product, Development, Quality Assurance, and Leadership.', 'Embrace learning, excited by challenges and maintains a growth mindset to gain expertise and grow in the position.', ""Bachelor's degree in Computer Science or related field."", 'Strong understanding of relational databases, specifically SQL Server.', 'Experience writing and optimizing complex SQL queries.', 'Knowledge of complex data extraction, transformation, and data loading techniques.', 'Experience implementing data validation strategies to ensure system accuracy and quality.', 'Experience integrating with REST APIs using higher level scripting or programming languages (e.g. PowerShell, Python, etc.) is a plus.', 'Knowledge and understanding of Amazon cloud data services (e.g. RDS, DynamoDB, etc.) is a plus', 'Demonstrated ability to manage multiple commitments, maintaining potentially aggressive timelines while ensuring a high level of quality in deliverables.', 'Strong planning and organizational skills involving the ability to manage multiple work tasks effectively.', 'Ability to provide mentorship/guidance to engineers on technologies and best practices.', 'Strong interpersonal and communication skills involving communicating technical and non-technical information in writing and verbally; including an occasional presentation.', 'Ability to be effective in a fast-paced environment.', 'Ability to work independently as well as collaborate in a team across functional groups.']",2020-09-24 14:14:29
Software Engineer III,Perspecta,3.3 out of 5,"King of Prussia, PA 19406","['Job', 'Company', 'Requires 5 to 8 years with BS/BA or 3 to 5 years with MS/MA or 0 to 2 years with PhD.', 'Computer Science degree (or equivalent)', 'Over 3 years’ experience required delivering Software support to similar DoD or Space Domain Programs', 'Ability to communicate status with senior Government Leaders at appropriate reviews', 'Minimum TS Clearance required']",2020-09-24 14:15:13
Analytics Engineer,The Voter Participation Center / Center for Voter Information,N/A,"Washington, DC 20036","['Experience:engineering, 4 years (Preferred)', 'Education:High school or equivalent (Preferred)', 'Work authorization:United States (Required)', 'Have exceptionally strong communications skills.', 'Have 4+ years of experience in a software engineering role;', 'Have deep experience in Python.', 'Have previously worked with SQL.', 'Are comfortable developing in, and for, a POSIX-compliant (Unix-like) environment. Experience with RHEL/CentOS a plus.', 'Have previous experience with data in politics.', 'Have previous experience in civic engagement, organizing or political campaigns.', 'Have taken a software system from design all the way to deployment and maintenance.', 'Have deep experience in at least one of the following: Ansible, Chef, Docker, Puppet, Terraform, or equivalent code-as-infrastructure tool.', '401(k)', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Parental Leave', 'Vision Insurance', 'Monday to Friday', 'engineering: 4 years (Preferred)', 'High school or equivalent (Preferred)', 'United States (Required)', 'One location', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Team-oriented -- cooperative and collaborative', 'https://www.voterparticipation.org', 'https://www.facebook.com/voterparticipationcenter', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-09-24 14:15:13
Hotel Maintenance Engineer,Able Services,3.8 out of 5,"Washington, DC 20002","['Experience:hotel maintenance engineering, 3 years (Preferred)', 'Education:High school or equivalent (Preferred)', 'Work authorization:United States (Required)', 'Perform repairs and maintenance as needed or requested by guests, Housekeeping, and/or management.', 'Such duties may consist of HVAC, plumbing and electrical repairs, and furniture replacement and/or repair, etc.', 'Perform preventive maintenance on hotel guest rooms per quota, equipment and assets per set schedule.', 'Check pool/spa chemical balance, adjusting as needed. Clean pool/spa deck, vacuum pool/spa, back flush filter when needed, and check pool/ spa filter equipment.', ""Perform inspection and repair of hotel's physical condition including paint, woodwork, wallpaper, plumbing, grout, tile."", 'Perform daily walk through, record all meter readings and boiler temperature.', 'Provide written details of work performed on work order forms and other documents.', 'Record all maintenance request work performed in the log program and return request to proper location on request board or as directed.', 'Inform Front Desk and Housekeeping of rooms where work is being performed so they may be put out of order if needed. Will notify Front Desk and Housekeeping when work has been completed.', 'Know hotel emergency procedures and where all emergency shutoffs are located. Assist hotel guests when necessary in case of an emergency.', 'Minimum of 3 to 5 years of hotel engineering/maintenance operations', 'Ability to develop, understand and work within a budget', 'Strong ability to work with e-mail, preferably MS Outlook', 'Facilities operational experience required', 'Strong oral and written communication skills', 'Strong working knowledge of safety and environmental certifications required', 'Strong working knowledge of energy conservation required, formal training preferred', 'Paid time off', 'hotel maintenance engineering: 3 years (Preferred)', 'High school or equivalent (Preferred)', 'United States (Required)', 'A job for which military experienced candidates are encouraged to apply', 'A job for which all ages, including older job seekers, are encouraged to apply', 'Open to applicants who do not have a college diploma', 'https://www.ableserve.com', 'https://www.facebook.com/ableserve', 'No']",2020-09-24 14:15:13
"Sr. Data Engineer- AWS, PYTHON, ETL, REDSHIFT- Local to Seattle",iCloudNexus,N/A,"Seattle, WA",['Yes'],2020-09-24 14:15:13
"Software Engineer I, Advertising",Cox Automotive,3.4 out of 5,"Burlington, VT 05401","['Job', 'Company', 'Develop and support features for the Cox Automotive Real Time Bidding (RTB) platform including Display, Web and CTV video Advertising', 'Design and develop service-oriented architecture solutions, constructing and managing services published to both internal and external consumers, integrating with complex database and third party components', 'Learn and leverage the automotive digital advertising domain to change the way the world buys cars', 'BA/BS degree in Computer Science or related field. Advanced technical degree and/or related training a plus', 'Experience designing and implementing applications with highly optimized and scalable architectures', 'Proven ability to work independently; designing, developing and deploying solutions, and to deliver projects on time with minimal direction', 'Strong Java skills and object-oriented design experience, including working knowledge of the Java web technology platform, applied use of design patterns, and MVC technologies', 'Strong database development skills including a solid understanding of database technologies, and logical and physical data modeling', 'Experience implementing automated unit tests', 'Knowledge of agile development methodologies desired', 'Knowledge of digital advertising is a plus']",2020-09-24 14:15:13
Quality Assurance Automation Engineer - Revenue Systems,Indeed,4.3 out of 5,Remote,"['Job', 'Company', 'You will have opportunities and challenges to grow your quality engineering skill-set at Indeed', 'Functional, usability, compatibility, performance, security, accessibility testing', 'Test across various countries, languages, and applications as well as browsers and devices (mobile, tablets, etc.)', 'Help influence how your product team works on a day-to-day basis', ""5 years' experience with all phases of software testing including test planning, functional testing, regression testing, and designing test architecture"", 'Experience with Selenium Webdriver, test framework development, and web application testing', 'Experience with working in a Agile environment and CI/CD driven testing culture', 'Demonstrated programming skills in Java, Python, Javascript or other OOD syntax', 'Prior success as an individual QA Automation Engineer embedded within a product team', 'Experience testing API and database levels of a product or application', 'B.S. in Computer Science or related area, or relevant work experience.', 'Turning complex testing and tools into simple and fun documentation for others to use', 'Collaborating with development teams on testing requirements and implementation details', 'Driving an idea or process improvement to completion', 'Researching tools that can be leveraged to improve quality', 'Telling a story with data in a compelling way to help other make data-driven decisions', 'Validating ideas by performing experiments and analyzing the results']",2020-09-24 14:15:13
Hardware Engineer,"Digital Dynamics, Inc.",N/A,"Scotts Valley, CA 95066","['BSEE or equivalent experience', '5+ years of experience designing electronic circuits and systems', 'OrCAD/Allegro experience required', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Bonus pay', 'www.digitaldynamics.com', 'Only full-time employees eligible', 'No']",2020-09-24 14:15:13
Data Integration Engineer for Manufacturing Process,Cornerstone Controls Inc,N/A,"Indianapolis, IN 46278","['Experience:Manufacturing, 3 years (Required)', ""Education:Bachelor's (Required)"", 'Location:Indianapolis, IN 46278 (Required)', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Referral program', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', 'Monday to Friday', 'Bonus pay', 'Manufacturing: 3 years (Required)', ""Bachelor's (Required)"", 'Indianapolis, IN 46278 (Required)', 'No: Not providing sponsorship for this job', 'A job for which all ages, including older job seekers, are encouraged to apply', 'www.cornerstonecontrols.com', 'Waiting period may apply', 'No']",2020-09-24 14:15:13
Senior Data Engineer,Perspecta,3.3 out of 5,"Charlottesville, VA 22904","['Job', 'Company', 'Clearance – TS//SCI or TS/SCI with current CI scope Polygraph – (with one year of currency minimum) OR willing to undergo CI scope Polygraph (based on specific analytical position) PLUS', 'Education – Bachelor’s Degree OR 10+ years direct relevant experience PLUS', 'Experience– 10+ years of analytical experience (with 8+ years of Identity Intelligence or functional/regional all-source analysis experience) at the operational/strategic level within DoD or equivalent Government agencies', 'Strong briefing skills to include the ability to clearly articulate information to senior members of the intelligence community', 'Ability to gather, analyze and collate and fuse available intelligence products to produce IIRs, reports, and briefings including the ability to clearly articulate information', 'Education: Master’s Degree in related field', 'Certification: Counter Terrorism/Counter Insurgency, Global Regional Issues, HUMINT, CI, POL/MIL/Geopolitical analysis; Senior Intelligence Analysis with familiarity of ICD 203, 204 and 206.Competed OS301 Fundamentals CourseCompleted OS302 OSINT Analytic Tools CourseCompleted a Basic Social Media Analysis CourseComplete an Advanced Social Media Analysis Course', 'Experience: 12 years of experience related to the specific labor category with at least a portion of the experience within the last 2 years', 'Equivalency – Chief Warrant Officer 3-5; Field Grade Officer (O4- O5) JISE/ACE Director or Deputy Director']",2020-09-24 14:15:13
Quality Engineer,CentralReach,N/A,"Matawan, NJ","['Enhance the test case library to increase test case coverage', 'Create test cases for verification and validation of web, mobile, API and all system integrations', 'Perform manual testing, keeping pace with the Agile team and reporting and finding bugs/defects', 'Develop automated test scripts to increase test coverage', 'Develop automated scripts within expected timeboxes to ensure all work that may impact the system has coverage', 'Maintain the test automation library for high reliability during execution', 'Contribute to the development of test plans to ensure full test coverage of changes in the application under test', 'Ensure quality releases of software with no production downs and/or critical impediments to users', 'Occasional travel to our Florida and Kansas City offices.', '5 to 7 years of experience in Development and/or Quality Assurance working in an Agile Engineering environment', '5 to 7 years of experience testing web and/or mobile applications in a SaaS organization', 'Effective written and verbal communication skills with the ability to collaborate with the Product and Engineering teams', 'Experience writing detailed test cases (functional and non-functional) and management of a test case library', 'Experience with scripting/programming languages to develop test automation scenarios for web and/or mobile applications, and API services', 'High level of competency in programming/scripting languages and concepts', 'Knowledge of web application technologies (HTML, CSS, JavaScript), REST API, and mobile platforms (iOS and Android)', 'Experience parsing and verifying responses/payloads from API interfaces', 'Ability to understand and query relational data in a database', 'Experience formulating testing strategies for software releases', 'Understanding of agile testing best practices and processes']",2020-09-24 14:15:13
Wave Propagation Engineer,Hexagon Group,4 out of 5,"Centennial, CO","['Experience:relevant, 5 years (Preferred)engineering, 5 years (Required)', ""Education:Bachelor's (Required)"", 'Location:Centennial, CO (Preferred)', 'Required travel:25% (Preferred)', 'Support technical development and implementation of current ultrasonic inspection products and inspection', 'Support technical development and implementation of new ultrasonic inspection products and inspection methods (Bulk UT, MAE, PA-MAE, and Guided Wave Inspection)', 'Perform inspections at facility and on site as required', 'The job has no supervisory responsibilities', 'Master’s degree required. PhD preferred in technical field; Engineering, Physics or GeoPhysics', 'Plus, 5 – 7 years’ experience in oil and gas industry; including field experience', 'Prior code writing utilizing, Matlab, LabView, C++, etc.', 'Strong analytical engineering background', 'Knowledge of wave propagation (dispersive guided wave propagation a large plus).', 'Materials knowledge to include: polymer matrix composites, steel and aluminum metallography', 'Knowledge of fracture mechanics and damage mechanics.', 'Ability to conduct (FEA) Finite Element Analysis.', 'Ability to perform dispersion curve computation and analysis.', 'Digital Signal Processing (DSP) background.', 'Non-destructive evaluation (NDE) experience.', 'Must be a self-starter.', 'Must have strong problem-solving skills and a desire to create solutions.', 'Must have demonstrated and effective interpersonal, oral and written communication skills with the ability to professionally interact with internal and external customers; respond to common inquiries or complaints from customers and regulatory agencies.', 'Ability to write correspondence that conforms to prescribed style and format.', 'Ability to establish and maintain rapport and effective communication with diverse levels within company and external customer organizations.', 'Prior experience working under tight deadlines with shifting priorities.', 'Must have the ability to work in sensitive and confidential situations.', 'Ability to define problems, collect data, establish facts, and draw valid conclusions with ability to deal with abstract and concrete variables.', 'Must have above average MS Office skills', 'The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.', 'While performing the duties of this job, the employee is frequently required to sit for long periods of time at a computer and use hands to finger, handle, or feel. The employee is moderately required to stand, walk, reach with hands and arms; stoop, kneel or crouch; talk and hear. The employee may occasionally lift and/or move up to 50 pounds. Specific vision abilities required by this job include close vision, and ability to adjust focus.', 'Must be able to travel up to 30% of the time. This position may work in the plant and outdoors in the field, therefore subject to all weather conditions sometimes to include extreme cold and heat. The work described while working in the plant or field will require wearing all PPE depending on circumstance which may include: safety glasses, hard hat, ear protection, leather gloves, safety vest and steel toed footwear.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Parental leave', 'Relocation Assistance', 'Vision Insurance', 'Monday to Friday', 'relevant: 5 years (Preferred)', 'engineering: 5 years (Required)', ""Bachelor's (Required)"", 'Centennial, CO (Preferred)', '25% (Preferred)', 'One location', 'w.www.hexagongroup.com', 'Waiting period may apply', 'No']",2020-09-24 14:15:13
WPaas Engineer (SRF 3508),General Dynamics,3.8 out of 5,"Stennis Space Center, MS","['Assist in supporting end-users of a remote desktop environment', 'Take a lead on security related patching and remediation in the production and UAT environments as dictated by the ISSO', 'Assist in the administration of a virtual Windows environment', 'Assist in the training and development of Tier 1 support.', 'BS/BA or equivalent and 2+ years of experience', 'Practical Knowledge in:', 'Experience with the following is required:', 'The ideal candidate will have familiarization with:', 'Ability to support a broad customer base through communication that include phone and email', 'Ability to work well within an established team of professionals in a demanding environment', 'Ability to act as an escalation point for remote support personnel', 'Must be able to operate efficiently with minimal supervision', 'Ability to mentor and assist less experienced members of the remote support team (assist in training)', 'Assist in performing root cause analyses for service interruptions, when necessary', 'Must be able to communicate via phone and email in a professional and effective manner', 'Work with team members to expand their skillset and become a more valuable member of the team']",2020-09-24 14:15:13
Senior Data Engineer,Garmin,3.8 out of 5,"Olathe, KS 66061","['Provides technical input to feature development plans and concept documents', 'Understands production and operations issues as they relate to engineering', 'Exemplifies Garmin’s Mission Statement and Quality Policy and proactively works to improve Garmin’s image and culture', 'Configure and administer data servers and Hadoop components', 'Develop scalable, extensible solution architectures leveraging contemporary big-data technologies in an evolving operational framework', 'Analyze existing data structures and recommend improvements', 'Partners with team lead to identify technical requirements and alternatives to accomplish project.', 'Participates in design, code, test, maintenance, enhance and decommission phases throughout software life cycle to contribute technical expertise and to identify issues', 'Serve as a mentor and advisor to team members.', 'Participate in and help guide research POCs, including design, coding, and performance and efficacy measurement.', 'Provide 24x7 on call support', 'Provides significant contributions to defining team roadmap and priorities', 'Experience with Java', 'Experience with Hadoop and various components', 'Demonstrated ability to implement new technologies effectively', 'Demonstrated strong and effective verbal, written, and interpersonal communication skills in a small team setting']",2020-09-24 14:15:13
Big Data Engineer - Deloitte (Remote/Contract),Experfy,N/A,"Boston, MA","['Experience:HDFS/Hadoop, 4 years (Required)Hive, 4 years (Required)Spark, 4 years (Required)Tableau/Qlik, 4 years (Required)SQL and NoSQL Databases, 4 years (Required)Python/Scala, 4 years (Required)', 'License:Spark (Preferred)AWS/Azure (Preferred)Hadoop (Preferred)', 'Develop fast data infrastructure leveraging data streaming, batch processing, and machine learning to personalize experiences for our customers.', 'Lead work and deliver elegant and scalable solutions', 'Work and collaborate with a nimble, autonomous, cross-functional team of makers, breakers, doers, and disruptors who love to solve real problems and meet real customer needs.', 'Bachelor-level Degree in engineering, Information Technology or Computer Science', '4 years of hands-on experience as a Data Engineer in a Big Data environment (Spark, Hive, HDFS, Sqoop)', 'Strong SQL knowledge and data analysis skills for data anomaly detection and data quality assurance', 'Programming experience in Scala, Python, shell scripting and automation', 'Experience with modern workflow/orchestration tools (e.g. Apache Airflow, Oozie, Azkaban, etc.)', 'Experience working with PostgreSQL, Teradata, Vertica and/or other DBMS platforms', 'Hadoop Certification or Spark Certification.', 'Experience with BI tools such as Tableau or Qlik to create visualizations and dashboards for various data quality metrics.', 'Monday to Friday', 'HDFS/Hadoop: 4 years (Required)', 'Hive: 4 years (Required)', 'Spark: 4 years (Required)', 'Tableau/Qlik: 4 years (Required)', 'SQL and NoSQL Databases: 4 years (Required)', 'Python/Scala: 4 years (Required)', 'Spark (Preferred)', 'AWS/Azure (Preferred)', 'Hadoop (Preferred)', 'Are you currently an independent contractor/have your own company/working on a W2 please specify? Also confirm if you need visa sponsorship?', 'Likely', 'Fully Remote', 'Yes']",2020-09-24 14:15:13
Data Architect,UnitedLex,3.7 out of 5,"Atlanta, GA","['Experience:Azure, 4 years (Preferred)Business Intelligence, 4 years (Preferred)', 'Minimum total of 8 years in information technology', 'Minimum 4 years hands-on experience in BI/DW design, development, and implementation', 'Strong ability to design and deliver enterprise data warehouse and business intelligence platforms', 'Ability to collaborate with technical and non-technical individuals to solve complex business problems', 'Ability to understand needs within the context of a specific organization and identify appropriate technology solutions to maximize ROI with the solutions that are implemented', 'In-depth understanding of a wide range of database systems and architecture practices', 'In-depth experience with designing, administering and maintaining Microsoft SQL Server and Databases', 'Experience with architecting star, snowflake galaxy schemas for data modeling', 'Experience in analysis and selection of BI platforms based on the data topography and needs of an organization', 'Experience with a major ETL tool, preferably Azure Data Factory', 'Experience with OLAP model and OLTP database models', 'Experience with Azure Data Bricks/Azure Synapse / Azure Analysis Services / (DW)/ADLS preferred', 'Experience with self-service BI tools, preferably PowerBI and the DAX language', 'Experience with cloud and hybrid data topographies', 'Experience working with various third-party data sources (MS Dynamics AX, HR/ERP systems, Salesforce, etc.) and connections to these through APIs as well as direct-to-DB and flat files', 'Experience maintaining data quality and integrity in a complex and ever-changing data environment', 'Experience maintaining source code in Git and managing a CI/CD pipeline, preferably with Azure DevOps', 'Experience with Python and R programming languages is a plus', 'Firm understanding of web applications and/or other distributed application architectures', 'Exposure to unstructured/semi-structured data systems (NoSQL) is preferred', 'Strong organization skills and high attention to detail', 'Ability to multi-task with good decision-making, analytical and problem-solving abilities', 'Ability to learn the intricacies of a new industry and move through new topics at a rapid pace', 'Excellent oral, written, presentation and interpersonal communications skills; Ability to effectively exercise tact, discretion, judgment and diplomacy when interacting and/or negotiating with internal and external customers', 'Ability to present and explain technical information in a way that establishes rapport, persuades others, and gains understanding', 'Ability and willingness to accept responsibility, willingness to challenge established practices and draw relevant conclusions, including the persistence and willingness to take calculated risk, to stimulate, market and sell new ideas within the organization.', 'Bachelor’s degree (preferably in Computer Science, MIS, or a related field) OR equivalent work experience required', 'Analyze BI needs, recommend BI solutions and strategy, design and implement an enterprise BI platform', 'Map out enterprise data systems/objects and define/design required ETL systems/processes', 'Document and maintain architectural design, technical configuration and mapping', 'Document and maintain best practices, standards, and processes for managing the BI/DW systems and services', 'Recommend on-going improvements to business and technology processes related to BI needs and solutioning', 'Lead, provide technical guidance, and serve as a mentor to other team members', 'Participate in technology leadership meetings to provide feedback and recommendations to the other leaders', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Bonus Pay', 'Azure: 4 years (Preferred)', 'Business Intelligence: 4 years (Preferred)', 'One location', 'Fully Remote', 'www.unitedlex.com', 'Yes']",2020-09-24 14:15:13
PROCESS ENGINEER,Georgia-Pacific,3.4 out of 5,"Gurdon, AR 71743","['Monitor product quality and contribute to the overall direction and success of the Camden operations.', 'To supervise/coordinate production efforts that result in sustained improvement in all associated work processes including: Environmental, Health & Safety (EHS) compliance, reliability, quality, production and costs', 'Monitor equipment for accuracy, value, and yield', 'Perform process checks and studies', 'Keep management informed on process variables', 'Use Data Analytics and a structure approach to problem solving. Assist facility leaders in improvements to products, flow, cost, recovery, quality, work processes, etc.', 'Assist in process optimization to maximize production rates, product quality and yield', 'Develop and apply strategies to optimize on-going operations using the automation platform in conjunction with the operations, maintenance and engineering staffs at the mill.', 'Troubleshoot and resolve production issues', 'Complete all analysis in a timely and efficient manner', ""Bachelor's degree in Engineering or higher"", 'Experience with data analytics and statistics- college classes are sufficient', 'Willingness to work in a manufacturing environment', '2 years experience as a Process Engineer', '2 years of experience working in a continuous industrial manufacturing process']",2020-09-24 14:15:57
Autonomous Driving Data Engineer,Lucid Motors,4.1 out of 5,"Newark, CA 94560","['Work with a state-of-the-art data pipeline on the development and test process of the ADAS/AD features', 'Enable efficient data (pre-)processing in our cloud infrastructure', 'Contribute to the architecture and implementation of an efficient data ingestion process to transfer and store large-scale vehicle sensor data from our Lucid Air test vehicles efficiently into our data storage', 'Help to optimize the data storage, search and data processing based on a diverse mix of storage solutions, caching techniques and big data frameworks.', 'Contribute to the implementation of a secure distributed data access solution for data on-premise and via cloud providers to connect Lucid data with service providers and partners', 'Work with machine learning experts, testing engineers and software developers to solve challenging development problems', 'Knowledge of database systems, big data concepts and cluster computing frameworks (e.g. Spark, Hadoop, or other tools)', 'Excellence in C++, Python, Java or other related programming languages', 'Previous experience with big data applications or back-end software development', 'Experience with machine learning, data engineering, deep learning frameworks and related open-loop testing techniques', 'Strong communication skills', 'Previous experience building efficient large-scale data collection, storage and processing pipelines', 'Understanding of cyber-security issues and best practices', 'Advanced degrees preferred', 'BS minimum in the areas of Computer Science/Engineering, Data Engineering or other related fields', '4+ years of work experience or a PhD in a related field']",2020-09-24 14:15:57
AWS Big Data Engineer,"TekPartners, A P2P Company",3.9 out of 5,"Miami, FL 33101","['3+ years of experience in software development with Python', '2+ years of development experience with Spark/PySpark, Pandas', '3+ years of database development experience with RDBMS, including development of stored procedures', '2+ years of ETL development experience', '2+ years of hands-on data engineering on AWS, including S3, Kinesis, Glue, Athena, RDS/Aurora, RedShift', 'AWS Solutions Architect Professional and Data Analytics Specialty (formerly Big Data Specialty) Certifications are a plus', 'A Bachelor’s Degree from an accredited college in Computer Science or equivalent experience', 'Build end-to-end big data pipelines on AWS, including:', 'Ingestion/replication from traditional on-prem RDBMS (e.g. Oracle, MS SQL Server, IBM DB2, MySQL, Postgres) to AWS', 'Streaming ingestion with Kinesis Streams, Kinesis Firehose, and Kinesis Analytics', 'Change Data Capture (CDC) logic and partitioning', 'ETL and Analytics with AWS Glue, Glue Streaming, EMR, Spark, Presto, Athena, Flink, Python, PySpark', 'Refactoring of existing RDBMS scripts (e.g. PL/SQL. T-SQL, PL/pgSQL) to PySpark jobs', 'Buildout of data warehouse and published data sets using RedShift, Aurora, RDS, ElasticSearch', 'Python scripting with AWS Lambda', 'Comprehensive Medical Benefits', 'Competitive Pay, 401K', 'Retirement Plan', 'And Much More']",2020-09-24 14:15:57
Data Engineer,jerry.ai,N/A,"Boston, MA","['Start-up energy working with a brilliant and passionate team', 'Exponential growth (5 straight quarters of 50-100%+ quarter over quarter growth)', 'Flat structure and access to senior leadership for continuous mentorship', 'Meritocracy - we promote based on performance, not tenure', 'Rockstar teammates. You will be working with a strong team with prior work experience at Amazon, Microsoft, NVIDIA, Alibaba, etc.', 'Owner of the core company data pipeline, responsible for scaling up data processing flow to meet the rapid data growth', 'Consistently evolve data model & data schema based on business and engineering needs', 'Implement systems tracking data quality and consistency', 'Develop tools supporting self-service data pipeline management (ETL)', 'SQL and MapReduce job tuning to improve data processing performance', '2+ years of data engineering experience within a rigorous engineering environment', 'Proficient in SQL, specially with Postgres dialect.', 'Expertise in Python for developing and maintaining data pipeline code.', 'Experience with Apache Spark and PySpark library (experience with AWS extension of PySpark is a plus).', 'Experience with BI software (preferably Metabase or Tableau).', 'Experience with Hadoop (or similar) Ecosystem.', 'Experience with deploying and maintaining data infrastructure in the cloud (experience with AWS preferred).', 'Comfortable working directly with data analytics to bridge business requirements with data engineering', 'Toronto', 'Boston', 'Dental insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-09-24 14:15:57
Transport Data Interconnect Engineer,ClientSolv Technologies,4 out of 5,"Littleton, CO","['Experience working with Internet Exchange Points (IPX) and Tier 1 telco hotels/data centers.', 'Define data interconnection requirements including APIs, transport interfaces and other interconnection.', 'Develop peering, IP transit and other interconnection requirements for the 5G network.', 'Manage data traffic flows and recommend network changes as traffic profiles change.', 'Define and later support the implementation of peering agreements and interconnection.', 'Understanding of traffic engineering, Internet access services and Ethernet services.', 'System architecture including reliability, security and redundancy requirements.', 'Working knowledge of various applicable standards and frameworks: IETF, MEF, etc.', 'Actively contribute to improvements and participate in innovation, lessons learned, and knowledge sharing activities.', 'Ability to define and manage performance with SLAs and KPIs.', 'Ensure that work meets all applicable engineering, financial, planning, and operational standards.', 'BS in a technical field or an equivalent combination of education and experience', '8 + years Internet / Telecommunications network experience', 'Working knowledge of DNS and BGP', 'Working knowledge of virtualization and software defined networking', 'Must have a strong understanding of O-RAN and other 5G architectures', 'Familiarity with optical networking and interfaces', 'Extensive work with data centers and familiarity with virtualized environments such as Amazon Web Services (AWS)', 'Analyzing new network requirements, deployments, augmentations, bandwidth upgrades and software upgrades', 'Ability to write detailed technical specifications', 'Ability to manage multiple commitments simultaneously', 'Excellent communication and follow-up skills', 'Proven ability to work independently and escalate issues appropriately', 'Ability to delivery in fast-paced high volume environment supporting aggressive targets', 'Monday to Friday', 'E911: 3 years (Preferred)', 'strong understanding of O-RAN and other 5G architectures: 3 years (Preferred)', 'Internet / Telecommunications networ : 7 years (Preferred)', 'Data Traffic : 5 years (Preferred)', 'Yes', 'No']",2020-09-24 14:15:57
PGIM Investments - Software Engineer,Prudential,3.9 out of 5,"Newark, NJ","['Knowledge of two or more of the following - Java, .Net (VB, C#, ASP), SQL, HTML, XML/XSL, Shell or Batch scripting', 'Familiarity with Object Oriented design concepts, data structures and algorithms, relational databases, web tools and technologies', 'Desire to be a coder and learn business concepts', 'Strong communication, interpersonal and collaboration skills', 'Ability to work in a fast-paced, high-tech, rapidly growing and exciting environment', 'Team-player, self-starter and fast-learner. Team-player is extremely important to the group.']",2020-09-24 14:15:57
Data Engineer,Brooksource,3.7 out of 5,"United, PA","['B.S. in Computer Science, Mathematics, Statistics or related field', 'Experience with Health Catalyst Data Platform', '5+ years of Data Development and Data Design', '3+ years in Healthcare analytics, with significant experience using payor claims data', '4+ years using SQL Server (SSIS, SSMS SSRS, MDM)', 'Write SQL queries, stored procedures, packages, functions, database triggers, and views', 'Create and develop automated ETL processes for data loading, report generation, data transfers, and quality control', 'Maintain robust QC processes to ensure data integrity', 'Utilize established and standard methodologies to QC data', 'Recommend and implement best practices for data management and governance', 'Help set technical direction and provide guidance to more junior data engineers', 'Solve technical problems, simple and complex, in a lean and efficient manner', 'Ensure data security implementations meet company requirements and standards', 'Health insurance', '8 hour shift', 'Monday to Friday', 'Health Catalyst: 1 year (Required)', 'Fully Remote']",2020-09-24 14:15:57
Data Engineer,Trianz,N/A,"Santa Clara, CA 95054","['Partner with leadership, engineers, program managers and data scientists to understand data needs.', 'Design, build and launch extremely efficient and reliable data pipelines to move data across a number of platforms including Data Warehouse, online caches and real-time systems.', 'Communicate, at scale, through multiple mediums: Presentations, dashboards, company-wide datasets, bots and more.', 'Educate your partners: Use your data and analytics experience to ‘see what’s missing’, identifying and addressing gaps in their existing logging and processes.', 'Leverage data and business principles to solve large scale web, mobile and data infrastructure problems.', 'Build data expertise and own data quality for your areas.', '5+ years of Python development experience.', '5+ years of SQL experience.', '3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, digdag.io, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M).', '3+ years experience with Data Modeling.', 'Experience analyzing data to discover opportunities and address gaps.', '5+ years experience in custom ETL design, implementation and maintenance.', 'Experience working with cloud or on-prem Big Data/MPP analytics platform(i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar).', 'Experience with more than one coding language.', 'Experience with designing and implementing real-time pipelines.', 'Experience with data quality and validation.', 'Experience with SQL performance tuning and E2E process optimization.', 'Experience with anomaly/outlier detection.', 'Experience with notebook-based Data Science workflow.', 'Experience with Airflow.', 'Experience querying massive datasets using Spark, Presto, Hive, Impala, etc.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Employee Assistance Program', 'Flexible Schedule', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Parental Leave', 'Professional Development Assistance', 'Referral Program', 'Relocation Assistance', 'Retirement Plan', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'www.trianz.com', 'Temporarily due to COVID-19']",2020-09-24 14:15:57
Tire Design Engineer,Toyo Tire North America Manufacturing Inc.,3.2 out of 5,"White, GA 30184","['Create and issue experimental tire building specifications or check experimental tire building specifications issued by another Tire Design Engineer.', 'Conduct controlled experimental tire builds, verifying component accuracy and placement, confirm cured tire appearance meet required standards and coordinate confirmation testing.', 'Perform cured tire analysis of experimental tire sections to ensure dimensional accuracy.', 'Analyze test tire sections and understand test tire failure modes and how each failure mode correlates to real world conditions.', 'Create and issue initial production tire building specifications or check initial production tire building specifications issued by another Tire Design Engineer.', 'Verify initial production component accuracy and placement; confirm cured tire appearance meet required standards and coordinate confirmation testing.', 'Review factory processing of the initial production tires (green scrap, cured scrap, cured anomalies, and uniformity levels).', 'Perform cured tire analysis of initial production tire sections to ensure dimensional accuracy.', 'Analyze test tire sections and understand test tire failure modes and how each failure mode correlates to real world conditions.', 'Create and issue mass production tire building specifications or check mass production tire building specifications issued by another Tire Design Engineer.', 'Create and maintain project schedules with the goal of meeting or exceeding project schedules.', 'Coordinate experimental and initial production testing and tire builds.', 'Perform competitor tire analysis using Smithers Scientific Data and / or through tire section analysis.', 'Work with Material Design Engineers to introduce new materials and / or material suppliers for existing materials to the plant through material evaluation programs.', 'Maintain existing specifications and support plant production departments when necessary.']",2020-09-24 14:15:57
AI/ML Data Engineer,MORSE Corp,N/A,"Cambridge, MA","['US CITIZENSHIP REQUIRED, or the ability to obtain a U.S. Security Clearance', 'BS, MS, or PhD in computer science, database management, data engineering, or equivalent', 'At least 5 years of experience as a data engineer', 'Proficiency in Python and PySpark', 'Experience with Docker', 'Good communication skills', 'Self-starter and driven', 'Experience with cloud computing (AWS, Azure, GCP) is a plus', 'Familiarity with Kedro is a plus', 'Familiarity with the latest data engineering trends', 'Experience with Docker-compose', 'Experience with Microservices', 'Proficiency in one or more programming languages', 'Demonstrated experience with large data sets in one or more of the following areas: parsing, cleaning, storage strategies, provenance tracking, database formats, and parallelized data transformations']",2020-09-24 14:15:57
Database Engineer,The Sequel Group,N/A,"Bohemia, NY 11716","['Effectively manage day-to-day tasks in coordination with a team of developers and stakeholders to meet deliverables.', 'Strong programming capabilities in SQL and other DB technologies– Stored Procedures, Functions, Triggers, Views, Transactions, Data Flow.', 'Maximize the utilization of data to generate insights and address business needs, application consulting, performance tuning, data organization, security, and statistical methods; including the development and monitoring of standards and procedures affecting models, database management, design and maintenance.', 'Use logical data models to create and maintain physical database designs which meet identified business needs and provide adequate safeguards for security and integrity.', 'Participate in the physical database design process. Ensures databases provide required functionality to meet identified business needs. Implements databases for testing and production.', 'Assist in monitoring capacity and performance for test and production databases to ensure they are reliable, efficient, cost effective, and provide the required functionality.', 'Ensure that test and production databases are properly backed up and recovered when necessary. Develop and maintain database backup and recovery procedures. Ensure test and production databases are properly maintained; databases are reorganized/resized when necessary and other DBA utilities run when appropriate.', 'Bachelor’s degree in Computer Science or a related field of study.', 'Experience performing in a Functional and Application DBA Support role', 'Experience with Postgresql and POSTGIS strongly preferred.', 'Strong problem-solving skills – Evaluate available SQL database resources. (tables or views) and mine data required for reports or debug by identifying data related solutions.', 'Experience with debugging and performance tuning of SQL code, Stored Procedures, Functions, and Indexes.', 'Experience with computer programming skills such as SQL, Python, PHP, R & Java.', 'Experience installing, configuring, and administering database platform. specific advanced features such as high availability and clustering.', 'Experience using and configuring Data Visualization/Business Analytics tools to ensure simple and efficient end user experience.', 'Experience with client reporting – Develop reports based on user requirements to meet client expectations. Perform ad-hoc reporting and exploratory data analysis upon request.', 'Strong written and oral communication skills.', 'Preferred experience working in AWS environment.', 'Preferred experience with geospatial applications.', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'Database Engineer: 3 years (Required)', 'Bohemia, NY 11716 (Required)', ""Driver's License (Required)"", 'United States (Required)', 'One location', 'No: Not providing sponsorship for this job', 'www.thesequelgroup.com', 'Waiting period may apply', 'Only full-time employees eligible', 'No']",2020-09-24 14:15:57
Software Engineer,"Xchangeworx, Inc.",N/A,"Albany, NY 12205","['Work as part of a cross-functional team to understand business needs, develop and refine requirements and design and develop software to meet business objectives.', 'Provide accurate estimates for software development work.', 'Follow disciplined, professional software engineering and project management processes to ensure successful deliveries.', 'Analyze, modify, and maintain moderately complex processes and code.', 'Code, deploy, and maintain applications.', 'Other duties as assigned.', 'B.S. degree in Computer Science or related discipline.', 'Strong background in Object-Oriented programming techniques.', 'Experience with several major modern computer languages/platforms such as Cache ObjectScript, Java, Python, SQL', 'Experience with data modeling tools such as ERWin and XMLSpy.', 'Knowledge of HL7, XML, XSLT, WSDL, SAML, and XACML.', 'Project management experience.', 'Excellent interpersonal skills.', 'Excellent problem solving ability.', 'Good teamwork skills.', 'Customer service orientation.', 'Knowledge of standards, principles, and techniques of software engineering and software project management.', 'Willingness to learn new languages/platforms as needed.', 'Strong database skills.', 'Strong verbal and written communication skills.', 'See description: 1 year (Required)', ""Master's (Required)"", 'Albany, NY 12205 (Required)', 'United States (Required)']",2020-09-24 14:15:57
Solutions Engineer – Unstructured Data,Request Technology,N/A,"Chicago, IL",[],2020-09-24 14:15:57
Principal Engineer - Big Data,Indeed,4.3 out of 5,"Austin, TX 78731","['Consult with product teams across Indeed to advise on data platform and data integration best practices', 'Partner with data infrastructure and product teams on the development of prototypes, as well as designs for future integrations.', 'Analyze existing solutions and requirements, perform cost/benefit and scalability analysis, and make recommendations for platform consolidation', 'Collect feedback on current data infrastructure gaps and opportunities for improvement and bring back to Data Infrastructure leadership for prioritization.', 'Provide documentation, training, and consulting for data infrastructure users', 'Provide input and feedback to support continuous improvement in team processes', 'Drive projects and coordinate cross-team efforts in an independent and self-directed way', '10+ years in a Data Engineering or Data Platforms role', '10+ years coding experience (java or python preferred)', '8+ years hands on experience with AWS and big data technologies (Hadoop, Spark, Presto, Kafka, and similar)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of data lake fundamentals and building efficient data pipelines', 'Strong communication, collaboration, and multi-tasking abilities', 'Experience with Agile methodologies', 'View our bounty of perks: [1] http://indeedhi.re/IndeedBenefits']",2020-09-24 14:15:57
Industrial Engineer,"Spanco, Inc.",4 out of 5,"Morgantown, PA 19543","['401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Tuition reimbursement', 'Vision insurance', 'Monday to Friday', 'Industrial Engineering: 2 years (Required)', 'United States (Required)', 'Will you now or in the future require sponsorship for employment visa status?', 'www.spanco.com', 'Waiting period may apply', 'Only full-time employees eligible', 'No']",2020-09-24 14:15:57
"Product Director, Revenue Systems (Billing & Order Management)",Indeed,4.3 out of 5,Remote,"['Other rewards may include quarterly bonuses, Long Term Incentives, an open Paid Time Off policy, and many region-specific benefits.', '185,000 - 243,000 USD per year', 'Product experience at a B2B or Marketplace company. Experience at an AdTech company is a plus.', 'Possess a deep understanding of billing, checkout, and order management', 'Have a strong track record of making data-driven business decisions', 'Possess outstanding data analysis skills', 'Well versed in defining product goals and metrics', 'Able to clearly identify and prioritize opportunities', 'Possess strong communication skills with the ability to influence colleagues and executives', 'Strong leadership skills and able to gain respect across functions/teams', 'Ability to make people around you more effective and productive', 'Strong attention to detail', 'Effectively able to build, grow, and manage a team of Product Managers and Engineers and help them meet and exceed all the expectations listed above', 'Work for a company where we strongly believe in our company mission: helping people find jobs.', 'A competitive compensation package with an open PTO policy!', 'Your choice in high tech gear - Laptops, ergonomic workstations, etc.', 'Opportunity to participate in a wide variety of IRGs that celebrate diversity and inclusion for all employees.']",2020-09-24 14:16:40
Network Engineer/Administrator,MSI,N/A,"New Orleans, LA 70112","['$30.00 - $35.00 per hour', 'Health insurance', 'computer', 'voice', 'firewall', 'establishing the networking environment by designing system configuration, directing system installation, defining, documenting and enforcing system standards;', 'the design and implementation of new solutions and improving resilience of the current environment;', 'maximizing network performance by monitoring performance, troubleshooting network problems and outages, scheduling upgrades and collaborating with network architects on network optimization;', 'undertaking data network fault investigations in local and wide area environments, using information from multiple sources;', 'securing network systems by establishing and enforcing policies, and defining and monitoring access;', 'the support and administration of firewall environments in line with IT security policy;', 'reporting network operational status by gathering and prioritizing information and managing projects;', 'upgrading data network equipment to the latest stable firmware releases;', 'the configuration of routing and switching equipment;', 'the configuration of hosted IP voice services;', 'the basic configuration of firewalls;', 'remote support of on-site engineers and end users/customers during installation;', 'remote troubleshooting and fault finding if issues occur upon initial installation;', 'capacity management and audit of IP addressing and hosted devices within data centers;', 'liaising with project management teams, third-line engineers and service desk engineers on a regular basis;', 'speaking with customers via email and phone for initial requirement capture', 'Knowledge of government procedures is a plus', 'Health insurance', '8 hour shift', 'Monday to Friday', 'New Orleans, LA 70112 (Required)', 'United States (Required)', '* How many years of Networking Engineering experience do you have?', 'How many years of Information Technology experience do you have?', 'One location', 'No']",2020-09-24 14:16:40
Cloud/Automation Engineer,Perspecta,3.3 out of 5,"Atlanta, GA",[],2020-09-24 14:16:40
Data Engineer,Envision LLC,N/A,"St. Louis, MO 63141","['Be a critical senior member of a data engineering team focused on creating distributed analysis capabilities around a large variety of datasets', 'Take pride in software craftsmanship, apply a deep knowledge of algorithms and data structures to continuously improve and innovate', 'Work with other top-level talent solving a wide range of complex and unique challenges that have real-world impact', 'Explore relevant technology stacks to find the best fit for each dataset', 'Pursue opportunities to present our work at relevant technical conferences', 'At least 2 years experience with Go', 'Proven experience (2 years) building and maintaining data-intensive APIs using a RESTful approach', 'Experience with stream processing using Apache Kafka', 'A level of comfort with Unit Testing and Test Driven Development methodologies', 'Familiarity with creating and maintaining containerized application deployments with a platform like Docker', 'A proven ability to build and maintain cloud based infrastructure on a major cloud provider like AWS, Azure or Google Cloud Platform', 'Experience data modeling for large scale databases, either relational or NoSQL', 'Experience with protocol buffers and gRPC', 'Experience with: Google Cloud Platform, Apache Beam and or Google Cloud Dataflow, Google Kubernetes Engine or Kubernetes', 'Experience working with scientific datasets, or a background in the application of quantitative science to business problems', 'Bioinformatics experience, especially large scale storage and data mining of variant data, variant annotation, and genotype to phenotype correlation']",2020-09-24 14:16:40
DMSMS Engineer,Northrop Grumman,4 out of 5,"Palmdale, CA 93550",[],2020-09-24 14:16:40
Data Engineer,Insight Global,4 out of 5,"Seattle, WA","['Monday to Friday', 'Yes']",2020-09-24 14:16:40
Data Encryption and Security Engineer,"A4SAFE, Inc.",N/A,"Chicago, IL","['$80,000.00 - $120,000.00 per year', 'Benefits:', 'Dental insurance', 'Employee assistance program', 'Employee discount', 'Health insurance', 'Referral program', 'Vision insurance', 'Design, build and implement enterprise-class security systems for a production environment', 'Align standards, frameworks and security with overall business and technology strategy', 'Identify and communicate current and emerging security threats', 'Design security architecture elements to mitigate threats as they emerge', 'Create solutions that balance business requirements with information and cyber security requirements', 'Identify security design gaps in existing and proposed architectures and recommend changes or enhancements', 'Use current programming language and technologies to writes code, complete programming and performs testing and debugging of applications', 'Train users in implementation or conversion of systems', 'Understanding of Data at Rest, In Use and in Motion', 'Database, Hard drive, Server, Application and AWS Encryption', 'Data Masking and Exchange', 'Password Hashing and Authentication', 'Key Generation and Discovery', 'Understanding of Cryptanalysis', 'Data Governance and Modeling', 'Dental insurance', 'Employee assistance program', 'Employee discount', 'Flexible schedule', 'Health insurance', 'Referral program', 'Vision insurance', 'Monday to Friday', 'Encryption: 3 years (Required)', 'Cybersecurity: 3 years (Preferred)', 'Disaster Recovery: 3 years (Preferred)', 'Fully Remote', 'No: Not providing sponsorship for this job', 'www.A4SAFE.com']",2020-09-24 14:16:40
"Consulting Data and Integration Engineer (AWS, ETL, Big Data) - Remote",Magellan Health,3.5 out of 5,"Glen Allen, VA 23060","['Participate in defining strategic IT objectives and leading subordinates toward that strategic vision for their products.', 'Acts as the primary focal point for both internal and external customers for software development tasks. This includes estimates of feasibility, time and effort of tasks.', 'Provide updates to both the user community and the programmers.', 'Monitor projects, determines potential problems and guides them to a successful completion.', 'Ensure that all work is getting accomplished by making assignments and monitoring tasks. This includes balancing work between programmers, analysts, project managers, supervisors, and managers, and ensuring that the proper policies and procedures are being followed.', 'Assists with budget preparation and management.', 'Mentor and evaluate staff performance. - Continues to work hands-on doing programming and analysis work themselves.', 'Tracks all project requests in functional area and updates status of projects on a regular basis.', 'Assists in estimating work effort associated with new project requests.', 'Assists in planning for the development and support of a functional systems area.', 'Reviews and evaluates work of subordinate staff and prepares performance reports.', 'Participates in planning and budgeting.', '7+ years related experience including a minimum of 3+ years of designing, building and maintaining high quality, secure software in IT.', 'Critical thinker.', 'Demonstrated problem solving techniques.', 'Strong verbal and written communication skills.']",2020-09-24 14:16:40
IMS Edge/LCC Operations Engineer,U.S. Cellular,3.7 out of 5,"Lynchburg, VA","['Responsible for providing 24x7 network service outage restoral up to and including tier-3 level support for CDMA/VoLTE voice and 3G/4G/5G data network services and equipment (including MME, SAE Gateway, Media Gateways, Aggregation Routers, legacy CDMA, Voicemail and Digital Cross Connects systems).', ""Interfaces with vendor's technical staff, driving escalations, and root cause analysis, as well as develops, reviews, and communicates technical bulletins and critical alerts for network wide distribution."", 'Partners with Engineering and Architecture groups by providing operational feedback on services, network designs, and architecture in the planning, testing, and acceptance of network expansion, new service and feature introduction, and software upgrades. Implements and integrates new services and technology.', 'Identifies opportunities for advanced analytics and automation utilizing object-oriented programming languages such as python and R and interfaces with Analytics and Automation Engineers.', 'Participates in effective change management processes to include writing/reviewing methods of procedure (MOPs), test plans, and documenting results.', 'Tests and validates services for operational changes to the network, new services, and feature introduction.', 'Maintains Local Connectivity Center (LCC) equipment and related peripherals to ensure proper operation and compliance with company standards to include HVAC, Generator, DC Power Plant, Fire Suppression, and Building Management System.', 'Performs administrative responsibilities associated with spares inventory control, repair and return process, asset management, Sarbanes-Oxley (SOX) compliance, time entry reporting, and expense reporting.']",2020-09-24 14:16:40
Process Engineer,Orange EV,N/A,"Riverside, MO 64150","['401(k) matching', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'Evaluate and improve on processes in manufacturing systems.', 'Develop and implement systems that optimize all phases of production process.', 'Maintain reliable and safe manufacturing systems while improving production rates, efficiencies, yields, costs, and changeovers.', 'Strong knowledge of Lean Manufacturing, 5S, OEE, KPI’s, Time Study’s and other manufacturing improvement and reporting systems.', 'Maintain production equipment.', 'Develop innovative solutions.', 'Improve process capability and production volume while maintaining and improving quality standards.', 'Evaluate engineering designs for production runs.', 'Evaluate processes for new products and existing changed products.', 'Collect, record, and transcribe production data.', 'Develop and Present results in reports.', 'Provide suggestions during incident investigations.', 'Investigate, advise, and implement on corrective actions.', 'Work with equipment designers and manufacturing officers to develop a cost-effective and working production process.', 'Ensure projects are completed on time.', 'Research and purchase new manufacturing technology and equipment.', 'Bachelor’s degree from an accredited university in engineering or related sub-field such as industrial engineering, or mechanical engineering', 'Strong interpersonal skills', 'Excellent written and verbal communication skills', 'Ability to work well independently and with a team', 'Proficiency with computer and information technology', 'Microsoft suite', 'AutoCAD Inventor', 'Specialized industry-specific training strongly preferred', 'Lean manufacturing and 5S', 'Six sigma a plus', 'TPM', 'Thorough understanding of scientific and mathematical principles', 'Thorough understanding and use of basic manufacturing equipment and terminology.', '401(k) matching', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', '10 hour shift', '8 hour shift', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.orangeev.com', 'Waiting period may apply', 'Temporarily due to COVID-19']",2020-09-24 14:16:40
"Systems Administrator (Washington, D.C. or U.S. Remote)",Wallethub,N/A,"Washington, DC 20006","['Potential for stock options after the first year', 'Pay:', '$90,000.00 - $130,000.00 per year', 'Min. 3 years of experience in supporting AWS-based production infrastructure', 'Min. 3 years of experience administering UNIX/Linux server required (or equivalent work experience)', 'Min. 3 years of experience with Apache, Tomcat and any other Java application servers and relational database servers like MySQL (LAMP experience is highly preferred', 'Experience with configuring and securing mission-critical production servers', 'Experience with configuring load balancers and data', 'Experience in Scripting, with experience implementing automation and monitoring using shell scripting and Python', 'Experience in analysis and system performance tuning', 'Critical thinking skills in a complex IT environment to analyze, troubleshoot, and resolve problems', 'Outstanding organizational skills and the ability to handle multiple projects simultaneously while meeting deadlines', 'Excellent verbal and written communication skills', ""Bachelor's or Master’s degree in Computer Science (or equivalent work experience)"", 'Willingness to work hard (55hrs per week min.)', 'Experience with monitoring tools like Nagios, tripwire, aide and other custom monitoring tools', 'Ensure proper security, monitoring, alerting and reporting for the infrastructure and be the on-call for production servers', 'Develop security monitoring and other tools to ensure the integrity and availability of our applications, server resources, reviewing system and application logs', 'Work with the incident team to diagnose and recover from hardware or software failures working with or as the Incident Commander to coordinate and communicate with our internal customers', 'Assist project teams with technical issues during development efforts', 'Gather system requirements and support several project teams in evolving, testing, and rolling-out new products and services, then transitioning the site or product to post launch operations activities throughout the life of the product or service', 'Work with the application development team and other systems engineers to make improvements to current infrastructure', 'Document processes and procedures and follow a formal change management procedure', 'Very competitive salary based on prior experience and qualifications', 'Potential for stock options after the first year', 'Raise and advancement opportunities based on periodic evaluations', 'Health benefits (if working from our office in Washington, D.C.)', 'Visa sponsorship (if working from our office in Washington, D.C.)']",2020-09-24 14:16:40
MySQL Database Administrator,Updox,N/A,Remote,"['Maintaining/Improving Infrastructure', 'Monitoring Existing Infrastructure', 'Deploying New Infrastructure', 'Automating Management Tasks', 'Evaluating Technologies and Tools', 'Troubleshooting and Fixing Infrastructure Issues', 'Writing and Updating Documentation', 'Maintain/Monitor/Improve Mysql/Percona Servers 30%', 'Maintain/Monitor/Improve Indexes, and Application Queries 15%', 'Manage/Verify Database Backups, Integrity, and DR Capabilities 15%', 'Plan/Automate/Deploy/Troubleshoot Infrastructure 15%', 'Work with Developers to Plan/Improve Application Queries 10%', 'Work with Analytics Team to Plan/Improve Data Warehouse and Analytics Queries 10%', 'Meetings/Presentations/Demos 5%', '3+ years experience with managing MySQL (Configuration, replication, etc.)', '2+ years experience with SQL, or as a MySQL database administrator. (Writing and tuning indexes, query optimization, data modeling)', '2+ years of experience planning, deploying, and managing Linux based infrastructure.', '2+ years of experience automating tasks and writing tools in a scripting language (i.e. Bash, Python, Go, Ruby).', '1+ years of experience with common networking technologies (i.e. IPv4, NAT, Firewalls).', '1+ years of experience working with a configuration management tool (i.e. Ansible, Puppet, Chef, SaltStack).', 'Production MySQL Orchestrator experience (or similar tech) is highly desired.', 'Production ProxySQL experience (or similar tech) is highly desired.', 'Production experience with Percona tools is highly desired.', 'Experience managing document databases such as Elastic, MongoDB, ArangoDB, etc.', 'Experience managing or automating tasks for Ubuntu/Redhat based systems.', 'Experience managing infrastructure with Ansible.', 'Experience managing or using RabbitMQ or Apache Kafka.', 'Experience managing or using Redis optionally with Sentinel.', 'Experience managing or using ElasticSearch, Logstash, or Kibana.', 'Experience working with Kubernetes or equivalent container orchestration.', ""Bachelor's degree or higher in Computer Science, IT or EE.""]",2020-09-24 14:16:40
Consultant-Custom Research,IQVIA,3.8 out of 5,"Horsham, PA 19044","['We are offering an attractive compensation package including base salary, company bonus, medical, dental, vision and life insurance benefits, and 401K plan.', 'LI-JK1']",2020-09-24 14:16:40
Frontend Engineer (Mid Level),"ReStream Solutions, Inc.",N/A,"Austin, TX 78751","['401k Retirement Plan', 'Fantastic medical, dental, and vision insurance', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Mechanical Engineering and Design - We design and build all of our own process equipment', 'Hardware Engineering - We design and build all of our own hardware', 'Software Engineering - We manage our own cloud infrastructure, end-to-end, including UI/UX', 'Data Science and Machine Learning - We do all of the analytics and machine learning applications with our data', 'Operations - We provide the “boots on the ground” and resources to keep our equipment operating smoothly', 'Business Development - We are always exploring new ways to make our data more useful', 'Design interfaces iteratively, with a strong foundation in UI and visual design practices, including translating initial concepts and requirements into wireframes, mockups and/or prototypes.', 'Deliver responsive designs across platforms and devices.', 'Work with other groups to identify UI design and user experience requirements', 'Take an idea from concept to implementation in actual code', 'A self-starter that can own the entire design process and provide input and guidance on the overall look and feel of a product.', 'Experience developing UIs with API-driven front-end systems and modern UI frameworks. Exposure to Elm and TypeScript are a plus.', 'Creative thinkers who can deliver simple, effective solutions with few “moving parts”', 'Willingness to handle back-end and front-end development of web applications', 'Fun-Loving, adventurous souls who don’t mind team events and happy hours', 'AWS', 'Python (Flask & Django)', 'Postgres', 'RabbitMQ', 'MongoDB', 'React', 'Experience with React, Elm, and Typescript', 'STEM Major (Engineering, Physics, Mathematics, etc)', 'Data Analytics with Python, including NumPy, SciPy, Pandas, and Jupyter Notebooks', 'Embedded system development experience', 'Familiarity with electrical, mechanical, fluid, or chemical processes', 'Experience in the Oil and Gas Industry', 'Bonus pool - When the company does well we all benefit', '401k Retirement Plan', 'Fantastic medical, dental, and vision insurance', 'Startup vibe with a casual environment - but we focus on maintaining a work/life balance!', 'Video games, happy hours, pot lucks….we like to have fun!', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'javascript: 2 years (Preferred)', 'Austin, TX 78751 (Required)', 'Temporarily due to COVID-19']",2020-09-24 14:16:40
Identity and Access Management Engineer - REMOTE,Centric Consulting,4.1 out of 5,"Louisville, KY 40207","['From $50.00 per hour', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Vision insurance', 'Based in the IT Department in Louisville, the position is responsible for the ownership, management, design, maintenance and support of identity and access management (IAM) systems across the enterprise. Analyzes trending issues and areas for improvement while acting as support escalation at various levels.', 'Operates in an architect and implementation capacity on operational and project based initiatives that involve IAM, account life cycle management, access provisioning, OS/software installation and configuration including upgrades and patching, monitoring and reporting of supported systems, auditing and assessment of access and provisioned access, and corporate acquisition support.', 'Based in the Health IT Department in Louisville, the position is responsible for the ownership, management, design, maintenance and support of identity and access management (IAM) systems across the enterprise. Analyzes trending issues and areas for improvement while acting as support escalation at various levels', 'Experienced with IAM implementation and administration, role-based access control, Active Directory, LDAP, Single Sign-On, End-User provisioning, identity and access governance, and identity data synchronization services with existing on-premise & cloud-based systems applications and systems.', 'Experienced with API Gateways, Enterprise Directories, Enterprise Databases, SSO and Access Management systems, identity federation protocols (SAML), and LDAP.', 'Experienced with SQL scripting in a large data base environment.', 'Knowledge of programming languages such as C, C++, Go, and Java.', 'Experience in understanding and implementing against technical IAM architecture designs across six major capability areas:', 'Identity Lifecycle Management', 'Identity Data Models', 'Access Lifecycle Management', 'Runtime Enforcement', 'Credential Management', 'Identity Federation', 'History of contributing to deployments in and engineering role. Deployment experience must include two or multiple of the following IAM solutions:', 'Identity Governance and Administration (IGA) for aggregating application and system data for access certification.', 'Identity Lifecycle Management and user provisioning/de-provisioning.', 'Single Sign On (SSO) integration and session management for multiple web and cloud applications.', 'Identity Federation (SAML) configuration and integration across multiple trusted third parties, applications, and systems.', 'Directory (LDAP) service implementation and integration for identity data consumption by applications and systems.', 'Multi Factor Authentication (MFA) such as Duo or Microsoft Authenticator security integration into the authentication, authorization, and single sing on process for applications and systems.', 'API security and API integration with IAM systems for sharing identity contexts.', 'Good knowledge in identity and access data correlation, normalization and building of cohesive identity and access data models for large enterprises.', 'Experience with complex Identity and Access Management integration and service delivery use cases and requirements.', 'Very good experience with relational database management systems (i.e. Oracle, SQL Server) including previous experience with writing SQL extracts, development of custom views and stored procedures.', 'Knowledge of IT, service-oriented architectures, software development life cycles, or information security platforms and applications.', 'Significant SailPoint Identity IQ development and architecture experience', '5+ years of related industry experience in an enterprise environment', '3+ years’ experience in integrating security and IAM products in mid to large enterprises.', '2+ years of experience with identity management, access management, and federation products such as One Identity or SailPoint.', '2+ years of experience with requirements, design, implementation, integration, and testing for IAM component integration into on-premise and cloud-based applications.', '2+ years of experience across a variety of technologies such databases, directory services, application servers, network infrastructures, Linux operating systems, and an understanding of fundamental security and data flows within these components.', 'Excellent verbal and written communication skills.', 'Self-motivated, driven, and creative with the ability to thrive under pressure and on tight deadlines', 'BS/BA in Computer Science, Information Technology or equivalent work experience', 'Completion of one (or more) IdentityIQ training courses', 'One (or more) of: CIAM, CAPM, PMP, PGMP, MPM, CPM, Project+ or equivalent work experience preferred', 'CISSP highly preferred.', 'Special Culture – Our people make us different. We have highly talented, intelligent individuals across a broad variety of disciplines – who are eager to learn from you and share their own expertise. We embrace fresh perspectives and each other. Don’t take our word for it – check us out on Glassdoor, Facebook, Twitter or Instagram to get a glimpse inside what makes us different.', ""Growth opportunities – As a mid-size firm, there is more flexibility when it comes to career paths. Figure out what you want to do and we'll help you figure out how to get there."", 'Impact – We think of ourselves as a big company with a small company feel – a local player with global reach that combines business, technology and industry expertise.', 'Unmatched Experiences – We are allowed to be ourselves here. We are encouraged to be human. It’s at the root of who we are as a firm and why we’re here.', 'Innovation – We value passion, determination, perseverance, and innovation. We are inspired because we believe in what we are doing and where we are going.', 'Passion for the greater good – We are steadfast in our devotion to the communities we serve and in actively promoting employee involvement in community improvement projects.', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Vision insurance', '8 hour shift', 'Identity & access management: 5 years (Preferred)', ""Bachelor's (Required)"", 'Louisville, KY 40207 (Required)', 'No']",2020-09-24 14:16:40
"Director, Data and Integration Engineering - Remote",Magellan Health,3.5 out of 5,"Glen Allen, VA 23060","['Influences changes/enhancements to business processes, policies, and system infrastructure.', 'Manage the selection, evaluation, contracting, and integration of externally available hardware, software, and data to deliver business solutions.', 'Directs and manages though analysis, planning, design, development, testing, installation, and maintenance of support systems for business areas.', 'Selects and builds strong teams through formal training, diverse assignments, and coaching, mentoring, and other development techniques.', 'Manages and develops project cost estimates, benefits and assessment of potential project risks.', 'Manages projects, people, customer expectations, and business priorities to achieve customer satisfaction.', 'Manages budgets, plans and expenses; may have cost center responsibilities.', 'May manage vendors.', 'Shares best practices throughout IT.', '10+ years of experience in Data and Integration Engineer and leading teams through the development and support of applications.', 'Must have 2+ years of experience leading teams.', 'Broader experience across IT or across different industries (for external hires) is a must.', 'Experience in health care, insurance or related field.', 'Critical thinker.', 'Demonstrated problem solving techniques.', 'Strong verbal and written communication skills.', 'Ability to coach and build skills within the team.']",2020-09-24 14:17:24
Geospatial Solutions Engineer,"New Light Technologies, Inc.",4.6 out of 5,"Washington, DC 20005","['$80,000.00 - $110,000.00 per year', 'Benefits:', '401(k)', 'Dental Insurance', 'Employee Assistance Program', 'Employee Discount', 'Flexible Spending Account', 'Health Insurance', 'Paid Time Off', 'Parental Leave', 'Professional Development Assistance', 'Referral Program', 'Retirement Plan', 'Vision Insurance', 'Work authorization:United States (Required)', 'Security Clearance Required:Confidential (Preferred)', 'Bachelor’s degree in geography, geosciences, business, computer science, or equivalent practical experience in a sales engineering role.', 'Sales engineering and implementation consulting experience including a demonstrated background in product/solution design, presentation, and demonstration capabilities to existing prospective customers.', 'Experience designing impactful presentations and pitches that have led to new clients or projects.', 'Rapid prototyping experience for demonstration of capabilities to prospective customer objectives and goals.', 'Ability to design and deploy end-to-end ESRI geospatial technology stack implementations.', 'Familiarity and experience with the full cycle of product development', 'Experience and familiarity with a variety of geospatial data formats', 'Ability to work independently and with groups', 'Experience with scripting languages such as JavaScript, Python, etc.', 'Experience with open-source solutions such as QGIS, GeoNode or other GIS suites.', 'Experience with Google Earth Engine', 'Experience analyzing and maintaining large imagery datasets', 'Knowledge of cloud environments (GCP, AWS, Azure)', '401(k)', 'Dental Insurance', 'Employee Assistance Program', 'Employee Discount', 'Flexible Schedule', 'Flexible Spending Account', 'Health Insurance', 'Paid Time Off', 'Parental Leave', 'Professional Development Assistance', 'Referral Program', 'Retirement Plan', 'Vision Insurance', 'Monday to Friday', 'On Call', 'Weekends', 'United States (Required)', 'Please list any presentations, repos, or other online content that is publicly available if you have them. For proper consideration, please make sure to take our skills tests in this indeed posting.', 'Confidential (Preferred)', '2 months or less', '3 - 4 months', '5 - 6 months', '7 - 11 months', '1 year', 'More than 1 year', 'Varies', 'Likely', 'One location', 'Multiple locations', 'Fully Remote', 'On the road', 'Less than 10', '10-19', '20-29', '30-39', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'https://NewLightTechnologies.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Yes']",2020-09-24 14:17:24
SDWAN Engineer,Windstream Communications,3.2 out of 5,Remote,"['Provides technical leadership and direction in area of expertise for engineering staff and Windstream internal teams by enhancing operations and maintaining reliability of systems.', 'Acts as technical consultant within and outside assigned department in area of expertise and promotes positive change in the company’s business strategy through achievement of specific objectives and technological innovation of a practical and profitable nature.', 'Works on problems of diverse scope, which includes technical escalations from customer facing teams and this will require self-motivation to accomplish expected tasks with some on call required', 'Act as escalation point for complex issues related to Security, SD-WAN, and their supporting components.', 'Assist in product roll-out, upgrades, and maintenances of Security and SD-WAN environments.', 'Discussing and developing customer designs that meet Windstream standards or architectural guidelines.', 'Document resolution and conduct appropriate root cause analysis post trouble resolution.', 'Work with Windstream internal teams to audit and optimize customer network solutions to ensure maximum service uptime, survivability and sustainability.', 'Identify and handle upstream communication regarding network service trends, escalation trends, emergent technology and network vulnerabilities both from a provider backbone perspective and a customer solution perspective.', 'Manage small-scale projects and tasks while working closely with Engineering teams or other internal teams as needed.', 'Develop and maintain expert level technical and marketing knowledge for Windstream Security and SD-WAN product sets.', 'Strong technical background, including industry relevant certifications (I.e. CCNA-Cloud, CCP, CCC)', 'BA degree in a technology track or hold equivalent experience of no less than 5 years in a Network Operations, Network Associate or Network Technician Role', 'Proven track record of being able to resolve complex issues and exhibit a genuine enthusiasm for working with network equipment', 'Experience working in a Service Provider environment and familiarity with key concepts including MPLS from a Service Provider standpoint, VoIP Architecture from a Service Provider Standpoint, and SD WAN from a Service Provider Standpoint.', 'Ability to work with Basic Scripting Languages and understanding of SAAS and Cloud Infrastructure is highly desirable', 'Bachelor’s degree in a technical discipline and 4-6 years technical experience with 6 years directly related to the job and 5 years of digital experience.', 'College hours or a college degree may be substituted for some experience as deemed appropriate.']",2020-09-24 14:17:24
"2021183 Data Scientest $100,000.00",B4CORP,N/A,"Tysons, VA","['Up to $100,000.00 per year', 'Position Level Min Salary Max Salary Level 1 – Subject Matter Expert $160,000 $215,000 Level 2 – Expert $140,000 $195,000 Level 3 – Senior $110,000 $170,000 Level 4 – Full Performance $60,000 $100,000', 'B4Corp’s benefits reflect the company’s policy of putting the employees first.', 'Our health insurance demonstrates this with 100% employer coverage and providing employees with a plan that has $0 copay, 0% coinsurance and an HSA that can allow employees to accrue health savings for the future.', 'B4Corp’s maximum flexibility comp / makeup time policy, along with the company’s cafeteria-style benefit plan that allows employees to maximize their benefit dollars, reflects B4Corp’s commitment to its employees.', 'Retirement:', 'Full Vanguard 401k Plan – Featuring a full scope of investment options – 100% employer matched contribution up to 6% of employee’s salary', 'Ability to max out 401k savings $57k ($63.5k if over 50)', 'Employees receive B4Corp phantom stock each year (2-year vesting period)', 'Insurance 100% Employer-Paid Premiums:', 'United Health Care Choice Plus HSA POS Gold 1500 w/HSA – Employer funded HSA to cover 100% health care deductible – Health insurance: $0 copay, $0 co-insurance.', 'Full scope protection for you and your family!', 'Health Equity HSA – B4Corp contributes $1500.00 for single and $3000.00 for family into your Health Equity HSA to cover 100% of your health care deductible.', 'Mutual of Omaha Dental VSP Vision Insurance Mutual of Omaha short-term disability (60% of salary up to $2,000.00/week)', 'Mutual of Omaha long-term disability (60% of salary up to $10,000.00/month)', 'Mutual of Omaha life insurance (', '$200,000.00)', 'Employee Referral Bonus:', 'Refer a friend or a coworker and receive $2,000 per year for every year the person works for B4CORP', 'Paid Time Off (PTO):', 'Seven weeks of leave per year (including ten federal holidays)', 'Free L inux Academy Online Training Account', 'This role supports creation of designs and method, process, and system development to consolidate and analyze structured and unstructured, diverse sources including big data sources.', 'This role will concentrate on data, pattern identification and analysis. As such will evaluate capabilities and analysis in Natural Language Processing, Machine Learning, predictive modeling, statistical analysis and hypothesis testing', 'This role develops and uses advanced software programs, algorithms, query techniques, model complex business problems, and automated processes to cleanse, integrate, and evaluate datasets.', 'Works with cross-discipline teams to ensure connectivity between various data sources and business problems.', 'Identifies meaningful insights and interprets and communicates findings and recommendations.', 'This role develops algorithms and analytical techniques to improve business performance.', 'Will research and explore emerging analytics and big-data technologies.', 'Master’s degree in engineering, computer science, or other related technical field or Bachelor’s degree in a business or management-related field accompanied by experience managing technical requirements in complex programs.', 'Candidate must have experience in Machine Learning', 'Experience with developing Random Forests decision trees and subsequent analysis.', 'Experience with Splunk and deployment methodologies', 'Experience with negotiating complex scenarios and challenges and devising courses of action to resolve situations with predictable outcomes.', 'Outstanding Salaries', 'Full Vanguard 401k Plan – Featuring a full scope of investment options– 100% employer matched contribution up to 6% of employee’s salary– Ability to max out 401k savings $57k ($63.5k if over 50)', 'Employees receive B4Corp phantom stock each year (2-year vesting period)', 'United Health Care Choice Plus HSA POS Gold 1500 w/HSA– Employer funded HSA to cover 100% health care deductible– Health insurance: $0 copay, $0 co-insurance. Full scope protection for you and your family!– 100% employer premium coverage for single and family', 'Health Equity HSA – B4Corp contributes $1500.00 for single and $3000.00 for family into your Health Equity HSA to cover 100% of your health care deductible.', 'Mutual of Omaha Dental VSP Vision Insurance Mutual of Omaha short-term disability (60% of salary up to $2,000.00/week)', 'Mutual of Omaha long-term disability (60% of salary up to $10,000.00/month)', 'Mutual of Omaha life insurance ($200,000.00)', 'Refer a friend or a coworker and receive $2,000 per year for every year the person works for B4CORP', 'Seven weeks of leave per year (including ten federal holidays)', 'Ability to purchase 2 additional weeks of vacation', 'Flexible work schedule with comp time (with customer approval)', 'Free CBTNuggets Online Training Account– More than 200 online IT courses on a large variety of topics, including networking, security, virtualization, and the cloud — from trusted vendors such as Cisco, Microsoft, and Google.– Train anytime, anywhere, and on a variety of devices – even offline!– Transcender® Practice Exams– Virtual Labs', 'Free L inux Academy Online Training Account']",2020-09-24 14:17:24
Sr. Big Data Engineer,Ursus,N/A,"Houston, TX 77057","['As part of an agile team, design, develop and maintain an optimal data pipeline architecture using both structured data sources and big data for both on-premise and cloud-based environments.', 'Develop and automate ETL code using scripting languages, ETL tools and job scheduling software to support all reporting and analytical data needs.', 'Design and build dimensional data models to support the data warehouse initiatives.', 'Assemble large, complex data sets that meet the analytical needs of the data scientist teams.', 'Assess new data sources to better understand availability and quality of data.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data pipeline performance, re-designing infrastructure for greater scalability and access to information.', 'Participate in requirements gathering sessions to distill technical requirements from business requests.', 'Collaborate with business partners to productionize, optimize, and scale enterprise analytics.', 'Collaborate with data architects and modelers on data store designs and best practices', 'Provide off-hours support for all developed data pipelines in an on-call rotation.', ""Bachelor's degree in Computer Science, Engineering, Information Science, Math or related discipline"", 'Data engineering, data management or cloud certification is a plus', 'At least six (6) to eight (8) years of experience in in a data engineering role or related specialty with demonstrated ability in data modeling', 'At least two (2) years Data engineering experience on the Microsoft Azure, Amazon Web Services (AWS), or Snowflake', 'Experience using Extract, Transformation and Load (ETL) tools with Informatica (IICS) to build automated data pipelines', 'Experience with object-oriented/object function scripting languages: Python, Java, C++', 'Thorough understanding of relational, columnar and NoSQL database architectures and industry best practices for development', 'Understanding of dimensional data modeling for designing and building data warehouses', 'Excellent advanced SQL coding and performance tuning skills', 'Experience with big data tools: Hadoop, Spark, Kafka, etc.', 'Experience with parsing data formats such as XML/JSON and leveraging external APIs', 'Understanding of agile development methodologies', 'Ability to work in a team-oriented, collaborative environment; good interpersonal skills', 'Strong analytical and problem-solving skills; ability to weigh various suggested technical solutions against the original business needs and choose the most cost-effective solution', 'Keen attention to detail and ability to access impact of design changes prior to implementation', 'Self-driven, highly motivated and ability to learn quick', 'Ability to effectively prioritize and execute tasks in a high-pressure environment', 'Strong customer service orientation', 'Ability to present and explain technical information to diverse types of audiences in a way that establishes rapport and gains understanding', 'Work experience with geospatial data and spatial analytics is preferred']",2020-09-24 14:17:24
Process Engineer,StarrTrax,4.5 out of 5,"Lebanon, PA 17042","['$75,000.00 - $85,000.00 per year', 'Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Tuition reimbursement', 'Vision insurance', 'Experience:working in a cleanroom, 1 year (Preferred)working closely with production and maintenance departments, 2 years (Required)continuous improvement, 2 years (Required)', ""Education:Bachelor's (Required)"", '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Tuition reimbursement', 'Vision insurance', 'Monday to Friday', 'Bonus pay', 'working in a cleanroom: 1 year (Preferred)', 'working closely with production and maintenance departments: 2 years (Required)', 'continuous improvement: 2 years (Required)', ""Bachelor's (Required)"", 'Are you willing to work a flexible Mon-Fri schedule so that your time is spent with personnel on both 1st and 2nd shift (i.e. 10am-7pm)?', 'No']",2020-09-24 14:17:24
2020 Software Engineer Intern,Bloomberg,3.9 out of 5,"New York, NY","['Take ownership of projects under the guidance of your mentor', 'Be a collaborative member of your team', 'Have a deep understanding of data structures and algorithms', 'Be an excellent problem solver', 'Have programming experience in C, C++, Java or Python', 'Have a minimum GPA of 3.0', 'Be working toward a BA, BS, MS or PhD in Computer Science']",2020-09-24 14:17:24
Engineer (NLP),Darwin Recruitment,N/A,"New York, NY","['Base salary up to $130K', '10% target bonus', 'Long term investment plan (3 years)', '$20K', 'Top-level Healthcare benefit programmes', 'Base salary up to $130K', '10% target bonus', 'Long term investment plan (3 years) - $20K', 'Top-level Healthcare benefit programmes', 'Initial stage screening with HR', 'Second round conversation with the Hiring Manager', 'Third stage with the Group Leader', 'Final stage - Take-home assignment that includes a follow review', 'Offer', ""You need to be a competent and confident Engineer that's open to working in NYC (post-COVID)."", ""On top of that, you'll also need to have some proven experience in creating and deploying production-ready code in Python/JavaScript in a Linux environment"", 'In an ideal world, you would have worked closely with Pharma based Research Scientists. These Researchers will then go on to use a number of different text mining/NLP techniques to extract data from clinical documentation to generate a target-indication database.', ""The work that this company is doing is not only highly complex but it's being done in unknown and unexplored territories meaning, you'll need to very comfortable working with other Engineers/Scientists/CV folks who all take a multimodal approach."", 'You have a desire for learning on the job! This is a fast-paced, forward-thinking company that really does encourage self-development', ""Oh and It's a huge plus if you have experience in MarkLogic platform (They're considering migrating to it) but not a must at this point.""]",2020-09-24 14:17:24
Systems Application Engineer,Yona-Brixtel LLC,N/A,"Vienna, VA 22182","['Pay:', '$0.00 per hour', '401(k)', 'Dental insurance', 'Employee discount', 'Health insurance', 'Life insurance', 'Paid time off', 'Retirement plan', 'Vision insurance', '401(k)', 'Dental insurance', 'Employee discount', 'Health insurance', 'Life insurance', 'Paid time off', 'Retirement plan', 'Vision insurance', 'Monday to Friday', 'Outcome-oriented -- results-focused with strong performance culture', 'A job for which military experienced candidates are encouraged to apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-09-24 14:17:24
Jr. Data Warehouse Developer,Brooksource,3.7 out of 5,"Richardson, TX","['Assists the team with technical direction for the design, development, testing, implementation, and maintenance of DW solutions', 'Hands-on experience and knowledge of Data Warehouse best practices, Teradata, and Informatica ETL.', 'Assists the technical team in identification and resolution of Data Quality issues', 'Experience in configuration management and software release principles as well as change management concepts', 'Work effectively with technical personnel (Development Team, Systems Analysts, Testers), and clearly translate business priorities and objectives into technical solutions.', ""1-2 years' experience working within Data Warehousing"", 'Experience utilizing SQL in a professional environment', 'Hands on ETL (e.g., Informatica/DataStage) experience', 'Experience working with Teradata or related Appliance']",2020-09-24 14:17:24
Intern Quality Engineer,Northrop Grumman,4 out of 5,"Baltimore, MD 21240","['Develops, modifies, applies and maintains quality evaluation and control systems and protocols for processing materials into partially finished or finished materials product', 'Collaborates with engineering and manufacturing functions to ensure quality standards are in place', 'Devises and implements methods and procedures for inspecting, testing and evaluating the precision and accuracy of products and production equipment', 'Designs and analyzes inspection and testing processes, mechanisms and equipment; conducts quality assurance tests; and performs statistical analysis to assess the cost of and determine the responsibility for, products or materials that do not meet required standards and specifications', 'Performs or assures quality, risk management, safety, reliability and maintainability of program achievements, subcontractors, and suppliers in accordance with contractual requirements', 'Evaluates key suppliers, ensure the suppliers are performing well and their capacity and capability to deliver products on time is acceptable']",2020-09-24 14:17:24
Machine Learning Engineer,Olive,3.3 out of 5,"Columbus, OH 43215","['Collaborate with team members to deliver ML and RPA solutions including but not limited to data analytics and analysis, ML model training, and RPA implementation', 'Identify machine learning architectures and models to solve complex data problems', 'Work with multiple stakeholders to deliver automated workflows in a timely fashion', 'Use software development programs and operating systems for development', 'Define new techniques and best practices for all areas of req and ML', 'Provide feedback to product and development teams to improve our in house tools', 'Document process, procedures, and training materials for staff and stakeholders', 'Attend daily stand-up and periodic team meetings', 'Bachelor Degree in Computer Science, Computer Engineering, Physics, Applied Mathematics, Systems Engineering, Electrical Engineering or other related degree or experience', 'Strong mathematical and data analysis skills', 'Solid understanding of data types and structures', 'Knowledge of remote connectivity applications: Citrix Receiver, Horizon VMWare Client, RDP', 'Version control such as GIT, Subversion, Team Foundation', 'Ability to understand large scale software & system architecture', 'Able to communicate technical issues with technical & non-technical stakeholders', 'Experience in one of the following programming languages: Python, R, SQL, and Javascript', 'Experience with Python ML tools: Keras, Jupyter Notebooks, Pandas, scikit-learn, Flask, OpenCV, Tesseract, and Numpy', 'Experience with Agile tools, Jira, Trello, Pivotal Tracker', 'Understanding of Continuous integration, testing, deployment & release methodologies', 'Automation Anywhere, Blue Prism, Autolt experience', 'Understanding of Computer Vision', 'Proficiency with recent Windows Server operating systems', 'Healthcare IT and EHR knowledge']",2020-09-24 14:17:24
Data Engineer,Perspective Talent LLC,N/A,"Wilmington, NC 28403","['Health Insurance - no premium for employee coverage', 'Flexible Spending Accounts', 'Paid vacation and sick leave, plus 10 paid holidays', 'Retirement pension, plus 401k with 3% employer match', 'Student Loan Forgiveness - Qualifying Employer', '$70,000.00 - $80,000.00 per year', 'Testing programs or databases, correcting errors and making necessary modifications', 'Planning, coordinating and implementing security measures (including regular audits) to safeguard information in databases and computer files against accidental or unauthorized damage, modification or disclosure', 'Assisting with automating ETL processes, data mining and data management', 'Developing reference and workflow documents for documentation purposes', 'Bachelor’s degree or Associates Degree with certifications', '6+ years experience in database management or database reporting-related field', 'Strong knowledge in SQL Server, including SSIS', 'Strong knowledge of TFS (Team Foundation Server), Source Control, and Visual Studio', 'Experience with .Net/C# or other object oriented programming languages preferred', 'Experience in an Agile Scrum environment preferred', 'Preferred certifications include MTA, MCSA, MCSE, ITIL v3, Note: applicable certification(s) may be substituted to equivalent degree requirements.', 'Flexible Work Schedules', 'Health Insurance - no premium for employee coverage', 'Flexible Spending Accounts', 'Paid vacation and sick leave, plus 10 paid holidays', 'Retirement pension, plus 401k with 3% employer match', 'Student Loan Forgiveness - Qualifying Employer', 'Monday to Friday', 'Fully Remote']",2020-09-24 14:17:24
Data Engineer,CyberCoders,3.3 out of 5,"West Menlo Park, CA 94025","['Competitive Salary, bonus plus equity', 'Room to grow with a growing startup', ""Make an impact on people's health"", 'Interface with engineers, product managers and machine learning scientists/engineers to understand data needs and implement solutions', 'Work directly with ML scientists/engineers to implement reusable data models', 'Build out automated solutions for ML feature testing, validation, and release', 'Implement and maintain a data version control system', 'Enable automated data preparation for model training', 'Ensure data quality and accessibility for all types of data used', 'Design, build, enhance, and launch ETL processes for new and existing data sources', 'Augment existing data with output from machine learning analysis/algorithms', 'Systematically identify and rectify data quality issues (missing data, mislabeled, old, poor schema/model, etc)', 'Produce basic statistical analyses and visualizations to help guide product and business decisions', 'Bachelors degree in Computer science, Engineering, Mathematics or Informatics', '3+ years of Data Engineering experience', '2+ years experience in ETL design, implementation and maintenance', '2+ years experience in the data warehouse space', '2+ years experience with schema design and dimensional data modeling', 'Expert usage of SQL and python', 'Practical application of basic statistical methods', 'Basic experience working on machine learning projects', 'Familiarity with tools for analysis of large datasets', 'Prior working experience with healthcare, wearable device, and/or human subject data is a PLUS', 'Data visualization skills (R, and Tableau) is a PLUS', 'MS or Advanced Degree is a PLUS', '']",2020-09-24 14:17:24
Industrial Engineer,System One,3.6 out of 5,"Mineral Point, WI","['Bachelor’s degree required', 'Monday- Friday 7AM-4PM', 'AutoCad experience', 'Hands on Industrial Engineering experience', 'Simulation: Responsible for envisioning creative solutions for process/method improvement and for leading others in the successful implementation of that vision. Design simulation models to reflect manufacturing process using discrete event simulators such as Witness and AutoMod.', 'Work Measurement Studies: This skill involves being able to perform and utilize work measurement studies or how long a job takes to perform. The experts who conduct work measurement studies should not only be able to conduct the studies, but apply the special rules to optimize the accuracy of the studies Specialist.', 'Line Balancing: The ability to balance a line. This requires an evaluation of work activities to be performed by a person or machine in relationship to the customer/product demand rate.', 'Workstation Design: This skill involves being able to design an operator station. Design of an operator station requires knowledge of anthropometrics, ergonomics, National Institute of Occupational Safety and Health (NIOSH) safety standards, office layout guidelines, etc.', 'Asset Utilization Management: Method of management of equipment which incorporates business objectives such as asset availability, product quality and overall equipment efficiency (OEE).', 'Process Layout: The ability to develop process layouts which encompasses all equipment, tooling and material flows necessary to provide for an effective Product Assembly process.', 'Ergonomics: Intended to reduce operator fatigue and discomfort.', 'Responsible for designing engineered material flow to support production and warehousing operations.', 'Provide engineering support for material flow processes, document standard procedures, develop layouts and act as the engineering liaison to Materials dept.', 'Interacts on a regular basis with other functional groups and vendors on technical matters.', 'Administers technical procedures including process and work procedures. Implements industrial engineering system (standard cost data, capacity and equipment requirement forecasting, shop floor control system).']",2020-09-24 14:17:24
Data Engineer,H&R Block,4.2 out of 5,"Kansas City, MO 64126","['Motivated by the idea of building something innovative, transformative, and impactful.', 'Committed to the idea that data can drive experiences and products that wow our business partners and clients', 'Obsessed with defying expectations and raising the bar', 'Driven by an innate sense of ownership for the products you create.', 'Design and deploy architecture, solutions, and software to capture, manage, store, and use structured and unstructured data from internal and external sources in both on-prem and cloud environments.', 'Deploy machine-learning models and other data-science products across the enterprise.', 'Navigate the balance between business needs, data governance best practices, and technical requirements.', 'Select or develop tools to cleanse, organize, and transform data and to maintain, defend, and update data structures and integrity on an automated basis.', 'Develop data products to facilitate self-service capabilities and assist the data teams to increase their efficiency and effectiveness.', 'Collaborate and communicate effectively within cross-functional teams that span internal Data Science & Analytics teams, IT, business groups, and executive stakeholders.', 'Be a positive force to cultivate a culture that is passionate about developing data tools as a business driver.', ""Bachelor's degree in a related field or the equivalent through a combination of education and related work experience."", '3 years Minimum related work experience', 'Use of Data Stage', 'Fluent in Java, Python, and a C based language', 'In-depth knowledge of Hadoop and bigdata technologies such as MapReduce, Hive, and Pig, NoSQL technologies, SQL technologies, and data warehousing solutions', 'Able to help partners articulate business requirements', 'Intermediate (practical application) Relationship building and conflict management skills', 'Oral, written and interpersonal communication skills']",2020-09-24 14:18:09
Medical Devices Engineer - Product Support,"Medical Components, Inc.",N/A,"Harleysville, PA 19438","['Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', ""About Us - Medcomp® develops, manufactures, markets and supports cutting-edge vascular access devices and accessories to meet the clinical needs of the medical industry, particularly in the fields of interventional medicine and dialysis. Our company's engineering and applications expertise provides superior products whose progressive designs accommodate advances in medicine and whose quality anticipates the requirements of our professional clients and the patients they serve. Currently one of the world's largest manufacturers of dialysis and centrally terminating venous catheters, Medcomp is, and always has been, on the cutting edge of new vascular access device technologies."", 'Working with DHF and holding design review meetings', 'Develop medical devices from concept to finished product following all Design Control procedures.', 'Work with regulatory to ensure the design meets 510k, MDD and MDR requirements.', 'Driven, detail oriented and able to look at multiple avenues to find solutions.', 'Responsible for developing project plan and verification testing and validation testing.', 'Maintain and follow proper compliance and quality systems requirements.', 'Lead projects including team members, and be responsible for all meetings, and working with all individuals from supporting departments such as scheduling and planning.', 'Write and review protocols and summaries.', 'Gather, track, and analyze product data as needed.', 'Understand and develop specifications, bills of materials, routers, SOPs and SUPs for prototypes.', 'Assist in root cause analysis for return product failures.', 'Responsible for investigating field complaints', 'Responsible for assessing design risk when completing change review', 'Responsible to create MS Project Plans, flow charts, tables and Power point presentations.', 'Assist with manufacturing to resolve production issues as required.', 'Actively communicate with lab and production to ensure the build and testing is done per project priority.', 'Perform feasibility studies on testing done out of house and calculate ROI on projects to provide support for new capital improvement projects.', 'Perform statistical analysis', 'Travel to other facilities.', 'Other duties as assigned.', 'Requires a Bachelor of Science in an engineering, scientific or technical discipline.', 'Would prefer M.S. degree in an engineering, scientific or technical discipline or other professional certifications. Knowledge of Six Sigma is preferred.', '3-5 years of related experience in the medical device industry in an engineering environment.', '401(k)', '401(k) matching', 'Dental insurance', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday']",2020-09-24 14:18:09
Aircraft Structures and Composites Engineer - FAA MRO,Preferred Composite Services,N/A,"Miami, FL 33172","['$60,000.00 - $100,000.00 per year', 'Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Supplemental Pay:', 'Develops or assists in developing solutions to a variety of routine and standardized engineering or technical problems or assignments following established engineering protocols in the analysis and design of aircraft structures or special purpose applications on operational aircraft.', 'Reviews and interprets engineering documentation and product specifications to assist in determining repair scopes.', 'Confers with the Shop Manager and/or Lead Inspector to clarify or resolve problems. Creates the design and development of structural repairs for aircraft structural components. This includes producing in the production of computer aided drawings and engineering reports.', 'Provides technical authority to modify aircraft configurations, maintenance programs and associated Instructions for Continued Airworthiness (ICAs.)', 'Responsible for ensuring safe, compliant aircraft parts and reliable operations while maintaining competitive costs.', 'Oversees and provides the technical authority to repair and modify aircraft/components outside the OEM maintenance manuals and works with Structures DER for FAA 8110 approval.', 'Ensures all regulatory required actions are implemented to ensure compliance.', 'Directs engineering actions that improve PCS business.', 'Incorporates new systems and technologies justified by other divisions.', 'Drives continuous improvement to PCS operations.', 'Drives review, analysis and incorporation of service documents (SB, SL, etc.) to provide tangible operational or cost benefits.', 'Manages and improves costs of engineering expenses.', 'Understands the costs associated with engineering actions to provide desired results at minimum cost.', 'Works with the PCS structures team and technical staff to ensure quality, timeliness and effectiveness is achieved.', 'Prioritizes and coordinate work from multiple customer orders that supports aircraft configuration and maintenance requirements, i.e., Reliability, Publications, Planning, etc.', 'Primary focal for all technical issues related to the aircraft structures.', 'Embodies the PCS spirit and conduct oneself with Professionalism, Integrity, Resourcefulness, and Caring.', ""Strong working knowledge of aircraft systems and FAR's relating to engineering and maintenance activities required."", 'Knowledge and experience in all relevant regulatory requirements and industry practices is required.', 'Must be an expert in airline technical operations and conversant in structures.', 'Issue instructions and documents to economically support operations and return aircraft parts to service in a safe, airworthy, and timely manner.', 'Develop plans, instructions, and documents to comply with FARs, ADs, and SBs and to resolve non-mandatory in-service issues.', 'Liaise with manufacturers; maintenance representatives, repair & overhaul (MRO) facilities; outside engineering departments; regulatory personnel; and other outside agencies.', 'Review work of consultant, contract, and MRO Structures Engineers.', 'Evaluate Federal Aviation Regulations (FARs), Airworthiness Directives (ADs), Service Bulletins (SBs), Service Letters (SLs), and other notifications of in-service issues.', 'Develop and/or obtain approved data, acceptable data, and Alternate Methods of Compliance (AMOCs) for repairs, alterations, and modifications.', 'Evaluate reported Level 2 and Level 3 corrosion findings, develop corrective action plans, and submits plan in accordance with regulatory requirements.', 'Evaluate discrepancies that require mandatory reporting to the FAA and submit these reports to the FAA in accordance with regulatory requirements.', 'Develop product improvement modifications as dictated by reliability indicators.', 'Work with original equipment manufacturers on emerging issues to help ensure safety and airworthiness, but also minimize the economic impact.', 'Organize, develop and provide all necessary Structures Engineering documentation required to complete aircraft structures modifications and repairs within the allocated time schedule and budget allowance.', 'Implement the Repair Assessment Program (RAP).', 'Implement programs to comply with new FARs on Repairs, Alterations, and Modifications (RAMs) and other Aging Aircraft programs such as Widespread Fatigue Damage (WFD).', 'Initiate maintenance program changes and changes to maintenance documents.', 'Physical Requirements - While performing the duties of this job, the employee may be required to bend, squat, sit, stand, walk, crawl, work in tight spaces and handle objects. The employee is occasionally required to push/pull, stack, reach above shoulder level or carry light-weight materials.', '4-8 years Aircraft Structural Engineering', 'S. Engineering/Technical Engineering Degree preferred', 'Meets deadlines', 'Remembers & follows instructions', 'Meets daily attendance & punctuality standard', 'Work is thorough', 'Produces accurate, dependable work', 'Output is consistent', 'Complete attention to detail', 'Volume of work produced meets expectations', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Monday to Friday', 'Bonus pay', 'Aircraft Structures: 5 years (Preferred)', 'Airframe & Powerplant License (Preferred)', 'Are you an FAA DER?', 'No']",2020-09-24 14:18:09
Resident Quality Engineer,Confidential,N/A,"Bowling Green, KY","['Pay:', 'Up to $30.00 per hour', 'Monday to Friday', 'Weekends', 'One location', 'No']",2020-09-24 14:18:09
Senior Data Engineer - 100% Remote,recruitAbility,N/A,"Austin, TX 78752","['Excellent Compensation range in the $150k - $180k range depending on experience', 'Comprehensive benefits include 16 weeks of fully paid maternity and paternity leave, Ownership opportunity through an employee stock option plan, Health, dental, and vision insurance, 4% company 401K matching vested immediately', 'At least 8 years experience designing and building data processing/ETL pipelines', 'At least 8 years experience in Python and Spark or similar technologies', 'At least 8 years experience with SQL and relational databases', 'At least 8 years experience parsing flat files', '8+ years of development experience', 'Prior track record in a hyper-growth, high-tech company', ""Bachelor's degree or equivalent practical experience"", 'Experience and interest in identifying security vulnerabilities in source code', 'Experience and interest in machine learning', 'Understanding of statistics and data analysis', 'Experience with a variety of programming languages and technologies (Java, Python, C++, C#, JavaScript, Go, Scala, etc.)', 'Experience with SQL and relational databases', 'Experience with Git, Mecurial, Maven, Gradle and other build and source code management tools', 'Experience with Google BigQuery, Compute Engine, and Cloud Storage', 'Experience with Docker and Kubernetes', 'Experience in static analysis', 'Experience with modern technology stacks', 'Experience with micro-services architectures', 'Experience with cloud platforms and SaaS solutions', 'Experience with agile/scrum development practices', 'Experience with test-driven development, continuous integration, continuous deployment', 'Excellent Compensation range in the $150k - $180k range depending on experience', 'Comprehensive benefits include 16 weeks of fully paid maternity and paternity leave, Ownership opportunity through an employee stock option plan, Health, dental, and vision insurance, 4% company 401K matching vested immediately', 'Be recognized, internally and publicly, for your contributions in a high profile position', 'Align your career trajectory with a hyper-growth company that is rapidly scaling', 'Be part of the initial team designing and building out the product', 'Join an industry with massive socio, economic, and political importance in the 21st century', 'Work alongside some of the best and the brightest minds in the security industry', 'Leave an indelible mark on a company where individual input has a real impact', 'Be recognized, internally and publicly, for your contributions in a high profile position', 'Align your career trajectory with a hyper-growth company that is on the move', ""Create a roadmap for our client's data acquisition and labeling efforts"", 'Create tools to find, ingest, organize, maintain, and label complex data sets for use in machine learning models', 'Work with data scientists to create and maintain data ontologies for security', 'Work with security engineers to identify and label vulnerabilities in source code repositories', ""Continually evolve the data engineering infrastructure and techniques to improve the client's ability to find security information"", 'Mentor junior data engineers and teach them how to use data engineering techniques to solve real world problems', 'Communicate complex concepts to team members', 'Creation and curation of source code datasets for the machine learning effort', 'Creation of data engineering pipelines to find and ingest source code', 'Creation of data engineering tools to help label and validate data']",2020-09-24 14:18:09
Data Engineer Senior,USAA,3.9 out of 5,"El Mirage, AZ 85335",[],2020-09-24 14:18:09
Process Engineer,MPP,2.8 out of 5,"Rockwood, TN 37854","['MPP offers a competitive compensation package and full benefits to include medical, dental, vision, disability and life insurance, 401(k) plan, paid vacation and holidays.', 'Pay:', '$50,000.00 - $70,000.00 per year', 'Benefits:', '401(k)', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Employee discount', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Relocation assistance', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', '401(k)', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Employee discount', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Relocation assistance', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Powdered Metal: 3 years (Preferred)', 'CNC / Machining: 3 years (Preferred)', 'Associate (Required)', 'Rockwood, TN (Required)', 'United States (Required)', 'One location', 'Detail-oriented -- quality and precision-focused', 'Team-oriented -- cooperative and collaborative', 'https://www.mppinnovation.com/', 'Only full-time employees eligible', 'No']",2020-09-24 14:18:09
Corporate Quality Engineer,Union Tank Car Company (UTLX),3.3 out of 5,"Chicago, IL","['$69,287.00 - $105,098.00 per year', 'Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Relocation assistance', 'Tuition reimbursement', 'Vision insurance', 'Ensures that the Company Quality Assurance manual, procedures, work instructions and program meet all regulatory and customer requirements. Posts revisions and updates to the company webpage.', 'Interacts with customer service and engineering personnel in addition to customers and regulators to provide support and technical expertise on quality issues.', 'Monitors and reports non-conformances and OTMA (One Time Movement Approvals) data in an effort to drive continual improvement. Assists Production and Quality personnel to ensure specifications are adhered to and corrective/preventative actions are followed.', 'Assists and supports the repair facility network with AAR QA-7.1 submittals and responses as needed.', 'Manages internal audit functions of the quality department to ensure adherence to design and regulatory requirements. Assists with external regulatory audit functions and vendor audits as required. Initiates, tracks and conducts supplier/contractor audits and oversees the criteria which triggers such audits.', 'Ensures compliance to subcontractor activities and renewals for the repair facility network.', 'Reviews, summarizes, uploads and distributes the applicable AAR Circulars as they are published.', 'Participates in and actively supports quality projects, activities and Responsible Care initiatives to ensure that the company stays compliant and achieves its goals.', '401(k)', '401(k) matching', 'Dental insurance', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Relocation assistance', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Quality Engineer: 4 years (Preferred)', ""Bachelor's (Required)"", 'legally can work in US now & future without sponsorship (Required)', 'United States (Preferred)', 'One location', 'No']",2020-09-24 14:18:09
Backend Engineer (Mid Level),"ReStream Solutions, Inc.",N/A,"Austin, TX 78751","['401k Retirement Plan', 'Fantastic medical, dental, and vision insurance', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Mechanical Engineering and Design - We design and build all of our own process equipment', 'Hardware Engineering - We design and build all of our own hardware', 'Software Engineering - We manage our own cloud infrastructure, end-to-end, including UI/UX', 'Data Science and Machine Learning - We do all of the analytics and machine learning applications with our data', 'Operations - We provide the “boots on the ground” and resources to keep our equipment operating smoothly', 'Business Development - We are always exploring new ways to make our data more useful', 'Build systems and tools that can parse, clean, and aggregate time-series data', 'Work with front end engineers to identify needed API functionality for our web applications', 'Work with data science team to identify API functionality needed for data analytics', 'Build, test, and maintain core services (APIs) with REST endpoints using the Flask framework', 'Support the embedded systems group as needed', '2+ Years Experience Coding Professionally', 'Experience with a major web framework (e.g., Django, Flask, Symfony, etc)', 'Creative thinkers who can deliver simple, effective solutions with few “moving parts”', 'Willingness to handle back-end and front-end development of web applications', 'Fun-Loving, adventurous souls who don’t mind team events and happy hours', 'AWS', 'Python (Flask & Django)', 'Postgres', 'RabbitMQ', 'MongoDB', 'React', 'STEM Major (Engineering, Physics, Mathematics, etc)', 'Data Analytics with Python, including NumPy, SciPy, Pandas, and Jupyter Notebooks', 'Embedded system development experience', 'Familiarity with electrical, mechanical, fluid, or chemical processes', 'Experience in the Oil and Gas Industry', 'Bonus pool - When the company does well we all benefit', '401k Retirement Plan', 'Fantastic medical, dental, and vision insurance', 'Startup vibe with a casual environment - but we focus on maintaining a work/life balance!', 'Video games, happy hours, pot lucks….we like to have fun!', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'python: 2 years (Preferred)', 'Austin, TX 78751 (Required)', 'Temporarily due to COVID-19']",2020-09-24 14:18:09
Technical Support Engineer,GFI Digital Inc.,N/A,"Maryland Heights, MO 63043","['$40,000.00 - $60,000.00 per year', 'Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Perform network design and capacity planning', 'Develop, implement and maintain policies/procedures for network resource, administration, appropriate use and Disaster Recovery', 'Oversee installation, configuration, maintenance and troubleshooting of end-user workstation hardware, software and peripheral devices', 'Research hardware and software and interact and negotiate with vendors, outsources and contractors to secure network products and services', 'Perform asset and operational management responsibilities such as managing servers, security solutions, routers, switches, network hardware (including upgrades), security and server audits, backup and recovery, administration of equipment and monitor, test and report on performance of networks', 'Ability to work on-call as part of a rotation', 'Work through inbound customer calls and ticketing systems to resolve issues', 'Occasional inspection of cables and floors and ceilings', 'Limited travel locally to client sites', 'Lifting and transporting moderately heavy objects such as computer and peripherals', 'Experience working in a team-oriented, collaborative environment', 'Working technical knowledge of network and PC operating systems, including Windows and others', 'Extensive application support experience using MS Office Suites and other software applications', 'Working technical knowledge of current network hardware, protocols and standards', 'Hands-on hardware and software troubleshooting experience', 'Working with coordinating vendor activities', 'Knowledgeable of applicable data privacy practices and laws', 'Strong written and oral communication skills', 'Excellent interpersonal, customer service and relationship building skills', 'Conduct research into networking issues and products', 'Present ideas in user-friendly language for customers', 'Effectively prioritize and execute tasks in high-pressure environment', 'Highly self-motivated and directed', 'Keen attention to detail', 'Proven analytical and problem solving abilities', 'Bachelor’s Degree and/or 4 years equivalent work experience', 'Microsoft, CompTIA and Cisco Certifications', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Paid time off', 'Referral program', 'Vision insurance', '8 hour shift', 'www.gfidigital.com', 'https://www.facebook.com/GfiDigital', 'Waiting period may apply']",2020-09-24 14:18:09
NOC Engineer,"USConnect Services Co., Inc.",N/A,"Livingston, TX 77351","['401(k)', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Wellness Program', 'Life Insurance', 'Paid Time Off', 'Tuition Reimbursement', 'Vision Insurance', 'Provide technical support to the customer regarding network issues and end user equipment.', 'Provide one on one support for Service Network Technicians working in the field.', 'Monitor all voice, data, and transport networks.', 'Provision and configure', 'Identify, recommend and facilitate services upgrades to customers as warranted following inhouse processes.', 'Works with vendors to resolve hardware operating system issues; researches and tests possible solutions and implements solutions. Obtains quotes for new hardware for projects and upgrades', 'Upgrade systems for servers and networking equipment', 'Perform remote troubleshooting through diagnostic techniques and pertinent questions', 'Record events, problems, and their resolutions in logs', 'Test, debug, implement, and document programs. Assists in the modification of company products & internal systems to meet the needs of the end-user.', 'Conduct routine audits of hardware and software on workstations and servers to ensure compliance with established standards, policies, and configuration guidelines', 'Assist Senior IT personnel with the implementation of new service offerings', 'Participate in on-call support, scheduled weekend outages, and Disaster Recovery activities as required', 'The candidate should have intermediate networking skills including troubleshooting network problems, traffic monitoring, PC connectivity and debugging, virus/spyware removal, DNS, DHCP, networked printers, file shares, and some familiarity and experience using Cisco hardware and Genband/Taqua switches.', 'Other duties as assigned', 'Experience in transport and voice-switched services or IP/router managed Internet or related technology.', 'Experience in Microsoft Excel, Word, Access, Visio, and WAN/LAN technology is preferred.', 'Knowledge of telecommunications technology and/or previous telecommunications or Internet', 'Service Provider experience preferred.', 'Must have strong self-motivational skills as well as possess administration, coordination, and prioritization abilities.', 'Skill in operating various office equipment such as personal computer and telephone systems.', 'Skill in identifying and resolving subscriber problems.', 'Skill in oral and written communication.', 'Ability to communicate with customers, employees, and various business contacts in a professional and courteous manner.', 'Ability to organize and prioritize multiple work assignments in a fast-paced, changing environment is also necessary.', 'Ability to pay close attention to detail.', 'Knowledge of telephony equipment such as Calix, Genband, and Taqua is STRONGLY preferred.', 'Knowledge of Unified Communications systems and protocols, specifically BroadSoft BroadWorks is a plus.', 'Knowledge of Network Management tools (Solarwinds, Splunk)', 'B.S. or M.S. in Computer Science or related areas is preferred.', '401(k)', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Wellness Program', 'Life Insurance', 'Paid Time Off', 'Tuition Reimbursement', 'Vision Insurance', '8 hour shift', 'No']",2020-09-24 14:18:09
Quality Assurance Tester,Hive Media Group,N/A,"Carlsbad, CA","['Medical, Dental, and Vision plan for all regular full-time employees and their dependents with significant employer contributions.', '401(k) plan with annual employer contributions.', 'Fully stocked Kitchen, daily catered lunch, and dinner for those working late.', 'Unlimited PTO (paid time off) & 12 paid holidays, plus your Birthday off.', 'On-site Gym and passes to a local yoga studio.', 'Identify, isolate, and track bugs through manual testing strategies.', 'Independently plan and execute new testing features that align with the company’s business objectives.', 'Adapt to changing priorities and pay close attention final testing details with strict time constraints.', 'Constantly review user interfaces for consistency, clarity, and functionality.', 'Investigate and report bugs to the development team.', 'Basic understanding of JavaScript – Should be able to read code line by line and have an idea of what is happening.', 'Basic understanding of the DOM API – Should be able to find elements on a page using JavaScript (document.getElementById, document.querySelector)', 'Basic understanding of CSS selectors (#id, .class)', 'Strong understanding of browser development and testing tools (Chrome DevTools,Fiddler).', 'Working knowledge of testing techniques used for testing websites.', 'Strong problem-solving skills.', 'Excellent time management skills.', 'Excellent verbal and written communication skills.', 'Broad understanding of JavaScript and other programming languages.', 'Previous experience in a start-up environment.', 'Knowledge of current trends and latest advancements in software development/QA.', 'Working knowledge of continuous integration and deployment.', 'Working knowledge of release and configuration management best practices.', 'Medical, Dental, and Vision plan for all regular full-time employees and their dependents with significant employer contributions.', '401(k) plan with annual employer contributions.', 'Fully stocked Kitchen, daily catered lunch, and dinner for those working late.', 'Work with intelligent, creative, and innovative colleagues in an intellectually stimulating environment.', 'Professional growth opportunities.', 'Unlimited PTO (paid time off) & 12 paid holidays, plus your Birthday off.', 'On-site Gym and passes to a local yoga studio.']",2020-09-24 14:18:09
Cyber Systems Engineer,Northrop Grumman,4 out of 5,"McLean, VA 22102","['Support of IA compliance (DoD/Army) for enterprise Operating Systems and Applications of AKO systems.', 'Review, manage and report system compliance status with DoD directives and vulnerability compliance data to include HBSS, ACAS, SCAP, IAVMs, DISA STIGs.', 'Manage organization SIEM tools, including analysis and reporting of suspicious events.', 'Perform detailed analysis in support of OS and Application level vulnerabilities.', 'Support design/deployment/maintenance of new and existing security infrastructure capabilities.', 'Manage security incident reporting and provide leadership with After Action Reports following incidents.', 'Maintain compliance with security standards defined in Army policy.']",2020-09-24 14:18:09
Quality Assurance Lab Engineer,AVX Corporation,3.3 out of 5,"Greenville, SC 29644","['Quality Assurance Lab Engineer', 'Understand how the manufacturing processes for ceramic capacitors affect the essential physical and electrical characteristics and apply that knowledge effectively.', 'Understand applicable MIL and customer requirements for functional and reliability tests, develop test methods and equipment to comply with those requirements', 'Manage transfer of test programs from other facilities including equipment, methods, and training of new personnel. Travel to other AVX locations as needed to support the transfer.', 'Improve systems for sample submission, data collection, and storage and reporting of test results', 'Participate in problem solving activities to identify root causes and implement effective corrective actions', 'Support the plant Quality Management System and compliance to ISO 9001, IATF 16949, MIL-STD- 790, etc.', 'BS Degree in Engineering (Electrical, Mechanical or Ceramics / Materials Eng. preferred)', 'Strong written and oral communication skills', 'Strong analytical and problem solving skills', 'Proficiency in the use of Microsoft Office tools', 'Manufacturing experience or Co-op / Internship in a manufacturing environment is preferred Familiarity with quality tools such as SPC, MSA (Gage R&R), root cause analysis (Fishbone, 5 Why, Fault Tree), 8D reports, and reliability estimates is preferred but not required', 'Familiarity with ISO-9001, ISO/TS-16949, MIL-STD-790, etc. is preferred but not required', 'Familiarity with LabVIEW, Visual Studio, Oracle SQL is preferred but not required', ""Bachelor's (Required)""]",2020-09-24 14:18:09
Staff Scientist/Engineer - Environmental (Full-Time),Renova Environmental Services,N/A,"Asbury Park, NJ 07712","['Pay:', '$40,000.00 - $45,000.00 per year', 'Benefits offered:', 'Paid time off', 'Health insurance', 'Dental insurance', 'Other types of insurance', 'Retirement benefits or accounts', 'Education assistance or tuition reimbursement', 'Office:', 'Report writing', 'Data management', 'AutoCAD drawings', 'Project scheduling, logistics, and implementation', 'Work scope and budget development', 'Develop knowledge of environmental and safety regulations', 'Interact with clients, subcontractors, regulatory officials, and industry professionals', 'Support overall business operations', 'Field:', 'Remedial action oversight', 'Remedial investigations of soil and groundwater via GeoProbe and hand auger', 'Monitoring well installation oversight and sampling', '0 to 5 years of experience', 'B.S. or B.A. in a Life Science, Physical Science, or Environmental Engineering', 'Excellent verbal, written, communication, and computer skills', 'Safe driving record', 'Monday to Friday', ""Bachelor's (Preferred)"", 'One location', 'Paid time off', 'Health insurance', 'Dental insurance', 'Other types of insurance', 'Retirement benefits or accounts', 'Education assistance or tuition reimbursement']",2020-09-24 14:18:09
Sr. Big Data Engineer,Ursus,N/A,"Houston, TX 77057","['As part of an agile team, design, develop and maintain an optimal data pipeline architecture using both structured data sources and big data for both on-premise and cloud-based environments.', 'Develop and automate ETL code using scripting languages, ETL tools and job scheduling software to support all reporting and analytical data needs.', 'Design and build dimensional data models to support the data warehouse initiatives.', 'Assemble large, complex data sets that meet the analytical needs of the data scientist teams.', 'Assess new data sources to better understand availability and quality of data.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data pipeline performance, re-designing infrastructure for greater scalability and access to information.', 'Participate in requirements gathering sessions to distill technical requirements from business requests.', 'Collaborate with business partners to productionize, optimize, and scale enterprise analytics.', 'Collaborate with data architects and modelers on data store designs and best practices', 'Provide off-hours support for all developed data pipelines in an on-call rotation.', ""Bachelor's degree in Computer Science, Engineering, Information Science, Math or related discipline"", 'Data engineering, data management or cloud certification is a plus', 'At least six (6) to eight (8) years of experience in in a data engineering role or related specialty with demonstrated ability in data modeling', 'At least two (2) years Data engineering experience on the Microsoft Azure, Amazon Web Services (AWS), or Snowflake', 'Experience using Extract, Transformation and Load (ETL) tools with Informatica (IICS) to build automated data pipelines', 'Experience with object-oriented/object function scripting languages: Python, Java, C++', 'Thorough understanding of relational, columnar and NoSQL database architectures and industry best practices for development', 'Understanding of dimensional data modeling for designing and building data warehouses', 'Excellent advanced SQL coding and performance tuning skills', 'Experience with big data tools: Hadoop, Spark, Kafka, etc.', 'Experience with parsing data formats such as XML/JSON and leveraging external APIs', 'Understanding of agile development methodologies', 'Ability to work in a team-oriented, collaborative environment; good interpersonal skills', 'Strong analytical and problem-solving skills; ability to weigh various suggested technical solutions against the original business needs and choose the most cost-effective solution', 'Keen attention to detail and ability to access impact of design changes prior to implementation', 'Self-driven, highly motivated and ability to learn quick', 'Ability to effectively prioritize and execute tasks in a high-pressure environment', 'Strong customer service orientation', 'Ability to present and explain technical information to diverse types of audiences in a way that establishes rapport and gains understanding', 'Work experience with geospatial data and spatial analytics is preferred']",2020-09-24 14:18:52
Gas Processing Engineer,American Energy Innovations,3.5 out of 5,"Springtown, TX 76082","['PTO provided.', 'Aggressive medical, dental and vision benefits.', 'Great working environment.', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Relocation Assistance', 'Vision Insurance', 'Lead the design process for our natural gas processing, scrubbing and measurement unit.', 'Provide drawings of the designed unit or work with other co-workers to provide a sat of plans for the fabrication of the gas processing unit.', 'Frequently visit job-sites and work with a team of engineers to create and maintain a process for scrubbing and cleaning natural gas from production or gathering facilities into a combustible fuel source for Tier 4 Dual Fuel Engines.', 'Once a method has been established, visit job-sites to ensure the process is safe and efficient while making adjustments to ensure the highest level of safety and efficiency are achieved.', 'Assist in the rigging up and rigging down of equipment when starting and finishing a specific job-site and/or well.', 'Work with safety departments from Texas Pride Fuels and customers to ensure that the set-up was completed in a safe and orderly fashion.', 'Analyze data and communicate findings and results to upper management.', 'Communicate any and all information and process changes to upper management.', 'Be the subject matter expert in the handling of natural gas and dealing with other hazardous items.', 'Ensure safety and consistency in the design of any gas processing systems utilized.', 'Maintain a safe working environment by being knowledgeable on safety risks associated with natural or liquefied gas produced, stored or transported by vessels or pipelines and mitigate risks through the design of the process.', 'Wear the proper company issued PPE and safety equipment while adhering to all company safety protocols while on an oil and gas site at all times.', 'Other duties as assigned.', 'Bachelor’s Degree in Mechanical Engineering, Automotive Engineering, Chemical Engineering or other Engineering related degree. (Required)', 'OR Trade or mechanical school certification. (Required)', 'Experience processing wellhead gases and custody transfer of natural gas. (Required)', 'Experience with H2S scavengers. (Required)', 'Experience dealing with pressure control valves and gas chromatographs. (Preferred)', 'Experience designing and processing skid units. (Preferred)', 'Experience processing natural gas to engine-fuel quality. (Preferred)', 'Extremely organized while also being detail and process oriented.', 'Driven individual who is not afraid of hard work.', 'Excellent communication skills both written and verbal.', 'Ability to speak, write and read the English language.', 'Able to exercise effective judgment, sensitivity, creativity to changing needs and situations.', 'Able to establish and maintain healthy working relationships with people in course of work.', 'Must satisfactorily pass a drug and background check.', 'Ability to travel 50% of each month.', '401k with company match.', 'PTO provided.', 'Aggressive medical, dental and vision benefits.', 'Great working environment.', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Relocation Assistance', 'Vision Insurance', 'Monday to Friday', 'Dual Fuel experience in the oilfield: 1 year (Required)', ""Bachelor's (Required)"", 'Springtown, TX 76082 (Required)', '25% (Required)', 'Other forms', 'One location', 'Waiting period may apply', 'No']",2020-09-24 14:18:52
Entry Level Test Engineer,Entech Staffing Solutions,3.9 out of 5,"Troy, MI 48083","['Pay:', 'From $25.00 per hour', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', ""Bachelor's (Preferred)""]",2020-09-24 14:18:52
IT Helpdesk Engineer,"IP Consulting, Inc.",N/A,"Grand Rapids, MI 49512","['Pay:', '$18.00 - $24.00 per hour', 'Benefits:', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Responsible for staging, configuration, implementation, and support for installations', 'Respond to service requests in a timely and efficient manner, with a primary emphasis on root cause remediation', 'Internal and end customer documentation', 'Follow established support policies and procedures', 'Possess a wide and sophisticated understanding of the overall technology environment, applications, systems, and customers that IPC supports', 'Provide excellent customer service', 'Pursue and successfully maintain critical industry and product certifications associated with IPC selected network solutions', 'Demonstrated grit. You embrace challenges and persist in the face of setbacks. You consider failure an opportunity to learn, so whatever happens, you win.', 'Growth mindset with a genuine desire and motivation to learn and develop yourself. You are passionate about “studying,” and you are always actively seeking knowledge and more expertise', 'Have fundamental knowledge of internetworking designs and their applications, to include IP subnetting and routing techniques on LAN/WAN networks, Security', 'Have desktop knowledge and experience to support: Windows, Linux, Mac', 'Have server knowledge and experience to support: Windows, Linux/Unix, VMware, Hyper-V, Exchange, SharePoint, DNS, Active Directory, File/Print, etc', 'Have network knowledge and experience to support: switches, routers, firewalls, VPNs, etc', 'Have security knowledge and experience to support: Multi-factor authentication, server hardening, vulnerability scanning/penetration testing, monitoring, etc', 'Strong customer service and documentation skills', 'Experience with ConnectWise a plus', 'Ability to travel up to 20%', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'IT Service Support: 2 years (Required)', 'Cisco Call Manager: 1 year (Preferred)', 'ConnectWise: 1 year (Preferred)', 'United States (Required)', 'Fully Remote', 'A job for which military experienced candidates are encouraged to apply', 'Monday to Friday', 'On call', 'https://www.ipconsultinginc.com/', 'Only full-time employees eligible']",2020-09-24 14:18:52
Intern Quality Engineer,Northrop Grumman,4 out of 5,"Baltimore, MD 21240","['Develops, modifies, applies and maintains quality evaluation and control systems and protocols for processing materials into partially finished or finished materials product', 'Collaborates with engineering and manufacturing functions to ensure quality standards are in place', 'Devises and implements methods and procedures for inspecting, testing and evaluating the precision and accuracy of products and production equipment', 'Designs and analyzes inspection and testing processes, mechanisms and equipment; conducts quality assurance tests; and performs statistical analysis to assess the cost of and determine the responsibility for, products or materials that do not meet required standards and specifications', 'Performs or assures quality, risk management, safety, reliability and maintainability of program achievements, subcontractors, and suppliers in accordance with contractual requirements', 'Evaluates key suppliers, ensure the suppliers are performing well and their capacity and capability to deliver products on time is acceptable']",2020-09-24 14:18:52
Space Systems Engineer,Northrop Grumman,4 out of 5,"Redondo Beach, CA 90278","['As a full-time employee of Northrop Grumman, you are eligible for:', 'Medical, Dental & Vision coverage', '401k', 'Educational Assistance', 'Life Insurance', 'Employee Assistance Programs & - Work/Life Solutions', 'Paid Time Off', 'Health & Wellness Resources', 'Employee Discounts', 'Space Vehicle and Bus Architectures', 'Design Integration', 'Mass Properties', 'Alignments/ Sensor Analysis/ Sensor Accommodations', 'Payload Accommodation and Integration', 'Fault Management', 'Testbeds/Vehicle Simulators', 'Launch Systems Integration', 'Requirements and Verification', 'Specification Development', 'Interface Definition', 'Functional Analysis', 'Configuration Data Management', 'Related Processes and Tools Development', 'Medical, Dental & Vision coverage', '401k', 'Educational Assistance', 'Life Insurance', 'Paid Time Off', 'Health & Wellness Resources', 'Employee Discounts', 'Flexible Schedules: For example the ability to work a 9/80 work schedule, which allows an employee to work a nine-hour day Monday through Thursday and take every other Friday off of work']",2020-09-24 14:18:52
Network Engineer - Automation,Sparklight,3.5 out of 5,Arizona,"['Medical, dental, and vision plans – Start immediately', 'Paid time off (vacation, holiday, and personal/sick days)', '401(k) - 100% Company match (match program starts after 1 year of service, up to 5% of salary)', 'Life Insurance (self, spouse, children)/ business travel life Insurance!', 'Plus other perks:', 'Tuition Reimbursement (up to $5,250 on 1st year)', 'Annual community support to various organizations across the U.S.', 'Benefits:', '401(k)', '401(k) matching', 'Dental insurance', 'Employee assistance program', 'Employee discount', 'Health insurance', 'Life insurance', 'Paid time off', 'Parental leave', 'Professional development assistance', 'Referral program', 'Tuition reimbursement', 'Vision insurance', 'Medical, dental, and vision plans – Start immediately', 'Paid time off (vacation, holiday, and personal/sick days)', '401(k) - 100% Company match (match program starts after 1 year of service, up to 5% of salary)', 'Life Insurance (self, spouse, children)/ business travel life Insurance!', 'Tuition Reimbursement (up to $5,250 on 1st year)', 'Annual community support to various organizations across the U.S.', 'Associate recognition & award Program', 'Advancement opportunities', 'Collaborative work environment', 'Onsite fitness center', 'Food truck Tuesdays', 'Develops, verifies and writes automation testing tools.', 'Proactively identifies opportunities for network operational teams to minimize or eliminate repetitive work through automation scripts.', 'Integrates internally developed Python scripts and 3rd party Python libraries with automation platforms.', 'Documents automation processes and workflows.', 'Participates in creating automation standards for configuring networking devices.', 'This position has the expectation and responsibility to take on other duties needed to help drive our Purpose, fulfill our Brand Principles, and abide by our Organization’s Values.', ""Associate's Degree AA or equivalent from two-year college or technical school."", 'Additional experience or training may substitute for education.', '3 years or more Configuring routers and switches in production environments.', 'Documenting complex processes, split logically into subtasks, and turning into requirements for developers to implement.', 'Testing network infrastructure (e.g. routers, switches), Application Programming Interface(API) in lab/ Proof of Concept (POC) environments, documenting results, and working with vendors to address deficiencies.', 'Data Handling and Models Extensible Markup Language (XML), Yet Another Next Generation (YANG), Yet Another Markup Language (YAML), JavaScript Object Notation (JSON).', 'Automating network configuration deployment using modern scripting languages (e.g. Python, PowerShell, JavaScript).', 'Cisco Certified Network Professional (CCNP).', 'Juniper Network Certified Internet Specialist (JNCIS).', 'Yet Another Next Generation (YANG) modeling and Network Configuration Protocol (NETCONF) preferred.', 'Large network design including gathering business requirements, developing standards and best practices, and conveying design intent to implementation and support teams preferred.', 'Designing network infrastructure deployment orchestration using inventory-backed processes, canonical design definitions, and no operator intervention in steady state preferred.', 'Providing feature requests to vendors in a constructive and informative manner preferred.', 'Flask or Node.js preferred.', 'Committed: Values each and every customer, while working hard to keep their business and support our communities.', 'Helpful: Delivers support in the ways that are most useful to our customers and addresses their needs with expertise, respect, and empathy.', 'Proactive: Understand what our customers need, and actively works to make their relationship with use seamless, easy, and rewarding.', 'Personal: Knows our customers well, and tailors our communications and interactions to address their needs and expectations.', '401(k)', '401(k) matching', 'Dental insurance', 'Employee assistance program', 'Employee discount', 'Health insurance', 'Life insurance', 'Paid time off', 'Parental leave', 'Professional development assistance', 'Referral program', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Fully Remote']",2020-09-24 14:18:52
"2021184 Data Scientest $170,000.00",B4CORP,N/A,"Tysons, VA","['Up to $170,000.00 per year', 'Position Level Min Salary Max Salary Level 1 – Subject Matter Expert $160,000 $215,000 Level 2 – Expert $140,000 $195,000 Level 3 – Senior $110,000 $170,000 Level 4 – Full Performance $60,000 $100,000', 'B4Corp’s benefits reflect the company’s policy of putting the employees first.', 'Our health insurance demonstrates this with 100% employer coverage and providing employees with a plan that has $0 copay, 0% coinsurance and an HSA that can allow employees to accrue health savings for the future.', 'B4Corp’s maximum flexibility comp / makeup time policy, along with the company’s cafeteria-style benefit plan that allows employees to maximize their benefit dollars, reflects B4Corp’s commitment to its employees.', 'Retirement:', 'Full Vanguard 401k Plan – Featuring a full scope of investment options – 100% employer matched contribution up to 6% of employee’s salary', 'Ability to max out 401k savings $57k ($63.5k if over 50)', 'Employees receive B4Corp phantom stock each year (2-year vesting period)', 'Insurance 100% Employer-Paid Premiums:', 'United Health Care Choice Plus HSA POS Gold 1500 w/HSA – Employer funded HSA to cover 100% health care deductible – Health insurance: $0 copay, $0 co-insurance.', 'Full scope protection for you and your family!', 'Health Equity HSA – B4Corp contributes $1500.00 for single and $3000.00 for family into your Health Equity HSA to cover 100% of your health care deductible.', 'Mutual of Omaha Dental VSP Vision Insurance Mutual of Omaha short-term disability (60% of salary up to $2,000.00/week)', 'Mutual of Omaha long-term disability (60% of salary up to $10,000.00/month)', 'Mutual of Omaha life insurance (', '$200,000.00)', 'Employee Referral Bonus:', 'Refer a friend or a coworker and receive $2,000 per year for every year the person works for B4CORP', 'Paid Time Off (PTO):', 'Seven weeks of leave per year (including ten federal holidays)', 'Free L inux Academy Online Training Account', 'Create innovative solutions to meet the technical needs of customers.', 'Develop custom data models and algorithms to apply to data sets.', 'Participate in the development of documentation.', 'This role conducts experimentation in various data science techniques, developing, executing, and maintaining scripts and prototypes to analyze, interpret, visualize, and gain knowledge from numerous data sets individually or in combination to meet mission needs.', 'Coordinate closely with customers, Scrum Masters, and cross-functional areas to communicate project statuses and initiatives.', 'Analyze data to effectively coordinate the installation of new systems or modifications to existing systems.', 'Support the Agile software development lifecycle.', 'Communicate key project data to team members and build team cohesion and effectiveness.', 'Develop and execute project plans leveraging Atlassian tool suite like JIRA and Confluence to track activities.', 'Apply best practices and standard operating procedures.', 'Experience using the statistical computer language Python to manipulate data and draw insights from large data sets.', 'Experience using Python to manipulate data and draw insights from large data sets.', 'Candidate must have an active TS/SCI with a polygraph.', 'Candidate must have a BS with 8-12 years of prior relevant experience or Masters with 6-10 years of prior relevant experience.', 'Experience using statistical computer languages using R, SQL, etc. to manipulate data and draw insights from large data sets.', 'Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.', 'Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.', 'Experience visualizing/presenting data for stakeholders.', 'Experience querying and analyzing machine logs.', 'Excellent written and verbal communication skills for coordinating across teams.', 'Outstanding Salaries', 'Full Vanguard 401k Plan – Featuring a full scope of investment options– 100% employer matched contribution up to 6% of employee’s salary– Ability to max out 401k savings $57k ($63.5k if over 50)', 'Employees receive B4Corp phantom stock each year (2-year vesting period)', 'United Health Care Choice Plus HSA POS Gold 1500 w/HSA– Employer funded HSA to cover 100% health care deductible– Health insurance: $0 copay, $0 co-insurance. Full scope protection for you and your family!– 100% employer premium coverage for single and family', 'Health Equity HSA – B4Corp contributes $1500.00 for single and $3000.00 for family into your Health Equity HSA to cover 100% of your health care deductible.', 'Mutual of Omaha Dental VSP Vision Insurance Mutual of Omaha short-term disability (60% of salary up to $2,000.00/week)', 'Mutual of Omaha long-term disability (60% of salary up to $10,000.00/month)', 'Mutual of Omaha life insurance ($200,000.00)', 'Refer a friend or a coworker and receive $2,000 per year for every year the person works for B4CORP', 'Seven weeks of leave per year (including ten federal holidays)', 'Ability to purchase 2 additional weeks of vacation', 'Flexible work schedule with comp time (with customer approval)', 'Free CBTNuggets Online Training Account– More than 200 online IT courses on a large variety of topics, including networking, security, virtualization, and the cloud — from trusted vendors such as Cisco, Microsoft, and Google.– Train anytime, anywhere, and on a variety of devices – even offline!– Transcender® Practice Exams– Virtual Labs', 'Free L inux Academy Online Training Account']",2020-09-24 14:18:52
Principal/Sr. Principal Engineer Quality,Northrop Grumman,4 out of 5,"Herndon, VA 20171","['The Principal / Sr. Principal Quality Engineer defines and monitors Mission Assurance (MA) program specifications and processes to ensure mission success of programs. Performs or assures quality, risk management, safety, reliability and maintainability of program achievements, subcontractors, and suppliers in accordance with contractual requirements.', 'Assesses program performance and risks, and determines resources to ensure MA effectiveness. Is responsible for MA task delegation and establishing budgets and spend plans.', 'Provides technical solutions which support Quality Management System (QMS) functions on software and hardware engineering, development, test, integration, and production programs. Utilize customer and Northrop Grumman Mission Assurance policies and procedures, such as ISO 9001/AS9100/CMMI, to help realize those solutions.', 'Candidate will provide quality leadership, task direction and technical guidance to program.', 'Ensures Mission and Quality Assurance support throughout the development, review, delivery, and maintenance cycles for program CDRL deliverables, internal plans, and risk-based process audits. Participates as MA representative in Configuration Control Board meetings to assure compliance with established Configuration Management policies and procedures. Participates in design reviews providing feedback on designs to engineering/manufacturing personnel.', 'Works with the MA team and program management team to define, gather, evaluate, and effectively present process and quality metrics to assist with program efficiency, effectiveness, and continuous improvement. Ability to coordinate/collaborate with external quality teams in data gathering, problem solving, risk mitigation, and root cause corrective action.', 'Experience providing root cause analysis and presenting key metrics to Quality and Program leadership. Attention to detail coupled with the ability to quickly learn, assess, and apply new processes/procedures.', 'Also serves as the primary liaison with customer representatives and supports product ""Sell-Off"" and well as responses to customer questions and requests for corrective actions.This requisition may be filled at a higher level based on the requirements below.']",2020-09-24 14:18:52
ADAS Engineer,Technical Professionals Group,3.5 out of 5,"Ann Arbor, MI 48105","['Benefits Package: Medical, Dental Vision, Life Insurance, 401k, Vacation & Holidays', 'Weekly Pay/Direct Deposit', 'Full-time & Home Daily', 'Benefits Package: Medical, Dental Vision, Life Insurance, 401k, Vacation & Holidays', 'Weekly Pay/Direct Deposit', 'Work alongside IVS development engineers to create issue summary from data generated from Automated vehicles.', 'Identifying, documenting, and tracking field performance issues.', 'Providing feedback to the evaluation and design engineering team to help further automate evaluation and analysis processes.', 'Construct, maintain, and upgrade ADS test vehicles.', '4-year degree (or equivalent) in Engineering, Computer Science, or related field.', ""A valid US drivers' license."", 'Experience in ADAS development/evaluation', 'Experience in using Cloud Storage such as Microsoft Azure/AWS.', 'Experience developing applications and data analysis using Python or equivalent.', 'Willingness to travel both domestically and internationally up to 10% of the time.', 'Strong safety mindset. Adhere to strict safety policies.']",2020-09-24 14:18:52
Tier I Network Operations Engineer,"Peerless Network, Inc.",N/A,"Chicago, IL 60606","['401(k)', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Supplemental Pay:', 'Bonus pay', '401(k)', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Bonus pay', 'Temporarily due to COVID-19']",2020-09-24 14:18:52
Industrial Quality Engineer,Zeman Manufacturing Company,N/A,"Lisle, IL 60532","['$73,258.00 per year', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Detail-oriented -- quality and precision-focused', 'Stable -- traditional, stable, strong processes', 'Team-oriented -- cooperative and collaborative', 'Monday to Friday', 'Day shift', '8 hour shift']",2020-09-24 14:18:52
Mechanical Process Engineer,"New England Airfoil Products, Inc",N/A,"Farmington, CT 06032","['Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Professional development assistance', 'relevant: 5 years (Preferred)', ""Bachelor's (Required)"", 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Professional development assistance', 'No']",2020-09-24 14:18:52
SDWAN Engineer,Windstream Communications,3.2 out of 5,Remote,"['Provides technical leadership and direction in area of expertise for engineering staff and Windstream internal teams by enhancing operations and maintaining reliability of systems.', 'Acts as technical consultant within and outside assigned department in area of expertise and promotes positive change in the company’s business strategy through achievement of specific objectives and technological innovation of a practical and profitable nature.', 'Works on problems of diverse scope, which includes technical escalations from customer facing teams and this will require self-motivation to accomplish expected tasks with some on call required', 'Act as escalation point for complex issues related to Security, SD-WAN, and their supporting components.', 'Assist in product roll-out, upgrades, and maintenances of Security and SD-WAN environments.', 'Discussing and developing customer designs that meet Windstream standards or architectural guidelines.', 'Document resolution and conduct appropriate root cause analysis post trouble resolution.', 'Work with Windstream internal teams to audit and optimize customer network solutions to ensure maximum service uptime, survivability and sustainability.', 'Identify and handle upstream communication regarding network service trends, escalation trends, emergent technology and network vulnerabilities both from a provider backbone perspective and a customer solution perspective.', 'Manage small-scale projects and tasks while working closely with Engineering teams or other internal teams as needed.', 'Develop and maintain expert level technical and marketing knowledge for Windstream Security and SD-WAN product sets.', 'Strong technical background, including industry relevant certifications (I.e. CCNA-Cloud, CCP, CCC)', 'BA degree in a technology track or hold equivalent experience of no less than 5 years in a Network Operations, Network Associate or Network Technician Role', 'Proven track record of being able to resolve complex issues and exhibit a genuine enthusiasm for working with network equipment', 'Experience working in a Service Provider environment and familiarity with key concepts including MPLS from a Service Provider standpoint, VoIP Architecture from a Service Provider Standpoint, and SD WAN from a Service Provider Standpoint.', 'Ability to work with Basic Scripting Languages and understanding of SAAS and Cloud Infrastructure is highly desirable', 'Bachelor’s degree in a technical discipline and 4-6 years technical experience with 6 years directly related to the job and 5 years of digital experience.', 'College hours or a college degree may be substituted for some experience as deemed appropriate.']",2020-09-24 14:18:52
Data Engineer - Remote,CyberCoders,3.3 out of 5,"San Francisco, CA","['$150k+)', 'FULLY paid healthcare benefits by employer', '401k safe harbor of 3%', 'Tons of PTO and free days', 'Building large scalable pipelines capable of processing massive quantities of data', 'Building upon existing data architecture in order to support internal and external applications', 'Working to support existing ETL pipelines, real time streams, and data warehouses', 'Designing and implementing process improvements, automating manual processes, and redesigning data infrastructure', 'Using Java, Python, SQL to build on the infrastructure required to optimize the extraction, transformation, and loading of data', 'Working in a remote setting with virtual team meetings on a regular basis', 'Collaborating with business analytics and business intelligence teams to optimize their reports in Tableau/Looker', '5+ years of Java scripting experience', '4+ years of Python scripting experience', '4+ years of SQL database experience', 'Awesome verbal and written communication experience', 'Experience designing relationship databases', 'RESTful API and server-side API integration experience', 'Experience with Cassandra databases', 'Additional NoSQL database experience', 'Experience with Maria databases', 'Salesforce integration experience', 'Awesome starting salary ($150k+)', 'FULLY paid healthcare benefits by employer', '401k safe harbor of 3%', 'Tons of PTO and free days', 'MacBook pro provided', 'Stipend for home workspace', 'Fully stocked snack area', 'Fully catered breakfast and lunch at least every other week', 'Human childcare assistance (fur babies welcomed at your desk)', 'Pet-friendly office', '']",2020-09-24 14:18:52
